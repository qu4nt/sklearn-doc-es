msgid ""
msgstr ""
"Project-Id-Version: scikit-learn\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-03-31 11:24-0400\n"
"PO-Revision-Date: 2021-04-26 15:59\n"
"Last-Translator: \n"
"Language-Team: Spanish\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Crowdin-Project: scikit-learn\n"
"X-Crowdin-Project-ID: 450526\n"
"X-Crowdin-Language: es-ES\n"
"X-Crowdin-File: /main/doc/en/glossary.po\n"
"X-Crowdin-File-ID: 4002\n"
"Language: es_ES\n"

#: ../glossary.rst:7
msgid "Glossary of Common Terms and API Elements"
msgstr "Glosario de Términos Comunes y Elementos de la API"

#: ../glossary.rst:9
msgid "This glossary hopes to definitively represent the tacit and explicit conventions applied in Scikit-learn and its API, while providing a reference for users and contributors. It aims to describe the concepts and either detail their corresponding API or link to other relevant parts of the documentation which do so. By linking to glossary entries from the API Reference and User Guide, we may minimize redundancy and inconsistency."
msgstr "Este glosario espera representar definitivamente las convenciones tácitas y explícitas aplicadas en scikit-learn y su API, proporcionando al mismo tiempo una referencia para los usuarios y colaboradores. Su objetivo es describir los conceptos y detallar su correspondiente API o bien enlazar con otras partes relevantes de la documentación que lo hagan. Al enlazar con las entradas de glosario de la Referencia de la API y la Guía de Usuario, podemos minimizar la redundancia y la inconsistencia."

#: ../glossary.rst:16
msgid "We begin by listing general concepts (and any that didn't fit elsewhere), but more specific sets of related terms are listed below: :ref:`glossary_estimator_types`, :ref:`glossary_target_types`, :ref:`glossary_methods`, :ref:`glossary_parameters`, :ref:`glossary_attributes`, :ref:`glossary_sample_props`."
msgstr "Empezamos por listar los conceptos generales (y cualquiera que no encajaba en otra parte), pero conjuntos más específicos de términos relacionados se listan a continuación: :ref:`glossary_estimator_types`, :ref:`glossary_target_types`, :ref:`glossary_methods`, :ref:`glossary_parameters`, :ref:`glossary_attributes`, :ref:`glossary_sample_props`."

#: ../glossary.rst:23
msgid "General Concepts"
msgstr "Conceptos Generales"

#: ../glossary.rst:26
msgid "1d"
msgstr "1D"

#: ../glossary.rst:27
msgid "1d array"
msgstr "Arreglo 1D"

#: ../glossary.rst:29
msgid "One-dimensional array. A NumPy array whose ``.shape`` has length 1. A vector."
msgstr "Un arreglo unidimensional. Un arreglo NumPy cuyo ``.shape`` tiene longitud 1. Un vector."

#: ../glossary.rst:31
msgid "2d"
msgstr "2D"

#: ../glossary.rst:32
msgid "2d array"
msgstr "Arreglo 2D"

#: ../glossary.rst:34
msgid "Two-dimensional array. A NumPy array whose ``.shape`` has length 2. Often represents a matrix."
msgstr "Un arreglo bidimensional. Un arreglo NumPy cuyo ``.shape`` tiene longitud 2. A menudo representa una matriz."

#: ../glossary.rst:36
msgid "API"
msgstr "API"

#: ../glossary.rst:38
msgid "Refers to both the *specific* interfaces for estimators implemented in Scikit-learn and the *generalized* conventions across types of estimators as described in this glossary and :ref:`overviewed in the contributor documentation <api_overview>`."
msgstr "Se refiere tanto a las interfaces *específicas* para los estimadores implementados en scikit-learn como a las convenciones *generalizadas* entre los tipos de estimadores, tal como se describe en este glosario y :ref:`se resume en la documentación de los colaboradores <api_overview>`."

#: ../glossary.rst:43
msgid "The specific interfaces that constitute Scikit-learn's public API are largely documented in :ref:`api_ref`. However, we less formally consider anything as public API if none of the identifiers required to access it begins with ``_``.  We generally try to maintain :term:`backwards compatibility` for all objects in the public API."
msgstr "Las interfaces específicas que constituyen la API pública de scikit-learn están ampliamente documentadas en :ref:`api_ref`. Sin embargo, consideramos menos formalmente cualquier cosa como API pública si ninguno de los identificadores requeridos para acceder a ella comienza con ``_``.  En general, tratamos de mantener :term:`compatibilidad con versiones anteriores` para todos los objetos en la API pública."

#: ../glossary.rst:49
msgid "Private API, including functions, modules and methods beginning ``_`` are not assured to be stable."
msgstr "La API privada, incluyendo funciones, módulos y métodos que empiezan por ``_`` no tienen garantizada su estabilidad."

#: ../glossary.rst:51
msgid "array-like"
msgstr "array-like"

#: ../glossary.rst:53
msgid "The most common data format for *input* to Scikit-learn estimators and functions, array-like is any type object for which :func:`numpy.asarray` will produce an array of appropriate shape (usually 1 or 2-dimensional) of appropriate dtype (usually numeric)."
msgstr "El formato de datos más común de *entrada* a los estimadores y funciones de Scikit-learn, array-like es cualquier tipo objeto para el que :func:`numpy.asarray` producirá un arreglo de forma apropiada (normalmente de 1 o 2 dimensiones) de dtype apropiado (normalmente numérico)."

#: ../glossary.rst:58
msgid "This includes:"
msgstr "Esto incluye:"

#: ../glossary.rst:60
msgid "a numpy array"
msgstr "un arreglo numpy"

#: ../glossary.rst:61
msgid "a list of numbers"
msgstr "una lista de números"

#: ../glossary.rst:62
msgid "a list of length-k lists of numbers for some fixed length k"
msgstr "una lista de listas de números de longitud-k para alguna longitud fija k"

#: ../glossary.rst:63
msgid "a :class:`pandas.DataFrame` with all columns numeric"
msgstr "una :class:`pandas.DataFrame` con todas las columnas numéricas"

#: ../glossary.rst:64
msgid "a numeric :class:`pandas.Series`"
msgstr "una :class:`pandas.Series` numérica"

#: ../glossary.rst:66
msgid "It excludes:"
msgstr "Excluye:"

#: ../glossary.rst:68
msgid "a :term:`sparse matrix`"
msgstr "una :term:`matriz dispersa`"

#: ../glossary.rst:69
msgid "an iterator"
msgstr "un iterador"

#: ../glossary.rst:70
msgid "a generator"
msgstr "un generador"

#: ../glossary.rst:72
msgid "Note that *output* from scikit-learn estimators and functions (e.g. predictions) should generally be arrays or sparse matrices, or lists thereof (as in multi-output :class:`tree.DecisionTreeClassifier`'s ``predict_proba``). An estimator where ``predict()`` returns a list or a `pandas.Series` is not valid."
msgstr ""

#: ../glossary.rst:77
msgid "attribute"
msgstr "atributo"

#: ../glossary.rst:78
msgid "attributes"
msgstr "atributos"

#: ../glossary.rst:80
msgid "We mostly use attribute to refer to how model information is stored on an estimator during fitting.  Any public attribute stored on an estimator instance is required to begin with an alphabetic character and end in a single underscore if it is set in :term:`fit` or :term:`partial_fit`.  These are what is documented under an estimator's *Attributes* documentation.  The information stored in attributes is usually either: sufficient statistics used for prediction or transformation; :term:`transductive` outputs such as :term:`labels_` or :term:`embedding_`; or diagnostic data, such as :term:`feature_importances_`. Common attributes are listed :ref:`below <glossary_attributes>`."
msgstr ""

#: ../glossary.rst:92
msgid "A public attribute may have the same name as a constructor :term:`parameter`, with a ``_`` appended.  This is used to store a validated or estimated version of the user's input. For example, :class:`decomposition.PCA` is constructed with an ``n_components`` parameter. From this, together with other parameters and the data, PCA estimates the attribute ``n_components_``."
msgstr ""

#: ../glossary.rst:99
msgid "Further private attributes used in prediction/transformation/etc. may also be set when fitting.  These begin with a single underscore and are not assured to be stable for public access."
msgstr ""

#: ../glossary.rst:103
msgid "A public attribute on an estimator instance that does not end in an underscore should be the stored, unmodified value of an ``__init__`` :term:`parameter` of the same name.  Because of this equivalence, these are documented under an estimator's *Parameters* documentation."
msgstr ""

#: ../glossary.rst:107
msgid "backwards compatibility"
msgstr ""

#: ../glossary.rst:109
msgid "We generally try to maintain backward compatibility (i.e. interfaces and behaviors may be extended but not changed or removed) from release to release but this comes with some exceptions:"
msgstr ""

#: ../glossary.rst:115
msgid "Public API only"
msgstr ""

#: ../glossary.rst:114
msgid "The behavior of objects accessed through private identifiers (those beginning ``_``) may be changed arbitrarily between versions."
msgstr ""

#: ../glossary.rst:120
msgid "As documented"
msgstr ""

#: ../glossary.rst:118
msgid "We will generally assume that the users have adhered to the documented parameter types and ranges. If the documentation asks for a list and the user gives a tuple, we do not assure consistent behavior from version to version."
msgstr ""

#: ../glossary.rst:124
msgid "Deprecation"
msgstr ""

#: ../glossary.rst:123
msgid "Behaviors may change following a :term:`deprecation` period (usually two releases long).  Warnings are issued using Python's :mod:`warnings` module."
msgstr ""

#: ../glossary.rst:128
msgid "Keyword arguments"
msgstr ""

#: ../glossary.rst:127
msgid "We may sometimes assume that all optional parameters (other than X and y to :term:`fit` and similar methods) are passed as keyword arguments only and may be positionally reordered."
msgstr ""

#: ../glossary.rst:133
msgid "Bug fixes and enhancements"
msgstr ""

#: ../glossary.rst:131
msgid "Bug fixes and -- less often -- enhancements may change the behavior of estimators, including the predictions of an estimator trained on the same data and :term:`random_state`.  When this happens, we attempt to note it clearly in the changelog."
msgstr ""

#: ../glossary.rst:139
msgid "Serialization"
msgstr ""

#: ../glossary.rst:136
msgid "We make no assurances that pickling an estimator in one version will allow it to be unpickled to an equivalent model in the subsequent version.  (For estimators in the sklearn package, we issue a warning when this unpickling is attempted, even if it may happen to work.)  See :ref:`persistence_limitations`."
msgstr ""

#: ../glossary.rst:145
msgid ":func:`utils.estimator_checks.check_estimator`"
msgstr ""

#: ../glossary.rst:142
msgid "We provide limited backwards compatibility assurances for the estimator checks: we may add extra requirements on estimators tested with this function, usually when these were informally assumed but not formally tested."
msgstr ""

#: ../glossary.rst:147
msgid "Despite this informal contract with our users, the software is provided as is, as stated in the license.  When a release inadvertently introduces changes that are not backward compatible, these are known as software regressions."
msgstr ""

#: ../glossary.rst:151
msgid "callable"
msgstr ""

#: ../glossary.rst:153
msgid "A function, class or an object which implements the ``__call__`` method; anything that returns True when the argument of `callable() <https://docs.python.org/3/library/functions.html#callable>`_."
msgstr ""

#: ../glossary.rst:156
msgid "categorical feature"
msgstr ""

#: ../glossary.rst:158
msgid "A categorical or nominal :term:`feature` is one that has a finite set of discrete values across the population of data. These are commonly represented as columns of integers or strings. Strings will be rejected by most scikit-learn estimators, and integers will be treated as ordinal or count-valued. For the use with most estimators, categorical variables should be one-hot encoded. Notable exceptions include tree-based models such as random forests and gradient boosting models that often work better and faster with integer-coded categorical variables. :class:`~sklearn.preprocessing.OrdinalEncoder` helps encoding string-valued categorical features as ordinal integers, and :class:`~sklearn.preprocessing.OneHotEncoder` can be used to one-hot encode categorical features. See also :ref:`preprocessing_categorical_features` and the `categorical-encoding <https://contrib.scikit-learn.org/categorical-encoding>`_ package for tools related to encoding categorical features."
msgstr ""

#: ../glossary.rst:176
msgid "clone"
msgstr ""

#: ../glossary.rst:177
msgid "cloned"
msgstr ""

#: ../glossary.rst:179
msgid "To copy an :term:`estimator instance` and create a new one with identical :term:`parameters`, but without any fitted :term:`attributes`, using :func:`~sklearn.base.clone`."
msgstr ""

#: ../glossary.rst:183
msgid "When ``fit`` is called, a :term:`meta-estimator` usually clones a wrapped estimator instance before fitting the cloned instance. (Exceptions, for legacy reasons, include :class:`~pipeline.Pipeline` and :class:`~pipeline.FeatureUnion`.)"
msgstr ""

#: ../glossary.rst:189
msgid "If the estimator's `random_state` parameter is an integer (or if the estimator doesn't have a `random_state` parameter), an *exact clone* is returned: the clone and the original estimator will give the exact same results. Otherwise, *statistical clone* is returned: the clone might yield different results from the original estimator. More details can be found in :ref:`randomness`."
msgstr ""

#: ../glossary.rst:195
msgid "common tests"
msgstr ""

#: ../glossary.rst:197
msgid "This refers to the tests run on almost every estimator class in Scikit-learn to check they comply with basic API conventions.  They are available for external use through :func:`utils.estimator_checks.check_estimator`, with most of the implementation in ``sklearn/utils/estimator_checks.py``."
msgstr ""

#: ../glossary.rst:203
msgid "Note: Some exceptions to the common testing regime are currently hard-coded into the library, but we hope to replace this by marking exceptional behaviours on the estimator using semantic :term:`estimator tags`."
msgstr ""

#: ../glossary.rst:207
msgid "deprecation"
msgstr ""

#: ../glossary.rst:209
msgid "We use deprecation to slowly violate our :term:`backwards compatibility` assurances, usually to to:"
msgstr ""

#: ../glossary.rst:212
msgid "change the default value of a parameter; or"
msgstr ""

#: ../glossary.rst:213
msgid "remove a parameter, attribute, method, class, etc."
msgstr ""

#: ../glossary.rst:215
msgid "We will ordinarily issue a warning when a deprecated element is used, although there may be limitations to this.  For instance, we will raise a warning when someone sets a parameter that has been deprecated, but may not when they access that parameter's attribute on the estimator instance."
msgstr ""

#: ../glossary.rst:221
msgid "See the :ref:`Contributors' Guide <contributing_deprecation>`."
msgstr ""

#: ../glossary.rst:222
msgid "dimensionality"
msgstr ""

#: ../glossary.rst:224
msgid "May be used to refer to the number of :term:`features` (i.e. :term:`n_features`), or columns in a 2d feature matrix. Dimensions are, however, also used to refer to the length of a NumPy array's shape, distinguishing a 1d array from a 2d matrix."
msgstr ""

#: ../glossary.rst:228
msgid "docstring"
msgstr ""

#: ../glossary.rst:230
msgid "The embedded documentation for a module, class, function, etc., usually in code as a string at the beginning of the object's definition, and accessible as the object's ``__doc__`` attribute."
msgstr ""

#: ../glossary.rst:234
msgid "We try to adhere to `PEP257 <https://www.python.org/dev/peps/pep-0257/>`_, and follow `NumpyDoc conventions <https://numpydoc.readthedocs.io/en/latest/format.html>`_."
msgstr ""

#: ../glossary.rst:237
msgid "double underscore"
msgstr ""

#: ../glossary.rst:238
msgid "double underscore notation"
msgstr ""

#: ../glossary.rst:240
msgid "When specifying parameter names for nested estimators, ``__`` may be used to separate between parent and child in some contexts. The most common use is when setting parameters through a meta-estimator with :term:`set_params` and hence in specifying a search grid in :ref:`parameter search <grid_search>`. See :term:`parameter`. It is also used in :meth:`pipeline.Pipeline.fit` for passing :term:`sample properties` to the ``fit`` methods of estimators in the pipeline."
msgstr ""

#: ../glossary.rst:248
msgid "dtype"
msgstr ""

#: ../glossary.rst:249
msgid "data type"
msgstr ""

#: ../glossary.rst:251
msgid "NumPy arrays assume a homogeneous data type throughout, available in the ``.dtype`` attribute of an array (or sparse matrix). We generally assume simple data types for scikit-learn data: float or integer. We may support object or string data types for arrays before encoding or vectorizing.  Our estimators do not work with struct arrays, for instance."
msgstr ""

#: ../glossary.rst:258
msgid "Our documentation can sometimes give information about the dtype precision, e.g. `np.int32`, `np.int64`, etc. When the precision is provided, it refers to the NumPy dtype. If an arbitrary precision is used, the documentation will refer to dtype `integer` or `floating`. Note that in this case, the precision can be platform dependent. The `numeric` dtype refers to accepting both `integer` and `floating`."
msgstr ""

#: ../glossary.rst:265
msgid "TODO: Mention efficiency and precision issues; casting policy."
msgstr ""

#: ../glossary.rst:266
msgid "duck typing"
msgstr ""

#: ../glossary.rst:268
msgid "We try to apply `duck typing <https://en.wikipedia.org/wiki/Duck_typing>`_ to determine how to handle some input values (e.g. checking whether a given estimator is a classifier).  That is, we avoid using ``isinstance`` where possible, and rely on the presence or absence of attributes to determine an object's behaviour.  Some nuance is required when following this approach:"
msgstr ""

#: ../glossary.rst:276
msgid "For some estimators, an attribute may only be available once it is :term:`fitted`.  For instance, we cannot a priori determine if :term:`predict_proba` is available in a grid search where the grid includes alternating between a probabilistic and a non-probabilistic predictor in the final step of the pipeline.  In the following, we can only determine if ``clf`` is probabilistic after fitting it on some data::"
msgstr ""

#: ../glossary.rst:289
msgid "This means that we can only check for duck-typed attributes after fitting, and that we must be careful to make :term:`meta-estimators` only present attributes according to the state of the underlying estimator after fitting."
msgstr ""

#: ../glossary.rst:294
msgid "Checking if an attribute is present (using ``hasattr``) is in general just as expensive as getting the attribute (``getattr`` or dot notation).  In some cases, getting the attribute may indeed be expensive (e.g. for some implementations of :term:`feature_importances_`, which may suggest this is an API design flaw).  So code which does ``hasattr`` followed by ``getattr`` should be avoided; ``getattr`` within a try-except block is preferred."
msgstr ""

#: ../glossary.rst:302
msgid "For determining some aspects of an estimator's expectations or support for some feature, we use :term:`estimator tags` instead of duck typing."
msgstr ""

#: ../glossary.rst:305
msgid "early stopping"
msgstr ""

#: ../glossary.rst:307
msgid "This consists in stopping an iterative optimization method before the convergence of the training loss, to avoid over-fitting. This is generally done by monitoring the generalization score on a validation set. When available, it is activated through the parameter ``early_stopping`` or by setting a positive :term:`n_iter_no_change`."
msgstr ""

#: ../glossary.rst:312
msgid "estimator instance"
msgstr ""

#: ../glossary.rst:314
msgid "We sometimes use this terminology to distinguish an :term:`estimator` class from a constructed instance. For example, in the following, ``cls`` is an estimator class, while ``est1`` and ``est2`` are instances::"
msgstr ""

#: ../glossary.rst:322
msgid "examples"
msgstr ""

#: ../glossary.rst:324
msgid "We try to give examples of basic usage for most functions and classes in the API:"
msgstr ""

#: ../glossary.rst:327
msgid "as doctests in their docstrings (i.e. within the ``sklearn/`` library code itself)."
msgstr ""

#: ../glossary.rst:329
msgid "as examples in the :ref:`example gallery <general_examples>` rendered (using `sphinx-gallery <https://sphinx-gallery.readthedocs.io/>`_) from scripts in the ``examples/`` directory, exemplifying key features or parameters of the estimator/function.  These should also be referenced from the User Guide."
msgstr ""

#: ../glossary.rst:335
msgid "sometimes in the :ref:`User Guide <user_guide>` (built from ``doc/``) alongside a technical description of the estimator."
msgstr ""

#: ../glossary.rst:337
msgid "experimental"
msgstr ""

#: ../glossary.rst:339
msgid "An experimental tool is already usable but its public API, such as default parameter values or fitted attributes, is still subject to change in future versions without the usual :term:`deprecation` warning policy."
msgstr ""

#: ../glossary.rst:343
msgid "evaluation metric"
msgstr ""

#: ../glossary.rst:344
msgid "evaluation metrics"
msgstr ""

#: ../glossary.rst:346
msgid "Evaluation metrics give a measure of how well a model performs.  We may use this term specifically to refer to the functions in :mod:`metrics` (disregarding :mod:`metrics.pairwise`), as distinct from the :term:`score` method and the :term:`scoring` API used in cross validation. See :ref:`model_evaluation`."
msgstr ""

#: ../glossary.rst:352
msgid "These functions usually accept a ground truth (or the raw data where the metric evaluates clustering without a ground truth) and a prediction, be it the output of :term:`predict` (``y_pred``), of :term:`predict_proba` (``y_proba``), or of an arbitrary score function including :term:`decision_function` (``y_score``). Functions are usually named to end with ``_score`` if a greater score indicates a better model, and ``_loss`` if a lesser score indicates a better model.  This diversity of interface motivates the scoring API."
msgstr ""

#: ../glossary.rst:362
msgid "Note that some estimators can calculate metrics that are not included in :mod:`metrics` and are estimator-specific, notably model likelihoods."
msgstr ""

#: ../glossary.rst:365
msgid "estimator tags"
msgstr ""

#: ../glossary.rst:367
msgid "A proposed feature (e.g. :issue:`8022`) by which the capabilities of an estimator are described through a set of semantic tags.  This would enable some runtime behaviors based on estimator inspection, but it also allows each estimator to be tested for appropriate invariances while being excepted from other :term:`common tests`."
msgstr ""

#: ../glossary.rst:373
msgid "Some aspects of estimator tags are currently determined through the :term:`duck typing` of methods like ``predict_proba`` and through some special attributes on estimator objects:"
msgstr ""

#: ../glossary.rst:378
msgid "``_estimator_type``"
msgstr ""

#: ../glossary.rst:380
msgid "This string-valued attribute identifies an estimator as being a classifier, regressor, etc. It is set by mixins such as :class:`base.ClassifierMixin`, but needs to be more explicitly adopted on a :term:`meta-estimator`.  Its value should usually be checked by way of a helper such as :func:`base.is_classifier`."
msgstr ""

#: ../glossary.rst:385
msgid "``_pairwise``"
msgstr ""

#: ../glossary.rst:387
msgid "This boolean attribute indicates whether the data (``X``) passed to :func:`fit` and similar methods consists of pairwise measures over samples rather than a feature representation for each sample.  It is usually ``True`` where an estimator has a ``metric`` or ``affinity`` or ``kernel`` parameter with value 'precomputed'. Its primary purpose is that when a :term:`meta-estimator` extracts a sub-sample of data intended for a pairwise estimator, the data needs to be indexed on both axes, while other data is indexed only on the first axis."
msgstr ""

#: ../glossary.rst:399
msgid "The _pairwise attribute is deprecated in 0.24. From 1.1 (renaming of 0.26) onward, the `pairwise` estimator tag should be used instead."
msgstr ""

#: ../glossary.rst:403
msgid "For more detailed info, see :ref:`estimator_tags`."
msgstr ""

#: ../glossary.rst:404
msgid "feature"
msgstr ""

#: ../glossary.rst:405
msgid "features"
msgstr ""

#: ../glossary.rst:406
msgid "feature vector"
msgstr ""

#: ../glossary.rst:408
msgid "In the abstract, a feature is a function (in its mathematical sense) mapping a sampled object to a numeric or categorical quantity. \"Feature\" is also commonly used to refer to these quantities, being the individual elements of a vector representing a sample. In a data matrix, features are represented as columns: each column contains the result of applying a feature function to a set of samples."
msgstr ""

#: ../glossary.rst:415
msgid "Elsewhere features are known as attributes, predictors, regressors, or independent variables."
msgstr ""

#: ../glossary.rst:418
msgid "Nearly all estimators in scikit-learn assume that features are numeric, finite and not missing, even when they have semantically distinct domains and distributions (categorical, ordinal, count-valued, real-valued, interval). See also :term:`categorical feature` and :term:`missing values`."
msgstr ""

#: ../glossary.rst:424
msgid "``n_features`` indicates the number of features in a dataset."
msgstr ""

#: ../glossary.rst:425
msgid "fitting"
msgstr ""

#: ../glossary.rst:427
msgid "Calling :term:`fit` (or :term:`fit_transform`, :term:`fit_predict`, etc.) on an estimator."
msgstr ""

#: ../glossary.rst:429
msgid "fitted"
msgstr ""

#: ../glossary.rst:431
msgid "The state of an estimator after :term:`fitting`."
msgstr ""

#: ../glossary.rst:433
msgid "There is no conventional procedure for checking if an estimator is fitted.  However, an estimator that is not fitted:"
msgstr ""

#: ../glossary.rst:436
msgid "should raise :class:`exceptions.NotFittedError` when a prediction method (:term:`predict`, :term:`transform`, etc.) is called. (:func:`utils.validation.check_is_fitted` is used internally for this purpose.)"
msgstr ""

#: ../glossary.rst:440
msgid "should not have any :term:`attributes` beginning with an alphabetic character and ending with an underscore. (Note that a descriptor for the attribute may still be present on the class, but hasattr should return False)"
msgstr ""

#: ../glossary.rst:444
msgid "function"
msgstr ""

#: ../glossary.rst:446
msgid "We provide ad hoc function interfaces for many algorithms, while :term:`estimator` classes provide a more consistent interface."
msgstr ""

#: ../glossary.rst:449
msgid "In particular, Scikit-learn may provide a function interface that fits a model to some data and returns the learnt model parameters, as in :func:`linear_model.enet_path`.  For transductive models, this also returns the embedding or cluster labels, as in :func:`manifold.spectral_embedding` or :func:`cluster.dbscan`.  Many preprocessing transformers also provide a function interface, akin to calling :term:`fit_transform`, as in :func:`preprocessing.maxabs_scale`.  Users should be careful to avoid :term:`data leakage` when making use of these ``fit_transform``-equivalent functions."
msgstr ""

#: ../glossary.rst:460
msgid "We do not have a strict policy about when to or when not to provide function forms of estimators, but maintainers should consider consistency with existing interfaces, and whether providing a function would lead users astray from best practices (as regards data leakage, etc.)"
msgstr ""

#: ../glossary.rst:465
msgid "gallery"
msgstr ""

#: ../glossary.rst:467
msgid "See :term:`examples`."
msgstr ""

#: ../glossary.rst:468
msgid "hyperparameter"
msgstr ""

#: ../glossary.rst:469
msgid "hyper-parameter"
msgstr ""

#: ../glossary.rst:471
msgid "See :term:`parameter`."
msgstr ""

#: ../glossary.rst:472
msgid "impute"
msgstr ""

#: ../glossary.rst:473
msgid "imputation"
msgstr ""

#: ../glossary.rst:475
msgid "Most machine learning algorithms require that their inputs have no :term:`missing values`, and will not work if this requirement is violated. Algorithms that attempt to fill in (or impute) missing values are referred to as imputation algorithms."
msgstr ""

#: ../glossary.rst:479
msgid "indexable"
msgstr ""

#: ../glossary.rst:481
msgid "An :term:`array-like`, :term:`sparse matrix`, pandas DataFrame or sequence (usually a list)."
msgstr ""

#: ../glossary.rst:483
msgid "induction"
msgstr ""

#: ../glossary.rst:484
msgid "inductive"
msgstr ""

#: ../glossary.rst:486
msgid "Inductive (contrasted with :term:`transductive`) machine learning builds a model of some data that can then be applied to new instances. Most estimators in Scikit-learn are inductive, having :term:`predict` and/or :term:`transform` methods."
msgstr ""

#: ../glossary.rst:490
msgid "joblib"
msgstr ""

#: ../glossary.rst:492
msgid "A Python library (https://joblib.readthedocs.io) used in Scikit-learn to facilite simple parallelism and caching.  Joblib is oriented towards efficiently working with numpy arrays, such as through use of :term:`memory mapping`. See :ref:`parallelism` for more information."
msgstr ""

#: ../glossary.rst:497
msgid "label indicator matrix"
msgstr ""

#: ../glossary.rst:498
msgid "multilabel indicator matrix"
msgstr ""

#: ../glossary.rst:499
msgid "multilabel indicator matrices"
msgstr ""

#: ../glossary.rst:501
msgid "The format used to represent multilabel data, where each row of a 2d array or sparse matrix corresponds to a sample, each column corresponds to a class, and each element is 1 if the sample is labeled with the class and 0 if not."
msgstr ""

#: ../glossary.rst:505
msgid "leakage"
msgstr ""

#: ../glossary.rst:506
msgid "data leakage"
msgstr ""

#: ../glossary.rst:508
msgid "A problem in cross validation where generalization performance can be over-estimated since knowledge of the test data was inadvertently included in training a model.  This is a risk, for instance, when applying a :term:`transformer` to the entirety of a dataset rather than each training portion in a cross validation split."
msgstr ""

#: ../glossary.rst:514
msgid "We aim to provide interfaces (such as :mod:`pipeline` and :mod:`model_selection`) that shield the user from data leakage."
msgstr ""

#: ../glossary.rst:516
msgid "memmapping"
msgstr ""

#: ../glossary.rst:517
msgid "memory map"
msgstr ""

#: ../glossary.rst:518
msgid "memory mapping"
msgstr ""

#: ../glossary.rst:520
msgid "A memory efficiency strategy that keeps data on disk rather than copying it into main memory.  Memory maps can be created for arrays that can be read, written, or both, using :obj:`numpy.memmap`. When using :term:`joblib` to parallelize operations in Scikit-learn, it may automatically memmap large arrays to reduce memory duplication overhead in multiprocessing."
msgstr ""

#: ../glossary.rst:526
msgid "missing values"
msgstr ""

#: ../glossary.rst:528
msgid "Most Scikit-learn estimators do not work with missing values. When they do (e.g. in :class:`impute.SimpleImputer`), NaN is the preferred representation of missing values in float arrays.  If the array has integer dtype, NaN cannot be represented. For this reason, we support specifying another ``missing_values`` value when :term:`imputation` or learning can be performed in integer space. :term:`Unlabeled data <unlabeled data>` is a special case of missing values in the :term:`target`."
msgstr ""

#: ../glossary.rst:536
msgid "``n_features``"
msgstr ""

#: ../glossary.rst:538
msgid "The number of :term:`features`."
msgstr ""

#: ../glossary.rst:539
msgid "``n_outputs``"
msgstr ""

#: ../glossary.rst:541
msgid "The number of :term:`outputs` in the :term:`target`."
msgstr ""

#: ../glossary.rst:542
msgid "``n_samples``"
msgstr ""

#: ../glossary.rst:544
msgid "The number of :term:`samples`."
msgstr ""

#: ../glossary.rst:545
msgid "``n_targets``"
msgstr ""

#: ../glossary.rst:547
msgid "Synonym for :term:`n_outputs`."
msgstr ""

#: ../glossary.rst:548
msgid "narrative docs"
msgstr ""

#: ../glossary.rst:549
msgid "narrative documentation"
msgstr ""

#: ../glossary.rst:551
msgid "An alias for :ref:`User Guide <user_guide>`, i.e. documentation written in ``doc/modules/``. Unlike the :ref:`API reference <api_ref>` provided through docstrings, the User Guide aims to:"
msgstr ""

#: ../glossary.rst:555
msgid "group tools provided by Scikit-learn together thematically or in terms of usage;"
msgstr ""

#: ../glossary.rst:557
msgid "motivate why someone would use each particular tool, often through comparison;"
msgstr ""

#: ../glossary.rst:559
msgid "provide both intuitive and technical descriptions of tools;"
msgstr ""

#: ../glossary.rst:560
msgid "provide or link to :term:`examples` of using key features of a tool."
msgstr ""

#: ../glossary.rst:562
msgid "np"
msgstr ""

#: ../glossary.rst:564
msgid "A shorthand for Numpy due to the conventional import statement::"
msgstr ""

#: ../glossary.rst:567
msgid "online learning"
msgstr ""

#: ../glossary.rst:569
msgid "Where a model is iteratively updated by receiving each batch of ground truth :term:`targets` soon after making predictions on corresponding batch of data.  Intrinsically, the model must be usable for prediction after each batch. See :term:`partial_fit`."
msgstr ""

#: ../glossary.rst:573
msgid "out-of-core"
msgstr ""

#: ../glossary.rst:575
msgid "An efficiency strategy where not all the data is stored in main memory at once, usually by performing learning on batches of data. See :term:`partial_fit`."
msgstr ""

#: ../glossary.rst:578
msgid "outputs"
msgstr ""

#: ../glossary.rst:580
msgid "Individual scalar/categorical variables per sample in the :term:`target`.  For example, in multilabel classification each possible label corresponds to a binary output. Also called *responses*, *tasks* or *targets*. See :term:`multiclass multioutput` and :term:`continuous multioutput`."
msgstr ""

#: ../glossary.rst:585
msgid "pair"
msgstr ""

#: ../glossary.rst:587
msgid "A tuple of length two."
msgstr ""

#: ../glossary.rst:588
msgid "parameter"
msgstr ""

#: ../glossary.rst:589
msgid "parameters"
msgstr ""

#: ../glossary.rst:590
msgid "param"
msgstr ""

#: ../glossary.rst:591
msgid "params"
msgstr ""

#: ../glossary.rst:593
msgid "We mostly use *parameter* to refer to the aspects of an estimator that can be specified in its construction. For example, ``max_depth`` and ``random_state`` are parameters of :class:`RandomForestClassifier`. Parameters to an estimator's constructor are stored unmodified as attributes on the estimator instance, and conventionally start with an alphabetic character and end with an alphanumeric character.  Each estimator's constructor parameters are described in the estimator's docstring."
msgstr ""

#: ../glossary.rst:602
msgid "We do not use parameters in the statistical sense, where parameters are values that specify a model and can be estimated from data. What we call parameters might be what statisticians call hyperparameters to the model: aspects for configuring model structure that are often not directly learnt from data.  However, our parameters are also used to prescribe modeling operations that do not affect the learnt model, such as :term:`n_jobs` for controlling parallelism."
msgstr ""

#: ../glossary.rst:610
msgid "When talking about the parameters of a :term:`meta-estimator`, we may also be including the parameters of the estimators wrapped by the meta-estimator.  Ordinarily, these nested parameters are denoted by using a :term:`double underscore` (``__``) to separate between the estimator-as-parameter and its parameter.  Thus ``clf = BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=3))`` has a deep parameter ``base_estimator__max_depth`` with value ``3``, which is accessible with ``clf.base_estimator.max_depth`` or ``clf.get_params()['base_estimator__max_depth']``."
msgstr ""

#: ../glossary.rst:620
msgid "The list of parameters and their current values can be retrieved from an :term:`estimator instance` using its :term:`get_params` method."
msgstr ""

#: ../glossary.rst:623
msgid "Between construction and fitting, parameters may be modified using :term:`set_params`.  To enable this, parameters are not ordinarily validated or altered when the estimator is constructed, or when each parameter is set. Parameter validation is performed when :term:`fit` is called."
msgstr ""

#: ../glossary.rst:629
msgid "Common parameters are listed :ref:`below <glossary_parameters>`."
msgstr ""

#: ../glossary.rst:630
msgid "pairwise metric"
msgstr ""

#: ../glossary.rst:631
msgid "pairwise metrics"
msgstr ""

#: ../glossary.rst:634
msgid "In its broad sense, a pairwise metric defines a function for measuring similarity or dissimilarity between two samples (with each ordinarily represented as a :term:`feature vector`).  We particularly provide implementations of distance metrics (as well as improper metrics like Cosine Distance) through :func:`metrics.pairwise_distances`, and of kernel functions (a constrained class of similarity functions) in :func:`metrics.pairwise_kernels`.  These can compute pairwise distance matrices that are symmetric and hence store data redundantly."
msgstr ""

#: ../glossary.rst:643
msgid "See also :term:`precomputed` and :term:`metric`."
msgstr ""

#: ../glossary.rst:645
msgid "Note that for most distance metrics, we rely on implementations from :mod:`scipy.spatial.distance`, but may reimplement for efficiency in our context.  The :mod:`neighbors` module also duplicates some metric implementations for integration with efficient binary tree search data structures."
msgstr ""

#: ../glossary.rst:650
msgid "pd"
msgstr ""

#: ../glossary.rst:652
msgid "A shorthand for `Pandas <https://pandas.pydata.org>`_ due to the conventional import statement::"
msgstr ""

#: ../glossary.rst:656
msgid "precomputed"
msgstr ""

#: ../glossary.rst:658
msgid "Where algorithms rely on :term:`pairwise metrics`, and can be computed from pairwise metrics alone, we often allow the user to specify that the :term:`X` provided is already in the pairwise (dis)similarity space, rather than in a feature space.  That is, when passed to :term:`fit`, it is a square, symmetric matrix, with each vector indicating (dis)similarity to every sample, and when passed to prediction/transformation methods, each row corresponds to a testing sample and each column to a training sample."
msgstr ""

#: ../glossary.rst:667
msgid "Use of precomputed X is usually indicated by setting a ``metric``, ``affinity`` or ``kernel`` parameter to the string 'precomputed'. If this is the case, then the estimator should set the `pairwise` estimator tag as True."
msgstr ""

#: ../glossary.rst:671
msgid "rectangular"
msgstr ""

#: ../glossary.rst:673
msgid "Data that can be represented as a matrix with :term:`samples` on the first axis and a fixed, finite set of :term:`features` on the second is called rectangular."
msgstr ""

#: ../glossary.rst:677
msgid "This term excludes samples with non-vectorial structures, such as text, an image of arbitrary size, a time series of arbitrary length, a set of vectors, etc. The purpose of a :term:`vectorizer` is to produce rectangular forms of such data."
msgstr ""

#: ../glossary.rst:681
msgid "sample"
msgstr ""

#: ../glossary.rst:682
msgid "samples"
msgstr ""

#: ../glossary.rst:684
msgid "We usually use this term as a noun to indicate a single feature vector. Elsewhere a sample is called an instance, data point, or observation. ``n_samples`` indicates the number of samples in a dataset, being the number of rows in a data array :term:`X`."
msgstr ""

#: ../glossary.rst:688
msgid "sample property"
msgstr ""

#: ../glossary.rst:689
msgid "sample properties"
msgstr ""

#: ../glossary.rst:691
msgid "A sample property is data for each sample (e.g. an array of length n_samples) passed to an estimator method or a similar function, alongside but distinct from the :term:`features` (``X``) and :term:`target` (``y``). The most prominent example is :term:`sample_weight`; see others at :ref:`glossary_sample_props`."
msgstr ""

#: ../glossary.rst:697
msgid "As of version 0.19 we do not have a consistent approach to handling sample properties and their routing in :term:`meta-estimators`, though a ``fit_params`` parameter is often used."
msgstr ""

#: ../glossary.rst:700
msgid "scikit-learn-contrib"
msgstr ""

#: ../glossary.rst:702
msgid "A venue for publishing Scikit-learn-compatible libraries that are broadly authorized by the core developers and the contrib community, but not maintained by the core developer team. See https://scikit-learn-contrib.github.io."
msgstr ""

#: ../glossary.rst:706
msgid "scikit-learn enhancement proposals"
msgstr ""

#: ../glossary.rst:707
msgid "SLEP"
msgstr ""

#: ../glossary.rst:708
msgid "SLEPs"
msgstr ""

#: ../glossary.rst:710
msgid "Changes to the API principles and changes to dependencies or supported versions happen via a :ref:`SLEP <slep>` and follows the decision-making process outlined in :ref:`governance`. For all votes, a proposal must have been made public and discussed before the vote. Such a proposal must be a consolidated document, in the form of a ‘Scikit-Learn Enhancement Proposal’ (SLEP), rather than a long discussion on an issue. A SLEP must be submitted as a pull-request to `enhancement proposals <https://scikit-learn-enhancement-proposals.readthedocs.io>`_ using the `SLEP template <https://scikit-learn-enhancement-proposals.readthedocs.io/en/latest/slep_template.html>`_."
msgstr ""

#: ../glossary.rst:719
msgid "semi-supervised"
msgstr ""

#: ../glossary.rst:720
msgid "semi-supervised learning"
msgstr ""

#: ../glossary.rst:721
msgid "semisupervised"
msgstr ""

#: ../glossary.rst:723
msgid "Learning where the expected prediction (label or ground truth) is only available for some samples provided as training data when :term:`fitting` the model.  We conventionally apply the label ``-1`` to :term:`unlabeled` samples in semi-supervised classification."
msgstr ""

#: ../glossary.rst:727
msgid "sparse matrix"
msgstr ""

#: ../glossary.rst:728
msgid "sparse graph"
msgstr ""

#: ../glossary.rst:730
msgid "A representation of two-dimensional numeric data that is more memory efficient the corresponding dense numpy array where almost all elements are zero. We use the :mod:`scipy.sparse` framework, which provides several underlying sparse data representations, or *formats*. Some formats are more efficient than others for particular tasks, and when a particular format provides especial benefit, we try to document this fact in Scikit-learn parameter descriptions."
msgstr ""

#: ../glossary.rst:738
msgid "Some sparse matrix formats (notably CSR, CSC, COO and LIL) distinguish between *implicit* and *explicit* zeros. Explicit zeros are stored (i.e. they consume memory in a ``data`` array) in the data structure, while implicit zeros correspond to every element not otherwise defined in explicit storage."
msgstr ""

#: ../glossary.rst:744
msgid "Two semantics for sparse matrices are used in Scikit-learn:"
msgstr ""

#: ../glossary.rst:750
msgid "matrix semantics"
msgstr ""

#: ../glossary.rst:747
msgid "The sparse matrix is interpreted as an array with implicit and explicit zeros being interpreted as the number 0.  This is the interpretation most often adopted, e.g. when sparse matrices are used for feature matrices or :term:`multilabel indicator matrices`."
msgstr ""

#: ../glossary.rst:761
msgid "graph semantics"
msgstr ""

#: ../glossary.rst:753
msgid "As with :mod:`scipy.sparse.csgraph`, explicit zeros are interpreted as the number 0, but implicit zeros indicate a masked or absent value, such as the absence of an edge between two vertices of a graph, where an explicit value indicates an edge's weight. This interpretation is adopted to represent connectivity in clustering, in representations of nearest neighborhoods (e.g. :func:`neighbors.kneighbors_graph`), and for precomputed distance representation where only distances in the neighborhood of each point are required."
msgstr ""

#: ../glossary.rst:763
msgid "When working with sparse matrices, we assume that it is sparse for a good reason, and avoid writing code that densifies a user-provided sparse matrix, instead maintaining sparsity or raising an error if not possible (i.e. if an estimator does not / cannot support sparse matrices)."
msgstr ""

#: ../glossary.rst:768
msgid "supervised"
msgstr ""

#: ../glossary.rst:769
msgid "supervised learning"
msgstr ""

#: ../glossary.rst:771
msgid "Learning where the expected prediction (label or ground truth) is available for each sample when :term:`fitting` the model, provided as :term:`y`.  This is the approach taken in a :term:`classifier` or :term:`regressor` among other estimators."
msgstr ""

#: ../glossary.rst:775
msgid "target"
msgstr ""

#: ../glossary.rst:776
msgid "targets"
msgstr ""

#: ../glossary.rst:778
msgid "The *dependent variable* in :term:`supervised` (and :term:`semisupervised`) learning, passed as :term:`y` to an estimator's :term:`fit` method.  Also known as *dependent variable*, *outcome variable*, *response variable*, *ground truth* or *label*. Scikit-learn works with targets that have minimal structure: a class from a finite set, a finite real-valued number, multiple classes, or multiple numbers. See :ref:`glossary_target_types`."
msgstr ""

#: ../glossary.rst:785
msgid "transduction"
msgstr ""

#: ../glossary.rst:786
msgid "transductive"
msgstr ""

#: ../glossary.rst:788
msgid "A transductive (contrasted with :term:`inductive`) machine learning method is designed to model a specific dataset, but not to apply that model to unseen data.  Examples include :class:`manifold.TSNE`, :class:`cluster.AgglomerativeClustering` and :class:`neighbors.LocalOutlierFactor`."
msgstr ""

#: ../glossary.rst:793
msgid "unlabeled"
msgstr ""

#: ../glossary.rst:794
msgid "unlabeled data"
msgstr ""

#: ../glossary.rst:796
msgid "Samples with an unknown ground truth when fitting; equivalently, :term:`missing values` in the :term:`target`.  See also :term:`semisupervised` and :term:`unsupervised` learning."
msgstr ""

#: ../glossary.rst:799
msgid "unsupervised"
msgstr ""

#: ../glossary.rst:800
msgid "unsupervised learning"
msgstr ""

#: ../glossary.rst:802
msgid "Learning where the expected prediction (label or ground truth) is not available for each sample when :term:`fitting` the model, as in :term:`clusterers` and :term:`outlier detectors`.  Unsupervised estimators ignore any :term:`y` passed to :term:`fit`."
msgstr ""

#: ../glossary.rst:810
msgid "Class APIs and Estimator Types"
msgstr ""

#: ../glossary.rst:813 ../glossary.rst:1334
msgid "classifier"
msgstr ""

#: ../glossary.rst:814
msgid "classifiers"
msgstr ""

#: ../glossary.rst:816
msgid "A :term:`supervised` (or :term:`semi-supervised`) :term:`predictor` with a finite set of discrete possible output values."
msgstr ""

#: ../glossary.rst:819
msgid "A classifier supports modeling some of :term:`binary`, :term:`multiclass`, :term:`multilabel`, or :term:`multiclass multioutput` targets.  Within scikit-learn, all classifiers support multi-class classification, defaulting to using a one-vs-rest strategy over the binary classification problem."
msgstr ""

#: ../glossary.rst:825
msgid "Classifiers must store a :term:`classes_` attribute after fitting, and usually inherit from :class:`base.ClassifierMixin`, which sets their :term:`_estimator_type` attribute."
msgstr ""

#: ../glossary.rst:829
msgid "A classifier can be distinguished from other estimators with :func:`~base.is_classifier`."
msgstr ""

#: ../glossary.rst:832
msgid "A classifier must implement:"
msgstr ""

#: ../glossary.rst:834 ../glossary.rst:851 ../glossary.rst:894
#: ../glossary.rst:942 ../glossary.rst:972
msgid ":term:`fit`"
msgstr ""

#: ../glossary.rst:835 ../glossary.rst:973
msgid ":term:`predict`"
msgstr ""

#: ../glossary.rst:836 ../glossary.rst:974
msgid ":term:`score`"
msgstr ""

#: ../glossary.rst:838
msgid "It may also be appropriate to implement :term:`decision_function`, :term:`predict_proba` and :term:`predict_log_proba`."
msgstr ""

#: ../glossary.rst:840 ../glossary.rst:1340
msgid "clusterer"
msgstr ""

#: ../glossary.rst:841
msgid "clusterers"
msgstr ""

#: ../glossary.rst:843
msgid "A :term:`unsupervised` :term:`predictor` with a finite set of discrete output values."
msgstr ""

#: ../glossary.rst:846
msgid "A clusterer usually stores :term:`labels_` after fitting, and must do so if it is :term:`transductive`."
msgstr ""

#: ../glossary.rst:849
msgid "A clusterer must implement:"
msgstr ""

#: ../glossary.rst:852 ../glossary.rst:943
msgid ":term:`fit_predict` if :term:`transductive`"
msgstr ""

#: ../glossary.rst:853 ../glossary.rst:944
msgid ":term:`predict` if :term:`inductive`"
msgstr ""

#: ../glossary.rst:854
msgid "density estimator"
msgstr ""

#: ../glossary.rst:856 ../glossary.rst:1391 ../glossary.rst:1498
msgid "TODO"
msgstr ""

#: ../glossary.rst:857
msgid "estimator"
msgstr ""

#: ../glossary.rst:858
msgid "estimators"
msgstr ""

#: ../glossary.rst:860
msgid "An object which manages the estimation and decoding of a model. The model is estimated as a deterministic function of:"
msgstr ""

#: ../glossary.rst:863
msgid ":term:`parameters` provided in object construction or with :term:`set_params`;"
msgstr ""

#: ../glossary.rst:865
msgid "the global :mod:`numpy.random` random state if the estimator's :term:`random_state` parameter is set to None; and"
msgstr ""

#: ../glossary.rst:867
msgid "any data or :term:`sample properties` passed to the most recent call to :term:`fit`, :term:`fit_transform` or :term:`fit_predict`, or data similarly passed in a sequence of calls to :term:`partial_fit`."
msgstr ""

#: ../glossary.rst:872
msgid "The estimated model is stored in public and private :term:`attributes` on the estimator instance, facilitating decoding through prediction and transformation methods."
msgstr ""

#: ../glossary.rst:876
msgid "Estimators must provide a :term:`fit` method, and should provide :term:`set_params` and :term:`get_params`, although these are usually provided by inheritance from :class:`base.BaseEstimator`."
msgstr ""

#: ../glossary.rst:880
msgid "The core functionality of some estimators may also be available as a :term:`function`."
msgstr ""

#: ../glossary.rst:882
msgid "feature extractor"
msgstr ""

#: ../glossary.rst:883
msgid "feature extractors"
msgstr ""

#: ../glossary.rst:885
msgid "A :term:`transformer` which takes input where each sample is not represented as an :term:`array-like` object of fixed length, and produces an :term:`array-like` object of :term:`features` for each sample (and thus a 2-dimensional array-like for a set of samples).  In other words, it (lossily) maps a non-rectangular data representation into :term:`rectangular` data."
msgstr ""

#: ../glossary.rst:892
msgid "Feature extractors must implement at least:"
msgstr ""

#: ../glossary.rst:895
msgid ":term:`transform`"
msgstr ""

#: ../glossary.rst:896
msgid ":term:`get_feature_names`"
msgstr ""

#: ../glossary.rst:897
msgid "meta-estimator"
msgstr ""

#: ../glossary.rst:898
msgid "meta-estimators"
msgstr ""

#: ../glossary.rst:899
msgid "metaestimator"
msgstr ""

#: ../glossary.rst:900
msgid "metaestimators"
msgstr ""

#: ../glossary.rst:902
msgid "An :term:`estimator` which takes another estimator as a parameter. Examples include :class:`pipeline.Pipeline`, :class:`model_selection.GridSearchCV`, :class:`feature_selection.SelectFromModel` and :class:`ensemble.BaggingClassifier`."
msgstr ""

#: ../glossary.rst:908
msgid "In a meta-estimator's :term:`fit` method, any contained estimators should be :term:`cloned` before they are fit (although FIXME: Pipeline and FeatureUnion do not do this currently). An exception to this is that an estimator may explicitly document that it accepts a pre-fitted estimator (e.g. using ``prefit=True`` in :class:`feature_selection.SelectFromModel`). One known issue with this is that the pre-fitted estimator will lose its model if the meta-estimator is cloned.  A meta-estimator should have ``fit`` called before prediction, even if all contained estimators are pre-fitted."
msgstr ""

#: ../glossary.rst:918
msgid "In cases where a meta-estimator's primary behaviors (e.g. :term:`predict` or :term:`transform` implementation) are functions of prediction/transformation methods of the provided *base estimator* (or multiple base estimators), a meta-estimator should provide at least the standard methods provided by the base estimator.  It may not be possible to identify which methods are provided by the underlying estimator until the meta-estimator has been :term:`fitted` (see also :term:`duck typing`), for which :func:`utils.metaestimators.if_delegate_has_method` may help.  It should also provide (or modify) the :term:`estimator tags` and :term:`classes_` attribute provided by the base estimator."
msgstr ""

#: ../glossary.rst:930
msgid "Meta-estimators should be careful to validate data as minimally as possible before passing it to an underlying estimator. This saves computation time, and may, for instance, allow the underlying estimator to easily work with data that is not :term:`rectangular`."
msgstr ""

#: ../glossary.rst:934 ../glossary.rst:1344
msgid "outlier detector"
msgstr ""

#: ../glossary.rst:935
msgid "outlier detectors"
msgstr ""

#: ../glossary.rst:937
msgid "An :term:`unsupervised` binary :term:`predictor` which models the distinction between core and outlying samples."
msgstr ""

#: ../glossary.rst:940
msgid "Outlier detectors must implement:"
msgstr ""

#: ../glossary.rst:946
msgid "Inductive outlier detectors may also implement :term:`decision_function` to give a normalized inlier score where outliers have score below 0.  :term:`score_samples` may provide an unnormalized score per sample."
msgstr ""

#: ../glossary.rst:950
msgid "predictor"
msgstr ""

#: ../glossary.rst:951
msgid "predictors"
msgstr ""

#: ../glossary.rst:953
msgid "An :term:`estimator` supporting :term:`predict` and/or :term:`fit_predict`. This encompasses :term:`classifier`, :term:`regressor`, :term:`outlier detector` and :term:`clusterer`."
msgstr ""

#: ../glossary.rst:957
msgid "In statistics, \"predictors\" refers to :term:`features`."
msgstr ""

#: ../glossary.rst:958 ../glossary.rst:1352
msgid "regressor"
msgstr ""

#: ../glossary.rst:959
msgid "regressors"
msgstr ""

#: ../glossary.rst:961
msgid "A :term:`supervised` (or :term:`semi-supervised`) :term:`predictor` with :term:`continuous` output values."
msgstr ""

#: ../glossary.rst:964
msgid "Regressors usually inherit from :class:`base.RegressorMixin`, which sets their :term:`_estimator_type` attribute."
msgstr ""

#: ../glossary.rst:967
msgid "A regressor can be distinguished from other estimators with :func:`~base.is_regressor`."
msgstr ""

#: ../glossary.rst:970
msgid "A regressor must implement:"
msgstr ""

#: ../glossary.rst:975
msgid "transformer"
msgstr ""

#: ../glossary.rst:976
msgid "transformers"
msgstr ""

#: ../glossary.rst:978
msgid "An estimator supporting :term:`transform` and/or :term:`fit_transform`. A purely :term:`transductive` transformer, such as :class:`manifold.TSNE`, may not implement ``transform``."
msgstr ""

#: ../glossary.rst:981
msgid "vectorizer"
msgstr ""

#: ../glossary.rst:982
msgid "vectorizers"
msgstr ""

#: ../glossary.rst:984
msgid "See :term:`feature extractor`."
msgstr ""

#: ../glossary.rst:986
msgid "There are further APIs specifically related to a small family of estimators, such as:"
msgstr ""

#: ../glossary.rst:990
msgid "cross-validation splitter"
msgstr ""

#: ../glossary.rst:991
msgid "CV splitter"
msgstr ""

#: ../glossary.rst:992
msgid "cross-validation generator"
msgstr ""

#: ../glossary.rst:994
msgid "A non-estimator family of classes used to split a dataset into a sequence of train and test portions (see :ref:`cross_validation`), by providing :term:`split` and :term:`get_n_splits` methods. Note that unlike estimators, these do not have :term:`fit` methods and do not provide :term:`set_params` or :term:`get_params`. Parameter validation may be performed in ``__init__``."
msgstr ""

#: ../glossary.rst:1000
msgid "cross-validation estimator"
msgstr ""

#: ../glossary.rst:1002
msgid "An estimator that has built-in cross-validation capabilities to automatically select the best hyper-parameters (see the :ref:`User Guide <grid_search>`). Some example of cross-validation estimators are :class:`ElasticNetCV <linear_model.ElasticNetCV>` and :class:`LogisticRegressionCV <linear_model.LogisticRegressionCV>`. Cross-validation estimators are named `EstimatorCV` and tend to be roughly equivalent to `GridSearchCV(Estimator(), ...)`. The advantage of using a cross-validation estimator over the canonical :term:`estimator` class along with :ref:`grid search <grid_search>` is that they can take advantage of warm-starting by reusing precomputed results in the previous steps of the cross-validation process. This generally leads to speed improvements. An exception is the :class:`RidgeCV <linear_model.RidgeCV>` class, which can instead perform efficient Leave-One-Out CV."
msgstr ""

#: ../glossary.rst:1016
msgid "scorer"
msgstr ""

#: ../glossary.rst:1018
msgid "A non-estimator callable object which evaluates an estimator on given test data, returning a number. Unlike :term:`evaluation metrics`, a greater returned number must correspond with a *better* score. See :ref:`scoring_parameter`."
msgstr ""

#: ../glossary.rst:1023
msgid "Further examples:"
msgstr ""

#: ../glossary.rst:1025
msgid ":class:`neighbors.DistanceMetric`"
msgstr ""

#: ../glossary.rst:1026
msgid ":class:`gaussian_process.kernels.Kernel`"
msgstr ""

#: ../glossary.rst:1027
msgid "``tree.Criterion``"
msgstr ""

#: ../glossary.rst:1032
msgid "Target Types"
msgstr ""

#: ../glossary.rst:1035
msgid "binary"
msgstr ""

#: ../glossary.rst:1037
msgid "A classification problem consisting of two classes.  A binary target may  be represented as for a :term:`multiclass` problem but with only two labels.  A binary decision function is represented as a 1d array."
msgstr ""

#: ../glossary.rst:1041
msgid "Semantically, one class is often considered the \"positive\" class. Unless otherwise specified (e.g. using :term:`pos_label` in :term:`evaluation metrics`), we consider the class label with the greater value (numerically or lexicographically) as the positive class: of labels [0, 1], 1 is the positive class; of [1, 2], 2 is the positive class; of ['no', 'yes'], 'yes' is the positive class; of ['no', 'YES'], 'no' is the positive class.  This affects the output of :term:`decision_function`, for instance."
msgstr ""

#: ../glossary.rst:1050
msgid "Note that a dataset sampled from a multiclass ``y`` or a continuous ``y`` may appear to be binary."
msgstr ""

#: ../glossary.rst:1053
msgid ":func:`~utils.multiclass.type_of_target` will return 'binary' for binary input, or a similar array with only a single class present."
msgstr ""

#: ../glossary.rst:1055
msgid "continuous"
msgstr ""

#: ../glossary.rst:1057
msgid "A regression problem where each sample's target is a finite floating point number represented as a 1-dimensional array of floats (or sometimes ints)."
msgstr ""

#: ../glossary.rst:1061
msgid ":func:`~utils.multiclass.type_of_target` will return 'continuous' for continuous input, but if the data is all integers, it will be identified as 'multiclass'."
msgstr ""

#: ../glossary.rst:1064
msgid "continuous multioutput"
msgstr ""

#: ../glossary.rst:1065
msgid "continuous multi-output"
msgstr ""

#: ../glossary.rst:1066
msgid "multioutput continuous"
msgstr ""

#: ../glossary.rst:1067
msgid "multi-output continuous"
msgstr ""

#: ../glossary.rst:1069
msgid "A regression problem where each sample's target consists of ``n_outputs`` :term:`outputs`, each one a finite floating point number, for a fixed int ``n_outputs > 1`` in a particular dataset."
msgstr ""

#: ../glossary.rst:1073
msgid "Continuous multioutput targets are represented as multiple :term:`continuous` targets, horizontally stacked into an array of shape ``(n_samples, n_outputs)``."
msgstr ""

#: ../glossary.rst:1077
msgid ":func:`~utils.multiclass.type_of_target` will return 'continuous-multioutput' for continuous multioutput input, but if the data is all integers, it will be identified as 'multiclass-multioutput'."
msgstr ""

#: ../glossary.rst:1081
msgid "multiclass"
msgstr ""

#: ../glossary.rst:1082
msgid "multi-class"
msgstr ""

#: ../glossary.rst:1084
msgid "A classification problem consisting of more than two classes.  A multiclass target may be represented as a 1-dimensional array of strings or integers.  A 2d column vector of integers (i.e. a single output in :term:`multioutput` terms) is also accepted."
msgstr ""

#: ../glossary.rst:1089
msgid "We do not officially support other orderable, hashable objects as class labels, even if estimators may happen to work when given classification targets of such type."
msgstr ""

#: ../glossary.rst:1093
msgid "For semi-supervised classification, :term:`unlabeled` samples should have the special label -1 in ``y``."
msgstr ""

#: ../glossary.rst:1096
msgid "Within sckit-learn, all estimators supporting binary classification also support multiclass classification, using One-vs-Rest by default."
msgstr ""

#: ../glossary.rst:1099
msgid "A :class:`preprocessing.LabelEncoder` helps to canonicalize multiclass targets as integers."
msgstr ""

#: ../glossary.rst:1102
msgid ":func:`~utils.multiclass.type_of_target` will return 'multiclass' for multiclass input. The user may also want to handle 'binary' input identically to 'multiclass'."
msgstr ""

#: ../glossary.rst:1105
msgid "multiclass multioutput"
msgstr ""

#: ../glossary.rst:1106
msgid "multi-class multi-output"
msgstr ""

#: ../glossary.rst:1107
msgid "multioutput multiclass"
msgstr ""

#: ../glossary.rst:1108
msgid "multi-output multi-class"
msgstr ""

#: ../glossary.rst:1110
msgid "A classification problem where each sample's target consists of ``n_outputs`` :term:`outputs`, each a class label, for a fixed int ``n_outputs > 1`` in a particular dataset.  Each output has a fixed set of available classes, and each sample is labeled with a class for each output. An output may be binary or multiclass, and in the case where all outputs are binary, the target is :term:`multilabel`."
msgstr ""

#: ../glossary.rst:1118
msgid "Multiclass multioutput targets are represented as multiple :term:`multiclass` targets, horizontally stacked into an array of shape ``(n_samples, n_outputs)``."
msgstr ""

#: ../glossary.rst:1122
msgid "XXX: For simplicity, we may not always support string class labels for multiclass multioutput, and integer class labels should be used."
msgstr ""

#: ../glossary.rst:1125
msgid ":mod:`multioutput` provides estimators which estimate multi-output problems using multiple single-output estimators.  This may not fully account for dependencies among the different outputs, which methods natively handling the multioutput case (e.g. decision trees, nearest neighbors, neural networks) may do better."
msgstr ""

#: ../glossary.rst:1131
msgid ":func:`~utils.multiclass.type_of_target` will return 'multiclass-multioutput' for multiclass multioutput input."
msgstr ""

#: ../glossary.rst:1133
msgid "multilabel"
msgstr ""

#: ../glossary.rst:1134
msgid "multi-label"
msgstr ""

#: ../glossary.rst:1136
msgid "A :term:`multiclass multioutput` target where each output is :term:`binary`.  This may be represented as a 2d (dense) array or sparse matrix of integers, such that each column is a separate binary target, where positive labels are indicated with 1 and negative labels are usually -1 or 0.  Sparse multilabel targets are not supported everywhere that dense multilabel targets are supported."
msgstr ""

#: ../glossary.rst:1143
msgid "Semantically, a multilabel target can be thought of as a set of labels for each sample.  While not used internally, :class:`preprocessing.MultiLabelBinarizer` is provided as a utility to convert from a list of sets representation to a 2d array or sparse matrix. One-hot encoding a multiclass target with :class:`preprocessing.LabelBinarizer` turns it into a multilabel problem."
msgstr ""

#: ../glossary.rst:1151
msgid ":func:`~utils.multiclass.type_of_target` will return 'multilabel-indicator' for multilabel input, whether sparse or dense."
msgstr ""

#: ../glossary.rst:1153
msgid "multioutput"
msgstr ""

#: ../glossary.rst:1154
msgid "multi-output"
msgstr ""

#: ../glossary.rst:1156
msgid "A target where each sample has multiple classification/regression labels. See :term:`multiclass multioutput` and :term:`continuous multioutput`. We do not currently support modelling mixed classification and regression targets."
msgstr ""

#: ../glossary.rst:1164
msgid "Methods"
msgstr ""

#: ../glossary.rst:1167
msgid "``decision_function``"
msgstr ""

#: ../glossary.rst:1169
msgid "In a fitted :term:`classifier` or :term:`outlier detector`, predicts a \"soft\" score for each sample in relation to each class, rather than the \"hard\" categorical prediction produced by :term:`predict`.  Its input is usually only some observed data, :term:`X`."
msgstr ""

#: ../glossary.rst:1174 ../glossary.rst:1324 ../glossary.rst:1363
#: ../glossary.rst:1384 ../glossary.rst:1393 ../glossary.rst:1420
msgid "If the estimator was not already :term:`fitted`, calling this method should raise a :class:`exceptions.NotFittedError`."
msgstr ""

#: ../glossary.rst:1177 ../glossary.rst:1327
msgid "Output conventions:"
msgstr ""

#: ../glossary.rst:1181
msgid "binary classification"
msgstr ""

#: ../glossary.rst:1180
msgid "A 1-dimensional array, where values strictly greater than zero indicate the positive class (i.e. the last class in :term:`classes_`)."
msgstr ""

#: ../glossary.rst:1185
msgid "multiclass classification"
msgstr ""

#: ../glossary.rst:1184
msgid "A 2-dimensional array, where the row-wise arg-maximum is the predicted class.  Columns are ordered according to :term:`classes_`."
msgstr ""

#: ../glossary.rst:1198
msgid "multilabel classification"
msgstr ""

#: ../glossary.rst:1188
msgid "Scikit-learn is inconsistent in its representation of multilabel decision functions.  Some estimators represent it like multiclass multioutput, i.e. a list of 2d arrays, each with two columns. Others represent it with a single 2d array, whose columns correspond to the individual binary classification decisions. The latter representation is ambiguously identical to the multiclass classification format, though its semantics differ: it should be interpreted, like in the binary case, by thresholding at 0."
msgstr ""

#: ../glossary.rst:1197
msgid "TODO: `This gist <https://gist.github.com/jnothman/4807b1b0266613c20ba4d1f88d0f8cf5>`_ highlights the use of the different formats for multilabel."
msgstr ""

#: ../glossary.rst:1201
msgid "multioutput classification"
msgstr ""

#: ../glossary.rst:1201
msgid "A list of 2d arrays, corresponding to each multiclass decision function."
msgstr ""

#: ../glossary.rst:1205
msgid "outlier detection"
msgstr ""

#: ../glossary.rst:1204
msgid "A 1-dimensional array, where a value greater than or equal to zero indicates an inlier."
msgstr ""

#: ../glossary.rst:1206
msgid "``fit``"
msgstr ""

#: ../glossary.rst:1208
msgid "The ``fit`` method is provided on every estimator. It usually takes some :term:`samples` ``X``, :term:`targets` ``y`` if the model is supervised, and potentially other :term:`sample properties` such as :term:`sample_weight`.  It should:"
msgstr ""

#: ../glossary.rst:1213
msgid "clear any prior :term:`attributes` stored on the estimator, unless :term:`warm_start` is used;"
msgstr ""

#: ../glossary.rst:1215
msgid "validate and interpret any :term:`parameters`, ideally raising an error if invalid;"
msgstr ""

#: ../glossary.rst:1217
msgid "validate the input data;"
msgstr ""

#: ../glossary.rst:1218
msgid "estimate and store model attributes from the estimated parameters and provided data; and"
msgstr ""

#: ../glossary.rst:1220
msgid "return the now :term:`fitted` estimator to facilitate method chaining."
msgstr ""

#: ../glossary.rst:1223
msgid ":ref:`glossary_target_types` describes possible formats for ``y``."
msgstr ""

#: ../glossary.rst:1224
msgid "``fit_predict``"
msgstr ""

#: ../glossary.rst:1226
msgid "Used especially for :term:`unsupervised`, :term:`transductive` estimators, this fits the model and returns the predictions (similar to :term:`predict`) on the training data. In clusterers, these predictions are also stored in the :term:`labels_` attribute, and the output of ``.fit_predict(X)`` is usually equivalent to ``.fit(X).predict(X)``. The parameters to ``fit_predict`` are the same as those to ``fit``."
msgstr ""

#: ../glossary.rst:1232
msgid "``fit_transform``"
msgstr ""

#: ../glossary.rst:1234
msgid "A method on :term:`transformers` which fits the estimator and returns the transformed training data. It takes parameters as in :term:`fit` and its output should have the same shape as calling ``.fit(X, ...).transform(X)``. There are nonetheless rare cases where ``.fit_transform(X, ...)`` and ``.fit(X, ...).transform(X)`` do not return the same value, wherein training data needs to be handled differently (due to model blending in stacked ensembles, for instance; such cases should be clearly documented). :term:`Transductive <transductive>` transformers may also provide ``fit_transform`` but not :term:`transform`."
msgstr ""

#: ../glossary.rst:1245
msgid "One reason to implement ``fit_transform`` is that performing ``fit`` and ``transform`` separately would be less efficient than together. :class:`base.TransformerMixin` provides a default implementation, providing a consistent interface across transformers where ``fit_transform`` is or is not specialized."
msgstr ""

#: ../glossary.rst:1251
msgid "In :term:`inductive` learning -- where the goal is to learn a generalized model that can be applied to new data -- users should be careful not to apply ``fit_transform`` to the entirety of a dataset (i.e. training and test data together) before further modelling, as this results in :term:`data leakage`."
msgstr ""

#: ../glossary.rst:1256
msgid "``get_feature_names``"
msgstr ""

#: ../glossary.rst:1258
msgid "Primarily for :term:`feature extractors`, but also used for other transformers to provide string names for each column in the output of the estimator's :term:`transform` method.  It outputs a list of strings and may take a list of strings as input, corresponding to the names of input columns from which output column names can be generated.  By default input features are named x0, x1, ...."
msgstr ""

#: ../glossary.rst:1264
msgid "``get_n_splits``"
msgstr ""

#: ../glossary.rst:1266
msgid "On a :term:`CV splitter` (not an estimator), returns the number of elements one would get if iterating through the return value of :term:`split` given the same parameters.  Takes the same parameters as split."
msgstr ""

#: ../glossary.rst:1270
msgid "``get_params``"
msgstr ""

#: ../glossary.rst:1272
msgid "Gets all :term:`parameters`, and their values, that can be set using :term:`set_params`.  A parameter ``deep`` can be used, when set to False to only return those parameters not including ``__``, i.e.  not due to indirection via contained estimators."
msgstr ""

#: ../glossary.rst:1277
msgid "Most estimators adopt the definition from :class:`base.BaseEstimator`, which simply adopts the parameters defined for ``__init__``. :class:`pipeline.Pipeline`, among others, reimplements ``get_params`` to declare the estimators named in its ``steps`` parameters as themselves being parameters."
msgstr ""

#: ../glossary.rst:1282
msgid "``partial_fit``"
msgstr ""

#: ../glossary.rst:1284
msgid "Facilitates fitting an estimator in an online fashion.  Unlike ``fit``, repeatedly calling ``partial_fit`` does not clear the model, but updates it with the data provided. The portion of data provided to ``partial_fit`` may be called a mini-batch. Each mini-batch must be of consistent shape, etc. In iterative estimators, ``partial_fit`` often only performs a single iteration."
msgstr ""

#: ../glossary.rst:1291
msgid "``partial_fit`` may also be used for :term:`out-of-core` learning, although usually limited to the case where learning can be performed online, i.e. the model is usable after each ``partial_fit`` and there is no separate processing needed to finalize the model. :class:`cluster.Birch` introduces the convention that calling ``partial_fit(X)`` will produce a model that is not finalized, but the model can be finalized by calling ``partial_fit()`` i.e. without passing a further mini-batch."
msgstr ""

#: ../glossary.rst:1300
msgid "Generally, estimator parameters should not be modified between calls to ``partial_fit``, although ``partial_fit`` should validate them as well as the new mini-batch of data.  In contrast, ``warm_start`` is used to repeatedly fit the same estimator with the same data but varying parameters."
msgstr ""

#: ../glossary.rst:1306
msgid "Like ``fit``, ``partial_fit`` should return the estimator object."
msgstr ""

#: ../glossary.rst:1308
msgid "To clear the model, a new estimator should be constructed, for instance with :func:`base.clone`."
msgstr ""

#: ../glossary.rst:1311
msgid "NOTE: Using ``partial_fit`` after ``fit`` results in undefined behavior."
msgstr ""

#: ../glossary.rst:1312
msgid "``predict``"
msgstr ""

#: ../glossary.rst:1314
msgid "Makes a prediction for each sample, usually only taking :term:`X` as input (but see under regressor output conventions below). In a :term:`classifier` or :term:`regressor`, this prediction is in the same target space used in fitting (e.g. one of {'red', 'amber', 'green'} if the ``y`` in fitting consisted of these strings).  Despite this, even when ``y`` passed to :term:`fit` is a list or other array-like, the output of ``predict`` should always be an array or sparse matrix. In a :term:`clusterer` or :term:`outlier detector` the prediction is an integer."
msgstr ""

#: ../glossary.rst:1330
msgid "An array of shape ``(n_samples,)`` ``(n_samples, n_outputs)``. :term:`Multilabel <multilabel>` data may be represented as a sparse matrix if a sparse matrix was used in fitting. Each element should be one of the values in the classifier's :term:`classes_` attribute."
msgstr ""

#: ../glossary.rst:1337
msgid "An array of shape ``(n_samples,)`` where each value is from 0 to ``n_clusters - 1`` if the corresponding sample is clustered, and -1 if the sample is not clustered, as in :func:`cluster.dbscan`."
msgstr ""

#: ../glossary.rst:1343
msgid "An array of shape ``(n_samples,)`` where each value is -1 for an outlier and 1 otherwise."
msgstr ""

#: ../glossary.rst:1347
msgid "A numeric array of shape ``(n_samples,)``, usually float64. Some regressors have extra options in their ``predict`` method, allowing them to return standard deviation (``return_std=True``) or covariance (``return_cov=True``) relative to the predicted value.  In this case, the return value is a tuple of arrays corresponding to (prediction mean, std, cov) as required."
msgstr ""

#: ../glossary.rst:1353
msgid "``predict_log_proba``"
msgstr ""

#: ../glossary.rst:1355
msgid "The natural logarithm of the output of :term:`predict_proba`, provided to facilitate numerical stability."
msgstr ""

#: ../glossary.rst:1357
msgid "``predict_proba``"
msgstr ""

#: ../glossary.rst:1359
msgid "A method in :term:`classifiers` and :term:`clusterers` that can return probability estimates for each class/cluster.  Its input is usually only some observed data, :term:`X`."
msgstr ""

#: ../glossary.rst:1366
msgid "Output conventions are like those for :term:`decision_function` except in the :term:`binary` classification case, where one column is output for each class (while ``decision_function`` outputs a 1d array). For binary and multiclass predictions, each row should add to 1."
msgstr ""

#: ../glossary.rst:1371
msgid "Like other methods, ``predict_proba`` should only be present when the estimator can make probabilistic predictions (see :term:`duck typing`). This means that the presence of the method may depend on estimator parameters (e.g. in :class:`linear_model.SGDClassifier`) or training data (e.g. in :class:`model_selection.GridSearchCV`) and may only appear after fitting."
msgstr ""

#: ../glossary.rst:1377
msgid "``score``"
msgstr ""

#: ../glossary.rst:1379
msgid "A method on an estimator, usually a :term:`predictor`, which evaluates its predictions on a given dataset, and returns a single numerical score.  A greater return value should indicate better predictions; accuracy is used for classifiers and R^2 for regressors by default."
msgstr ""

#: ../glossary.rst:1387
msgid "Some estimators implement a custom, estimator-specific score function, often the likelihood of the data under the model."
msgstr ""

#: ../glossary.rst:1389
msgid "``score_samples``"
msgstr ""

#: ../glossary.rst:1395
msgid "``set_params``"
msgstr ""

#: ../glossary.rst:1397
msgid "Available in any estimator, takes keyword arguments corresponding to keys in :term:`get_params`.  Each is provided a new value to assign such that calling ``get_params`` after ``set_params`` will reflect the changed :term:`parameters`.  Most estimators use the implementation in :class:`base.BaseEstimator`, which handles nested parameters and otherwise sets the parameter as an attribute on the estimator. The method is overridden in :class:`pipeline.Pipeline` and related estimators."
msgstr ""

#: ../glossary.rst:1405
msgid "``split``"
msgstr ""

#: ../glossary.rst:1407
msgid "On a :term:`CV splitter` (not an estimator), this method accepts parameters (:term:`X`, :term:`y`, :term:`groups`), where all may be optional, and returns an iterator over ``(train_idx, test_idx)`` pairs.  Each of {train,test}_idx is a 1d integer array, with values from 0 from ``X.shape[0] - 1`` of any length, such that no values appear in both some ``train_idx`` and its corresponding ``test_idx``."
msgstr ""

#: ../glossary.rst:1413
msgid "``transform``"
msgstr ""

#: ../glossary.rst:1415
msgid "In a :term:`transformer`, transforms the input, usually only :term:`X`, into some transformed space (conventionally notated as :term:`Xt`). Output is an array or sparse matrix of length :term:`n_samples` and with the number of columns fixed after :term:`fitting`."
msgstr ""

#: ../glossary.rst:1426
msgid "Parameters"
msgstr ""

#: ../glossary.rst:1428
msgid "These common parameter names, specifically used in estimator construction (see concept :term:`parameter`), sometimes also appear as parameters of functions or non-estimator constructors."
msgstr ""

#: ../glossary.rst:1433
msgid "``class_weight``"
msgstr ""

#: ../glossary.rst:1435
msgid "Used to specify sample weights when fitting classifiers as a function of the :term:`target` class.  Where :term:`sample_weight` is also supported and given, it is multiplied by the ``class_weight`` contribution. Similarly, where ``class_weight`` is used in a :term:`multioutput` (including :term:`multilabel`) tasks, the weights are multiplied across outputs (i.e. columns of ``y``)."
msgstr ""

#: ../glossary.rst:1442
msgid "By default, all samples have equal weight such that classes are effectively weighted by their prevalence in the training data. This could be achieved explicitly with ``class_weight={label1: 1, label2: 1, ...}`` for all class labels."
msgstr ""

#: ../glossary.rst:1447
msgid "More generally, ``class_weight`` is specified as a dict mapping class labels to weights (``{class_label: weight}``), such that each sample of the named class is given that weight."
msgstr ""

#: ../glossary.rst:1451
msgid "``class_weight='balanced'`` can be used to give all classes equal weight by giving each sample a weight inversely related to its class's prevalence in the training data: ``n_samples / (n_classes * np.bincount(y))``. Class weights will be used differently depending on the algorithm: for linear models (such as linear SVM or logistic regression), the class weights will alter the loss function by weighting the loss of each sample by its class weight. For tree-based algorithms, the class weights will be used for reweighting the splitting criterion. **Note** however that this rebalancing does not take the weight of samples in each class into account."
msgstr ""

#: ../glossary.rst:1463
msgid "For multioutput classification, a list of dicts is used to specify weights for each output. For example, for four-class multilabel classification weights should be ``[{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}]`` instead of ``[{1:1}, {2:5}, {3:1}, {4:1}]``."
msgstr ""

#: ../glossary.rst:1468
msgid "The ``class_weight`` parameter is validated and interpreted with :func:`utils.compute_class_weight`."
msgstr ""

#: ../glossary.rst:1470
msgid "``cv``"
msgstr ""

#: ../glossary.rst:1472
msgid "Determines a cross validation splitting strategy, as used in cross-validation based routines. ``cv`` is also available in estimators such as :class:`multioutput.ClassifierChain` or :class:`calibration.CalibratedClassifierCV` which use the predictions of one estimator as training data for another, to not overfit the training supervision."
msgstr ""

#: ../glossary.rst:1479
msgid "Possible inputs for ``cv`` are usually:"
msgstr ""

#: ../glossary.rst:1481
msgid "An integer, specifying the number of folds in K-fold cross validation. K-fold will be stratified over classes if the estimator is a classifier (determined by :func:`base.is_classifier`) and the :term:`targets` may represent a binary or multiclass (but not multioutput) classification problem (determined by :func:`utils.multiclass.type_of_target`)."
msgstr ""

#: ../glossary.rst:1487
msgid "A :term:`cross-validation splitter` instance. Refer to the :ref:`User Guide <cross_validation>` for splitters available within Scikit-learn."
msgstr ""

#: ../glossary.rst:1490
msgid "An iterable yielding train/test splits."
msgstr ""

#: ../glossary.rst:1492
msgid "With some exceptions (especially where not using cross validation at all is an option), the default is 5-fold."
msgstr ""

#: ../glossary.rst:1495
msgid "``cv`` values are validated and interpreted with :func:`utils.check_cv`."
msgstr ""

#: ../glossary.rst:1496
msgid "``kernel``"
msgstr ""

#: ../glossary.rst:1499
msgid "``max_iter``"
msgstr ""

#: ../glossary.rst:1501
msgid "For estimators involving iterative optimization, this determines the maximum number of iterations to be performed in :term:`fit`.  If ``max_iter`` iterations are run without convergence, a :class:`exceptions.ConvergenceWarning` should be raised.  Note that the interpretation of \"a single iteration\" is inconsistent across estimators: some, but not all, use it to mean a single epoch (i.e. a pass over every sample in the data)."
msgstr ""

#: ../glossary.rst:1509
msgid "FIXME perhaps we should have some common tests about the relationship between ConvergenceWarning and max_iter."
msgstr ""

#: ../glossary.rst:1511
msgid "``memory``"
msgstr ""

#: ../glossary.rst:1513
msgid "Some estimators make use of :class:`joblib.Memory` to store partial solutions during fitting. Thus when ``fit`` is called again, those partial solutions have been memoized and can be reused."
msgstr ""

#: ../glossary.rst:1517
msgid "A ``memory`` parameter can be specified as a string with a path to a directory, or a :class:`joblib.Memory` instance (or an object with a similar interface, i.e. a ``cache`` method) can be used."
msgstr ""

#: ../glossary.rst:1521
msgid "``memory`` values are validated and interpreted with :func:`utils.validation.check_memory`."
msgstr ""

#: ../glossary.rst:1523
msgid "``metric``"
msgstr ""

#: ../glossary.rst:1525
msgid "As a parameter, this is the scheme for determining the distance between two data points.  See :func:`metrics.pairwise_distances`.  In practice, for some algorithms, an improper distance metric (one that does not obey the triangle inequality, such as Cosine Distance) may be used."
msgstr ""

#: ../glossary.rst:1530
msgid "XXX: hierarchical clustering uses ``affinity`` with this meaning."
msgstr ""

#: ../glossary.rst:1532
msgid "We also use *metric* to refer to :term:`evaluation metrics`, but avoid using this sense as a parameter name."
msgstr ""

#: ../glossary.rst:1534
msgid "``n_components``"
msgstr ""

#: ../glossary.rst:1536
msgid "The number of features which a :term:`transformer` should transform the input into. See :term:`components_` for the special case of affine projection."
msgstr ""

#: ../glossary.rst:1539
msgid "``n_iter_no_change``"
msgstr ""

#: ../glossary.rst:1541
msgid "Number of iterations with no improvement to wait before stopping the iterative procedure. This is also known as a *patience* parameter. It is typically used with :term:`early stopping` to avoid stopping too early."
msgstr ""

#: ../glossary.rst:1545
msgid "``n_jobs``"
msgstr ""

#: ../glossary.rst:1547
msgid "This parameter is used to specify how many concurrent processes or threads should be used for routines that are parallelized with :term:`joblib`."
msgstr ""

#: ../glossary.rst:1551
msgid "``n_jobs`` is an integer, specifying the maximum number of concurrently running workers. If 1 is given, no joblib parallelism is used at all, which is useful for debugging. If set to -1, all CPUs are used. For ``n_jobs`` below -1, (n_cpus + 1 + n_jobs) are used. For example with ``n_jobs=-2``, all CPUs but one are used."
msgstr ""

#: ../glossary.rst:1557
msgid "``n_jobs`` is ``None`` by default, which means *unset*; it will generally be interpreted as ``n_jobs=1``, unless the current :class:`joblib.Parallel` backend context specifies otherwise."
msgstr ""

#: ../glossary.rst:1561
msgid "For more details on the use of ``joblib`` and its interactions with scikit-learn, please refer to our :ref:`parallelism notes <parallelism>`."
msgstr ""

#: ../glossary.rst:1564
msgid "``pos_label``"
msgstr ""

#: ../glossary.rst:1566
msgid "Value with which positive labels must be encoded in binary classification problems in which the positive class is not assumed. This value is typically required to compute asymmetric evaluation metrics such as precision and recall."
msgstr ""

#: ../glossary.rst:1570
msgid "``random_state``"
msgstr ""

#: ../glossary.rst:1572
msgid "Whenever randomization is part of a Scikit-learn algorithm, a ``random_state`` parameter may be provided to control the random number generator used.  Note that the mere presence of ``random_state`` doesn't mean that randomization is always used, as it may be dependent on another parameter, e.g. ``shuffle``, being set."
msgstr ""

#: ../glossary.rst:1578
msgid "The passed value will have an effect on the reproducibility of the results returned by the function (:term:`fit`, :term:`split`, or any other function like :func:`~sklearn.cluster.k_means`). `random_state`'s value may be:"
msgstr ""

#: ../glossary.rst:1586
msgid "None (default)"
msgstr ""

#: ../glossary.rst:1584
msgid "Use the global random state instance from :mod:`numpy.random`. Calling the function multiple times will reuse the same instance, and will produce different results."
msgstr ""

#: ../glossary.rst:1595
msgid "An integer"
msgstr ""

#: ../glossary.rst:1589
msgid "Use a new random number generator seeded by the given integer. Using an int will produce the same results across different calls. However, it may be worthwhile checking that your results are stable across a number of different distinct random seeds. Popular integer random seeds are 0 and `42 <https://en.wikipedia.org/wiki/Answer_to_the_Ultimate_Question_of_Life%2C_the_Universe%2C_and_Everything>`_."
msgstr ""

#: ../glossary.rst:1601
msgid "A :class:`numpy.random.RandomState` instance"
msgstr ""

#: ../glossary.rst:1598
msgid "Use the provided random state, only affecting other users of that same random state instance. Calling the function multiple times will reuse the same instance, and will produce different results."
msgstr ""

#: ../glossary.rst:1603
msgid ":func:`utils.check_random_state` is used internally to validate the input ``random_state`` and return a :class:`~numpy.random.RandomState` instance."
msgstr ""

#: ../glossary.rst:1607
msgid "For more details on how to control the randomness of scikit-learn objects and avoid common pitfalls, you may refer to :ref:`randomness`."
msgstr ""

#: ../glossary.rst:1609
msgid "``scoring``"
msgstr ""

#: ../glossary.rst:1611
msgid "Specifies the score function to be maximized (usually by :ref:`cross validation <cross_validation>`), or -- in some cases -- multiple score functions to be reported. The score function can be a string accepted by :func:`metrics.get_scorer` or a callable :term:`scorer`, not to be confused with an :term:`evaluation metric`, as the latter have a more diverse API.  ``scoring`` may also be set to None, in which case the estimator's :term:`score` method is used.  See :ref:`scoring_parameter` in the User Guide."
msgstr ""

#: ../glossary.rst:1620
msgid "Where multiple metrics can be evaluated, ``scoring`` may be given either as a list of unique strings, a dictionary with names as keys and callables as values or a callable that returns a dictionary. Note that this does *not* specify which score function is to be maximized, and another parameter such as ``refit`` maybe used for this purpose."
msgstr ""

#: ../glossary.rst:1627
msgid "The ``scoring`` parameter is validated and interpreted using :func:`metrics.check_scoring`."
msgstr ""

#: ../glossary.rst:1629
msgid "``verbose``"
msgstr ""

#: ../glossary.rst:1631
msgid "Logging is not handled very consistently in Scikit-learn at present, but when it is provided as an option, the ``verbose`` parameter is usually available to choose no logging (set to False). Any True value should enable some logging, but larger integers (e.g. above 10) may be needed for full verbosity.  Verbose logs are usually printed to Standard Output. Estimators should not produce any output on Standard Output with the default ``verbose`` setting."
msgstr ""

#: ../glossary.rst:1639
msgid "``warm_start``"
msgstr ""

#: ../glossary.rst:1642
msgid "When fitting an estimator repeatedly on the same dataset, but for multiple parameter values (such as to find the value maximizing performance as in :ref:`grid search <grid_search>`), it may be possible to reuse aspects of the model learned from the previous parameter value, saving time.  When ``warm_start`` is true, the existing :term:`fitted` model :term:`attributes` are used to initialize the new model in a subsequent call to :term:`fit`."
msgstr ""

#: ../glossary.rst:1650
msgid "Note that this is only applicable for some models and some parameters, and even some orders of parameter values. For example, ``warm_start`` may be used when building random forests to add more trees to the forest (increasing ``n_estimators``) but not to reduce their number."
msgstr ""

#: ../glossary.rst:1656
msgid ":term:`partial_fit` also retains the model between calls, but differs: with ``warm_start`` the parameters change and the data is (more-or-less) constant across calls to ``fit``; with ``partial_fit``, the mini-batch of data changes and model parameters stay fixed."
msgstr ""

#: ../glossary.rst:1661
msgid "There are cases where you want to use ``warm_start`` to fit on different, but closely related data. For example, one may initially fit to a subset of the data, then fine-tune the parameter search on the full dataset. For classification, all data in a sequence of ``warm_start`` calls to ``fit`` must include samples from each class."
msgstr ""

#: ../glossary.rst:1670
msgid "Attributes"
msgstr ""

#: ../glossary.rst:1672
msgid "See concept :term:`attribute`."
msgstr ""

#: ../glossary.rst:1675
msgid "``classes_``"
msgstr ""

#: ../glossary.rst:1677
msgid "A list of class labels known to the :term:`classifier`, mapping each label to a numerical index used in the model representation our output. For instance, the array output from :term:`predict_proba` has columns aligned with ``classes_``. For :term:`multi-output` classifiers, ``classes_`` should be a list of lists, with one class listing for each output.  For each output, the classes should be sorted (numerically, or lexicographically for strings)."
msgstr ""

#: ../glossary.rst:1685
msgid "``classes_`` and the mapping to indices is often managed with :class:`preprocessing.LabelEncoder`."
msgstr ""

#: ../glossary.rst:1687
msgid "``components_``"
msgstr ""

#: ../glossary.rst:1689
msgid "An affine transformation matrix of shape ``(n_components, n_features)`` used in many linear :term:`transformers` where :term:`n_components` is the number of output features and :term:`n_features` is the number of input features."
msgstr ""

#: ../glossary.rst:1694
msgid "See also :term:`components_` which is a similar attribute for linear predictors."
msgstr ""

#: ../glossary.rst:1696
msgid "``coef_``"
msgstr ""

#: ../glossary.rst:1698
msgid "The weight/coefficient matrix of a generalised linear model :term:`predictor`, of shape ``(n_features,)`` for binary classification and single-output regression, ``(n_classes, n_features)`` for multiclass classification and ``(n_targets, n_features)`` for multi-output regression. Note this does not include the intercept (or bias) term, which is stored in ``intercept_``."
msgstr ""

#: ../glossary.rst:1705
msgid "When available, ``feature_importances_`` is not usually provided as well, but can be calculated as the  norm of each feature's entry in ``coef_``."
msgstr ""

#: ../glossary.rst:1709
msgid "See also :term:`components_` which is a similar attribute for linear transformers."
msgstr ""

#: ../glossary.rst:1711
msgid "``embedding_``"
msgstr ""

#: ../glossary.rst:1713
msgid "An embedding of the training data in :ref:`manifold learning <manifold>` estimators, with shape ``(n_samples, n_components)``, identical to the output of :term:`fit_transform`.  See also :term:`labels_`."
msgstr ""

#: ../glossary.rst:1717
msgid "``n_iter_``"
msgstr ""

#: ../glossary.rst:1719
msgid "The number of iterations actually performed when fitting an iterative estimator that may stop upon convergence. See also :term:`max_iter`."
msgstr ""

#: ../glossary.rst:1721
msgid "``feature_importances_``"
msgstr ""

#: ../glossary.rst:1723
msgid "A vector of shape ``(n_features,)`` available in some :term:`predictors` to provide a relative measure of the importance of each feature in the predictions of the model."
msgstr ""

#: ../glossary.rst:1726
msgid "``labels_``"
msgstr ""

#: ../glossary.rst:1728
msgid "A vector containing a cluster label for each sample of the training data in :term:`clusterers`, identical to the output of :term:`fit_predict`.  See also :term:`embedding_`."
msgstr ""

#: ../glossary.rst:1735
msgid "Data and sample properties"
msgstr ""

#: ../glossary.rst:1737
msgid "See concept :term:`sample property`."
msgstr ""

#: ../glossary.rst:1740
msgid "``groups``"
msgstr ""

#: ../glossary.rst:1742
msgid "Used in cross-validation routines to identify samples that are correlated. Each value is an identifier such that, in a supporting :term:`CV splitter`, samples from some ``groups`` value may not appear in both a training set and its corresponding test set. See :ref:`group_cv`."
msgstr ""

#: ../glossary.rst:1747
msgid "``sample_weight``"
msgstr ""

#: ../glossary.rst:1749
msgid "A relative weight for each sample.  Intuitively, if all weights are integers, a weighted model or score should be equivalent to that calculated when repeating the sample the number of times specified in the weight.  Weights may be specified as floats, so that sample weights are usually equivalent up to a constant positive scaling factor."
msgstr ""

#: ../glossary.rst:1755
msgid "FIXME  Is this interpretation always the case in practice? We have no common tests."
msgstr ""

#: ../glossary.rst:1758
msgid "Some estimators, such as decision trees, support negative weights. FIXME: This feature or its absence may not be tested or documented in many estimators."
msgstr ""

#: ../glossary.rst:1762
msgid "This is not entirely the case where other parameters of the model consider the number of samples in a region, as with ``min_samples`` in :class:`cluster.DBSCAN`.  In this case, a count of samples becomes to a sum of their weights."
msgstr ""

#: ../glossary.rst:1767
msgid "In classification, sample weights can also be specified as a function of class with the :term:`class_weight` estimator :term:`parameter`."
msgstr ""

#: ../glossary.rst:1769
msgid "``X``"
msgstr ""

#: ../glossary.rst:1771
msgid "Denotes data that is observed at training and prediction time, used as independent variables in learning.  The notation is uppercase to denote that it is ordinarily a matrix (see :term:`rectangular`). When a matrix, each sample may be represented by a :term:`feature` vector, or a vector of :term:`precomputed` (dis)similarity with each training sample. ``X`` may also not be a matrix, and may require a :term:`feature extractor` or a :term:`pairwise metric` to turn it into one before learning a model."
msgstr ""

#: ../glossary.rst:1779
msgid "``Xt``"
msgstr ""

#: ../glossary.rst:1781
msgid "Shorthand for \"transformed :term:`X`\"."
msgstr ""

#: ../glossary.rst:1782
msgid "``y``"
msgstr ""

#: ../glossary.rst:1783
msgid "``Y``"
msgstr ""

#: ../glossary.rst:1785
msgid "Denotes data that may be observed at training time as the dependent variable in learning, but which is unavailable at prediction time, and is usually the :term:`target` of prediction.  The notation may be uppercase to denote that it is a matrix, representing :term:`multi-output` targets, for instance; but usually we use ``y`` and sometimes do so even when multiple outputs are assumed."
msgstr ""

