msgid ""
msgstr ""
"Project-Id-Version: scikit-learn\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-03-31 11:24-0400\n"
"PO-Revision-Date: 2021-05-11 00:22\n"
"Last-Translator: \n"
"Language-Team: Spanish\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Crowdin-Project: scikit-learn\n"
"X-Crowdin-Project-ID: 450526\n"
"X-Crowdin-Language: es-ES\n"
"X-Crowdin-File: /main/doc/en/modules/generated/sklearn.decomposition.non_negative_factorization.po\n"
"X-Crowdin-File-ID: 5026\n"
"Language: es_ES\n"

#: ../modules/generated/sklearn.decomposition.non_negative_factorization.rst:2
msgid ":mod:`sklearn.decomposition`.non_negative_factorization"
msgstr ":mod:`sklearn.decomposition`.non_negative_factorization"

#: of sklearn.decomposition._nmf.non_negative_factorization:2
msgid "Compute Non-negative Matrix Factorization (NMF)."
msgstr "Calcula la Matriz de Factorización no-negativa (NMF)."

#: of sklearn.decomposition._nmf.non_negative_factorization:4
msgid "Find two non-negative matrices (W, H) whose product approximates the non- negative matrix X. This factorization can be used for example for dimensionality reduction, source separation or topic extraction."
msgstr "Encuentra dos matrices no negativas (W, H) cuyo producto se aproxima a la matriz no negativa X. Esta factorización se puede utilizar, por ejemplo, para la reducción de la dimensionalidad, la separación de fuentes o la extracción de temas."

#: of sklearn.decomposition._nmf.non_negative_factorization:8
msgid "The objective function is:"
msgstr "La función objetivo es:"

#: of sklearn.decomposition._nmf.non_negative_factorization:10
msgid "0.5 * ||X - WH||_{Fro}^2 + alpha * l1_{ratio} * ||vec(W)||_1\n\n"
"+ alpha * l1_{ratio} * ||vec(H)||_1\n\n"
"+ 0.5 * alpha * (1 - l1_{ratio}) * ||W||_{Fro}^2\n\n"
"+ 0.5 * alpha * (1 - l1_{ratio}) * ||H||_{Fro}^2"
msgstr "0.5 * ||X - WH||_{Fro}^2 + alpha * l1_{ratio} * ||vec(W)||_1\n\n"
"+ alpha * l1_{ratio} * ||vec(H)||_1\n\n"
"+ 0.5 * alpha * (1 - l1_{ratio}) * ||W||_{Fro}^2\n\n"
"+ 0.5 * alpha * (1 - l1_{ratio}) * ||H||_{Fro}^2"

#: of sklearn.decomposition._nmf.non_negative_factorization:20
msgid "Where:"
msgstr "Donde:"

#: of sklearn.decomposition._nmf.non_negative_factorization:22
msgid ":math:`||A||_{Fro}^2 = \\sum_{i,j} A_{ij}^2` (Frobenius norm)"
msgstr ":math:`|A||_{Fro}^2 = \\su_{i,j} A_{ij}^2` (Norma de Frobenius)"

#: of sklearn.decomposition._nmf.non_negative_factorization:24
msgid ":math:`||vec(A)||_1 = \\sum_{i,j} abs(A_{ij})` (Elementwise L1 norm)"
msgstr ""

#: of sklearn.decomposition._nmf.non_negative_factorization:26
msgid "For multiplicative-update ('mu') solver, the Frobenius norm :math:`(0.5 * ||X - WH||_{Fro}^2)` can be changed into another beta-divergence loss, by changing the beta_loss parameter."
msgstr ""

#: of sklearn.decomposition._nmf.non_negative_factorization:30
msgid "The objective function is minimized with an alternating minimization of W and H. If H is given and update_H=False, it solves for W only."
msgstr ""

#: of sklearn.decomposition._nmf.non_negative_factorization
msgid "Parameters"
msgstr ""

#: of sklearn.decomposition._nmf.non_negative_factorization:36
msgid "**X**"
msgstr ""

#: of
msgid "array-like of shape (n_samples, n_features)"
msgstr ""

#: of sklearn.decomposition._nmf.non_negative_factorization:36
msgid "Constant matrix."
msgstr ""

#: of sklearn.decomposition._nmf.non_negative_factorization:39
#: sklearn.decomposition._nmf.non_negative_factorization:137
msgid "**W**"
msgstr ""

#: of
msgid "array-like of shape (n_samples, n_components), default=None"
msgstr ""

#: of sklearn.decomposition._nmf.non_negative_factorization:39
msgid "If init='custom', it is used as initial guess for the solution."
msgstr ""

#: of sklearn.decomposition._nmf.non_negative_factorization:43
#: sklearn.decomposition._nmf.non_negative_factorization:140
msgid "**H**"
msgstr ""

#: of
msgid "array-like of shape (n_components, n_features), default=None"
msgstr ""

#: of sklearn.decomposition._nmf.non_negative_factorization:42
msgid "If init='custom', it is used as initial guess for the solution. If update_H=False, it is used as a constant, to solve for W only."
msgstr ""

#: of sklearn.decomposition._nmf.non_negative_factorization:47
msgid "**n_components**"
msgstr ""

#: of
msgid "int, default=None"
msgstr ""

#: of sklearn.decomposition._nmf.non_negative_factorization:46
msgid "Number of components, if n_components is not set all features are kept."
msgstr ""

#: of sklearn.decomposition._nmf.non_negative_factorization:73
msgid "**init**"
msgstr ""

#: of
msgid "{'random', 'nndsvd', 'nndsvda', 'nndsvdar', 'custom'}, default=None"
msgstr ""

#: of sklearn.decomposition._nmf.non_negative_factorization:50
msgid "Method used to initialize the procedure."
msgstr ""

#: of sklearn.decomposition._nmf.non_negative_factorization:52
msgid "Valid options:"
msgstr ""

#: of sklearn.decomposition._nmf.non_negative_factorization:54
msgid "None: 'nndsvd' if n_components < n_features, otherwise 'random'."
msgstr ""

#: of sklearn.decomposition._nmf.non_negative_factorization:57
msgid "'random': non-negative random matrices, scaled with:"
msgstr ""

#: of sklearn.decomposition._nmf.non_negative_factorization:57
msgid "sqrt(X.mean() / n_components)"
msgstr ""

#: of sklearn.decomposition._nmf.non_negative_factorization:60
msgid "'nndsvd': Nonnegative Double Singular Value Decomposition (NNDSVD)"
msgstr ""

#: of sklearn.decomposition._nmf.non_negative_factorization:60
msgid "initialization (better for sparseness)"
msgstr ""

#: of sklearn.decomposition._nmf.non_negative_factorization:63
msgid "'nndsvda': NNDSVD with zeros filled with the average of X"
msgstr ""

#: of sklearn.decomposition._nmf.non_negative_factorization:63
msgid "(better when sparsity is not desired)"
msgstr ""

#: of sklearn.decomposition._nmf.non_negative_factorization:67
msgid "'nndsvdar': NNDSVD with zeros filled with small random values"
msgstr ""

#: of sklearn.decomposition._nmf.non_negative_factorization:66
msgid "(generally faster, less accurate alternative to NNDSVDa for when sparsity is not desired)"
msgstr ""

#: of sklearn.decomposition._nmf.non_negative_factorization:69
msgid "'custom': use custom matrices W and H if `update_H=True`. If `update_H=False`, then only custom matrix H is used."
msgstr ""

#: of sklearn.decomposition._nmf.non_negative_factorization:72
msgid "The default value of `init` changed from 'random' to None in 0.23."
msgstr ""

#: of sklearn.decomposition._nmf.non_negative_factorization:77
msgid "**update_H**"
msgstr ""

#: of
msgid "bool, default=True"
msgstr ""

#: of sklearn.decomposition._nmf.non_negative_factorization:76
msgid "Set to True, both W and H will be estimated from initial guesses. Set to False, only W will be estimated."
msgstr ""

#: of sklearn.decomposition._nmf.non_negative_factorization:91
msgid "**solver**"
msgstr ""

#: of
msgid "{'cd', 'mu'}, default='cd'"
msgstr ""

#: of sklearn.decomposition._nmf.non_negative_factorization:80
msgid "Numerical solver to use:"
msgstr ""

#: of sklearn.decomposition._nmf.non_negative_factorization:83
msgid "'cd' is a Coordinate Descent solver that uses Fast Hierarchical"
msgstr ""

#: of sklearn.decomposition._nmf.non_negative_factorization:83
msgid "Alternating Least Squares (Fast HALS)."
msgstr ""

#: of sklearn.decomposition._nmf.non_negative_factorization:85
msgid "'mu' is a Multiplicative Update solver."
msgstr ""

#: of sklearn.decomposition._nmf.non_negative_factorization:87
msgid "Coordinate Descent solver."
msgstr ""

#: of sklearn.decomposition._nmf.non_negative_factorization:90
msgid "Multiplicative Update solver."
msgstr ""

#: of sklearn.decomposition._nmf.non_negative_factorization:100
msgid "**beta_loss**"
msgstr ""

#: of
msgid "float or {'frobenius', 'kullback-leibler',             'itakura-saito'}, default='frobenius'"
msgstr ""

#: of sklearn.decomposition._nmf.non_negative_factorization:94
msgid "Beta divergence to be minimized, measuring the distance between X and the dot product WH. Note that values different from 'frobenius' (or 2) and 'kullback-leibler' (or 1) lead to significantly slower fits. Note that for beta_loss <= 0 (or 'itakura-saito'), the input matrix X cannot contain zeros. Used only in 'mu' solver."
msgstr ""

#: of sklearn.decomposition._nmf.non_negative_factorization:103
msgid "**tol**"
msgstr ""

#: of
msgid "float, default=1e-4"
msgstr ""

#: of sklearn.decomposition._nmf.non_negative_factorization:103
msgid "Tolerance of the stopping condition."
msgstr ""

#: of sklearn.decomposition._nmf.non_negative_factorization:106
msgid "**max_iter**"
msgstr ""

#: of
msgid "int, default=200"
msgstr ""

#: of sklearn.decomposition._nmf.non_negative_factorization:106
msgid "Maximum number of iterations before timing out."
msgstr ""

#: of sklearn.decomposition._nmf.non_negative_factorization:109
msgid "**alpha**"
msgstr ""

#: of
msgid "float, default=0."
msgstr ""

#: of sklearn.decomposition._nmf.non_negative_factorization:109
msgid "Constant that multiplies the regularization terms."
msgstr ""

#: of sklearn.decomposition._nmf.non_negative_factorization:116
msgid "**l1_ratio**"
msgstr ""

#: of sklearn.decomposition._nmf.non_negative_factorization:112
msgid "The regularization mixing parameter, with 0 <= l1_ratio <= 1. For l1_ratio = 0 the penalty is an elementwise L2 penalty (aka Frobenius Norm). For l1_ratio = 1 it is an elementwise L1 penalty. For 0 < l1_ratio < 1, the penalty is a combination of L1 and L2."
msgstr ""

#: of sklearn.decomposition._nmf.non_negative_factorization:120
msgid "**regularization**"
msgstr ""

#: of
msgid "{'both', 'components', 'transformation'}, default=None"
msgstr ""

#: of sklearn.decomposition._nmf.non_negative_factorization:119
msgid "Select whether the regularization affects the components (H), the transformation (W), both or none of them."
msgstr ""

#: of sklearn.decomposition._nmf.non_negative_factorization:126
msgid "**random_state**"
msgstr ""

#: of
msgid "int, RandomState instance or None, default=None"
msgstr ""

#: of sklearn.decomposition._nmf.non_negative_factorization:123
msgid "Used for NMF initialisation (when ``init`` == 'nndsvdar' or 'random'), and in Coordinate Descent. Pass an int for reproducible results across multiple function calls. See :term:`Glossary <random_state>`."
msgstr ""

#: of sklearn.decomposition._nmf.non_negative_factorization:129
msgid "**verbose**"
msgstr ""

#: of
msgid "int, default=0"
msgstr ""

#: of sklearn.decomposition._nmf.non_negative_factorization:129
msgid "The verbosity level."
msgstr ""

#: of sklearn.decomposition._nmf.non_negative_factorization:132
msgid "**shuffle**"
msgstr ""

#: of
msgid "bool, default=False"
msgstr ""

#: of sklearn.decomposition._nmf.non_negative_factorization:132
msgid "If true, randomize the order of coordinates in the CD solver."
msgstr ""

#: of sklearn.decomposition._nmf.non_negative_factorization
msgid "Returns"
msgstr ""

#: of
msgid "ndarray of shape (n_samples, n_components)"
msgstr ""

#: of sklearn.decomposition._nmf.non_negative_factorization:137
#: sklearn.decomposition._nmf.non_negative_factorization:140
msgid "Solution to the non-negative least squares problem."
msgstr ""

#: of
msgid "ndarray of shape (n_components, n_features)"
msgstr ""

#: of sklearn.decomposition._nmf.non_negative_factorization:151
msgid "**n_iter**"
msgstr ""

#: of
msgid "int"
msgstr ""

#: of sklearn.decomposition._nmf.non_negative_factorization:143
msgid "Actual number of iterations."
msgstr ""

#: of sklearn.decomposition._nmf.non_negative_factorization:154
msgid "References"
msgstr ""

#: of sklearn.decomposition._nmf.non_negative_factorization:155
msgid "Cichocki, Andrzej, and P. H. A. N. Anh-Huy. \"Fast local algorithms for large scale nonnegative matrix and tensor factorizations.\" IEICE transactions on fundamentals of electronics, communications and computer sciences 92.3: 708-721, 2009."
msgstr ""

#: of sklearn.decomposition._nmf.non_negative_factorization:160
msgid "Fevotte, C., & Idier, J. (2011). Algorithms for nonnegative matrix factorization with the beta-divergence. Neural Computation, 23(9)."
msgstr ""

#: of sklearn.decomposition._nmf.non_negative_factorization:168
msgid "Examples"
msgstr ""

