msgid ""
msgstr ""
"Project-Id-Version: scikit-learn\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-03-31 12:43-0400\n"
"PO-Revision-Date: 2021-04-15 00:05\n"
"Last-Translator: \n"
"Language-Team: Spanish\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Crowdin-Project: scikit-learn\n"
"X-Crowdin-Project-ID: 450526\n"
"X-Crowdin-Language: es-ES\n"
"X-Crowdin-File: /main/doc/en/modules/generated/sklearn.metrics.auc.po\n"
"X-Crowdin-File-ID: 3374\n"
"Language: es_ES\n"

#: ../modules/generated/sklearn.metrics.auc.rst:2
msgid ":mod:`sklearn.metrics`.auc"
msgstr ""

#: of sklearn.metrics._ranking.auc:2
msgid "Compute Area Under the Curve (AUC) using the trapezoidal rule."
msgstr ""

#: of sklearn.metrics._ranking.auc:4
msgid "This is a general function, given points on a curve.  For computing the area under the ROC-curve, see :func:`roc_auc_score`.  For an alternative way to summarize a precision-recall curve, see :func:`average_precision_score`."
msgstr ""

#: of sklearn.metrics._ranking.auc
msgid "Parameters"
msgstr ""

#: of sklearn.metrics._ranking.auc:13
msgid "**x**"
msgstr ""

#: of
msgid "ndarray of shape (n,)"
msgstr ""

#: of sklearn.metrics._ranking.auc:12
msgid "x coordinates. These must be either monotonic increasing or monotonic decreasing."
msgstr ""

#: of sklearn.metrics._ranking.auc:16
msgid "**y**"
msgstr ""

#: of
msgid "ndarray of shape, (n,)"
msgstr ""

#: of sklearn.metrics._ranking.auc:16
msgid "y coordinates."
msgstr ""

#: of sklearn.metrics._ranking.auc
msgid "Returns"
msgstr ""

#: of sklearn.metrics._ranking.auc:27
msgid "**auc**"
msgstr ""

#: of
msgid "float"
msgstr ""

#: of sklearn.metrics._ranking.auc:32
msgid ":obj:`roc_auc_score`"
msgstr ""

#: of sklearn.metrics._ranking.auc:33
msgid "Compute the area under the ROC curve."
msgstr ""

#: of sklearn.metrics._ranking.auc:34
msgid ":obj:`average_precision_score`"
msgstr ""

#: of sklearn.metrics._ranking.auc:35
msgid "Compute average precision from prediction scores."
msgstr ""

#: of sklearn.metrics._ranking.auc:36
msgid ":obj:`precision_recall_curve`"
msgstr ""

#: of sklearn.metrics._ranking.auc:37
msgid "Compute precision-recall pairs for different probability thresholds."
msgstr ""

#: of sklearn.metrics._ranking.auc:43
msgid "Examples"
msgstr ""

#: ../modules/generated/sklearn.metrics.auc.examples:4
msgid "Examples using ``sklearn.metrics.auc``"
msgstr ""

#: ../modules/generated/sklearn.metrics.auc.examples:15
#: ../modules/generated/sklearn.metrics.auc.examples:23
msgid ":ref:`sphx_glr_auto_examples_linear_model_plot_poisson_regression_non_normal_loss.py`"
msgstr ""

#: ../modules/generated/sklearn.metrics.auc.examples:34
#: ../modules/generated/sklearn.metrics.auc.examples:42
msgid ":ref:`sphx_glr_auto_examples_linear_model_plot_tweedie_regression_insurance_claims.py`"
msgstr ""

#~ msgid ":ref:`sphx_glr_auto_examples_model_selection_plot_roc_crossval.py`"
#~ msgstr ""

#~ msgid ":ref:`sphx_glr_auto_examples_model_selection_plot_roc.py`"
#~ msgstr ""

#~ msgid ":ref:`sphx_glr_auto_examples_model_selection_plot_precision_recall.py`"
#~ msgstr ""

