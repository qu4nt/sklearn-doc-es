msgid ""
msgstr ""
"Project-Id-Version: scikit-learn\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-03-31 11:24-0400\n"
"PO-Revision-Date: 2021-04-15 00:03\n"
"Last-Translator: \n"
"Language-Team: Spanish\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Crowdin-Project: scikit-learn\n"
"X-Crowdin-Project-ID: 450526\n"
"X-Crowdin-Language: es-ES\n"
"X-Crowdin-File: /main/doc/en/modules/generated/sklearn.preprocessing.robust_scale.po\n"
"X-Crowdin-File-ID: 3726\n"
"Language: es_ES\n"

#: ../modules/generated/sklearn.preprocessing.robust_scale.rst:2
msgid ":mod:`sklearn.preprocessing`.robust_scale"
msgstr ""

#: of sklearn.preprocessing._data.robust_scale:2
msgid "Standardize a dataset along any axis"
msgstr ""

#: of sklearn.preprocessing._data.robust_scale:4
msgid "Center to the median and component wise scale according to the interquartile range."
msgstr ""

#: of sklearn.preprocessing._data.robust_scale:7
msgid "Read more in the :ref:`User Guide <preprocessing_scaler>`."
msgstr ""

#: of sklearn.preprocessing._data.robust_scale
msgid "Parameters"
msgstr ""

#: of sklearn.preprocessing._data.robust_scale:12
msgid "**X**"
msgstr ""

#: of
msgid "{array-like, sparse matrix} of shape (n_sample, n_features)"
msgstr ""

#: of sklearn.preprocessing._data.robust_scale:12
msgid "The data to center and scale."
msgstr ""

#: of sklearn.preprocessing._data.robust_scale:17
msgid "**axis**"
msgstr ""

#: of
msgid "int, default=0"
msgstr ""

#: of sklearn.preprocessing._data.robust_scale:15
msgid "axis used to compute the medians and IQR along. If 0, independently scale each feature, otherwise (if 1) scale each sample."
msgstr ""

#: of sklearn.preprocessing._data.robust_scale:20
msgid "**with_centering**"
msgstr ""

#: of
msgid "bool, default=True"
msgstr ""

#: of sklearn.preprocessing._data.robust_scale:20
msgid "If True, center the data before scaling."
msgstr ""

#: of sklearn.preprocessing._data.robust_scale:24
msgid "**with_scaling**"
msgstr ""

#: of sklearn.preprocessing._data.robust_scale:23
msgid "If True, scale the data to unit variance (or equivalently, unit standard deviation)."
msgstr ""

#: of sklearn.preprocessing._data.robust_scale:30
msgid "**quantile_range**"
msgstr ""

#: of
msgid "tuple (q_min, q_max), 0.0 < q_min < q_max < 100.0"
msgstr ""

#: of sklearn.preprocessing._data.robust_scale:27
msgid "default=(25.0, 75.0), == (1st quantile, 3rd quantile), == IQR Quantile range used to calculate ``scale_``."
msgstr ""

#: of sklearn.preprocessing._data.robust_scale:35
msgid "**copy**"
msgstr ""

#: of sklearn.preprocessing._data.robust_scale:33
msgid "set to False to perform inplace row normalization and avoid a copy (if the input is already a numpy array or a scipy.sparse CSR matrix and if axis is 1)."
msgstr ""

#: of sklearn.preprocessing._data.robust_scale:44
msgid "**unit_variance**"
msgstr ""

#: of
msgid "bool, default=False"
msgstr ""

#: of sklearn.preprocessing._data.robust_scale:38
msgid "If True, scale data so that normally distributed features have a variance of 1. In general, if the difference between the x-values of ``q_max`` and ``q_min`` for a standard normal distribution is greater than 1, the dataset will be scaled down. If less than 1, the dataset will be scaled up."
msgstr ""

#: of sklearn.preprocessing._data.robust_scale
msgid "Returns"
msgstr ""

#: of sklearn.preprocessing._data.robust_scale:55
msgid "**X_tr**"
msgstr ""

#: of
msgid "{ndarray, sparse matrix} of shape (n_samples, n_features)"
msgstr ""

#: of sklearn.preprocessing._data.robust_scale:49
msgid "The transformed data."
msgstr ""

#: of sklearn.preprocessing._data.robust_scale:60
msgid ":obj:`RobustScaler`"
msgstr ""

#: of sklearn.preprocessing._data.robust_scale:61
msgid "Performs centering and scaling using the Transformer API (e.g. as part of a preprocessing :class:`~sklearn.pipeline.Pipeline`)."
msgstr ""

#: of sklearn.preprocessing._data.robust_scale:65
msgid "Notes"
msgstr ""

#: of sklearn.preprocessing._data.robust_scale:66
msgid "This implementation will refuse to center scipy.sparse matrices since it would make them non-sparse and would potentially crash the program with memory exhaustion problems."
msgstr ""

#: of sklearn.preprocessing._data.robust_scale:70
msgid "Instead the caller is expected to either set explicitly `with_centering=False` (in that case, only variance scaling will be performed on the features of the CSR matrix) or to call `X.toarray()` if he/she expects the materialized dense array to fit in memory."
msgstr ""

#: of sklearn.preprocessing._data.robust_scale:75
msgid "To avoid memory copy the caller should pass a CSR matrix."
msgstr ""

#: of sklearn.preprocessing._data.robust_scale:77
msgid "For a comparison of the different scalers, transformers, and normalizers, see :ref:`examples/preprocessing/plot_all_scaling.py <sphx_glr_auto_examples_preprocessing_plot_all_scaling.py>`."
msgstr ""

#: of sklearn.preprocessing._data.robust_scale:81
msgid "Risk of data leak"
msgstr ""

#: of sklearn.preprocessing._data.robust_scale:83
msgid "Do not use :func:`~sklearn.preprocessing.robust_scale` unless you know what you are doing. A common mistake is to apply it to the entire data *before* splitting into training and test sets. This will bias the model evaluation because information would have leaked from the test set to the training set. In general, we recommend using :class:`~sklearn.preprocessing.RobustScaler` within a :ref:`Pipeline <pipeline>` in order to prevent most risks of data leaking: `pipe = make_pipeline(RobustScaler(), LogisticRegression())`."
msgstr ""

