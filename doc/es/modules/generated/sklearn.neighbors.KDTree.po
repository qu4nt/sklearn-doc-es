msgid ""
msgstr ""
"Project-Id-Version: scikit-learn\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-03-31 11:24-0400\n"
"PO-Revision-Date: 2021-07-17 22:51\n"
"Last-Translator: \n"
"Language-Team: Spanish\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Crowdin-Project: scikit-learn\n"
"X-Crowdin-Project-ID: 450526\n"
"X-Crowdin-Language: es-ES\n"
"X-Crowdin-File: /main/doc/en/modules/generated/sklearn.neighbors.KDTree.po\n"
"X-Crowdin-File-ID: 5232\n"
"Language: es_ES\n"

#: ../modules/generated/sklearn.neighbors.KDTree.rst:2
msgid ":mod:`sklearn.neighbors`.KDTree"
msgstr ":mod:`sklearn.neighbors`.KDTree"

#: ../docstring of sklearn.neighbors._kd_tree.KDTree:2
msgid "KDTree for fast generalized N-point problems"
msgstr "KDTree para problemas rápidos de N puntos generalizados"

#: ../docstring of sklearn.neighbors._kd_tree.KDTree:4
msgid "Read more in the :ref:`User Guide <unsupervised_neighbors>`."
msgstr "Más información en el :ref:`Manual de usuario <unsupervised_neighbors>`."

#: ../docstring of sklearn.neighbors.KDTree.kernel_density
#: sklearn.neighbors.KDTree.query sklearn.neighbors.KDTree.query_radius
#: sklearn.neighbors.KDTree.two_point_correlation
#: sklearn.neighbors._kd_tree.KDTree
msgid "Parameters"
msgstr "Parámetros"

#: ../docstring of sklearn.neighbors.KDTree.kernel_density:10
#: sklearn.neighbors.KDTree.query:8 sklearn.neighbors.KDTree.query_radius:8
#: sklearn.neighbors.KDTree.two_point_correlation:9
#: sklearn.neighbors._kd_tree.KDTree:12
msgid "**X**"
msgstr "**X**"

#: ../docstring of
msgid "array-like of shape (n_samples, n_features)"
msgstr "array-like de forma (n_samples, n_features)"

#: ../docstring of sklearn.neighbors._kd_tree.KDTree:9
msgid "n_samples is the number of points in the data set, and n_features is the dimension of the parameter space. Note: if X is a C-contiguous array of doubles then data will not be copied. Otherwise, an internal copy will be made."
msgstr "n_samples es el número de puntos del conjunto de datos, y n_features es la dimensión del espacio de parámetros. Nota: si X es una matriz de dobles contigua a C, los datos no se copiarán. En caso contrario, se realizará una copia interna."

#: ../docstring of sklearn.neighbors._kd_tree.KDTree:22
msgid "**leaf_size**"
msgstr "**leaf_size**"

#: ../docstring of
msgid "positive int, default=40"
msgstr "positive int, default=40"

#: ../docstring of sklearn.neighbors._kd_tree.KDTree:15
msgid "Number of points at which to switch to brute-force. Changing leaf_size will not affect the results of a query, but can significantly impact the speed of a query and the memory required to store the constructed tree.  The amount of memory needed to store the tree scales as approximately n_samples / leaf_size. For a specified ``leaf_size``, a leaf node is guaranteed to satisfy ``leaf_size <= n_points <= 2 * leaf_size``, except in the case that ``n_samples < leaf_size``."
msgstr "Número de puntos en los que se cambia a fuerza bruta. Cambiar el tamaño de las hojas no afectará a los resultados de una consulta, pero puede afectar significativamente a la velocidad de una consulta y a la memoria necesaria para almacenar el árbol construido.  La cantidad de memoria necesaria para almacenar el árbol es aproximadamente n_samples / leaf_size. Para un ``leaf_size`` especificado, se garantiza que un nodo hoja satisface ``leaf_size <= n_points <= 2 * leaf_size``, excepto en el caso de que ``n_samples < leaf_size``."

#: ../docstring of sklearn.neighbors._kd_tree.KDTree:29
msgid "**metric**"
msgstr "**metric**"

#: ../docstring of
msgid "str or DistanceMetric object"
msgstr "str o DistanceMetric object"

#: ../docstring of sklearn.neighbors._kd_tree.KDTree:25
msgid "the distance metric to use for the tree.  Default='minkowski' with p=2 (that is, a euclidean metric). See the documentation of the DistanceMetric class for a list of available metrics. kd_tree.valid_metrics gives a list of the metrics which are valid for KDTree."
msgstr "la métrica de distancia a utilizar para el árbol.  Default='minkowski' con p=2 (es decir, una métrica euclidiana). Ver la documentación de la clase DistanceMetric para una lista de métricas disponibles. kd_tree.valid_metrics da una lista de las métricas que son válidas para KDTree."

#: ../docstring of sklearn.neighbors._kd_tree.KDTree:32
msgid "**Additional keywords are passed to the distance metric class.**"
msgstr "**Las palabras clave adicionales se pasan a la clase de métrica de distancia.**"

#: ../docstring of sklearn.neighbors._kd_tree.KDTree:35
msgid "**Note: Callable functions in the metric parameter are NOT supported for KDTree**"
msgstr "**Nota: Las funciones invocables en el parámetro métrico NO son compatibles con KDTree**"

#: ../docstring of sklearn.neighbors._kd_tree.KDTree:41
msgid "**and Ball Tree. Function call overhead will result in very poor performance.**"
msgstr "**y el Árbol de Bolas. La sobrecarga de las llamadas a las funciones dará lugar a un rendimiento muy pobre.**"

#: ../docstring of sklearn.neighbors._kd_tree.KDTree
msgid "Attributes"
msgstr "Atributos"

#: ../docstring of sklearn.neighbors._kd_tree.KDTree:52
msgid "**data**"
msgstr "**data**"

#: ../docstring of
msgid "memory view"
msgstr "vista de la memoria"

#: ../docstring of sklearn.neighbors._kd_tree.KDTree:46
msgid "The training data"
msgstr "Datos del entrenamiento"

#: ../docstring of sklearn.neighbors._kd_tree.KDTree:55
msgid "Examples"
msgstr "Ejemplos"

#: ../docstring of sklearn.neighbors._kd_tree.KDTree:56
msgid "Query for k-nearest neighbors"
msgstr "Consulta de los vecinos más cercanos (k-nearest neighbors)"

#: ../docstring of sklearn.neighbors._kd_tree.KDTree:68
msgid "Pickle and Unpickle a tree.  Note that the state of the tree is saved in the pickle operation: the tree needs not be rebuilt upon unpickling."
msgstr "Recoge y despeja un árbol.  Tenga en cuenta que el estado del árbol se guarda en la operación de pickle: el árbol no necesita ser reconstruido al unpickle."

#: ../docstring of sklearn.neighbors._kd_tree.KDTree:84
msgid "Query for neighbors within a given radius"
msgstr "Búsqueda de vecinos en un radio determinado"

#: ../docstring of sklearn.neighbors._kd_tree.KDTree:96
msgid "Compute a gaussian kernel density estimate:"
msgstr "Calcular una estimación de la densidad del núcleo gaussiano:"

#: ../docstring of sklearn.neighbors._kd_tree.KDTree:105
msgid "Compute a two-point auto-correlation function"
msgstr "Calcula una función de autocorrelación de dos puntos"

#: ../docstring of sklearn.neighbors._kd_tree.KDTree:116
msgid "Methods"
msgstr "Métodos"

#: ../docstring of sklearn.neighbors._kd_tree.KDTree:127:<autosummary>:1
msgid ":obj:`get_arrays <sklearn.neighbors.KDTree.get_arrays>`\\ \\(self\\)"
msgstr ":obj:`get_arrays <sklearn.neighbors.KDTree.get_arrays>`\\ \\(self\\)"

#: ../docstring of sklearn.neighbors.KDTree.get_arrays:2
#: sklearn.neighbors._kd_tree.KDTree:127:<autosummary>:1
msgid "Get data and node arrays."
msgstr "Obtener datos y arreglos de nodos."

#: ../docstring of sklearn.neighbors._kd_tree.KDTree:127:<autosummary>:1
msgid ":obj:`get_n_calls <sklearn.neighbors.KDTree.get_n_calls>`\\ \\(self\\)"
msgstr ":obj:`get_n_calls <sklearn.neighbors.KDTree.get_n_calls>`\\ \\(self\\)"

#: ../docstring of sklearn.neighbors.KDTree.get_n_calls:2
#: sklearn.neighbors._kd_tree.KDTree:127:<autosummary>:1
msgid "Get number of calls."
msgstr "Obtenga el número de llamadas."

#: ../docstring of sklearn.neighbors._kd_tree.KDTree:127:<autosummary>:1
msgid ":obj:`get_tree_stats <sklearn.neighbors.KDTree.get_tree_stats>`\\ \\(self\\)"
msgstr ":obj:`get_tree_stats <sklearn.neighbors.KDTree.get_tree_stats>`\\ \\(self\\)"

#: ../docstring of sklearn.neighbors.KDTree.get_tree_stats:2
#: sklearn.neighbors._kd_tree.KDTree:127:<autosummary>:1
msgid "Get tree status."
msgstr "Obtener el estado del árbol."

#: ../docstring of sklearn.neighbors._kd_tree.KDTree:127:<autosummary>:1
msgid ":obj:`kernel_density <sklearn.neighbors.KDTree.kernel_density>`\\ \\(self\\, X\\, h\\[\\, kernel\\, atol\\, ...\\]\\)"
msgstr ":obj:`kernel_density <sklearn.neighbors.KDTree.kernel_density>`\\ \\(self\\, X\\, h\\[\\, kernel\\, atol\\, ...\\]\\)"

#: ../docstring of sklearn.neighbors.KDTree.kernel_density:2
#: sklearn.neighbors._kd_tree.KDTree:127:<autosummary>:1
msgid "Compute the kernel density estimate at points X with the given kernel, using the distance metric specified at tree creation."
msgstr "Calcula la estimación de la densidad del núcleo en los puntos X con el núcleo dado, utilizando la métrica de distancia especificada en la creación del árbol."

#: ../docstring of sklearn.neighbors._kd_tree.KDTree:127:<autosummary>:1
msgid ":obj:`query <sklearn.neighbors.KDTree.query>`\\ \\(X\\[\\, k\\, return\\_distance\\, dualtree\\, ...\\]\\)"
msgstr ":obj:`query <sklearn.neighbors.KDTree.query>`\\ \\(X\\[\\, k\\, return\\_distance\\, dualtree\\, ...\\]\\)"

#: ../docstring of sklearn.neighbors.KDTree.query:2
#: sklearn.neighbors._kd_tree.KDTree:127:<autosummary>:1
msgid "query the tree for the k nearest neighbors"
msgstr "consultar el árbol para los k vecinos más cercanos"

#: ../docstring of sklearn.neighbors._kd_tree.KDTree:127:<autosummary>:1
msgid ":obj:`query_radius <sklearn.neighbors.KDTree.query_radius>`\\ \\(X\\, r\\[\\, return\\_distance\\, ...\\]\\)"
msgstr ":obj:`query_radius <sklearn.neighbors.KDTree.query_radius>`\\ \\(X\\, r\\[\\, return\\_distance\\, ...\\]\\)"

#: ../docstring of sklearn.neighbors.KDTree.query_radius:2
#: sklearn.neighbors._kd_tree.KDTree:127:<autosummary>:1
msgid "query the tree for neighbors within a radius r"
msgstr "consultar el árbol en busca de vecinos en un radio r"

#: ../docstring of sklearn.neighbors._kd_tree.KDTree:127:<autosummary>:1
msgid ":obj:`reset_n_calls <sklearn.neighbors.KDTree.reset_n_calls>`\\ \\(self\\)"
msgstr ":obj:`reset_n_calls <sklearn.neighbors.KDTree.reset_n_calls>`\\ \\(self\\)"

#: ../docstring of sklearn.neighbors.KDTree.reset_n_calls:2
#: sklearn.neighbors._kd_tree.KDTree:127:<autosummary>:1
msgid "Reset number of calls to 0."
msgstr "Restablecer el número de llamadas a 0."

#: ../docstring of sklearn.neighbors._kd_tree.KDTree:127:<autosummary>:1
msgid ":obj:`two_point_correlation <sklearn.neighbors.KDTree.two_point_correlation>`\\ \\(X\\, r\\[\\, dualtree\\]\\)"
msgstr ":obj:`two_point_correlation <sklearn.neighbors.KDTree.two_point_correlation>`\\ \\(X\\, r\\[\\, dualtree\\]\\)"

#: ../docstring of sklearn.neighbors.KDTree.two_point_correlation:2
#: sklearn.neighbors._kd_tree.KDTree:127:<autosummary>:1
msgid "Compute the two-point correlation function"
msgstr "Calcula la función de correlación de dos puntos"

#: ../docstring of sklearn.neighbors.KDTree.get_arrays
#: sklearn.neighbors.KDTree.get_n_calls sklearn.neighbors.KDTree.get_tree_stats
#: sklearn.neighbors.KDTree.kernel_density sklearn.neighbors.KDTree.query
#: sklearn.neighbors.KDTree.query_radius
#: sklearn.neighbors.KDTree.two_point_correlation
msgid "Returns"
msgstr "Devuelve"

#: ../docstring of sklearn.neighbors.KDTree.get_arrays:20
msgid "arrays: tuple of array"
msgstr "arrays: tupla de arreglo"

#: ../docstring of sklearn.neighbors.KDTree.get_arrays:9
msgid "Arrays for storing tree data, index, node data and node bounds."
msgstr "Arreglos para almacenar datos de árboles, índices, datos de nodos y límites de nodos."

#: ../docstring of sklearn.neighbors.KDTree.get_n_calls:20
msgid "n_calls: int"
msgstr "n_calls: int"

#: ../docstring of sklearn.neighbors.KDTree.get_n_calls:9
msgid "number of distance computation calls"
msgstr "número de llamadas de cálculo de la distancia"

#: ../docstring of sklearn.neighbors.KDTree.get_tree_stats:20
msgid "tree_stats: tuple of int"
msgstr "tree_stats: tuple of int"

#: ../docstring of sklearn.neighbors.KDTree.get_tree_stats:9
msgid "(number of trims, number of leaves, number of splits)"
msgstr "(número de recortes, número de hojas, número de divisiones)"

#: ../docstring of sklearn.neighbors.KDTree.kernel_density:9
#: sklearn.neighbors.KDTree.two_point_correlation:8
msgid "An array of points to query.  Last dimension should match dimension of training data."
msgstr "Un arreglo de puntos a consultar.  La última dimensión debe corresponder con la dimensión de los datos de entrenamiento."

#: ../docstring of sklearn.neighbors.KDTree.kernel_density:13
msgid "**h**"
msgstr "**h**"

#: ../docstring of
msgid "float"
msgstr "float"

#: ../docstring of sklearn.neighbors.KDTree.kernel_density:13
msgid "the bandwidth of the kernel"
msgstr "el ancho de banda del núcleo"

#: ../docstring of sklearn.neighbors.KDTree.kernel_density:23
msgid "**kernel**"
msgstr "**kernel**"

#: ../docstring of
msgid "str, default=\"gaussian\""
msgstr "str, default=\"gaussian\""

#: ../docstring of sklearn.neighbors.KDTree.kernel_density:16
msgid "specify the kernel to use.  Options are - 'gaussian' - 'tophat' - 'epanechnikov' - 'exponential' - 'linear' - 'cosine' Default is kernel = 'gaussian'"
msgstr "especifica el núcleo a utilizar. Las opciones son - 'gaussian' - 'tophat' - 'epanechnikov' - 'exponential' - 'linear' - 'cosine' Por defecto es kernel = 'gaussian'"

#: ../docstring of sklearn.neighbors.KDTree.kernel_density:29
msgid "**atol, rtol**"
msgstr "**atol, rtol**"

#: ../docstring of
msgid "float, default=0, 1e-8"
msgstr "float, default=0, 1e-8"

#: ../docstring of sklearn.neighbors.KDTree.kernel_density:26
msgid "Specify the desired relative and absolute tolerance of the result. If the true result is K_true, then the returned result K_ret satisfies ``abs(K_true - K_ret) < atol + rtol * K_ret`` The default is zero (i.e. machine precision) for both."
msgstr "Especifica la tolerancia relativa y absoluta deseada del resultado. Si el resultado verdadero es K_true, entonces el resultado devuelto K_ret satisface ``abs(K_true - K_ret) < atol + rtol * K_ret`` El valor predeterminado es cero (es decir, precisión de máquina) para ambos."

#: ../docstring of sklearn.neighbors.KDTree.kernel_density:34
#: sklearn.neighbors.KDTree.query:25
msgid "**breadth_first**"
msgstr "**breadth_first**"

#: ../docstring of
msgid "bool, default=False"
msgstr "bool, default=False"

#: ../docstring of sklearn.neighbors.KDTree.kernel_density:32
msgid "If True, use a breadth-first search.  If False (default) use a depth-first search.  Breadth-first is generally faster for compact kernels and/or high tolerances."
msgstr "Si es True, utiliza una búsqueda de tipo breadth-first.  Si es False (predeterminado) utiliza una búsqueda de profundidad.  La búsqueda en profundidad es generalmente más rápida para los nñucleos compactos y/o las tolerancias altas."

#: ../docstring of sklearn.neighbors.KDTree.kernel_density:38
msgid "**return_log**"
msgstr "**return_log**"

#: ../docstring of sklearn.neighbors.KDTree.kernel_density:37
msgid "Return the logarithm of the result.  This can be more accurate than returning the result itself for narrow kernels."
msgstr "Devuelve el logaritmo del resultado.  Esto puede ser más preciso que devolver el propio resultado para los núcleos estrechos."

#: ../docstring of sklearn.neighbors.KDTree.kernel_density:54
msgid "**density**"
msgstr "**density**"

#: ../docstring of
msgid "ndarray of shape X.shape[:-1]"
msgstr "ndarray de forma X.forma[:-1]"

#: ../docstring of sklearn.neighbors.KDTree.kernel_density:43
msgid "The array of (log)-density evaluations"
msgstr "El arreglo de evaluaciones de densidad (logarítmica)"

#: ../docstring of sklearn.neighbors.KDTree.query:8
#: sklearn.neighbors.KDTree.query_radius:8
msgid "An array of points to query"
msgstr "Un arreglo de puntos a consultar"

#: ../docstring of sklearn.neighbors.KDTree.query:11
msgid "**k**"
msgstr "**k**"

#: ../docstring of
msgid "int, default=1"
msgstr "int, default=1"

#: ../docstring of sklearn.neighbors.KDTree.query:11
msgid "The number of nearest neighbors to return"
msgstr "El número de vecinos más cercanos a devolver"

#: ../docstring of sklearn.neighbors.KDTree.query:15
#: sklearn.neighbors.KDTree.query_radius:20
msgid "**return_distance**"
msgstr "**return_distance**"

#: ../docstring of
msgid "bool, default=True"
msgstr "bool, default=True"

#: ../docstring of sklearn.neighbors.KDTree.query:14
msgid "if True, return a tuple (d, i) of distances and indices if False, return array i"
msgstr "si es True, devuelve una tupla (d, i) de distancias e índices si es False, devuelve el arreglo i"

#: ../docstring of sklearn.neighbors.KDTree.query:21
#: sklearn.neighbors.KDTree.two_point_correlation:17
msgid "**dualtree**"
msgstr "**dualtree**"

#: ../docstring of sklearn.neighbors.KDTree.query:18
msgid "if True, use the dual tree formalism for the query: a tree is built for the query points, and the pair of trees is used to efficiently search this space.  This can lead to better performance as the number of points grows large."
msgstr "si es True, utiliza el formalismo de árbol dual para la consulta: se construye un árbol para los puntos de la consulta, y el par de árboles se utiliza para buscar eficientemente en este espacio.  Esto puede conducir a un mejor rendimiento a medida que el número de puntos crece."

#: ../docstring of sklearn.neighbors.KDTree.query:24
msgid "if True, then query the nodes in a breadth-first manner. Otherwise, query the nodes in a depth-first manner."
msgstr "si es True, se consultan los nodos de una manera breadth-first. En caso contrario, consulta los nodos en profundidad."

#: ../docstring of sklearn.neighbors.KDTree.query:30
#: sklearn.neighbors.KDTree.query_radius:32
msgid "**sort_results**"
msgstr "**sort_results**"

#: ../docstring of sklearn.neighbors.KDTree.query:28
msgid "if True, then distances and indices of each point are sorted on return, so that the first column contains the closest points. Otherwise, neighbors are returned in an arbitrary order."
msgstr "si es True, entonces las distancias y los índices de cada punto se ordenan al regresar, de manera que la primera columna contiene los puntos más cercanos. En caso contrario, los vecinos se devuelven en un orden arbitrario."

#: ../docstring of sklearn.neighbors.KDTree.query:35
#: sklearn.neighbors.KDTree.query:57
msgid "**i**"
msgstr "**i**"

#: ../docstring of
msgid "if return_distance == False"
msgstr "if return_distance == False"

#: ../docstring of sklearn.neighbors.KDTree.query:38
msgid "**(d,i)**"
msgstr "**(d,i)**"

#: ../docstring of
msgid "if return_distance == True"
msgstr "if return_distance == True"

#: ../docstring of sklearn.neighbors.KDTree.query:42
msgid "**d**"
msgstr "**d**"

#: ../docstring of
msgid "ndarray of shape X.shape[:-1] + (k,), dtype=double"
msgstr "ndarray de forma X.forma[:-1] + (k,), dtype=double"

#: ../docstring of sklearn.neighbors.KDTree.query:41
msgid "Each entry gives the list of distances to the neighbors of the corresponding point."
msgstr "Cada entrada da la lista de distancias a los vecinos del punto correspondiente."

#: ../docstring of
msgid "ndarray of shape X.shape[:-1] + (k,), dtype=int"
msgstr "ndarray de forma X.forma[:-1] + (k,), dtype=int"

#: ../docstring of sklearn.neighbors.KDTree.query:45
msgid "Each entry gives the list of indices of neighbors of the corresponding point."
msgstr "Cada entrada da la lista de índices de los vecinos del punto correspondiente."

#: ../docstring of sklearn.neighbors.KDTree.query_radius:12
#: sklearn.neighbors.KDTree.two_point_correlation:12
msgid "**r**"
msgstr "**r**"

#: ../docstring of
msgid "distance within which neighbors are returned"
msgstr "distancia dentro de la cual se devuelven los vecinos"

#: ../docstring of sklearn.neighbors.KDTree.query_radius:11
msgid "r can be a single value, or an array of values of shape x.shape[:-1] if different radii are desired for each point."
msgstr "r puede ser un valor único, o un arreglo de valores de forma x.shape[:-1] si se desean diferentes radios para cada punto."

#: ../docstring of sklearn.neighbors.KDTree.query_radius:15
msgid "if True,  return distances to neighbors of each point if False, return only neighbors Note that unlike the query() method, setting return_distance=True here adds to the computation time.  Not all distances need to be calculated explicitly for return_distance=False.  Results are not sorted by default: see ``sort_results`` keyword."
msgstr "si es True, devuelve las distancias a los vecinos de cada punto si es False, devuelve sólo los vecinos. Ten en cuenta que, a diferencia del método query(), establecer return_distance=True aquí aumenta el tiempo de cálculo.  No es necesario calcular explícitamente todas las distancias para return_distance=False.  Los resultados no están ordenados por defecto: ver la palabra clave ``sort_results``."

#: ../docstring of sklearn.neighbors.KDTree.query_radius:26
msgid "**count_only**"
msgstr "**count_only**"

#: ../docstring of sklearn.neighbors.KDTree.query_radius:23
msgid "if True,  return only the count of points within distance r if False, return the indices of all points within distance r If return_distance==True, setting count_only=True will result in an error."
msgstr "si es True, devuelve sólo el recuento de puntos dentro de la distancia r si es False, devuelve los índices de todos los puntos dentro de la distancia r Si return_distance==True, establecer count_only=True dará lugar a un error."

#: ../docstring of sklearn.neighbors.KDTree.query_radius:29
msgid "if True, the distances and indices will be sorted before being returned.  If False, the results will not be sorted.  If return_distance == False, setting sort_results = True will result in an error."
msgstr "si es True, las distancias e índices serán ordenados antes de ser devueltos.  Si es False, los resultados no se ordenarán.  Si return_distance == False, al establecer sort_results = True se producirá un error."

#: ../docstring of sklearn.neighbors.KDTree.query_radius:37
#: sklearn.neighbors.KDTree.query_radius:47
msgid "**count**"
msgstr "**count**"

#: ../docstring of
msgid "if count_only == True"
msgstr "if count_only == True"

#: ../docstring of sklearn.neighbors.KDTree.query_radius:40
#: sklearn.neighbors.KDTree.query_radius:53
msgid "**ind**"
msgstr "**ind**"

#: ../docstring of
msgid "if count_only == False and return_distance == False"
msgstr "if count_only == False and return_distance == False"

#: ../docstring of sklearn.neighbors.KDTree.query_radius:43
msgid "**(ind, dist)**"
msgstr "**(ind, dist)**"

#: ../docstring of
msgid "if count_only == False and return_distance == True"
msgstr "if count_only == False and return_distance == True"

#: ../docstring of
msgid "ndarray of shape X.shape[:-1], dtype=int"
msgstr "ndarray de forma X.forma[:-1], dtype=int"

#: ../docstring of sklearn.neighbors.KDTree.query_radius:46
msgid "Each entry gives the number of neighbors within a distance r of the corresponding point."
msgstr "Cada entrada da el número de vecinos a una distancia r del punto correspondiente."

#: ../docstring of
msgid "ndarray of shape X.shape[:-1], dtype=object"
msgstr "ndarray de forma X.forma[:-1], dtype=object"

#: ../docstring of sklearn.neighbors.KDTree.query_radius:50
msgid "Each element is a numpy integer array listing the indices of neighbors of the corresponding point.  Note that unlike the results of a k-neighbors query, the returned neighbors are not sorted by distance by default."
msgstr "Cada elemento es un arreglo de enteros de numpy que lista los índices de los vecinos del punto correspondiente.  Ten en cuenta que, a diferencia de los resultados de una consulta k-neighbors, los vecinos devueltos no están ordenados por distancia de forma predeterminada."

#: ../docstring of sklearn.neighbors.KDTree.query_radius:68
msgid "**dist**"
msgstr "**dist**"

#: ../docstring of sklearn.neighbors.KDTree.query_radius:56
msgid "Each element is a numpy double array listing the distances corresponding to indices in i."
msgstr "Cada elemento es un arreglo doble de numpy que lista las distancias correspondientes a los índices en i."

#: ../docstring of
msgid "array-like"
msgstr "array-like"

#: ../docstring of sklearn.neighbors.KDTree.two_point_correlation:12
msgid "A one-dimensional array of distances"
msgstr "Un arreglo unidimensional de distancias"

#: ../docstring of sklearn.neighbors.KDTree.two_point_correlation:15
msgid "If True, use a dualtree algorithm.  Otherwise, use a single-tree algorithm.  Dual tree algorithms can have better scaling for large N."
msgstr "Si es True, utiliza un algoritmo de doble árbol.  En caso contrario, utilice un algoritmo de árbol único.  Los algoritmos de árbol dual pueden tener un mejor escalado para N grandes."

#: ../docstring of sklearn.neighbors.KDTree.two_point_correlation:34
msgid "**counts**"
msgstr "**counts**"

#: ../docstring of
msgid "ndarray"
msgstr "ndarray"

#: ../docstring of sklearn.neighbors.KDTree.two_point_correlation:22
msgid "counts[i] contains the number of pairs of points with distance less than or equal to r[i]"
msgstr "counts[i] contiene el número de pares de puntos con distancia menor o igual a r[i]"

