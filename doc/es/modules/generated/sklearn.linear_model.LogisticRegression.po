msgid ""
msgstr ""
"Project-Id-Version: scikit-learn\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-03-31 12:43-0400\n"
"PO-Revision-Date: 2021-04-15 06:12\n"
"Last-Translator: \n"
"Language-Team: Spanish\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Crowdin-Project: scikit-learn\n"
"X-Crowdin-Project-ID: 450526\n"
"X-Crowdin-Language: es-ES\n"
"X-Crowdin-File: /main/doc/en/modules/generated/sklearn.linear_model.LogisticRegression.po\n"
"X-Crowdin-File-ID: 5432\n"
"Language: es_ES\n"

#: ../modules/generated/sklearn.linear_model.LogisticRegression.rst:2
msgid ":mod:`sklearn.linear_model`.LogisticRegression"
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:2
msgid "Logistic Regression (aka logit, MaxEnt) classifier."
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:4
msgid "In the multiclass case, the training algorithm uses the one-vs-rest (OvR) scheme if the 'multi_class' option is set to 'ovr', and uses the cross-entropy loss if the 'multi_class' option is set to 'multinomial'. (Currently the 'multinomial' option is supported only by the 'lbfgs', 'sag', 'saga' and 'newton-cg' solvers.)"
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:10
msgid "This class implements regularized logistic regression using the 'liblinear' library, 'newton-cg', 'sag', 'saga' and 'lbfgs' solvers. **Note that regularization is applied by default**. It can handle both dense and sparse input. Use C-ordered arrays or CSR matrices containing 64-bit floats for optimal performance; any other input format will be converted (and copied)."
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:17
msgid "The 'newton-cg', 'sag', and 'lbfgs' solvers support only L2 regularization with primal formulation, or no regularization. The 'liblinear' solver supports both L1 and L2 regularization, with a dual formulation only for the L2 penalty. The Elastic-Net regularization is only supported by the 'saga' solver."
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:23
msgid "Read more in the :ref:`User Guide <logistic_regression>`."
msgstr ""

#: of sklearn.base.BaseEstimator.get_params
#: sklearn.base.BaseEstimator.set_params sklearn.base.ClassifierMixin.score
#: sklearn.linear_model._base.LinearClassifierMixin.decision_function
#: sklearn.linear_model._base.LinearClassifierMixin.predict
#: sklearn.linear_model._logistic.LogisticRegression
#: sklearn.linear_model._logistic.LogisticRegression.fit
#: sklearn.linear_model._logistic.LogisticRegression.predict_log_proba
#: sklearn.linear_model._logistic.LogisticRegression.predict_proba
msgid "Parameters"
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:34
msgid "**penalty**"
msgstr ""

#: of
msgid "{'l1', 'l2', 'elasticnet', 'none'}, default='l2'"
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:28
msgid "Used to specify the norm used in the penalization. The 'newton-cg', 'sag' and 'lbfgs' solvers support only l2 penalties. 'elasticnet' is only supported by the 'saga' solver. If 'none' (not supported by the liblinear solver), no regularization is applied."
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:33
msgid "l1 penalty with SAGA solver (allowing 'multinomial' + L1)"
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:39
msgid "**dual**"
msgstr ""

#: of
msgid "bool, default=False"
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:37
msgid "Dual or primal formulation. Dual formulation is only implemented for l2 penalty with liblinear solver. Prefer dual=False when n_samples > n_features."
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:42
msgid "**tol**"
msgstr ""

#: of
msgid "float, default=1e-4"
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:42
msgid "Tolerance for stopping criteria."
msgstr ""

#: of sklearn.linear_model._base.LinearClassifierMixin.predict:24
#: sklearn.linear_model._logistic.LogisticRegression:47
msgid "**C**"
msgstr ""

#: of
msgid "float, default=1.0"
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:45
msgid "Inverse of regularization strength; must be a positive float. Like in support vector machines, smaller values specify stronger regularization."
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:51
msgid "**fit_intercept**"
msgstr ""

#: of
msgid "bool, default=True"
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:50
msgid "Specifies if a constant (a.k.a. bias or intercept) should be added to the decision function."
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:64
msgid "**intercept_scaling**"
msgstr ""

#: of
msgid "float, default=1"
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:54
msgid "Useful only when the solver 'liblinear' is used and self.fit_intercept is set to True. In this case, x becomes [x, self.intercept_scaling], i.e. a \"synthetic\" feature with constant value equal to intercept_scaling is appended to the instance vector. The intercept becomes ``intercept_scaling * synthetic_feature_weight``."
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:61
msgid "Note! the synthetic feature weight is subject to l1/l2 regularization as all other features. To lessen the effect of regularization on synthetic feature weight (and therefore on the intercept) intercept_scaling has to be increased."
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:78
msgid "**class_weight**"
msgstr ""

#: of
msgid "dict or 'balanced', default=None"
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:67
msgid "Weights associated with classes in the form ``{class_label: weight}``. If not given, all classes are supposed to have weight one."
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:70
msgid "The \"balanced\" mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as ``n_samples / (n_classes * np.bincount(y))``."
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:74
msgid "Note that these weights will be multiplied with sample_weight (passed through the fit method) if sample_weight is specified."
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:77
msgid "*class_weight='balanced'*"
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:82
msgid "**random_state**"
msgstr ""

#: of
msgid "int, RandomState instance, default=None"
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:81
msgid "Used when ``solver`` == 'sag', 'saga' or 'liblinear' to shuffle the data. See :term:`Glossary <random_state>` for details."
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:106
msgid "**solver**"
msgstr ""

#: of
msgid "{'newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'},             default='lbfgs'"
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:85
msgid "Algorithm to use in the optimization problem."
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:87
msgid "For small datasets, 'liblinear' is a good choice, whereas 'sag' and 'saga' are faster for large ones."
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:89
msgid "For multiclass problems, only 'newton-cg', 'sag', 'saga' and 'lbfgs' handle multinomial loss; 'liblinear' is limited to one-versus-rest schemes."
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:92
msgid "'newton-cg', 'lbfgs', 'sag' and 'saga' handle L2 or no penalty"
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:93
msgid "'liblinear' and 'saga' also handle L1 penalty"
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:94
msgid "'saga' also supports 'elasticnet' penalty"
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:95
msgid "'liblinear' does not support setting ``penalty='none'``"
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:97
msgid "Note that 'sag' and 'saga' fast convergence is only guaranteed on features with approximately the same scale. You can preprocess the data with a scaler from sklearn.preprocessing."
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:101
msgid "Stochastic Average Gradient descent solver."
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:103
msgid "SAGA solver."
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:105
msgid "The default solver changed from 'liblinear' to 'lbfgs' in 0.22."
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:109
msgid "**max_iter**"
msgstr ""

#: of
msgid "int, default=100"
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:109
msgid "Maximum number of iterations taken for the solvers to converge."
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:122
msgid "**multi_class**"
msgstr ""

#: of
msgid "{'auto', 'ovr', 'multinomial'}, default='auto'"
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:112
msgid "If the option chosen is 'ovr', then a binary problem is fit for each label. For 'multinomial' the loss minimised is the multinomial loss fit across the entire probability distribution, *even when the data is binary*. 'multinomial' is unavailable when solver='liblinear'. 'auto' selects 'ovr' if the data is binary, or if solver='liblinear', and otherwise selects 'multinomial'."
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:119
msgid "Stochastic Average Gradient descent solver for 'multinomial' case."
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:121
msgid "Default changed from 'ovr' to 'auto' in 0.22."
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:126
msgid "**verbose**"
msgstr ""

#: of
msgid "int, default=0"
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:125
msgid "For the liblinear and lbfgs solvers set verbose to any positive number for verbosity."
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:134
msgid "**warm_start**"
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:129
msgid "When set to True, reuse the solution of the previous call to fit as initialization, otherwise, just erase the previous solution. Useless for liblinear solver. See :term:`the Glossary <warm_start>`."
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:133
msgid "*warm_start* to support *lbfgs*, *newton-cg*, *sag*, *saga* solvers."
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:142
msgid "**n_jobs**"
msgstr ""

#: of
msgid "int, default=None"
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:137
msgid "Number of CPU cores used when parallelizing over classes if multi_class='ovr'\". This parameter is ignored when the ``solver`` is set to 'liblinear' regardless of whether 'multi_class' is specified or not. ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context. ``-1`` means using all processors. See :term:`Glossary <n_jobs>` for more details."
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:152
msgid "**l1_ratio**"
msgstr ""

#: of
msgid "float, default=None"
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:145
msgid "The Elastic-Net mixing parameter, with ``0 <= l1_ratio <= 1``. Only used if ``penalty='elasticnet'``. Setting ``l1_ratio=0`` is equivalent to using ``penalty='l2'``, while setting ``l1_ratio=1`` is equivalent to using ``penalty='l1'``. For ``0 < l1_ratio <1``, the penalty is a combination of L1 and L2."
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression
msgid "Attributes"
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:157
msgid "**classes_**"
msgstr ""

#: of
msgid "ndarray of shape (n_classes, )"
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:157
msgid "A list of class labels known to the classifier."
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:164
msgid "**coef_**"
msgstr ""

#: of
msgid "ndarray of shape (1, n_features) or (n_classes, n_features)"
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:160
msgid "Coefficient of the features in the decision function."
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:162
msgid "`coef_` is of shape (1, n_features) when the given problem is binary. In particular, when `multi_class='multinomial'`, `coef_` corresponds to outcome 1 (True) and `-coef_` corresponds to outcome 0 (False)."
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:173
msgid "**intercept_**"
msgstr ""

#: of
msgid "ndarray of shape (1,) or (n_classes,)"
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:167
msgid "Intercept (a.k.a. bias) added to the decision function."
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:169
msgid "If `fit_intercept` is set to False, the intercept is set to zero. `intercept_` is of shape (1,) when the given problem is binary. In particular, when `multi_class='multinomial'`, `intercept_` corresponds to outcome 1 (True) and `-intercept_` corresponds to outcome 0 (False)."
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:186
msgid "**n_iter_**"
msgstr ""

#: of
msgid "ndarray of shape (n_classes,) or (1, )"
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:176
msgid "Actual number of iterations for all classes. If binary or multinomial, it returns only 1 element. For liblinear solver, only the maximum number of iteration across all classes is given."
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:182
msgid "In SciPy <= 1.0.0 the number of lbfgs iterations may exceed ``max_iter``. ``n_iter_`` will now report at most ``max_iter``."
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:191
msgid ":obj:`SGDClassifier`"
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:192
msgid "Incrementally trained logistic regression (when given the parameter ``loss=\"log\"``)."
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:193
msgid ":obj:`LogisticRegressionCV`"
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:194
msgid "Logistic regression with built-in cross validation."
msgstr ""

#: of sklearn.linear_model._base.SparseCoefMixin.sparsify:24
#: sklearn.linear_model._logistic.LogisticRegression:198
#: sklearn.linear_model._logistic.LogisticRegression.fit:34
msgid "Notes"
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:199
msgid "The underlying C implementation uses a random number generator to select features when fitting the model. It is thus not uncommon, to have slightly different results for the same input data. If that happens, try with a smaller tol parameter."
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:204
msgid "Predict output may not match that of standalone liblinear in certain cases. See :ref:`differences from liblinear <liblinear_differences>` in the narrative documentation."
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:209
msgid "References"
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:212
msgid "L-BFGS-B -- Software for Large-scale Bound-constrained Optimization"
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:211
msgid "Ciyou Zhu, Richard Byrd, Jorge Nocedal and Jose Luis Morales. http://users.iems.northwestern.edu/~nocedal/lbfgsb.html"
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:215
msgid "LIBLINEAR -- A Library for Large Linear Classification"
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:215
msgid "https://www.csie.ntu.edu.tw/~cjlin/liblinear/"
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:219
msgid "SAG -- Mark Schmidt, Nicolas Le Roux, and Francis Bach"
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:218
msgid "Minimizing Finite Sums with the Stochastic Average Gradient https://hal.inria.fr/hal-00860051/document"
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:224
msgid "SAGA -- Defazio, A., Bach F. & Lacoste-Julien S. (2014)."
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:222
msgid "SAGA: A Fast Incremental Gradient Method With Support for Non-Strongly Convex Composite Objectives https://arxiv.org/abs/1407.0202"
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:229
msgid "Hsiang-Fu Yu, Fang-Lan Huang, Chih-Jen Lin (2011). Dual coordinate descent"
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:227
msgid "methods for logistic regression and maximum entropy models. Machine Learning 85(1-2):41-75. https://www.csie.ntu.edu.tw/~cjlin/papers/maxent_dual.pdf"
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:236
msgid "Examples"
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:250
msgid "Methods"
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:263:<autosummary>:1
msgid ":obj:`decision_function <sklearn.linear_model.LogisticRegression.decision_function>`\\"
msgstr ""

#: of sklearn.linear_model._base.LinearClassifierMixin.decision_function:2
#: sklearn.linear_model._logistic.LogisticRegression:263:<autosummary>:1
msgid "Predict confidence scores for samples."
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:263:<autosummary>:1
msgid ":obj:`densify <sklearn.linear_model.LogisticRegression.densify>`\\"
msgstr ""

#: of sklearn.linear_model._base.SparseCoefMixin.densify:2
#: sklearn.linear_model._logistic.LogisticRegression:263:<autosummary>:1
msgid "Convert coefficient matrix to dense array format."
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:263:<autosummary>:1
msgid ":obj:`fit <sklearn.linear_model.LogisticRegression.fit>`\\"
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression.fit:2
#: sklearn.linear_model._logistic.LogisticRegression:263:<autosummary>:1
msgid "Fit the model according to the given training data."
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:263:<autosummary>:1
msgid ":obj:`get_params <sklearn.linear_model.LogisticRegression.get_params>`\\"
msgstr ""

#: of sklearn.base.BaseEstimator.get_params:2
#: sklearn.linear_model._logistic.LogisticRegression:263:<autosummary>:1
msgid "Get parameters for this estimator."
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:263:<autosummary>:1
msgid ":obj:`predict <sklearn.linear_model.LogisticRegression.predict>`\\"
msgstr ""

#: of sklearn.linear_model._base.LinearClassifierMixin.predict:2
#: sklearn.linear_model._logistic.LogisticRegression:263:<autosummary>:1
msgid "Predict class labels for samples in X."
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:263:<autosummary>:1
msgid ":obj:`predict_log_proba <sklearn.linear_model.LogisticRegression.predict_log_proba>`\\"
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression.predict_log_proba:2
#: sklearn.linear_model._logistic.LogisticRegression:263:<autosummary>:1
msgid "Predict logarithm of probability estimates."
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:263:<autosummary>:1
msgid ":obj:`predict_proba <sklearn.linear_model.LogisticRegression.predict_proba>`\\"
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression.predict_proba:2
#: sklearn.linear_model._logistic.LogisticRegression:263:<autosummary>:1
msgid "Probability estimates."
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:263:<autosummary>:1
msgid ":obj:`score <sklearn.linear_model.LogisticRegression.score>`\\"
msgstr ""

#: of sklearn.base.ClassifierMixin.score:2
#: sklearn.linear_model._logistic.LogisticRegression:263:<autosummary>:1
msgid "Return the mean accuracy on the given test data and labels."
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:263:<autosummary>:1
msgid ":obj:`set_params <sklearn.linear_model.LogisticRegression.set_params>`\\"
msgstr ""

#: of sklearn.base.BaseEstimator.set_params:2
#: sklearn.linear_model._logistic.LogisticRegression:263:<autosummary>:1
msgid "Set the parameters of this estimator."
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression:263:<autosummary>:1
msgid ":obj:`sparsify <sklearn.linear_model.LogisticRegression.sparsify>`\\"
msgstr ""

#: of sklearn.linear_model._base.SparseCoefMixin.sparsify:2
#: sklearn.linear_model._logistic.LogisticRegression:263:<autosummary>:1
msgid "Convert coefficient matrix to sparse format."
msgstr ""

#: of sklearn.linear_model._base.LinearClassifierMixin.decision_function:4
msgid "The confidence score for a sample is proportional to the signed distance of that sample to the hyperplane."
msgstr ""

#: of sklearn.base.ClassifierMixin.score:11
#: sklearn.linear_model._base.LinearClassifierMixin.decision_function:10
#: sklearn.linear_model._base.LinearClassifierMixin.predict:8
#: sklearn.linear_model._logistic.LogisticRegression.fit:9
#: sklearn.linear_model._logistic.LogisticRegression.predict_log_proba:11
#: sklearn.linear_model._logistic.LogisticRegression.predict_proba:18
msgid "**X**"
msgstr ""

#: of
msgid "array-like or sparse matrix, shape (n_samples, n_features)"
msgstr ""

#: of sklearn.linear_model._base.LinearClassifierMixin.decision_function:10
#: sklearn.linear_model._base.LinearClassifierMixin.predict:8
msgid "Samples."
msgstr ""

#: of sklearn.base.BaseEstimator.get_params
#: sklearn.base.BaseEstimator.set_params sklearn.base.ClassifierMixin.score
#: sklearn.linear_model._base.LinearClassifierMixin.decision_function
#: sklearn.linear_model._base.LinearClassifierMixin.predict
#: sklearn.linear_model._base.SparseCoefMixin.densify
#: sklearn.linear_model._base.SparseCoefMixin.sparsify
#: sklearn.linear_model._logistic.LogisticRegression.fit
#: sklearn.linear_model._logistic.LogisticRegression.predict_log_proba
#: sklearn.linear_model._logistic.LogisticRegression.predict_proba
msgid "Returns"
msgstr ""

#: of sklearn.linear_model._base.LinearClassifierMixin.decision_function:28
msgid "array, shape=(n_samples,) if n_classes == 2 else (n_samples, n_classes)"
msgstr ""

#: of sklearn.linear_model._base.LinearClassifierMixin.decision_function:15
msgid "Confidence scores per (sample, class) combination. In the binary case, confidence score for self.classes_[1] where >0 means this class would be predicted."
msgstr ""

#: of sklearn.linear_model._base.SparseCoefMixin.densify:4
msgid "Converts the ``coef_`` member (back) to a numpy.ndarray. This is the default format of ``coef_`` and is required for fitting, so calling this method is only required on models that have previously been sparsified; otherwise, it is a no-op."
msgstr ""

#: of sklearn.linear_model._base.SparseCoefMixin.densify:24
#: sklearn.linear_model._base.SparseCoefMixin.sparsify:21
#: sklearn.linear_model._logistic.LogisticRegression.fit:31
msgid "self"
msgstr ""

#: of sklearn.linear_model._base.SparseCoefMixin.densify:13
#: sklearn.linear_model._base.SparseCoefMixin.sparsify:14
#: sklearn.linear_model._logistic.LogisticRegression.fit:24
msgid "Fitted estimator."
msgstr ""

#: of
msgid "{array-like, sparse matrix} of shape (n_samples, n_features)"
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression.fit:8
msgid "Training vector, where n_samples is the number of samples and n_features is the number of features."
msgstr ""

#: of sklearn.base.ClassifierMixin.score:14
#: sklearn.linear_model._logistic.LogisticRegression.fit:12
msgid "**y**"
msgstr ""

#: of
msgid "array-like of shape (n_samples,)"
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression.fit:12
msgid "Target vector relative to X."
msgstr ""

#: of sklearn.base.ClassifierMixin.score:17
#: sklearn.linear_model._logistic.LogisticRegression.fit:19
msgid "**sample_weight**"
msgstr ""

#: of
msgid "array-like of shape (n_samples,) default=None"
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression.fit:15
msgid "Array of weights that are assigned to individual samples. If not provided, then each sample is given unit weight."
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression.fit:18
msgid "*sample_weight* support to LogisticRegression."
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression.fit:35
msgid "The SAGA solver supports both float64 and float32 bit arrays."
msgstr ""

#: of sklearn.base.BaseEstimator.get_params:9
msgid "**deep**"
msgstr ""

#: of sklearn.base.BaseEstimator.get_params:8
msgid "If True, will return the parameters for this estimator and contained subobjects that are estimators."
msgstr ""

#: of sklearn.base.BaseEstimator.get_params:25
msgid "**params**"
msgstr ""

#: of
msgid "dict"
msgstr ""

#: of sklearn.base.BaseEstimator.get_params:14
msgid "Parameter names mapped to their values."
msgstr ""

#: of
msgid "array, shape [n_samples]"
msgstr ""

#: of sklearn.linear_model._base.LinearClassifierMixin.predict:13
msgid "Predicted class label per sample."
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression.predict_log_proba:4
#: sklearn.linear_model._logistic.LogisticRegression.predict_proba:4
msgid "The returned estimates for all classes are ordered by the label of classes."
msgstr ""

#: of
msgid "array-like of shape (n_samples, n_features)"
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression.predict_log_proba:10
#: sklearn.linear_model._logistic.LogisticRegression.predict_proba:17
msgid "Vector to be scored, where `n_samples` is the number of samples and `n_features` is the number of features."
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression.predict_log_proba:28
#: sklearn.linear_model._logistic.LogisticRegression.predict_proba:35
msgid "**T**"
msgstr ""

#: of
msgid "array-like of shape (n_samples, n_classes)"
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression.predict_log_proba:16
msgid "Returns the log-probability of the sample for each class in the model, where classes are ordered as they are in ``self.classes_``."
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression.predict_proba:7
msgid "For a multi_class problem, if multi_class is set to be \"multinomial\" the softmax function is used to find the predicted probability of each class. Else use a one-vs-rest approach, i.e calculate the probability of each class assuming it to be positive using the logistic function. and normalize these values across all the classes."
msgstr ""

#: of sklearn.linear_model._logistic.LogisticRegression.predict_proba:23
msgid "Returns the probability of the sample for each class in the model, where classes are ordered as they are in ``self.classes_``."
msgstr ""

#: of sklearn.base.ClassifierMixin.score:4
msgid "In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted."
msgstr ""

#: of sklearn.base.ClassifierMixin.score:11
msgid "Test samples."
msgstr ""

#: of
msgid "array-like of shape (n_samples,) or (n_samples, n_outputs)"
msgstr ""

#: of sklearn.base.ClassifierMixin.score:14
msgid "True labels for `X`."
msgstr ""

#: of
msgid "array-like of shape (n_samples,), default=None"
msgstr ""

#: of sklearn.base.ClassifierMixin.score:17
msgid "Sample weights."
msgstr ""

#: of sklearn.base.ClassifierMixin.score:33
msgid "**score**"
msgstr ""

#: of
msgid "float"
msgstr ""

#: of sklearn.base.ClassifierMixin.score:22
msgid "Mean accuracy of ``self.predict(X)`` wrt. `y`."
msgstr ""

#: of sklearn.base.BaseEstimator.set_params:4
msgid "The method works on simple estimators as well as on nested objects (such as :class:`~sklearn.pipeline.Pipeline`). The latter have parameters of the form ``<component>__<parameter>`` so that it's possible to update each component of a nested object."
msgstr ""

#: of sklearn.base.BaseEstimator.set_params:12
msgid "**\\*\\*params**"
msgstr ""

#: of sklearn.base.BaseEstimator.set_params:12
msgid "Estimator parameters."
msgstr ""

#: of sklearn.base.BaseEstimator.set_params:28
msgid "**self**"
msgstr ""

#: of
msgid "estimator instance"
msgstr ""

#: of sklearn.base.BaseEstimator.set_params:17
msgid "Estimator instance."
msgstr ""

#: of sklearn.linear_model._base.SparseCoefMixin.sparsify:4
msgid "Converts the ``coef_`` member to a scipy.sparse matrix, which for L1-regularized models can be much more memory- and storage-efficient than the usual numpy.ndarray representation."
msgstr ""

#: of sklearn.linear_model._base.SparseCoefMixin.sparsify:8
msgid "The ``intercept_`` member is not converted."
msgstr ""

#: of sklearn.linear_model._base.SparseCoefMixin.sparsify:25
#, python-format
msgid "For non-sparse models, i.e. when there are not many zeros in ``coef_``, this may actually *increase* memory usage, so use this method with care. A rule of thumb is that the number of zero elements, which can be computed with ``(coef_ == 0).sum()``, must be more than 50% for this to provide significant benefits."
msgstr ""

#: of sklearn.linear_model._base.SparseCoefMixin.sparsify:31
msgid "After calling this method, further fitting with the partial_fit method (if any) will not work until you call densify."
msgstr ""

#: ../modules/generated/sklearn.linear_model.LogisticRegression.examples:4
msgid "Examples using ``sklearn.linear_model.LogisticRegression``"
msgstr ""

#: ../modules/generated/sklearn.linear_model.LogisticRegression.examples:15
#: ../modules/generated/sklearn.linear_model.LogisticRegression.examples:23
msgid ":ref:`sphx_glr_auto_examples_release_highlights_plot_release_highlights_0_24_0.py`"
msgstr ""

#: ../modules/generated/sklearn.linear_model.LogisticRegression.examples:34
#: ../modules/generated/sklearn.linear_model.LogisticRegression.examples:42
msgid ":ref:`sphx_glr_auto_examples_release_highlights_plot_release_highlights_0_22_0.py`"
msgstr ""

#: ../modules/generated/sklearn.linear_model.LogisticRegression.examples:53
#: ../modules/generated/sklearn.linear_model.LogisticRegression.examples:61
msgid ":ref:`sphx_glr_auto_examples_miscellaneous_plot_display_object_visualization.py`"
msgstr ""

#: ../modules/generated/sklearn.linear_model.LogisticRegression.examples:72
#: ../modules/generated/sklearn.linear_model.LogisticRegression.examples:80
msgid ":ref:`sphx_glr_auto_examples_multioutput_plot_classifier_chain_yeast.py`"
msgstr ""

#: ../modules/generated/sklearn.linear_model.LogisticRegression.examples:91
#: ../modules/generated/sklearn.linear_model.LogisticRegression.examples:99
msgid ":ref:`sphx_glr_auto_examples_compose_plot_digits_pipe.py`"
msgstr ""

#: ../modules/generated/sklearn.linear_model.LogisticRegression.examples:110
#: ../modules/generated/sklearn.linear_model.LogisticRegression.examples:118
msgid ":ref:`sphx_glr_auto_examples_compose_plot_column_transformer_mixed_types.py`"
msgstr ""

#~ msgid ":ref:`sphx_glr_auto_examples_linear_model_plot_logistic.py`"
#~ msgstr ""

#~ msgid ":ref:`sphx_glr_auto_examples_linear_model_plot_logistic_path.py`"
#~ msgstr ""

#~ msgid ":ref:`sphx_glr_auto_examples_linear_model_plot_iris_logistic.py`"
#~ msgstr ""

#~ msgid ":ref:`sphx_glr_auto_examples_linear_model_plot_sgd_comparison.py`"
#~ msgstr ""

#~ msgid ":ref:`sphx_glr_auto_examples_linear_model_plot_sparse_logistic_regression_mnist.py`"
#~ msgstr ""

#~ msgid ":ref:`sphx_glr_auto_examples_linear_model_plot_logistic_multinomial.py`"
#~ msgstr ""

#~ msgid ":ref:`sphx_glr_auto_examples_linear_model_plot_logistic_l1_l2_sparsity.py`"
#~ msgstr ""

#~ msgid ":ref:`sphx_glr_auto_examples_linear_model_plot_sparse_logistic_regression_20newsgroups.py`"
#~ msgstr ""

#~ msgid ":ref:`sphx_glr_auto_examples_miscellaneous_plot_changed_only_pprint_parameter.py`"
#~ msgstr ""

#~ msgid ":ref:`sphx_glr_auto_examples_neural_networks_plot_rbm_logistic_classification.py`"
#~ msgstr ""

#~ msgid ":ref:`sphx_glr_auto_examples_preprocessing_plot_discretization_classification.py`"
#~ msgstr ""

#~ msgid ":ref:`sphx_glr_auto_examples_exercises_plot_digits_classification_exercise.py`"
#~ msgstr ""

