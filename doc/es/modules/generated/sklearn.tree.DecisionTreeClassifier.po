msgid ""
msgstr ""
"Project-Id-Version: scikit-learn\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-03-31 11:24-0400\n"
"PO-Revision-Date: 2021-08-28 21:07\n"
"Last-Translator: \n"
"Language-Team: Spanish\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Crowdin-Project: scikit-learn\n"
"X-Crowdin-Project-ID: 450526\n"
"X-Crowdin-Language: es-ES\n"
"X-Crowdin-File: /main/doc/en/modules/generated/sklearn.tree.DecisionTreeClassifier.po\n"
"X-Crowdin-File-ID: 5350\n"
"Language: es_ES\n"

#: ../modules/generated/sklearn.tree.DecisionTreeClassifier.rst:2
msgid ":mod:`sklearn.tree`.DecisionTreeClassifier"
msgstr ":mod:`sklearn.tree`.DecisionTreeClassifier"

#: of sklearn.tree._classes.DecisionTreeClassifier:2
msgid "A decision tree classifier."
msgstr "Un clasificador de árbol de decisiones."

#: of sklearn.tree._classes.DecisionTreeClassifier:4
msgid "Read more in the :ref:`User Guide <tree>`."
msgstr "Lee más en el :ref:`Manual de usuario <tree>`."

#: of sklearn.base.BaseEstimator.get_params
#: sklearn.base.BaseEstimator.set_params sklearn.base.ClassifierMixin.score
#: sklearn.tree._classes.BaseDecisionTree.apply
#: sklearn.tree._classes.BaseDecisionTree.cost_complexity_pruning_path
#: sklearn.tree._classes.BaseDecisionTree.decision_path
#: sklearn.tree._classes.BaseDecisionTree.predict
#: sklearn.tree._classes.DecisionTreeClassifier
#: sklearn.tree._classes.DecisionTreeClassifier.fit
#: sklearn.tree._classes.DecisionTreeClassifier.predict_log_proba
#: sklearn.tree._classes.DecisionTreeClassifier.predict_proba
msgid "Parameters"
msgstr "Parámetros"

#: of sklearn.tree._classes.DecisionTreeClassifier:10
msgid "**criterion**"
msgstr "**criterion**"

#: of
msgid "{\"gini\", \"entropy\"}, default=\"gini\""
msgstr "{\"gini\", \"entropy\"}, default=\"gini\""

#: of sklearn.tree._classes.DecisionTreeClassifier:9
msgid "The function to measure the quality of a split. Supported criteria are \"gini\" for the Gini impurity and \"entropy\" for the information gain."
msgstr "La función de medir la calidad de una división, los criterios soportados son \"gini\" para la impureza de Gini y \"entropy\" para la ganancia de información."

#: of sklearn.tree._classes.DecisionTreeClassifier:15
msgid "**splitter**"
msgstr "**splitter**"

#: of
msgid "{\"best\", \"random\"}, default=\"best\""
msgstr "{\"best\", \"random\"}, default=\"best\""

#: of sklearn.tree._classes.DecisionTreeClassifier:13
msgid "The strategy used to choose the split at each node. Supported strategies are \"best\" to choose the best split and \"random\" to choose the best random split."
msgstr "La estrategia utilizada para elegir la división en cada nodo. Las estrategias apoyadas son \"best\" para elegir la mejor división y \"random\" para elegir la mejor división aleatoria."

#: of sklearn.tree._classes.DecisionTreeClassifier:20
msgid "**max_depth**"
msgstr "**max_depth**"

#: of
msgid "int, default=None"
msgstr "entero, default=None"

#: of sklearn.tree._classes.DecisionTreeClassifier:18
msgid "The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples."
msgstr "La profundidad máxima del árbol. Si None, entonces los nodos se expanden hasta que todas las hojas sean puras o hasta que todas contengan menos que min_samples_split muestras."

#: of sklearn.tree._classes.DecisionTreeClassifier:31
msgid "**min_samples_split**"
msgstr "**min_samples_split**"

#: of
msgid "int or float, default=2"
msgstr "entero o flotante, default=2"

#: of sklearn.tree._classes.DecisionTreeClassifier:23
msgid "The minimum number of samples required to split an internal node:"
msgstr "El número mínimo de muestras requeridas para dividir un nodo interno:"

#: of sklearn.tree._classes.DecisionTreeClassifier:25
msgid "If int, then consider `min_samples_split` as the minimum number."
msgstr "Si es entero, entonces considera `min_samples_split` como el número mínimo."

#: of sklearn.tree._classes.DecisionTreeClassifier:26
msgid "If float, then `min_samples_split` is a fraction and `ceil(min_samples_split * n_samples)` are the minimum number of samples for each split."
msgstr "Si float, entonces `min_samples_split` es una fracción y `ceil(min_samples_split * n_samples)` son el número mínimo de muestras para cada división."

#: of sklearn.tree._classes.DecisionTreeClassifier:30
#: sklearn.tree._classes.DecisionTreeClassifier:45
msgid "Added float values for fractions."
msgstr "Se añadieron valores flotantes para las fracciones."

#: of sklearn.tree._classes.DecisionTreeClassifier:46
msgid "**min_samples_leaf**"
msgstr "**min_samples_leaf**"

#: of
msgid "int or float, default=1"
msgstr "entero o punto flotante, default=1"

#: of sklearn.tree._classes.DecisionTreeClassifier:34
msgid "The minimum number of samples required to be at a leaf node. A split point at any depth will only be considered if it leaves at least ``min_samples_leaf`` training samples in each of the left and right branches.  This may have the effect of smoothing the model, especially in regression."
msgstr "El número mínimo de muestras requeridas para estar en un nodo de hoja. Un punto dividido a cualquier profundidad sólo se considerará si deja al menos ``min_samples_leaf`` muestras de entrenamiento en cada una de las ramas izquierda y derecha. Esto puede tener el efecto de suavizar el modelo, especialmente en regresión."

#: of sklearn.tree._classes.DecisionTreeClassifier:40
msgid "If int, then consider `min_samples_leaf` as the minimum number."
msgstr "Si es entero, entonces considera `min_samples_split` como el número mínimo."

#: of sklearn.tree._classes.DecisionTreeClassifier:41
msgid "If float, then `min_samples_leaf` is a fraction and `ceil(min_samples_leaf * n_samples)` are the minimum number of samples for each node."
msgstr "Si es flotante, entonces `min_samples_leaf` es una fracción y `ceil(min_samples_leaf * n_samples)` son el número mínimo de muestras para cada nodo."

#: of sklearn.tree._classes.DecisionTreeClassifier:51
msgid "**min_weight_fraction_leaf**"
msgstr "**min_weight_fraction_leaf**"

#: of
msgid "float, default=0.0"
msgstr "flotante, default=0.0"

#: of sklearn.tree._classes.DecisionTreeClassifier:49
msgid "The minimum weighted fraction of the sum total of weights (of all the input samples) required to be at a leaf node. Samples have equal weight when sample_weight is not provided."
msgstr "La fracción mínima ponderada de la suma total de las ponderaciones (de todas las muestras de entrada) requeridas para estar en un nodo de hoja. Las muestras tienen la misma ponderación cuando no se proporciona sample_weight."

#: of sklearn.tree._classes.DecisionTreeClassifier:67
msgid "**max_features**"
msgstr "**max_features**"

#: of
msgid "int, float or {\"auto\", \"sqrt\", \"log2\"}, default=None"
msgstr "int, float or {\"auto\", \"sqrt\", \"log2\"}, default=None"

#: of sklearn.tree._classes.DecisionTreeClassifier:54
msgid "The number of features to consider when looking for the best split:"
msgstr "El número de características a tener en cuenta cuando se busca la mejor división:"

#: of sklearn.tree._classes.DecisionTreeClassifier:56
msgid "If int, then consider `max_features` features at each split."
msgstr "Si es int, entonces considera las características `max_features` en cada división."

#: of sklearn.tree._classes.DecisionTreeClassifier:57
msgid "If float, then `max_features` is a fraction and `int(max_features * n_features)` features are considered at each split."
msgstr "Si es float, entonces `max_features` es una fracción y las características `int(max_features * n_features)` son consideradas en cada división."

#: of sklearn.tree._classes.DecisionTreeClassifier:60
msgid "If \"auto\", then `max_features=sqrt(n_features)`."
msgstr "Si es \"auto\", entonces `max_features=sqrt(n_features)`."

#: of sklearn.tree._classes.DecisionTreeClassifier:61
msgid "If \"sqrt\", then `max_features=sqrt(n_features)`."
msgstr "Si es \"sqrt\", entonces `max_features=sqrt(n_features)`."

#: of sklearn.tree._classes.DecisionTreeClassifier:62
msgid "If \"log2\", then `max_features=log2(n_features)`."
msgstr "Si es \"log2\", entonces `max_features=log2(n_features)`."

#: of sklearn.tree._classes.DecisionTreeClassifier:63
msgid "If None, then `max_features=n_features`."
msgstr "Si es None, entonces `max_features=n_features`."

#: of sklearn.tree._classes.DecisionTreeClassifier:65
msgid "Note: the search for a split does not stop until at least one valid partition of the node samples is found, even if it requires to effectively inspect more than ``max_features`` features."
msgstr "Nota: la búsqueda de una división no se detiene hasta que se encuentre al menos una partición válida de las muestras de nodos, incluso si requiere inspeccionar eficazmente más de las características de ``max_features``."

#: of sklearn.tree._classes.DecisionTreeClassifier:79
msgid "**random_state**"
msgstr "**random_state**"

#: of
msgid "int, RandomState instance or None, default=None"
msgstr "entero, instancia de RandomState o None, por defecto=None"

#: of sklearn.tree._classes.DecisionTreeClassifier:70
msgid "Controls the randomness of the estimator. The features are always randomly permuted at each split, even if ``splitter`` is set to ``\"best\"``. When ``max_features < n_features``, the algorithm will select ``max_features`` at random at each split before finding the best split among them. But the best found split may vary across different runs, even if ``max_features=n_features``. That is the case, if the improvement of the criterion is identical for several splits and one split has to be selected at random. To obtain a deterministic behaviour during fitting, ``random_state`` has to be fixed to an integer. See :term:`Glossary <random_state>` for details."
msgstr "Controla la aleatoriedad del estimador. Las características siempre son aleatoriamente permutadas en cada división, incluso si ``splitter`` es establecido a ``\"best\"``. Cuando ``max_features < n_features``, el algoritmo seleccionará ``max_features`` aleatoriamente en cada división antes de encontrar la mejor división entre ellos. Pero la mejor división encontrada podría variar a lo largo de diferentes ejecuciones, incluso sí ``max_features=n_features``. Ese es el caso, si la mejoría del criterio es idéntica para numerosas divisiones y una división tiene que ser seleccionada aleatoriamente. Para obtener un comportamiento determinístico durante el ajuste, ``random_state`` debe ser fijado a un entero. Ver el :term:`Glosario <random_state>` para más detalles."

#: of sklearn.tree._classes.DecisionTreeClassifier:84
msgid "**max_leaf_nodes**"
msgstr "**max_leaf_nodes**"

#: of sklearn.tree._classes.DecisionTreeClassifier:82
msgid "Grow a tree with ``max_leaf_nodes`` in best-first fashion. Best nodes are defined as relative reduction in impurity. If None then unlimited number of leaf nodes."
msgstr "Hace crecer un árbol con ``max_leaf_nodes`` en modo best-first. Los mejores nodos se definen como una reducción relativa de la impureza. Si es None, el número de nodos hoja es ilimitado."

#: of sklearn.tree._classes.DecisionTreeClassifier:102
msgid "**min_impurity_decrease**"
msgstr "**min_impurity_decrease**"

#: of sklearn.tree._classes.DecisionTreeClassifier:87
msgid "A node will be split if this split induces a decrease of the impurity greater than or equal to this value."
msgstr "Un nodo se dividirá si esta división induce una disminución de la impureza mayor o igual a este valor."

#: of sklearn.tree._classes.DecisionTreeClassifier:90
msgid "The weighted impurity decrease equation is the following::"
msgstr "La ecuación de disminución de impureza ponderada es la siguiente::"

#: of sklearn.tree._classes.DecisionTreeClassifier:95
msgid "where ``N`` is the total number of samples, ``N_t`` is the number of samples at the current node, ``N_t_L`` is the number of samples in the left child, and ``N_t_R`` is the number of samples in the right child."
msgstr "donde ``N`` es el número total de muestras, ``N_t`` es el número de muestras en el nodo actual, ``N_t_L`` es el número de muestras en el hijo izquierdo, y ``N_t_R`` es el número de muestras en el hijo derecho."

#: of sklearn.tree._classes.DecisionTreeClassifier:99
msgid "``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum, if ``sample_weight`` is passed."
msgstr "``N``, ``N_t``, ``N_t_R`` y ``N_t_L`` se refieren a la suma ponderada, si ``sample_weight`` es pasada."

#: of sklearn.tree._classes.DecisionTreeClassifier:113
msgid "**min_impurity_split**"
msgstr "**min_impurity_split**"

#: of
msgid "float, default=0"
msgstr "float, default=0"

#: of sklearn.tree._classes.DecisionTreeClassifier:105
msgid "Threshold for early stopping in tree growth. A node will split if its impurity is above the threshold, otherwise it is a leaf."
msgstr "El umbral para la parada anticipada en el crecimiento de árboles. Un nodo se dividirá si su impureza está por encima del umbral, de lo contrario será una hoja."

#: of sklearn.tree._classes.DecisionTreeClassifier:108
msgid "``min_impurity_split`` has been deprecated in favor of ``min_impurity_decrease`` in 0.19. The default value of ``min_impurity_split`` has changed from 1e-7 to 0 in 0.23 and it will be removed in 1.0 (renaming of 0.25). Use ``min_impurity_decrease`` instead."
msgstr "``min_impurity_split`` ha sido obviado en favor de ``min_impurity_decrease`` en 0.19. El valor predeterminado de ``min_impurity_split`` ha cambiado de 1e-7 a 0 en 0.23 y se eliminará en 1.0 (renombrado de 0.25). Use ``min_impurity_decrease`` en su lugar."

#: of sklearn.tree._classes.DecisionTreeClassifier:134
msgid "**class_weight**"
msgstr "**class_weight**"

#: of
msgid "dict, list of dict or \"balanced\", default=None"
msgstr "dict, list of dict o \"balanced\", default=None"

#: of sklearn.tree._classes.DecisionTreeClassifier:116
msgid "Weights associated with classes in the form ``{class_label: weight}``. If None, all classes are supposed to have weight one. For multi-output problems, a list of dicts can be provided in the same order as the columns of y."
msgstr "Ponderaciones asociadas a las clases de la forma ``{class_label: weight}``. Si es None, se supone que todas las clases tienen ponderación uno. Para los problemas de salida múltiple, se puede proporcionar una lista de dicts en el mismo orden que las columnas de y."

#: of sklearn.tree._classes.DecisionTreeClassifier:121
msgid "Note that for multioutput (including multilabel) weights should be defined for each class of every column in its own dict. For example, for four-class multilabel classification weights should be [{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of [{1:1}, {2:5}, {3:1}, {4:1}]."
msgstr "Ten en cuenta que para la salida múltiple (incluyendo la multietiqueta) las ponderaciones deben ser definidas para cada clase de cada columna en su propio diccionario. Por ejemplo, para la clasificación multietiqueta de cuatro clases las ponderaciones deben ser [{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] en lugar de [{1:1}, {2:5}, {3:1}, {4:1}]."

#: of sklearn.tree._classes.DecisionTreeClassifier:127
msgid "The \"balanced\" mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as ``n_samples / (n_classes * np.bincount(y))``"
msgstr "El modo \"balanced\" utiliza los valores de y para ajustar automáticamente las ponderaciones inversamente proporcionales a las frecuencias de clase en los datos de entrada como ``n_samples / (n_classes * np.bincount(y))``"

#: of sklearn.tree._classes.DecisionTreeClassifier:131
msgid "For multi-output, the weights of each column of y will be multiplied."
msgstr "Para multisalida, las ponderaciones de cada columna de y se multiplicarán."

#: of sklearn.tree._classes.DecisionTreeClassifier:133
msgid "Note that these weights will be multiplied with sample_weight (passed through the fit method) if sample_weight is specified."
msgstr "Ten en cuenta que estas ponderaciones serán multiplicadas con sample_weight (pasadas por el método de ajuste) si se especifica sample_weight."

#: of sklearn.tree._classes.DecisionTreeClassifier:145
msgid "**ccp_alpha**"
msgstr "**ccp_alpha**"

#: of
msgid "non-negative float, default=0.0"
msgstr "float no negativo, default=0.0"

#: of sklearn.tree._classes.DecisionTreeClassifier:137
msgid "Complexity parameter used for Minimal Cost-Complexity Pruning. The subtree with the largest cost complexity that is smaller than ``ccp_alpha`` will be chosen. By default, no pruning is performed. See :ref:`minimal_cost_complexity_pruning` for details."
msgstr "Parámetro de complejidad utilizado para la Poda de Mínima Complejidad de Costo. El subárbol con la complejidad de costo mayor que sea menor que ``ccp_alpha`` será elegido. Por defecto, no se realiza ninguna poda. Ver :ref:`minimal_cost_complexity_pruning` para más detalles."

#: of sklearn.tree._classes.DecisionTreeClassifier
msgid "Attributes"
msgstr "Atributos"

#: of sklearn.tree._classes.DecisionTreeClassifier:151
msgid "**classes_**"
msgstr "**classes_**"

#: of
msgid "ndarray of shape (n_classes,) or list of ndarray"
msgstr "ndarray de forma (n_classes,) o lista de ndarray"

#: of sklearn.tree._classes.DecisionTreeClassifier:150
msgid "The classes labels (single output problem), or a list of arrays of class labels (multi-output problem)."
msgstr "Las etiquetas de clases (problema de salida única), o una lista de arreglos de etiquetas de clase (problema de multi-salida)."

#: of sklearn.tree._classes.DecisionTreeClassifier:154
msgid ":obj:`feature_importances_ <feature_importances_>`"
msgstr ":obj:`feature_importances_ <feature_importances_>`"

#: of
msgid "ndarray of shape (n_features,)"
msgstr "ndarray de forma (n_features,)"

#: of sklearn.tree.DecisionTreeClassifier.feature_importances_:2
#: sklearn.tree._classes.DecisionTreeClassifier:154
msgid "Return the feature importances."
msgstr "Devuelve la importancia de las características."

#: of sklearn.tree._classes.DecisionTreeClassifier:157
msgid "**max_features_**"
msgstr "**max_features_**"

#: of
msgid "int"
msgstr "entero"

#: of sklearn.tree._classes.DecisionTreeClassifier:157
msgid "The inferred value of max_features."
msgstr "El valor inferido de max_features."

#: of sklearn.tree._classes.DecisionTreeClassifier:162
msgid "**n_classes_**"
msgstr "**n_classes_**"

#: of
msgid "int or list of int"
msgstr "int o lista de int"

#: of sklearn.tree._classes.DecisionTreeClassifier:160
msgid "The number of classes (for single output problems), or a list containing the number of classes for each output (for multi-output problems)."
msgstr "El número de clases (para problemas de salida única), o una lista que contiene el número de clases para cada salida (para problemas de salida múltiple)."

#: of sklearn.tree._classes.DecisionTreeClassifier:165
msgid "**n_features_**"
msgstr "**n_features_**"

#: of sklearn.tree._classes.DecisionTreeClassifier:165
msgid "The number of features when ``fit`` is performed."
msgstr "El número de características cuando ``fit`` es realizado."

#: of sklearn.tree._classes.DecisionTreeClassifier:168
msgid "**n_outputs_**"
msgstr "**n_outputs_**"

#: of sklearn.tree._classes.DecisionTreeClassifier:168
msgid "The number of outputs when ``fit`` is performed."
msgstr "El número de salidas cuando se realiza ``fit``."

#: of sklearn.tree._classes.DecisionTreeClassifier:177
msgid "**tree_**"
msgstr "**tree_**"

#: of
msgid "Tree instance"
msgstr "Instancia del árbol"

#: of sklearn.tree._classes.DecisionTreeClassifier:171
msgid "The underlying Tree object. Please refer to ``help(sklearn.tree._tree.Tree)`` for attributes of Tree object and :ref:`sphx_glr_auto_examples_tree_plot_unveil_tree_structure.py` for basic usage of these attributes."
msgstr "El objeto Tree subyacente. Por favor, consulte ``help(sklearn.tree._tree.Tree)`` para obtener los atributos del objeto Tree y :ref:`sphx_glr_auto_examples_tree_plot_unveil_tree_structure.py` para el uso básico de estos atributos."

#: of sklearn.tree._classes.DecisionTreeClassifier:182
msgid ":obj:`DecisionTreeRegressor`"
msgstr ":obj:`DecisionTreeRegressor`"

#: of sklearn.tree._classes.DecisionTreeClassifier:183
msgid "A decision tree regressor."
msgstr "Un regresor de árbol de decisión."

#: of sklearn.tree._classes.DecisionTreeClassifier:187
msgid "Notes"
msgstr "Notas"

#: of sklearn.tree._classes.DecisionTreeClassifier:188
msgid "The default values for the parameters controlling the size of the trees (e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and unpruned trees which can potentially be very large on some data sets. To reduce memory consumption, the complexity and size of the trees should be controlled by setting those parameter values."
msgstr "Los valores predeterminados de los parámetros que controlan el tamaño de los árboles (por ejemplo, ```max_depth``, ``min_samples_leaf``, etc.) conducen a árboles completamente desarrollados y sin podar que pueden ser potencialmente muy grandes en algunos conjuntos de datos. Para reducir el consumo de memoria, la complejidad y el tamaño de los árboles deben controlarse estableciendo los valores de esos parámetros."

#: of sklearn.tree._classes.DecisionTreeClassifier:194
msgid "The :meth:`predict` method operates using the :func:`numpy.argmax` function on the outputs of :meth:`predict_proba`. This means that in case the highest predicted probabilities are tied, the classifier will predict the tied class with the lowest index in :term:`classes_`."
msgstr "El método :meth:`predict` opera usando la función :func:`numpy.argmax` en las salidas de :meth:`predict_proba`. Esto significa que en caso de que las mayores probabilidades predichas estén atadas, el clasificador predirá la clase vinculada con el índice más bajo en :term:`classes_`."

#: of sklearn.tree._classes.DecisionTreeClassifier:200
msgid "References"
msgstr "Referencias"

#: of sklearn.tree._classes.DecisionTreeClassifier:201
msgid "https://en.wikipedia.org/wiki/Decision_tree_learning"
msgstr "https://en.wikipedia.org/wiki/Decision_tree_learning"

#: of sklearn.tree._classes.DecisionTreeClassifier:203
msgid "L. Breiman, J. Friedman, R. Olshen, and C. Stone, \"Classification and Regression Trees\", Wadsworth, Belmont, CA, 1984."
msgstr "L. Breiman, J. Friedman, R. Olshen, and C. Stone, \"Classification and Regression Trees\", Wadsworth, Belmont, CA, 1984."

#: of sklearn.tree._classes.DecisionTreeClassifier:206
msgid "T. Hastie, R. Tibshirani and J. Friedman. \"Elements of Statistical Learning\", Springer, 2009."
msgstr "T. Hastie, R. Tibshirani and J. Friedman. \"Elements of Statistical Learning\", Springer, 2009."

#: of sklearn.tree._classes.DecisionTreeClassifier:209
msgid "L. Breiman, and A. Cutler, \"Random Forests\", https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm"
msgstr "L. Breiman, and A. Cutler, \"Random Forests\", https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm"

#: of sklearn.tree._classes.DecisionTreeClassifier:214
msgid "[Rb1ec977cd307-1]_, [Rb1ec977cd307-2]_, [Rb1ec977cd307-3]_, [Rb1ec977cd307-4]_"
msgstr "[Rb1ec977cd307-1]_, [Rb1ec977cd307-2]_, [Rb1ec977cd307-3]_, [Rb1ec977cd307-4]_"

#: of sklearn.tree._classes.DecisionTreeClassifier:217
msgid "Examples"
msgstr "Ejemplos"

#: of sklearn.tree._classes.DecisionTreeClassifier:230
msgid "Methods"
msgstr "Métodos"

#: of sklearn.tree._classes.DecisionTreeClassifier:245:<autosummary>:1
msgid ":obj:`apply <sklearn.tree.DecisionTreeClassifier.apply>`\\"
msgstr ":obj:`apply <sklearn.tree.DecisionTreeClassifier.apply>`\\"

#: of sklearn.tree._classes.BaseDecisionTree.apply:2
#: sklearn.tree._classes.DecisionTreeClassifier:245:<autosummary>:1
msgid "Return the index of the leaf that each sample is predicted as."
msgstr "Devuelve el índice de la hoja en la que se predice cada muestra."

#: of sklearn.tree._classes.DecisionTreeClassifier:245:<autosummary>:1
msgid ":obj:`cost_complexity_pruning_path <sklearn.tree.DecisionTreeClassifier.cost_complexity_pruning_path>`\\"
msgstr ":obj:`cost_complexity_pruning_path <sklearn.tree.DecisionTreeClassifier.cost_complexity_pruning_path>`\\"

#: of sklearn.tree._classes.BaseDecisionTree.cost_complexity_pruning_path:2
#: sklearn.tree._classes.DecisionTreeClassifier:245:<autosummary>:1
msgid "Compute the pruning path during Minimal Cost-Complexity Pruning."
msgstr "Calcula la ruta de poda durante la Poda de Mínima Complejidad de costes."

#: of sklearn.tree._classes.DecisionTreeClassifier:245:<autosummary>:1
msgid ":obj:`decision_path <sklearn.tree.DecisionTreeClassifier.decision_path>`\\"
msgstr ":obj:`decision_path <sklearn.tree.DecisionTreeClassifier.decision_path>`\\"

#: of sklearn.tree._classes.BaseDecisionTree.decision_path:2
#: sklearn.tree._classes.DecisionTreeClassifier:245:<autosummary>:1
msgid "Return the decision path in the tree."
msgstr "Devuelve la ruta de decisión en el árbol."

#: of sklearn.tree._classes.DecisionTreeClassifier:245:<autosummary>:1
msgid ":obj:`fit <sklearn.tree.DecisionTreeClassifier.fit>`\\"
msgstr ":obj:`fit <sklearn.tree.DecisionTreeClassifier.fit>`\\"

#: of sklearn.tree._classes.DecisionTreeClassifier.fit:2
#: sklearn.tree._classes.DecisionTreeClassifier:245:<autosummary>:1
msgid "Build a decision tree classifier from the training set (X, y)."
msgstr "Construye un clasificador de árbol de decisión a partir del conjunto de entrenamiento (X, y)."

#: of sklearn.tree._classes.DecisionTreeClassifier:245:<autosummary>:1
msgid ":obj:`get_depth <sklearn.tree.DecisionTreeClassifier.get_depth>`\\"
msgstr ":obj:`get_depth <sklearn.tree.DecisionTreeClassifier.get_depth>`\\"

#: of sklearn.tree._classes.BaseDecisionTree.get_depth:2
#: sklearn.tree._classes.DecisionTreeClassifier:245:<autosummary>:1
msgid "Return the depth of the decision tree."
msgstr "Devuelve la profundidad del árbol de decisión."

#: of sklearn.tree._classes.DecisionTreeClassifier:245:<autosummary>:1
msgid ":obj:`get_n_leaves <sklearn.tree.DecisionTreeClassifier.get_n_leaves>`\\"
msgstr ":obj:`get_n_leaves <sklearn.tree.DecisionTreeClassifier.get_n_leaves>`\\"

#: of sklearn.tree._classes.BaseDecisionTree.get_n_leaves:2
#: sklearn.tree._classes.DecisionTreeClassifier:245:<autosummary>:1
msgid "Return the number of leaves of the decision tree."
msgstr "Devuelve el número de hojas del árbol de decisión."

#: of sklearn.tree._classes.DecisionTreeClassifier:245:<autosummary>:1
msgid ":obj:`get_params <sklearn.tree.DecisionTreeClassifier.get_params>`\\"
msgstr ":obj:`get_params <sklearn.tree.DecisionTreeClassifier.get_params>`\\"

#: of sklearn.base.BaseEstimator.get_params:2
#: sklearn.tree._classes.DecisionTreeClassifier:245:<autosummary>:1
msgid "Get parameters for this estimator."
msgstr "Obtiene los parámetros para este estimador."

#: of sklearn.tree._classes.DecisionTreeClassifier:245:<autosummary>:1
msgid ":obj:`predict <sklearn.tree.DecisionTreeClassifier.predict>`\\"
msgstr ":obj:`predict <sklearn.tree.DecisionTreeClassifier.predict>`\\"

#: of sklearn.tree._classes.BaseDecisionTree.predict:2
#: sklearn.tree._classes.DecisionTreeClassifier:245:<autosummary>:1
msgid "Predict class or regression value for X."
msgstr "Predice la clase de regresión para X."

#: of sklearn.tree._classes.DecisionTreeClassifier:245:<autosummary>:1
msgid ":obj:`predict_log_proba <sklearn.tree.DecisionTreeClassifier.predict_log_proba>`\\"
msgstr ":obj:`predict_log_proba <sklearn.tree.DecisionTreeClassifier.predict_log_proba>`\\"

#: of sklearn.tree._classes.DecisionTreeClassifier.predict_log_proba:2
#: sklearn.tree._classes.DecisionTreeClassifier:245:<autosummary>:1
msgid "Predict class log-probabilities of the input samples X."
msgstr "Predice las log-probabilidades de clase de las muestras de entrada X."

#: of sklearn.tree._classes.DecisionTreeClassifier:245:<autosummary>:1
msgid ":obj:`predict_proba <sklearn.tree.DecisionTreeClassifier.predict_proba>`\\"
msgstr ":obj:`predict_proba <sklearn.tree.DecisionTreeClassifier.predict_proba>`\\"

#: of sklearn.tree._classes.DecisionTreeClassifier.predict_proba:2
#: sklearn.tree._classes.DecisionTreeClassifier:245:<autosummary>:1
msgid "Predict class probabilities of the input samples X."
msgstr "Predice las probabilidades de clase de las muestras de entrada X."

#: of sklearn.tree._classes.DecisionTreeClassifier:245:<autosummary>:1
msgid ":obj:`score <sklearn.tree.DecisionTreeClassifier.score>`\\"
msgstr ":obj:`score <sklearn.tree.DecisionTreeClassifier.score>`\\"

#: of sklearn.base.ClassifierMixin.score:2
#: sklearn.tree._classes.DecisionTreeClassifier:245:<autosummary>:1
msgid "Return the mean accuracy on the given test data and labels."
msgstr "Devuelve la precisión media en los datos y etiquetas de prueba dados."

#: of sklearn.tree._classes.DecisionTreeClassifier:245:<autosummary>:1
msgid ":obj:`set_params <sklearn.tree.DecisionTreeClassifier.set_params>`\\"
msgstr ":obj:`set_params <sklearn.tree.DecisionTreeClassifier.set_params>`\\"

#: of sklearn.base.BaseEstimator.set_params:2
#: sklearn.tree._classes.DecisionTreeClassifier:245:<autosummary>:1
msgid "Set the parameters of this estimator."
msgstr "Establece los parámetros de este estimador."

#: of sklearn.base.ClassifierMixin.score:11
#: sklearn.tree._classes.BaseDecisionTree.apply:11
#: sklearn.tree._classes.BaseDecisionTree.cost_complexity_pruning_path:12
#: sklearn.tree._classes.BaseDecisionTree.decision_path:11
#: sklearn.tree._classes.BaseDecisionTree.predict:13
#: sklearn.tree._classes.DecisionTreeClassifier.fit:10
#: sklearn.tree._classes.DecisionTreeClassifier.predict_log_proba:10
#: sklearn.tree._classes.DecisionTreeClassifier.predict_proba:12
msgid "**X**"
msgstr "**X**"

#: of
msgid "{array-like, sparse matrix} of shape (n_samples, n_features)"
msgstr "{array-like, sparse matrix} de forma (n_samples, n_features)"

#: of sklearn.tree._classes.BaseDecisionTree.apply:9
#: sklearn.tree._classes.BaseDecisionTree.decision_path:9
#: sklearn.tree._classes.BaseDecisionTree.predict:11
#: sklearn.tree._classes.DecisionTreeClassifier.predict_log_proba:8
#: sklearn.tree._classes.DecisionTreeClassifier.predict_proba:10
msgid "The input samples. Internally, it will be converted to ``dtype=np.float32`` and if a sparse matrix is provided to a sparse ``csr_matrix``."
msgstr "Las muestras de entrada. Internamente, se convertirá a ``dtype=np.float32`` y si se proporciona una matriz dispersa se convertirá a una dispersa ``csr_matrix``."

#: of sklearn.tree._classes.BaseDecisionTree.apply:15
#: sklearn.tree._classes.BaseDecisionTree.decision_path:15
#: sklearn.tree._classes.BaseDecisionTree.predict:17
#: sklearn.tree._classes.DecisionTreeClassifier.fit:24
#: sklearn.tree._classes.DecisionTreeClassifier.predict_proba:16
msgid "**check_input**"
msgstr "**check_input**"

#: of
msgid "bool, default=True"
msgstr "booleano, default=True"

#: of sklearn.tree._classes.BaseDecisionTree.apply:14
#: sklearn.tree._classes.BaseDecisionTree.decision_path:14
#: sklearn.tree._classes.BaseDecisionTree.predict:16
#: sklearn.tree._classes.DecisionTreeClassifier.fit:23
#: sklearn.tree._classes.DecisionTreeClassifier.predict_proba:15
msgid "Allow to bypass several input checking. Don't use this parameter unless you know what you do."
msgstr "Permite omitir varias comprobaciones de entrada. No uses este parámetro a menos que sepas lo que haces."

#: of sklearn.base.BaseEstimator.get_params
#: sklearn.base.BaseEstimator.set_params sklearn.base.ClassifierMixin.score
#: sklearn.tree.DecisionTreeClassifier.feature_importances_
#: sklearn.tree._classes.BaseDecisionTree.apply
#: sklearn.tree._classes.BaseDecisionTree.cost_complexity_pruning_path
#: sklearn.tree._classes.BaseDecisionTree.decision_path
#: sklearn.tree._classes.BaseDecisionTree.get_depth
#: sklearn.tree._classes.BaseDecisionTree.get_n_leaves
#: sklearn.tree._classes.BaseDecisionTree.predict
#: sklearn.tree._classes.DecisionTreeClassifier.fit
#: sklearn.tree._classes.DecisionTreeClassifier.predict_log_proba
#: sklearn.tree._classes.DecisionTreeClassifier.predict_proba
msgid "Returns"
msgstr "Devuelve"

#: of sklearn.tree._classes.BaseDecisionTree.apply:34
msgid "**X_leaves**"
msgstr "**X_leaves**"

#: of
msgid "array-like of shape (n_samples,)"
msgstr "array-like de forma (n_samples,)"

#: of sklearn.tree._classes.BaseDecisionTree.apply:20
msgid "For each datapoint x in X, return the index of the leaf x ends up in. Leaves are numbered within ``[0; self.tree_.node_count)``, possibly with gaps in the numbering."
msgstr "Para cada punto de datos x en X, devuelve el índice de la hoja en la que termina x. Las hojas se numeran dentro de ``[0; self.tree_.node_count)``, posiblemente con huecos en la numeración."

#: of sklearn.tree._classes.BaseDecisionTree.cost_complexity_pruning_path:4
msgid "See :ref:`minimal_cost_complexity_pruning` for details on the pruning process."
msgstr "Ver :ref:`minimal_cost_complexity_pruning` for details on the pruning process."

#: of sklearn.tree._classes.BaseDecisionTree.cost_complexity_pruning_path:10
#: sklearn.tree._classes.DecisionTreeClassifier.fit:8
msgid "The training input samples. Internally, it will be converted to ``dtype=np.float32`` and if a sparse matrix is provided to a sparse ``csc_matrix``."
msgstr "Las muestras de entrada de entrenamiento. Internamente, se convertirán a ``dtype=np.float32`` y si se proporciona una matriz dispersa a una ``csc_matrix`` dispersa."

#: of sklearn.base.ClassifierMixin.score:14
#: sklearn.tree._classes.BaseDecisionTree.cost_complexity_pruning_path:15
#: sklearn.tree._classes.BaseDecisionTree.predict:33
#: sklearn.tree._classes.DecisionTreeClassifier.fit:13
msgid "**y**"
msgstr "**y**"

#: of
msgid "array-like of shape (n_samples,) or (n_samples, n_outputs)"
msgstr "array-like de forma (n_samples,) o (n_samples, n_outputs)"

#: of sklearn.tree._classes.BaseDecisionTree.cost_complexity_pruning_path:15
#: sklearn.tree._classes.DecisionTreeClassifier.fit:13
msgid "The target values (class labels) as integers or strings."
msgstr "Los valores destino (etiquetas de clase) como enteros o cadenas."

#: of sklearn.base.ClassifierMixin.score:17
#: sklearn.tree._classes.BaseDecisionTree.cost_complexity_pruning_path:22
#: sklearn.tree._classes.DecisionTreeClassifier.fit:20
msgid "**sample_weight**"
msgstr "**sample_weight**"

#: of
msgid "array-like of shape (n_samples,), default=None"
msgstr "array-like de forma (n_samples,) default=None"

#: of sklearn.tree._classes.BaseDecisionTree.cost_complexity_pruning_path:18
#: sklearn.tree._classes.DecisionTreeClassifier.fit:16
msgid "Sample weights. If None, then samples are equally weighted. Splits that would create child nodes with net zero or negative weight are ignored while searching for a split in each node. Splits are also ignored if they would result in any single class carrying a negative weight in either child node."
msgstr "Ponderación de las muestras. Si es None, las muestras se ponderan por igual. Las divisiones que crearían nodos hijos con peso neto cero o negativo se ignoran al buscar una división en cada nodo. Las divisiones también se ignoran si dan lugar a que una sola clase tenga un peso negativo en cualquiera de los nodos hijos."

#: of sklearn.tree._classes.BaseDecisionTree.cost_complexity_pruning_path:45
msgid "**ccp_path** : :class:`~sklearn.utils.Bunch`"
msgstr "**ccp_path** : :class:`~sklearn.utils.Bunch`"

#: of sklearn.tree._classes.BaseDecisionTree.cost_complexity_pruning_path:44
msgid "Bunch"
msgstr "Bunch"

#: of sklearn.tree._classes.BaseDecisionTree.cost_complexity_pruning_path:27
msgid "Dictionary-like object, with the following attributes."
msgstr "Objeto tipo diccionario, con los siguientes atributos."

#: of sklearn.tree._classes.BaseDecisionTree.cost_complexity_pruning_path:30
msgid "ccp_alphas"
msgstr "ccp_alphas"

#: of
msgid "ndarray"
msgstr "ndarray"

#: of sklearn.tree._classes.BaseDecisionTree.cost_complexity_pruning_path:30
msgid "Effective alphas of subtree during pruning."
msgstr "Alfas efectivos del subárbol durante la poda."

#: of sklearn.tree._classes.BaseDecisionTree.cost_complexity_pruning_path:45
msgid "impurities"
msgstr "impurezas"

#: of sklearn.tree._classes.BaseDecisionTree.cost_complexity_pruning_path:33
msgid "Sum of the impurities of the subtree leaves for the corresponding alpha value in ``ccp_alphas``."
msgstr "Suma de las impurezas de las hojas del subárbol para el valor alfa correspondiente en ``ccp_alphas``."

#: of sklearn.tree._classes.BaseDecisionTree.decision_path:32
msgid "**indicator**"
msgstr "**indicator**"

#: of
msgid "sparse matrix of shape (n_samples, n_nodes)"
msgstr "matriz dispersa de forma (n_samples, n_nodes)"

#: of sklearn.tree._classes.BaseDecisionTree.decision_path:20
msgid "Return a node indicator CSR matrix where non zero elements indicates that the samples goes through the nodes."
msgstr "Devuelve una matriz CSR indicadora de nodos donde los elementos distintos de cero indican que las muestras pasan por los nodos."

#: of sklearn.tree.DecisionTreeClassifier.feature_importances_:4
msgid "The importance of a feature is computed as the (normalized) total reduction of the criterion brought by that feature. It is also known as the Gini importance."
msgstr "La importancia de una característica se calcula como la reducción total (normalizada) del criterio traído por esa función. También se le conoce como la importancia de Gini."

#: of sklearn.tree.DecisionTreeClassifier.feature_importances_:8
msgid "Warning: impurity-based feature importances can be misleading for high cardinality features (many unique values). See :func:`sklearn.inspection.permutation_importance` as an alternative."
msgstr "Advertencia: las importancias de características basadas en la impureza pueden ser no representativas para las características de alta cardinalidad (muchos valores únicos). Ver :func:`sklearn.inspection.permutation_importance` como una alternativa."

#: of sklearn.tree.DecisionTreeClassifier.feature_importances_:28
msgid "**feature_importances_**"
msgstr "**feature_importances_**"

#: of sklearn.tree.DecisionTreeClassifier.feature_importances_:16
msgid "Normalized total reduction of criteria by feature (Gini importance)."
msgstr "Reducción total normalizada del criterio por función (importancia Gini)."

#: of sklearn.tree._classes.DecisionTreeClassifier.fit:30
msgid "**X_idx_sorted**"
msgstr "**X_idx_sorted**"

#: of
msgid "deprecated, default=\"deprecated\""
msgstr "obsoleto, default=\"deprecated\""

#: of sklearn.tree._classes.DecisionTreeClassifier.fit:27
msgid "This parameter is deprecated and has no effect. It will be removed in 1.1 (renaming of 0.26)."
msgstr "Este atributo está obsoleto y no tiene ningún efecto. Se eliminará en 1.1 (cambio de nombre de 0.26)."

#: of sklearn.base.BaseEstimator.set_params:28
#: sklearn.tree._classes.DecisionTreeClassifier.fit:46
msgid "**self**"
msgstr "**self**"

#: of
msgid "DecisionTreeClassifier"
msgstr "DecisionTreeClassifier"

#: of sklearn.tree._classes.DecisionTreeClassifier.fit:35
msgid "Fitted estimator."
msgstr "Estimador ajustado."

#: of sklearn.tree._classes.BaseDecisionTree.get_depth:4
msgid "The depth of a tree is the maximum distance between the root and any leaf."
msgstr "La profundidad de un árbol es la distancia máxima entre la raíz y cualquier hoja."

#: of sklearn.tree._classes.BaseDecisionTree.get_depth:22
msgid "**self.tree_.max_depth**"
msgstr "**self.tree_.max_depth**"

#: of sklearn.tree._classes.BaseDecisionTree.get_depth:11
msgid "The maximum depth of the tree."
msgstr "La profundidad máxima del árbol."

#: of sklearn.tree._classes.BaseDecisionTree.get_n_leaves:20
msgid "**self.tree_.n_leaves**"
msgstr "**self.tree_.n_leaves**"

#: of sklearn.tree._classes.BaseDecisionTree.get_n_leaves:9
msgid "Number of leaves."
msgstr "Número de hojas."

#: of sklearn.base.BaseEstimator.get_params:9
msgid "**deep**"
msgstr "**deep**"

#: of sklearn.base.BaseEstimator.get_params:8
msgid "If True, will return the parameters for this estimator and contained subobjects that are estimators."
msgstr "Si es True, devolverá los parámetros para este estimador y los sub objetos contenidos que son estimadores."

#: of sklearn.base.BaseEstimator.get_params:25
msgid "**params**"
msgstr "**params**"

#: of
msgid "dict"
msgstr "dict"

#: of sklearn.base.BaseEstimator.get_params:14
msgid "Parameter names mapped to their values."
msgstr "Nombres de parámetros mapeados a sus valores."

#: of sklearn.tree._classes.BaseDecisionTree.predict:4
msgid "For a classification model, the predicted class for each sample in X is returned. For a regression model, the predicted value based on X is returned."
msgstr "Para un modelo de clasificación, se devuelve la clase predicha para cada muestra en X. Para un modelo de regresión, se devuelve el valor predicho basado en X."

#: of sklearn.tree._classes.BaseDecisionTree.predict:22
msgid "The predicted classes, or the predict values."
msgstr "Las clases predichas, o los valores predichos."

#: of sklearn.tree._classes.DecisionTreeClassifier.predict_log_proba:27
#: sklearn.tree._classes.DecisionTreeClassifier.predict_proba:33
msgid "**proba**"
msgstr "**proba**"

#: of
msgid "ndarray of shape (n_samples, n_classes) or list of n_outputs             such arrays if n_outputs > 1"
msgstr "ndarray de forma (n_samples, n_classes), o una lista de n_outputs             tales arreglos sí n_outputs > 1"

#: of sklearn.tree._classes.DecisionTreeClassifier.predict_log_proba:15
msgid "The class log-probabilities of the input samples. The order of the classes corresponds to that in the attribute :term:`classes_`."
msgstr "Las log-probabilidades de clase de las muestras de entrada. El orden de las clases corresponde a aquel en el atributo :term:`classes_`."

#: of sklearn.tree._classes.DecisionTreeClassifier.predict_proba:4
msgid "The predicted class probability is the fraction of samples of the same class in a leaf."
msgstr "La probabilidad predicha de clase es la fracción de muestras de la misma clase en una hoja."

#: of sklearn.tree._classes.DecisionTreeClassifier.predict_proba:21
msgid "The class probabilities of the input samples. The order of the classes corresponds to that in the attribute :term:`classes_`."
msgstr "Las probabilidades de clase de las muestras de entrada. El orden de las clases corresponde a aquel en el atributo :term:`classes_`."

#: of sklearn.base.ClassifierMixin.score:4
msgid "In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted."
msgstr "En la clasificación multietiqueta, se trata de la precisión del subconjunto, que es una métrica rigurosa, ya que se requiere para cada muestra que cada conjunto de etiquetas sea predicho correctamente."

#: of
msgid "array-like of shape (n_samples, n_features)"
msgstr "array-like de forma (n_samples_X, n_features)"

#: of sklearn.base.ClassifierMixin.score:11
msgid "Test samples."
msgstr "Muestras de prueba."

#: of sklearn.base.ClassifierMixin.score:14
msgid "True labels for `X`."
msgstr "Etiquetas True para `X`."

#: of sklearn.base.ClassifierMixin.score:17
msgid "Sample weights."
msgstr "Ponderaciones de la muestra."

#: of sklearn.base.ClassifierMixin.score:33
msgid "**score**"
msgstr "**score**"

#: of
msgid "float"
msgstr "de punto flotante (float)"

#: of sklearn.base.ClassifierMixin.score:22
msgid "Mean accuracy of ``self.predict(X)`` wrt. `y`."
msgstr "Precisión media de ``self.predict(X)`` con respecto a `y`."

#: of sklearn.base.BaseEstimator.set_params:4
msgid "The method works on simple estimators as well as on nested objects (such as :class:`~sklearn.pipeline.Pipeline`). The latter have parameters of the form ``<component>__<parameter>`` so that it's possible to update each component of a nested object."
msgstr "El método funciona tanto con estimadores simples como en objetos anidados (como :class:`~sklearn.pipeline.Pipeline`). Estos últimos tienen parámetros de la forma ``<component>__<parameter>`` para que sea posible actualizar cada componente de un objeto anidado."

#: of sklearn.base.BaseEstimator.set_params:12
msgid "**\\*\\*params**"
msgstr "**\\*\\*params**"

#: of sklearn.base.BaseEstimator.set_params:12
msgid "Estimator parameters."
msgstr "Parámetros del estimador."

#: of
msgid "estimator instance"
msgstr "instancia del estimador"

#: of sklearn.base.BaseEstimator.set_params:17
msgid "Estimator instance."
msgstr "Instancia de estimador."

#: ../modules/generated/sklearn.tree.DecisionTreeClassifier.examples:4
msgid "Examples using ``sklearn.tree.DecisionTreeClassifier``"
msgstr "Ejemplos usando ``sklearn.tree.DecisionTreeClassifier``"

#: ../modules/generated/sklearn.tree.DecisionTreeClassifier.examples:15
#: ../modules/generated/sklearn.tree.DecisionTreeClassifier.examples:23
msgid ":ref:`sphx_glr_auto_examples_model_selection_plot_multi_metric_evaluation.py`"
msgstr ":ref:`sphx_glr_auto_examples_model_selection_plot_multi_metric_evaluation.py`"

