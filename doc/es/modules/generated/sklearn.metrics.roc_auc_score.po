msgid ""
msgstr ""
"Project-Id-Version: scikit-learn\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-03-31 12:56-0400\n"
"PO-Revision-Date: 2021-06-03 20:37\n"
"Last-Translator: \n"
"Language-Team: Spanish\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Crowdin-Project: scikit-learn\n"
"X-Crowdin-Project-ID: 450526\n"
"X-Crowdin-Language: es-ES\n"
"X-Crowdin-File: /main/doc/en/modules/generated/sklearn.metrics.roc_auc_score.po\n"
"X-Crowdin-File-ID: 5056\n"
"Language: es_ES\n"

#: ../modules/generated/sklearn.metrics.roc_auc_score.rst:2
msgid ":mod:`sklearn.metrics`.roc_auc_score"
msgstr ""

#: of sklearn.metrics._ranking.roc_auc_score:2
msgid "Compute Area Under the Receiver Operating Characteristic Curve (ROC AUC) from prediction scores."
msgstr ""

#: of sklearn.metrics._ranking.roc_auc_score:5
msgid "Note: this implementation can be used with binary, multiclass and multilabel classification, but some restrictions apply (see Parameters)."
msgstr ""

#: of sklearn.metrics._ranking.roc_auc_score:8
msgid "Read more in the :ref:`User Guide <roc_metrics>`."
msgstr ""

#: of sklearn.metrics._ranking.roc_auc_score
msgid "Parameters"
msgstr ""

#: of sklearn.metrics._ranking.roc_auc_score:15
msgid "**y_true**"
msgstr "**y_true**"

#: of
msgid "array-like of shape (n_samples,) or (n_samples, n_classes)"
msgstr ""

#: of sklearn.metrics._ranking.roc_auc_score:13
msgid "True labels or binary label indicators. The binary and multiclass cases expect labels with shape (n_samples,) while the multilabel case expects binary label indicators with shape (n_samples, n_classes)."
msgstr ""

#: of sklearn.metrics._ranking.roc_auc_score:42
msgid "**y_score**"
msgstr "**y_score**"

#: of sklearn.metrics._ranking.roc_auc_score:18
msgid "Target scores."
msgstr ""

#: of sklearn.metrics._ranking.roc_auc_score:20
msgid "In the binary case, it corresponds to an array of shape `(n_samples,)`. Both probability estimates and non-thresholded decision values can be provided. The probability estimates correspond to the **probability of the class with the greater label**, i.e. `estimator.classes_[1]` and thus `estimator.predict_proba(X, y)[:, 1]`. The decision values corresponds to the output of `estimator.decision_function(X, y)`. See more information in the :ref:`User guide <roc_auc_binary>`;"
msgstr ""

#: of sklearn.metrics._ranking.roc_auc_score:28
msgid "In the multiclass case, it corresponds to an array of shape `(n_samples, n_classes)` of probability estimates provided by the `predict_proba` method. The probability estimates **must** sum to 1 across the possible classes. In addition, the order of the class scores must correspond to the order of ``labels``, if provided, or else to the numerical or lexicographical order of the labels in ``y_true``. See more information in the :ref:`User guide <roc_auc_multiclass>`;"
msgstr ""

#: of sklearn.metrics._ranking.roc_auc_score:36
msgid "In the multilabel case, it corresponds to an array of shape `(n_samples, n_classes)`. Probability estimates are provided by the `predict_proba` method and the non-thresholded decision values by the `decision_function` method. The probability estimates correspond to the **probability of the class with the greater label for each output** of the classifier. See more information in the :ref:`User guide <roc_auc_multilabel>`."
msgstr ""

#: of sklearn.metrics._ranking.roc_auc_score:62
msgid "**average**"
msgstr "**average**"

#: of
msgid "{'micro', 'macro', 'samples', 'weighted'} or None,             default='macro'"
msgstr ""

#: of sklearn.metrics._ranking.roc_auc_score:45
msgid "If ``None``, the scores for each class are returned. Otherwise, this determines the type of averaging performed on the data: Note: multiclass ROC AUC currently only handles the 'macro' and 'weighted' averages."
msgstr ""

#: of sklearn.metrics._ranking.roc_auc_score:51
msgid "``'micro'``:"
msgstr ""

#: of sklearn.metrics._ranking.roc_auc_score:51
msgid "Calculate metrics globally by considering each element of the label indicator matrix as a label."
msgstr ""

#: of sklearn.metrics._ranking.roc_auc_score:54
msgid "``'macro'``:"
msgstr ""

#: of sklearn.metrics._ranking.roc_auc_score:54
msgid "Calculate metrics for each label, and find their unweighted mean.  This does not take label imbalance into account."
msgstr ""

#: of sklearn.metrics._ranking.roc_auc_score:57
msgid "``'weighted'``:"
msgstr ""

#: of sklearn.metrics._ranking.roc_auc_score:57
msgid "Calculate metrics for each label, and find their average, weighted by support (the number of true instances for each label)."
msgstr ""

#: of sklearn.metrics._ranking.roc_auc_score:60
msgid "``'samples'``:"
msgstr ""

#: of sklearn.metrics._ranking.roc_auc_score:60
msgid "Calculate metrics for each instance, and find their average."
msgstr ""

#: of sklearn.metrics._ranking.roc_auc_score:62
msgid "Will be ignored when ``y_true`` is binary."
msgstr ""

#: of sklearn.metrics._ranking.roc_auc_score:65
msgid "**sample_weight**"
msgstr "**sample_weight**"

#: of
msgid "array-like of shape (n_samples,), default=None"
msgstr ""

#: of sklearn.metrics._ranking.roc_auc_score:65
msgid "Sample weights."
msgstr ""

#: of sklearn.metrics._ranking.roc_auc_score:71
msgid "**max_fpr**"
msgstr "**max_fpr**"

#: of
msgid "float > 0 and <= 1, default=None"
msgstr ""

#: of sklearn.metrics._ranking.roc_auc_score:68
msgid "If not ``None``, the standardized partial AUC [R4bb7c4558997-2]_ over the range [0, max_fpr] is returned. For the multiclass case, ``max_fpr``, should be either equal to ``None`` or ``1.0`` as AUC ROC partial computation currently is not supported for multiclass."
msgstr ""

#: of sklearn.metrics._ranking.roc_auc_score:89
msgid "**multi_class**"
msgstr "**multi_class**"

#: of
msgid "{'raise', 'ovr', 'ovo'}, default='raise'"
msgstr ""

#: of sklearn.metrics._ranking.roc_auc_score:74
msgid "Only used for multiclass targets. Determines the type of configuration to use. The default value raises an error, so either ``'ovr'`` or ``'ovo'`` must be passed explicitly."
msgstr ""

#: of sklearn.metrics._ranking.roc_auc_score:83
msgid "``'ovr'``:"
msgstr ""

#: of sklearn.metrics._ranking.roc_auc_score:79
msgid "Stands for One-vs-rest. Computes the AUC of each class against the rest [R4bb7c4558997-3]_ [R4bb7c4558997-4]_. This treats the multiclass case in the same way as the multilabel case. Sensitive to class imbalance even when ``average == 'macro'``, because class imbalance affects the composition of each of the 'rest' groupings."
msgstr ""

#: of sklearn.metrics._ranking.roc_auc_score:89
msgid "``'ovo'``:"
msgstr ""

#: of sklearn.metrics._ranking.roc_auc_score:86
msgid "Stands for One-vs-one. Computes the average AUC of all possible pairwise combinations of classes [R4bb7c4558997-5]_. Insensitive to class imbalance when ``average == 'macro'``."
msgstr ""

#: of sklearn.metrics._ranking.roc_auc_score:94
msgid "**labels**"
msgstr "**labels**"

#: of
msgid "array-like of shape (n_classes,), default=None"
msgstr ""

#: of sklearn.metrics._ranking.roc_auc_score:92
msgid "Only used for multiclass targets. List of labels that index the classes in ``y_score``. If ``None``, the numerical or lexicographical order of the labels in ``y_true`` is used."
msgstr ""

#: of sklearn.metrics._ranking.roc_auc_score
msgid "Returns"
msgstr ""

#: of sklearn.metrics._ranking.roc_auc_score:105
msgid "**auc**"
msgstr "**auc**"

#: of
msgid "float"
msgstr ""

#: of sklearn.metrics._ranking.roc_auc_score:110
msgid ":obj:`average_precision_score`"
msgstr ""

#: of sklearn.metrics._ranking.roc_auc_score:111
msgid "Area under the precision-recall curve."
msgstr ""

#: of sklearn.metrics._ranking.roc_auc_score:112
msgid ":obj:`roc_curve`"
msgstr ""

#: of sklearn.metrics._ranking.roc_auc_score:113
msgid "Compute Receiver operating characteristic (ROC) curve."
msgstr ""

#: of sklearn.metrics._ranking.roc_auc_score:114
msgid ":obj:`plot_roc_curve`"
msgstr ""

#: of sklearn.metrics._ranking.roc_auc_score:115
msgid "Plot Receiver operating characteristic (ROC) curve."
msgstr ""

#: of sklearn.metrics._ranking.roc_auc_score:120
msgid "References"
msgstr ""

#: of sklearn.metrics._ranking.roc_auc_score:121
msgid "`Wikipedia entry for the Receiver operating characteristic <https://en.wikipedia.org/wiki/Receiver_operating_characteristic>`_"
msgstr ""

#: of sklearn.metrics._ranking.roc_auc_score:124
msgid "`Analyzing a portion of the ROC curve. McClish, 1989 <https://www.ncbi.nlm.nih.gov/pubmed/2668680>`_"
msgstr ""

#: of sklearn.metrics._ranking.roc_auc_score:127
msgid "Provost, F., Domingos, P. (2000). Well-trained PETs: Improving probability estimation trees (Section 6.2), CeDER Working Paper #IS-00-04, Stern School of Business, New York University."
msgstr ""

#: of sklearn.metrics._ranking.roc_auc_score:131
msgid "`Fawcett, T. (2006). An introduction to ROC analysis. Pattern Recognition Letters, 27(8), 861-874. <https://www.sciencedirect.com/science/article/pii/S016786550500303X>`_"
msgstr ""

#: of sklearn.metrics._ranking.roc_auc_score:135
msgid "`Hand, D.J., Till, R.J. (2001). A Simple Generalisation of the Area Under the ROC Curve for Multiple Class Classification Problems. Machine Learning, 45(2), 171-186. <http://link.springer.com/article/10.1023/A:1010920819831>`_"
msgstr ""

#: of sklearn.metrics._ranking.roc_auc_score:142
msgid "[R4bb7c4558997-1]_, [R4bb7c4558997-2]_, [R4bb7c4558997-3]_, [R4bb7c4558997-4]_, [R4bb7c4558997-5]_"
msgstr ""

#: of sklearn.metrics._ranking.roc_auc_score:145
msgid "Examples"
msgstr ""

#: of sklearn.metrics._ranking.roc_auc_score:146
msgid "Binary case:"
msgstr ""

#: of sklearn.metrics._ranking.roc_auc_score:158
msgid "Multiclass case:"
msgstr ""

#: of sklearn.metrics._ranking.roc_auc_score:166
msgid "Multilabel case:"
msgstr ""

#: ../modules/generated/sklearn.metrics.roc_auc_score.examples:4
msgid "Examples using ``sklearn.metrics.roc_auc_score``"
msgstr ""

#: ../modules/generated/sklearn.metrics.roc_auc_score.examples:15
#: ../modules/generated/sklearn.metrics.roc_auc_score.examples:23
msgid ":ref:`sphx_glr_auto_examples_model_selection_plot_grid_search_stats.py`"
msgstr ""

#~ msgid ":ref:`sphx_glr_auto_examples_release_highlights_plot_release_highlights_0_22_0.py`"
#~ msgstr ""

#~ msgid ":ref:`sphx_glr_auto_examples_model_selection_plot_roc_crossval.py`"
#~ msgstr ""

#~ msgid ":ref:`sphx_glr_auto_examples_model_selection_plot_roc.py`"
#~ msgstr ""

