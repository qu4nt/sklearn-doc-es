msgid ""
msgstr ""
"Project-Id-Version: scikit-learn\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-03-31 11:24-0400\n"
"PO-Revision-Date: 2021-05-13 02:00\n"
"Last-Translator: \n"
"Language-Team: Spanish\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Crowdin-Project: scikit-learn\n"
"X-Crowdin-Project-ID: 450526\n"
"X-Crowdin-Language: es-ES\n"
"X-Crowdin-File: /main/doc/en/modules/generated/sklearn.decomposition.NMF.po\n"
"X-Crowdin-File-ID: 5158\n"
"Language: es_ES\n"

#: ../modules/generated/sklearn.decomposition.NMF.rst:2
msgid ":mod:`sklearn.decomposition`.NMF"
msgstr ":mod:`sklearn.decomposition`.NMF"

#: of sklearn.decomposition._nmf.NMF:2
msgid "Non-Negative Matrix Factorization (NMF)."
msgstr "Factorización de Matrices No Negativas (Non-Negative Matrix Factorization, NMF)."

#: of sklearn.decomposition._nmf.NMF:4
msgid "Find two non-negative matrices (W, H) whose product approximates the non- negative matrix X. This factorization can be used for example for dimensionality reduction, source separation or topic extraction."
msgstr "Encontrar dos matrices no negativas (W, H) cuyo producto se aproxime a la matriz no negativa X. Esta factorización se puede utilizar, por ejemplo, para la reducción de la dimensionalidad, la separación de fuentes o la extracción de temas."

#: of sklearn.decomposition._nmf.NMF:8
msgid "The objective function is:"
msgstr "La función objetivo es:"

#: of sklearn.decomposition._nmf.NMF:10
msgid "0.5 * ||X - WH||_{Fro}^2 + alpha * l1_{ratio} * ||vec(W)||_1\n\n"
"+ alpha * l1_{ratio} * ||vec(H)||_1\n\n"
"+ 0.5 * alpha * (1 - l1_{ratio}) * ||W||_{Fro}^2\n\n"
"+ 0.5 * alpha * (1 - l1_{ratio}) * ||H||_{Fro}^2"
msgstr "0.5 * ||X - WH||_{Fro}^2 + alpha * l1_{ratio} * ||vec(W)||_1\n\n"
"+ alpha * l1_{ratio} * ||vec(H)||_1\n\n"
"+ 0.5 * alpha * (1 - l1_{ratio}) * ||W||_{Fro}^2\n\n"
"+ 0.5 * alpha * (1 - l1_{ratio}) * ||H||_{Fro}^2"

#: of sklearn.decomposition._nmf.NMF:20
msgid "Where:"
msgstr "Donde:"

#: of sklearn.decomposition._nmf.NMF:22
msgid ":math:`||A||_{Fro}^2 = \\sum_{i,j} A_{ij}^2` (Frobenius norm)"
msgstr ":math:`||A||_{Fro}^2 = \\sum_{i,j} A_{ij}^2` (norma de Frobenius)"

#: of sklearn.decomposition._nmf.NMF:24
msgid ":math:`||vec(A)||_1 = \\sum_{i,j} abs(A_{ij})` (Elementwise L1 norm)"
msgstr ""

#: of sklearn.decomposition._nmf.NMF:26
msgid "For multiplicative-update ('mu') solver, the Frobenius norm (:math:`0.5 * ||X - WH||_{Fro}^2`) can be changed into another beta-divergence loss, by changing the beta_loss parameter."
msgstr ""

#: of sklearn.decomposition._nmf.NMF:30
msgid "The objective function is minimized with an alternating minimization of W and H."
msgstr ""

#: of sklearn.decomposition._nmf.NMF:33
msgid "Read more in the :ref:`User Guide <NMF>`."
msgstr ""

#: of sklearn.base.BaseEstimator.get_params
#: sklearn.base.BaseEstimator.set_params sklearn.decomposition._nmf.NMF
#: sklearn.decomposition._nmf.NMF.fit
#: sklearn.decomposition._nmf.NMF.fit_transform
#: sklearn.decomposition._nmf.NMF.inverse_transform
#: sklearn.decomposition._nmf.NMF.transform
msgid "Parameters"
msgstr ""

#: of sklearn.decomposition._nmf.NMF:39
msgid "**n_components**"
msgstr ""

#: of
msgid "int, default=None"
msgstr ""

#: of sklearn.decomposition._nmf.NMF:38
msgid "Number of components, if n_components is not set all features are kept."
msgstr ""

#: of sklearn.decomposition._nmf.NMF:62
msgid "**init**"
msgstr ""

#: of
msgid "{'random', 'nndsvd', 'nndsvda', 'nndsvdar', 'custom'}, default=None"
msgstr ""

#: of sklearn.decomposition._nmf.NMF:42
msgid "Method used to initialize the procedure. Default: None. Valid options:"
msgstr ""

#: of sklearn.decomposition._nmf.NMF:46
msgid "`None`: 'nndsvd' if n_components <= min(n_samples, n_features), otherwise random."
msgstr ""

#: of sklearn.decomposition._nmf.NMF:49
msgid "`'random'`: non-negative random matrices, scaled with: sqrt(X.mean() / n_components)"
msgstr ""

#: of sklearn.decomposition._nmf.NMF:52
msgid "`'nndsvd'`: Nonnegative Double Singular Value Decomposition (NNDSVD) initialization (better for sparseness)"
msgstr ""

#: of sklearn.decomposition._nmf.NMF:55
msgid "`'nndsvda'`: NNDSVD with zeros filled with the average of X (better when sparsity is not desired)"
msgstr ""

#: of sklearn.decomposition._nmf.NMF:58
msgid "`'nndsvdar'` NNDSVD with zeros filled with small random values (generally faster, less accurate alternative to NNDSVDa for when sparsity is not desired)"
msgstr ""

#: of sklearn.decomposition._nmf.NMF:62
msgid "`'custom'`: use custom matrices W and H"
msgstr ""

#: of sklearn.decomposition._nmf.NMF:73
msgid "**solver**"
msgstr ""

#: of
msgid "{'cd', 'mu'}, default='cd'"
msgstr ""

#: of sklearn.decomposition._nmf.NMF:65
msgid "Numerical solver to use: 'cd' is a Coordinate Descent solver. 'mu' is a Multiplicative Update solver."
msgstr ""

#: of sklearn.decomposition._nmf.NMF:69
msgid "Coordinate Descent solver."
msgstr ""

#: of sklearn.decomposition._nmf.NMF:72
msgid "Multiplicative Update solver."
msgstr ""

#: of sklearn.decomposition._nmf.NMF:82
msgid "**beta_loss**"
msgstr ""

#: of
msgid "float or {'frobenius', 'kullback-leibler',             'itakura-saito'}, default='frobenius'"
msgstr ""

#: of sklearn.decomposition._nmf.NMF:76
msgid "Beta divergence to be minimized, measuring the distance between X and the dot product WH. Note that values different from 'frobenius' (or 2) and 'kullback-leibler' (or 1) lead to significantly slower fits. Note that for beta_loss <= 0 (or 'itakura-saito'), the input matrix X cannot contain zeros. Used only in 'mu' solver."
msgstr ""

#: of sklearn.decomposition._nmf.NMF:85
msgid "**tol**"
msgstr ""

#: of
msgid "float, default=1e-4"
msgstr ""

#: of sklearn.decomposition._nmf.NMF:85
msgid "Tolerance of the stopping condition."
msgstr ""

#: of sklearn.decomposition._nmf.NMF:88
msgid "**max_iter**"
msgstr ""

#: of
msgid "int, default=200"
msgstr ""

#: of sklearn.decomposition._nmf.NMF:88
msgid "Maximum number of iterations before timing out."
msgstr ""

#: of sklearn.decomposition._nmf.NMF:94
msgid "**random_state**"
msgstr ""

#: of
msgid "int, RandomState instance or None, default=None"
msgstr ""

#: of sklearn.decomposition._nmf.NMF:91
msgid "Used for initialisation (when ``init`` == 'nndsvdar' or 'random'), and in Coordinate Descent. Pass an int for reproducible results across multiple function calls. See :term:`Glossary <random_state>`."
msgstr ""

#: of sklearn.decomposition._nmf.NMF:101
msgid "**alpha**"
msgstr ""

#: of
msgid "float, default=0."
msgstr ""

#: of sklearn.decomposition._nmf.NMF:97
msgid "Constant that multiplies the regularization terms. Set it to zero to have no regularization."
msgstr ""

#: of sklearn.decomposition._nmf.NMF:100
msgid "*alpha* used in the Coordinate Descent solver."
msgstr ""

#: of sklearn.decomposition._nmf.NMF:112
msgid "**l1_ratio**"
msgstr ""

#: of sklearn.decomposition._nmf.NMF:104
msgid "The regularization mixing parameter, with 0 <= l1_ratio <= 1. For l1_ratio = 0 the penalty is an elementwise L2 penalty (aka Frobenius Norm). For l1_ratio = 1 it is an elementwise L1 penalty. For 0 < l1_ratio < 1, the penalty is a combination of L1 and L2."
msgstr ""

#: of sklearn.decomposition._nmf.NMF:110
msgid "Regularization parameter *l1_ratio* used in the Coordinate Descent solver."
msgstr ""

#: of sklearn.decomposition._nmf.NMF:115
msgid "**verbose**"
msgstr ""

#: of
msgid "int, default=0"
msgstr ""

#: of sklearn.decomposition._nmf.NMF:115
msgid "Whether to be verbose."
msgstr ""

#: of sklearn.decomposition._nmf.NMF:121
msgid "**shuffle**"
msgstr ""

#: of
msgid "bool, default=False"
msgstr ""

#: of sklearn.decomposition._nmf.NMF:118
msgid "If true, randomize the order of coordinates in the CD solver."
msgstr ""

#: of sklearn.decomposition._nmf.NMF:120
msgid "*shuffle* parameter used in the Coordinate Descent solver."
msgstr ""

#: of sklearn.decomposition._nmf.NMF:130
msgid "**regularization**"
msgstr ""

#: of
msgid "{'both', 'components', 'transformation', None},                      default='both'"
msgstr ""

#: of sklearn.decomposition._nmf.NMF:124
msgid "Select whether the regularization affects the components (H), the transformation (W), both or none of them."
msgstr ""

#: of sklearn.decomposition._nmf.NMF
msgid "Attributes"
msgstr ""

#: of sklearn.decomposition._nmf.NMF:135
msgid "**components_**"
msgstr ""

#: of
msgid "ndarray of shape (n_components, n_features)"
msgstr ""

#: of sklearn.decomposition._nmf.NMF:135
msgid "Factorization matrix, sometimes called 'dictionary'."
msgstr ""

#: of sklearn.decomposition._nmf.NMF:140
msgid "**n_components_**"
msgstr ""

#: of
msgid "int"
msgstr ""

#: of sklearn.decomposition._nmf.NMF:138
msgid "The number of components. It is same as the `n_components` parameter if it was given. Otherwise, it will be same as the number of features."
msgstr ""

#: of sklearn.decomposition._nmf.NMF:145
msgid "**reconstruction_err_**"
msgstr ""

#: of
msgid "float"
msgstr ""

#: of sklearn.decomposition._nmf.NMF:143
msgid "Frobenius norm of the matrix difference, or beta-divergence, between the training data ``X`` and the reconstructed data ``WH`` from the fitted model."
msgstr ""

#: of sklearn.decomposition._nmf.NMF:153
msgid "**n_iter_**"
msgstr ""

#: of sklearn.decomposition._nmf.NMF:148
msgid "Actual number of iterations."
msgstr ""

#: of sklearn.decomposition._nmf.NMF:156
msgid "References"
msgstr ""

#: of sklearn.decomposition._nmf.NMF:157
msgid "Cichocki, Andrzej, and P. H. A. N. Anh-Huy. \"Fast local algorithms for large scale nonnegative matrix and tensor factorizations.\" IEICE transactions on fundamentals of electronics, communications and computer sciences 92.3: 708-721, 2009."
msgstr ""

#: of sklearn.decomposition._nmf.NMF:162
msgid "Fevotte, C., & Idier, J. (2011). Algorithms for nonnegative matrix factorization with the beta-divergence. Neural Computation, 23(9)."
msgstr ""

#: of sklearn.decomposition._nmf.NMF:170
msgid "Examples"
msgstr ""

#: of sklearn.decomposition._nmf.NMF:179
msgid "Methods"
msgstr ""

#: of sklearn.decomposition._nmf.NMF:188:<autosummary>:1
msgid ":obj:`fit <sklearn.decomposition.NMF.fit>`\\"
msgstr ""

#: of sklearn.decomposition._nmf.NMF.fit:2
#: sklearn.decomposition._nmf.NMF:188:<autosummary>:1
msgid "Learn a NMF model for the data X."
msgstr ""

#: of sklearn.decomposition._nmf.NMF:188:<autosummary>:1
msgid ":obj:`fit_transform <sklearn.decomposition.NMF.fit_transform>`\\"
msgstr ""

#: of sklearn.decomposition._nmf.NMF.fit_transform:2
#: sklearn.decomposition._nmf.NMF:188:<autosummary>:1
msgid "Learn a NMF model for the data X and returns the transformed data."
msgstr ""

#: of sklearn.decomposition._nmf.NMF:188:<autosummary>:1
msgid ":obj:`get_params <sklearn.decomposition.NMF.get_params>`\\"
msgstr ""

#: of sklearn.base.BaseEstimator.get_params:2
#: sklearn.decomposition._nmf.NMF:188:<autosummary>:1
msgid "Get parameters for this estimator."
msgstr ""

#: of sklearn.decomposition._nmf.NMF:188:<autosummary>:1
msgid ":obj:`inverse_transform <sklearn.decomposition.NMF.inverse_transform>`\\"
msgstr ""

#: of sklearn.decomposition._nmf.NMF.inverse_transform:2
#: sklearn.decomposition._nmf.NMF:188:<autosummary>:1
msgid "Transform data back to its original space."
msgstr ""

#: of sklearn.decomposition._nmf.NMF:188:<autosummary>:1
msgid ":obj:`set_params <sklearn.decomposition.NMF.set_params>`\\"
msgstr ""

#: of sklearn.base.BaseEstimator.set_params:2
#: sklearn.decomposition._nmf.NMF:188:<autosummary>:1
msgid "Set the parameters of this estimator."
msgstr ""

#: of sklearn.decomposition._nmf.NMF:188:<autosummary>:1
msgid ":obj:`transform <sklearn.decomposition.NMF.transform>`\\"
msgstr ""

#: of sklearn.decomposition._nmf.NMF.transform:2
#: sklearn.decomposition._nmf.NMF:188:<autosummary>:1
msgid "Transform the data X according to the fitted NMF model."
msgstr ""

#: of sklearn.decomposition._nmf.NMF.fit:8
#: sklearn.decomposition._nmf.NMF.fit_transform:9
#: sklearn.decomposition._nmf.NMF.inverse_transform:13
#: sklearn.decomposition._nmf.NMF.transform:8
msgid "**X**"
msgstr ""

#: of
msgid "{array-like, sparse matrix} of shape (n_samples, n_features)"
msgstr ""

#: of sklearn.decomposition._nmf.NMF.fit:8
#: sklearn.decomposition._nmf.NMF.fit_transform:9
msgid "Data matrix to be decomposed"
msgstr ""

#: of sklearn.decomposition._nmf.NMF.fit:11
#: sklearn.decomposition._nmf.NMF.fit_transform:12
msgid "**y**"
msgstr ""

#: of
msgid "Ignored"
msgstr ""

#: of sklearn.base.BaseEstimator.get_params
#: sklearn.base.BaseEstimator.set_params sklearn.decomposition._nmf.NMF.fit
#: sklearn.decomposition._nmf.NMF.fit_transform
#: sklearn.decomposition._nmf.NMF.inverse_transform
#: sklearn.decomposition._nmf.NMF.transform
msgid "Returns"
msgstr ""

#: of sklearn.decomposition._nmf.NMF.fit:27
msgid "self"
msgstr ""

#: of sklearn.decomposition._nmf.NMF.fit_transform:4
msgid "This is more efficient than calling fit followed by transform."
msgstr ""

#: of sklearn.decomposition._nmf.NMF.fit_transform:15
#: sklearn.decomposition._nmf.NMF.fit_transform:34
#: sklearn.decomposition._nmf.NMF.inverse_transform:8
#: sklearn.decomposition._nmf.NMF.transform:24
msgid "**W**"
msgstr ""

#: of
msgid "array-like of shape (n_samples, n_components)"
msgstr ""

#: of sklearn.decomposition._nmf.NMF.fit_transform:15
#: sklearn.decomposition._nmf.NMF.fit_transform:18
msgid "If init='custom', it is used as initial guess for the solution."
msgstr ""

#: of sklearn.decomposition._nmf.NMF.fit_transform:18
msgid "**H**"
msgstr ""

#: of
msgid "array-like of shape (n_components, n_features)"
msgstr ""

#: of
msgid "ndarray of shape (n_samples, n_components)"
msgstr ""

#: of sklearn.decomposition._nmf.NMF.fit_transform:23
#: sklearn.decomposition._nmf.NMF.transform:13
msgid "Transformed data."
msgstr ""

#: of sklearn.base.BaseEstimator.get_params:9
msgid "**deep**"
msgstr ""

#: of
msgid "bool, default=True"
msgstr ""

#: of sklearn.base.BaseEstimator.get_params:8
msgid "If True, will return the parameters for this estimator and contained subobjects that are estimators."
msgstr ""

#: of sklearn.base.BaseEstimator.get_params:25
msgid "**params**"
msgstr ""

#: of
msgid "dict"
msgstr ""

#: of sklearn.base.BaseEstimator.get_params:14
msgid "Parameter names mapped to their values."
msgstr ""

#: of
msgid "{ndarray, sparse matrix} of shape (n_samples, n_components)"
msgstr ""

#: of sklearn.decomposition._nmf.NMF.inverse_transform:8
msgid "Transformed data matrix."
msgstr ""

#: of
msgid "{ndarray, sparse matrix} of shape (n_samples, n_features)"
msgstr ""

#: of sklearn.decomposition._nmf.NMF.inverse_transform:13
msgid "Data matrix of original shape."
msgstr ""

#: of sklearn.decomposition._nmf.NMF.inverse_transform:15
msgid ".."
msgstr ""

#: of sklearn.base.BaseEstimator.set_params:4
msgid "The method works on simple estimators as well as on nested objects (such as :class:`~sklearn.pipeline.Pipeline`). The latter have parameters of the form ``<component>__<parameter>`` so that it's possible to update each component of a nested object."
msgstr ""

#: of sklearn.base.BaseEstimator.set_params:12
msgid "**\\*\\*params**"
msgstr ""

#: of sklearn.base.BaseEstimator.set_params:12
msgid "Estimator parameters."
msgstr ""

#: of sklearn.base.BaseEstimator.set_params:28
msgid "**self**"
msgstr ""

#: of
msgid "estimator instance"
msgstr ""

#: of sklearn.base.BaseEstimator.set_params:17
msgid "Estimator instance."
msgstr ""

#: of sklearn.decomposition._nmf.NMF.transform:8
msgid "Data matrix to be transformed by the model."
msgstr ""

#: ../modules/generated/sklearn.decomposition.NMF.examples:4
msgid "Examples using ``sklearn.decomposition.NMF``"
msgstr ""

#: ../modules/generated/sklearn.decomposition.NMF.examples:15
#: ../modules/generated/sklearn.decomposition.NMF.examples:23
msgid ":ref:`sphx_glr_auto_examples_compose_plot_compare_reduction.py`"
msgstr ""

