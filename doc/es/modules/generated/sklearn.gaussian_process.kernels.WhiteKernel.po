msgid ""
msgstr ""
"Project-Id-Version: scikit-learn\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-03-31 11:24-0400\n"
"PO-Revision-Date: 2021-05-18 13:39\n"
"Last-Translator: \n"
"Language-Team: Spanish\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Crowdin-Project: scikit-learn\n"
"X-Crowdin-Project-ID: 450526\n"
"X-Crowdin-Language: es-ES\n"
"X-Crowdin-File: /main/doc/en/modules/generated/sklearn.gaussian_process.kernels.WhiteKernel.po\n"
"X-Crowdin-File-ID: 5418\n"
"Language: es_ES\n"

#: ../modules/generated/sklearn.gaussian_process.kernels.WhiteKernel.rst:2
msgid ":mod:`sklearn.gaussian_process.kernels`.WhiteKernel"
msgstr ":mod:`sklearn.gaussian_process.kernels`.WhiteKernel"

#: of sklearn.gaussian_process.kernels.WhiteKernel:2
msgid "White kernel."
msgstr "Núcleo blanco."

#: of sklearn.gaussian_process.kernels.WhiteKernel:4
msgid "The main use-case of this kernel is as part of a sum-kernel where it explains the noise of the signal as independently and identically normally-distributed. The parameter noise_level equals the variance of this noise."
msgstr "El principal caso de uso de este núcleo es como parte de un núcleo de suma en el que se explica el ruido de la señal como independiente e idénticamente distribuido de forma normal. El parámetro noise_level es igual a la varianza de este ruido."

#: of sklearn.gaussian_process.kernels.WhiteKernel:9
msgid "k(x_1, x_2) = noise\\_level \\text{ if } x_i == x_j \\text{ else } 0\n\n"
msgstr "k(x_1, x_2) = noise\\_level \\text{ if } x_i == x_j \\text{ else } 0\n\n"

#: of sklearn.gaussian_process.kernels.WhiteKernel:12
msgid "Read more in the :ref:`User Guide <gp_kernels>`."
msgstr "Más información en el :ref:`User Guide <gp_kernels>`."

#: of sklearn.gaussian_process.kernels.Kernel.clone_with_theta
#: sklearn.gaussian_process.kernels.Kernel.get_params
#: sklearn.gaussian_process.kernels.WhiteKernel
#: sklearn.gaussian_process.kernels.WhiteKernel.__call__
#: sklearn.gaussian_process.kernels.WhiteKernel.diag
msgid "Parameters"
msgstr "Parameters"

#: of sklearn.gaussian_process.kernels.WhiteKernel:19
msgid "**noise_level**"
msgstr "**noise_level**"

#: of
msgid "float, default=1.0"
msgstr "float, default=1.0"

#: of sklearn.gaussian_process.kernels.WhiteKernel:19
msgid "Parameter controlling the noise level (variance)"
msgstr "Parámetro que controla el nivel de ruido (varianza)"

#: of sklearn.gaussian_process.kernels.WhiteKernel:27
msgid "**noise_level_bounds**"
msgstr "**noise_level_bounds**"

#: of
msgid "pair of floats >= 0 or \"fixed\", default=(1e-5, 1e5)"
msgstr "pair of floats >= 0 or \"fixed\", default=(1e-5, 1e5)"

#: of sklearn.gaussian_process.kernels.WhiteKernel:22
msgid "The lower and upper bound on 'noise_level'. If set to \"fixed\", 'noise_level' cannot be changed during hyperparameter tuning."
msgstr "El límite inferior y superior de 'noise_level'. Si se establece como \"fijo\", 'noise_level' no puede cambiarse durante el ajuste de los hiperparámetros."

#: of sklearn.gaussian_process.kernels.WhiteKernel
msgid "Attributes"
msgstr "Atributos"

#: of sklearn.gaussian_process.kernels.WhiteKernel:32
msgid ":obj:`bounds <bounds>`"
msgstr ":obj:`bounds <bounds>`"

#: of sklearn.gaussian_process.kernels.WhiteKernel:32
#: sklearn.gaussian_process.kernels.WhiteKernel.bounds:2
msgid "Returns the log-transformed bounds on the theta."
msgstr "Devuelve los límites transformados en logaritmo de la theta."

#: of sklearn.gaussian_process.kernels.WhiteKernel:35
msgid "**hyperparameter_noise_level**"
msgstr "**hyperparameter_noise_level**"

#: of sklearn.gaussian_process.kernels.WhiteKernel:38
msgid ":obj:`hyperparameters <hyperparameters>`"
msgstr ":obj:`hyperparameters <hyperparameters>`"

#: of sklearn.gaussian_process.kernels.WhiteKernel:38
#: sklearn.gaussian_process.kernels.WhiteKernel.hyperparameters:2
msgid "Returns a list of all hyperparameter specifications."
msgstr "Devuelve una lista de todas las especificaciones de los hiperparámetros."

#: of sklearn.gaussian_process.kernels.WhiteKernel:41
msgid ":obj:`n_dims <n_dims>`"
msgstr ":obj:`n_dims <n_dims>`"

#: of sklearn.gaussian_process.kernels.WhiteKernel:41
#: sklearn.gaussian_process.kernels.WhiteKernel.n_dims:2
msgid "Returns the number of non-fixed hyperparameters of the kernel."
msgstr "Devuelve el número de hiperparámetros no fijos del núcleo."

#: of sklearn.gaussian_process.kernels.WhiteKernel:44
msgid ":obj:`requires_vector_input <requires_vector_input>`"
msgstr ":obj:`requires_vector_input <requires_vector_input>`"

#: of sklearn.gaussian_process.kernels.WhiteKernel:44
#: sklearn.gaussian_process.kernels.WhiteKernel.requires_vector_input:2
msgid "Whether the kernel works only on fixed-length feature vectors."
msgstr "Si el núcleo funciona sólo con vectores de características de longitud fija."

#: of sklearn.gaussian_process.kernels.WhiteKernel:53
msgid ":obj:`theta <theta>`"
msgstr ":obj:`theta <theta>`"

#: of sklearn.gaussian_process.kernels.WhiteKernel:47
#: sklearn.gaussian_process.kernels.WhiteKernel.theta:2
msgid "Returns the (flattened, log-transformed) non-fixed hyperparameters."
msgstr "Devuelve los hiperparámetros no fijos (aplanados y transformados en logaritmos)."

#: of sklearn.gaussian_process.kernels.WhiteKernel:56
msgid "Examples"
msgstr "Ejemplos"

#: of sklearn.gaussian_process.kernels.WhiteKernel:70
msgid "Methods"
msgstr "Métodos"

#: of sklearn.gaussian_process.kernels.WhiteKernel:79:<autosummary>:1
msgid ":obj:`__call__ <sklearn.gaussian_process.kernels.WhiteKernel.__call__>`\\"
msgstr ":obj:`__call__ <sklearn.gaussian_process.kernels.WhiteKernel.__call__>`\\"

#: of sklearn.gaussian_process.kernels.WhiteKernel.__call__:2
#: sklearn.gaussian_process.kernels.WhiteKernel:79:<autosummary>:1
msgid "Return the kernel k(X, Y) and optionally its gradient."
msgstr "Devuelve el núcleo k(X, Y) y opcionalmente su gradiente."

#: of sklearn.gaussian_process.kernels.WhiteKernel:79:<autosummary>:1
msgid ":obj:`clone_with_theta <sklearn.gaussian_process.kernels.WhiteKernel.clone_with_theta>`\\"
msgstr ":obj:`clone_with_theta <sklearn.gaussian_process.kernels.WhiteKernel.clone_with_theta>`\\"

#: of sklearn.gaussian_process.kernels.Kernel.clone_with_theta:2
#: sklearn.gaussian_process.kernels.WhiteKernel:79:<autosummary>:1
msgid "Returns a clone of self with given hyperparameters theta."
msgstr "Devuelve un clon de sí mismo con los hiperparámetros dados theta."

#: of sklearn.gaussian_process.kernels.WhiteKernel:79:<autosummary>:1
msgid ":obj:`diag <sklearn.gaussian_process.kernels.WhiteKernel.diag>`\\"
msgstr ":obj:`diag <sklearn.gaussian_process.kernels.WhiteKernel.diag>`\\"

#: of sklearn.gaussian_process.kernels.WhiteKernel.diag:2
#: sklearn.gaussian_process.kernels.WhiteKernel:79:<autosummary>:1
msgid "Returns the diagonal of the kernel k(X, X)."
msgstr "Devuelve la diagonal del núcleo k(X, X)."

#: of sklearn.gaussian_process.kernels.WhiteKernel:79:<autosummary>:1
msgid ":obj:`get_params <sklearn.gaussian_process.kernels.WhiteKernel.get_params>`\\"
msgstr ":obj:`get_params <sklearn.gaussian_process.kernels.WhiteKernel.get_params>`\\"

#: of sklearn.gaussian_process.kernels.Kernel.get_params:2
#: sklearn.gaussian_process.kernels.WhiteKernel:79:<autosummary>:1
msgid "Get parameters of this kernel."
msgstr "Obtener los parámetros de este núcleo."

#: of sklearn.gaussian_process.kernels.WhiteKernel:79:<autosummary>:1
msgid ":obj:`is_stationary <sklearn.gaussian_process.kernels.WhiteKernel.is_stationary>`\\"
msgstr ":obj:`is_stationary <sklearn.gaussian_process.kernels.WhiteKernel.is_stationary>`\\"

#: of sklearn.gaussian_process.kernels.StationaryKernelMixin.is_stationary:2
#: sklearn.gaussian_process.kernels.WhiteKernel:79:<autosummary>:1
msgid "Returns whether the kernel is stationary."
msgstr "Devuelve si el núcleo es estacionario."

#: of sklearn.gaussian_process.kernels.WhiteKernel:79:<autosummary>:1
msgid ":obj:`set_params <sklearn.gaussian_process.kernels.WhiteKernel.set_params>`\\"
msgstr ":obj:`set_params <sklearn.gaussian_process.kernels.WhiteKernel.set_params>`\\"

#: of sklearn.gaussian_process.kernels.Kernel.set_params:2
#: sklearn.gaussian_process.kernels.WhiteKernel:79:<autosummary>:1
msgid "Set the parameters of this kernel."
msgstr "Establece los parámetros de este núcleo."

#: of sklearn.gaussian_process.kernels.WhiteKernel.__call__:8
#: sklearn.gaussian_process.kernels.WhiteKernel.diag:11
msgid "**X**"
msgstr "**X**"

#: of
msgid "array-like of shape (n_samples_X, n_features) or list of object"
msgstr "array-like de forma (n_samples_X, n_features) o lista de objeto"

#: of sklearn.gaussian_process.kernels.WhiteKernel.__call__:8
msgid "Left argument of the returned kernel k(X, Y)"
msgstr "Argumento izquierdo del núcleo devuelto k(X, Y)"

#: of sklearn.gaussian_process.kernels.WhiteKernel.__call__:12
msgid "**Y**"
msgstr "**Y**"

#: of
msgid "array-like of shape (n_samples_X, n_features) or list of object,            default=None"
msgstr "array-like de forma (n_samples_X, n_features) o lista de objetos, por defecto = None"

#: of sklearn.gaussian_process.kernels.WhiteKernel.__call__:11
msgid "Right argument of the returned kernel k(X, Y). If None, k(X, X) is evaluated instead."
msgstr "Argumento derecho del núcleo devuelto k(X, Y). Si es None, se evalúa k(X, X) en su lugar."

#: of sklearn.gaussian_process.kernels.WhiteKernel.__call__:17
msgid "**eval_gradient**"
msgstr "**eval_gradient**"

#: of
msgid "bool, default=False"
msgstr "bool, default=False"

#: of sklearn.gaussian_process.kernels.WhiteKernel.__call__:15
msgid "Determines whether the gradient with respect to the log of the kernel hyperparameter is computed. Only supported when Y is None."
msgstr "Determina si se calcula el gradiente con respecto al logaritmo del hiperparámetro del núcleo. Sólo se admite cuando Y es None."

#: of sklearn.gaussian_process.kernels.Kernel.get_params
#: sklearn.gaussian_process.kernels.Kernel.set_params
#: sklearn.gaussian_process.kernels.WhiteKernel.__call__
#: sklearn.gaussian_process.kernels.WhiteKernel.bounds
#: sklearn.gaussian_process.kernels.WhiteKernel.diag
#: sklearn.gaussian_process.kernels.WhiteKernel.theta
msgid "Returns"
msgstr "Devuelve"

#: of sklearn.gaussian_process.kernels.WhiteKernel.__call__:22
msgid "**K**"
msgstr "**K**"

#: of
msgid "ndarray of shape (n_samples_X, n_samples_Y)"
msgstr "ndarray of shape (n_samples_X, n_samples_Y)"

#: of sklearn.gaussian_process.kernels.WhiteKernel.__call__:22
msgid "Kernel k(X, Y)"
msgstr "Núcleo k(X, Y)"

#: of sklearn.gaussian_process.kernels.WhiteKernel.__call__:38
msgid "**K_gradient**"
msgstr "**K_gradient**"

#: of
msgid "ndarray of shape (n_samples_X, n_samples_X, n_dims),            optional"
msgstr "ndarray of shape (n_samples_X, n_samples_X, n_dims),            optional"

#: of sklearn.gaussian_process.kernels.WhiteKernel.__call__:25
msgid "The gradient of the kernel k(X, X) with respect to the log of the hyperparameter of the kernel. Only returned when eval_gradient is True."
msgstr "El gradiente del núcleo k(X, X) con respecto al logaritmo del hiperparámetro del núcleo. Sólo se devuelve cuando eval_gradient es True."

#: of sklearn.gaussian_process.kernels.WhiteKernel.bounds:20
msgid "**bounds**"
msgstr "**bounds**"

#: of
msgid "ndarray of shape (n_dims, 2)"
msgstr "ndarray of shape (n_dims, 2)"

#: of sklearn.gaussian_process.kernels.WhiteKernel.bounds:9
msgid "The log-transformed bounds on the kernel's hyperparameters theta"
msgstr "Los límites transformados logarítmicamente de los hiperparámetros del núcleo theta"

#: of sklearn.gaussian_process.kernels.Kernel.clone_with_theta:20
#: sklearn.gaussian_process.kernels.WhiteKernel.theta:24
msgid "**theta**"
msgstr "**theta**"

#: of
msgid "ndarray of shape (n_dims,)"
msgstr "ndarray of shape (n_dims,)"

#: of sklearn.gaussian_process.kernels.Kernel.clone_with_theta:8
msgid "The hyperparameters"
msgstr "Hiperparámetros"

#: of sklearn.gaussian_process.kernels.WhiteKernel.diag:4
msgid "The result of this method is identical to np.diag(self(X)); however, it can be evaluated more efficiently since only the diagonal is evaluated."
msgstr "El resultado de este método es idéntico al de np.diag(self(X)); sin embargo, se puede evaluar de forma más eficiente ya que sólo se evalúa la diagonal."

#: of sklearn.gaussian_process.kernels.WhiteKernel.diag:11
msgid "Argument to the kernel."
msgstr "Argumento para el núcleo."

#: of sklearn.gaussian_process.kernels.WhiteKernel.diag:27
msgid "**K_diag**"
msgstr "**K_diag**"

#: of
msgid "ndarray of shape (n_samples_X,)"
msgstr "ndarray of shape (n_samples_X,)"

#: of sklearn.gaussian_process.kernels.WhiteKernel.diag:16
msgid "Diagonal of kernel k(X, X)"
msgstr "Diagonal del núcleo k(X, X)"

#: of sklearn.gaussian_process.kernels.Kernel.get_params:9
msgid "**deep**"
msgstr "**deep**"

#: of
msgid "bool, default=True"
msgstr "bool, default=True"

#: of sklearn.gaussian_process.kernels.Kernel.get_params:8
msgid "If True, will return the parameters for this estimator and contained subobjects that are estimators."
msgstr "Si es True, devolverá los parámetros para este estimador y los subobjetos contenidos que son estimadores."

#: of sklearn.gaussian_process.kernels.Kernel.get_params:25
msgid "**params**"
msgstr "**params**"

#: of
msgid "dict"
msgstr "dict"

#: of sklearn.gaussian_process.kernels.Kernel.get_params:14
msgid "Parameter names mapped to their values."
msgstr "Nombres de parámetros mapeados a sus valores."

#: of sklearn.gaussian_process.kernels.Kernel.set_params:4
msgid "The method works on simple kernels as well as on nested kernels. The latter have parameters of the form ``<component>__<parameter>`` so that it's possible to update each component of a nested object."
msgstr "El método funciona tanto en núcleos simples como en núcleos anidados. Estos últimos tienen parámetros de la forma ``<component>__<parameter>`` para que sea posible actualizar cada componente de un objeto anidado."

#: of sklearn.gaussian_process.kernels.Kernel.set_params:23
msgid "self"
msgstr "self"

#: of sklearn.gaussian_process.kernels.WhiteKernel.theta:4
msgid "Note that theta are typically the log-transformed values of the kernel's hyperparameters as this representation of the search space is more amenable for hyperparameter search, as hyperparameters like length-scales naturally live on a log-scale."
msgstr "Nótese que theta son típicamente los valores transformados en logaritmos de los hiperparámetros del núcleo, ya que esta representación del espacio de búsqueda es más adecuada para la búsqueda de hiperparámetros, ya que los hiperparámetros como las escalas de longitud viven naturalmente en una escala logarítmica."

#: of sklearn.gaussian_process.kernels.WhiteKernel.theta:13
msgid "The non-fixed, log-transformed hyperparameters of the kernel"
msgstr "Los hiperparámetros no fijos y transformados en logaritmos del núcleo"

#: ../modules/generated/sklearn.gaussian_process.kernels.WhiteKernel.examples:4
msgid "Examples using ``sklearn.gaussian_process.kernels.WhiteKernel``"
msgstr "Ejemplos usando ``sklearn.gaussian_process.kernels.WhiteKernel``"

#: ../modules/generated/sklearn.gaussian_process.kernels.WhiteKernel.examples:15
#: ../modules/generated/sklearn.gaussian_process.kernels.WhiteKernel.examples:23
msgid ":ref:`sphx_glr_auto_examples_gaussian_process_plot_compare_gpr_krr.py`"
msgstr ":ref:`sphx_glr_auto_examples_gaussian_process_plot_compare_gpr_krr.py`"

#: ../modules/generated/sklearn.gaussian_process.kernels.WhiteKernel.examples:34
#: ../modules/generated/sklearn.gaussian_process.kernels.WhiteKernel.examples:42
msgid ":ref:`sphx_glr_auto_examples_gaussian_process_plot_gpr_noisy.py`"
msgstr ":ref:`sphx_glr_auto_examples_gaussian_process_plot_gpr_noisy.py`"

#: ../modules/generated/sklearn.gaussian_process.kernels.WhiteKernel.examples:53
#: ../modules/generated/sklearn.gaussian_process.kernels.WhiteKernel.examples:61
msgid ":ref:`sphx_glr_auto_examples_gaussian_process_plot_gpr_co2.py`"
msgstr ":ref:`sphx_glr_auto_examples_gaussian_process_plot_gpr_co2.py`"

