msgid ""
msgstr ""
"Project-Id-Version: scikit-learn\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-03-31 11:24-0400\n"
"PO-Revision-Date: 2021-05-17 20:58\n"
"Last-Translator: \n"
"Language-Team: Spanish\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Crowdin-Project: scikit-learn\n"
"X-Crowdin-Project-ID: 450526\n"
"X-Crowdin-Language: es-ES\n"
"X-Crowdin-File: /main/doc/en/modules/generated/sklearn.gaussian_process.kernels.RBF.po\n"
"X-Crowdin-File-ID: 5602\n"
"Language: es_ES\n"

#: ../modules/generated/sklearn.gaussian_process.kernels.RBF.rst:2
msgid ":mod:`sklearn.gaussian_process.kernels`.RBF"
msgstr ":mod:`sklearn.gaussian_process.kernels`.RBF"

#: of sklearn.gaussian_process.kernels.RBF:2
msgid "Radial-basis function kernel (aka squared-exponential kernel)."
msgstr "Kernel o núcleo de la función base Radial (también conocido como kernel cuadrado-exponencial)."

#: of sklearn.gaussian_process.kernels.RBF:4
msgid "The RBF kernel is a stationary kernel. It is also known as the \"squared exponential\" kernel. It is parameterized by a length scale parameter :math:`l>0`, which can either be a scalar (isotropic variant of the kernel) or a vector with the same number of dimensions as the inputs X (anisotropic variant of the kernel). The kernel is given by:"
msgstr "El núcleo RBF es un núcleo estacionario. También se conoce como núcleo \"exponencial cuadrado\". Está parametrizado por un parámetro de escala de longitud :math:`l>0`, que puede ser un escalar (variante isotrópica del núcleo) o un vector con el mismo número de dimensiones que las entradas X (variante anisotrópica del núcleo). El núcleo viene dado por:"

#: of sklearn.gaussian_process.kernels.RBF:10
msgid "k(x_i, x_j) = \\exp\\left(- \\frac{d(x_i, x_j)^2}{2l^2} \\right)\n\n"
msgstr "k(x_i, x_j) = \\exp\\left(- \\frac{d(x_i, x_j)^2}{2l^2} \\right)\n\n"

#: of sklearn.gaussian_process.kernels.RBF:13
msgid "where :math:`l` is the length scale of the kernel and :math:`d(\\cdot,\\cdot)` is the Euclidean distance. For advice on how to set the length scale parameter, see e.g. [Redc669bcbe98-1]_."
msgstr "donde :math:`l` es la escala de longitud del núcleo y :math:`d(\\cdot,\\cdot)` es la distancia euclidiana. Para saber cómo establecer el parámetro de la escala de longitud, ver, por ejemplo, [Redc669bcbe98-1]_."

#: of sklearn.gaussian_process.kernels.RBF:17
msgid "This kernel is infinitely differentiable, which implies that GPs with this kernel as covariance function have mean square derivatives of all orders, and are thus very smooth. See [Redc669bcbe98-2]_, Chapter 4, Section 4.2, for further details of the RBF kernel."
msgstr "Este núcleo es infinitamente diferenciable, lo que implica que las GPs con este núcleo como función de covarianza tienen derivadas cuadráticas medias de todos los órdenes, y por tanto son muy suaves. Ver [Redc669bcbe98-2]_, Capítulo 4, Sección 4.2, para más detalles del núcleo RBF."

#: of sklearn.gaussian_process.kernels.RBF:22
msgid "Read more in the :ref:`User Guide <gp_kernels>`."
msgstr "Más información en el :ref:`Manual de usuario <gp_kernels>`."

#: of sklearn.gaussian_process.kernels.Kernel.clone_with_theta
#: sklearn.gaussian_process.kernels.Kernel.get_params
#: sklearn.gaussian_process.kernels.NormalizedKernelMixin.diag
#: sklearn.gaussian_process.kernels.RBF
#: sklearn.gaussian_process.kernels.RBF.__call__
msgid "Parameters"
msgstr "Parámetros"

#: of sklearn.gaussian_process.kernels.RBF:31
msgid "**length_scale**"
msgstr "**length_scale**"

#: of
msgid "float or ndarray of shape (n_features,), default=1.0"
msgstr "float or ndarray of shape (n_features,), default=1.0"

#: of sklearn.gaussian_process.kernels.RBF:29
msgid "The length scale of the kernel. If a float, an isotropic kernel is used. If an array, an anisotropic kernel is used where each dimension of l defines the length-scale of the respective feature dimension."
msgstr "La escala de longitud del núcleo. Si es un flotador, se utiliza un núcleo isotrópico. Si es un arreglo, se utiliza un núcleo anisotrópico en el que cada dimensión de l define la escala de longitud de la respectiva dimensión de la característica."

#: of sklearn.gaussian_process.kernels.RBF:39
msgid "**length_scale_bounds**"
msgstr "**length_scale_bounds**"

#: of
msgid "pair of floats >= 0 or \"fixed\", default=(1e-5, 1e5)"
msgstr "pair of floats >= 0 or \"fixed\", default=(1e-5, 1e5)"

#: of sklearn.gaussian_process.kernels.RBF:34
msgid "The lower and upper bound on 'length_scale'. If set to \"fixed\", 'length_scale' cannot be changed during hyperparameter tuning."
msgstr "El límite inferior y superior de 'length_scale'. Si se establece como \" fixed\", 'length_scale' no puede cambiarse durante el ajuste de los hiperparámetros."

#: of sklearn.gaussian_process.kernels.RBF
msgid "Attributes"
msgstr "Atributos"

#: of sklearn.gaussian_process.kernels.RBF:44
msgid "**anisotropic**"
msgstr "**anisotropic**"

#: of sklearn.gaussian_process.kernels.RBF:47
msgid ":obj:`bounds <bounds>`"
msgstr ":obj:`bounds <bounds>`"

#: of sklearn.gaussian_process.kernels.RBF:47
#: sklearn.gaussian_process.kernels.RBF.bounds:2
msgid "Returns the log-transformed bounds on the theta."
msgstr "Devuelve los límites transformados en logaritmo de la theta."

#: of sklearn.gaussian_process.kernels.RBF:50
msgid "**hyperparameter_length_scale**"
msgstr "**hyperparameter_length_scale**"

#: of sklearn.gaussian_process.kernels.RBF:53
msgid ":obj:`hyperparameters <hyperparameters>`"
msgstr ":obj:`hyperparameters <hyperparameters>`"

#: of sklearn.gaussian_process.kernels.RBF:53
#: sklearn.gaussian_process.kernels.RBF.hyperparameters:2
msgid "Returns a list of all hyperparameter specifications."
msgstr "Devuelve una lista de todas las especificaciones de los hiperparámetros."

#: of sklearn.gaussian_process.kernels.RBF:56
msgid ":obj:`n_dims <n_dims>`"
msgstr ":obj:`n_dims <n_dims>`"

#: of sklearn.gaussian_process.kernels.RBF:56
#: sklearn.gaussian_process.kernels.RBF.n_dims:2
msgid "Returns the number of non-fixed hyperparameters of the kernel."
msgstr "Devuelve el número de hiperparámetros no fijos del núcleo."

#: of sklearn.gaussian_process.kernels.RBF:59
msgid ":obj:`requires_vector_input <requires_vector_input>`"
msgstr ":obj:`requires_vector_input <requires_vector_input>`"

#: of sklearn.gaussian_process.kernels.RBF:59
msgid "Returns whether the kernel is defined on fixed-length feature vectors or generic objects."
msgstr "Devuelve si el núcleo está definido en vectores de características de longitud fija o en objetos genéricos."

#: of sklearn.gaussian_process.kernels.RBF:67
msgid ":obj:`theta <theta>`"
msgstr ":obj:`theta <theta>`"

#: of sklearn.gaussian_process.kernels.RBF:62
#: sklearn.gaussian_process.kernels.RBF.theta:2
msgid "Returns the (flattened, log-transformed) non-fixed hyperparameters."
msgstr "Devuelve los hiperparámetros no fijos (aplanados y transformados en logaritmos)."

#: of sklearn.gaussian_process.kernels.RBF:70
msgid "References"
msgstr "Referencias"

#: of sklearn.gaussian_process.kernels.RBF:71
msgid "`David Duvenaud (2014). \"The Kernel Cookbook: Advice on Covariance functions\". <https://www.cs.toronto.edu/~duvenaud/cookbook/>`_"
msgstr "`David Duvenaud (2014). \"The Kernel Cookbook: Advice on Covariance functions\". <https://www.cs.toronto.edu/~duvenaud/cookbook/>`_"

#: of sklearn.gaussian_process.kernels.RBF:75
msgid "`Carl Edward Rasmussen, Christopher K. I. Williams (2006). \"Gaussian Processes for Machine Learning\". The MIT Press. <http://www.gaussianprocess.org/gpml/>`_"
msgstr "`Carl Edward Rasmussen, Christopher K. I. Williams (2006). \"Gaussian Processes for Machine Learning\". The MIT Press. <http://www.gaussianprocess.org/gpml/>`_"

#: of sklearn.gaussian_process.kernels.RBF:81
msgid "[Redc669bcbe98-1]_, [Redc669bcbe98-2]_"
msgstr "[Redc669bcbe98-1]_, [Redc669bcbe98-2]_"

#: of sklearn.gaussian_process.kernels.RBF:84
msgid "Examples"
msgstr "Ejemplos"

#: of sklearn.gaussian_process.kernels.RBF:99
msgid "Methods"
msgstr "Métodos"

#: of sklearn.gaussian_process.kernels.RBF:108:<autosummary>:1
msgid ":obj:`__call__ <sklearn.gaussian_process.kernels.RBF.__call__>`\\"
msgstr ":obj:`__call__ <sklearn.gaussian_process.kernels.RBF.__call__>`\\"

#: of sklearn.gaussian_process.kernels.RBF.__call__:2
#: sklearn.gaussian_process.kernels.RBF:108:<autosummary>:1
msgid "Return the kernel k(X, Y) and optionally its gradient."
msgstr "Devuelve el núcleo k(X, Y) y opcionalmente su gradiente."

#: of sklearn.gaussian_process.kernels.RBF:108:<autosummary>:1
msgid ":obj:`clone_with_theta <sklearn.gaussian_process.kernels.RBF.clone_with_theta>`\\"
msgstr ":obj:`clone_with_theta <sklearn.gaussian_process.kernels.RBF.clone_with_theta>`\\"

#: of sklearn.gaussian_process.kernels.Kernel.clone_with_theta:2
#: sklearn.gaussian_process.kernels.RBF:108:<autosummary>:1
msgid "Returns a clone of self with given hyperparameters theta."
msgstr "Devuelve un clon de sí mismo con los hiperparámetros dados theta."

#: of sklearn.gaussian_process.kernels.RBF:108:<autosummary>:1
msgid ":obj:`diag <sklearn.gaussian_process.kernels.RBF.diag>`\\"
msgstr ":obj:`diag <sklearn.gaussian_process.kernels.RBF.diag>`\\"

#: of sklearn.gaussian_process.kernels.NormalizedKernelMixin.diag:2
#: sklearn.gaussian_process.kernels.RBF:108:<autosummary>:1
msgid "Returns the diagonal of the kernel k(X, X)."
msgstr "Devuelve la diagonal del núcleo k(X, X)."

#: of sklearn.gaussian_process.kernels.RBF:108:<autosummary>:1
msgid ":obj:`get_params <sklearn.gaussian_process.kernels.RBF.get_params>`\\"
msgstr ":obj:`get_params <sklearn.gaussian_process.kernels.RBF.get_params>`\\"

#: of sklearn.gaussian_process.kernels.Kernel.get_params:2
#: sklearn.gaussian_process.kernels.RBF:108:<autosummary>:1
msgid "Get parameters of this kernel."
msgstr "Obtener los parámetros de este núcleo."

#: of sklearn.gaussian_process.kernels.RBF:108:<autosummary>:1
msgid ":obj:`is_stationary <sklearn.gaussian_process.kernels.RBF.is_stationary>`\\"
msgstr ":obj:`is_stationary <sklearn.gaussian_process.kernels.RBF.is_stationary>`\\"

#: of sklearn.gaussian_process.kernels.RBF:108:<autosummary>:1
#: sklearn.gaussian_process.kernels.StationaryKernelMixin.is_stationary:2
msgid "Returns whether the kernel is stationary."
msgstr "Devuelve si el núcleo es estacionario."

#: of sklearn.gaussian_process.kernels.RBF:108:<autosummary>:1
msgid ":obj:`set_params <sklearn.gaussian_process.kernels.RBF.set_params>`\\"
msgstr ":obj:`set_params <sklearn.gaussian_process.kernels.RBF.set_params>`\\"

#: of sklearn.gaussian_process.kernels.Kernel.set_params:2
#: sklearn.gaussian_process.kernels.RBF:108:<autosummary>:1
msgid "Set the parameters of this kernel."
msgstr "Obtener los parámetros de este núcleo."

#: of sklearn.gaussian_process.kernels.NormalizedKernelMixin.diag:11
#: sklearn.gaussian_process.kernels.RBF.__call__:8
msgid "**X**"
msgstr "**X**"

#: of
msgid "ndarray of shape (n_samples_X, n_features)"
msgstr "ndarray of shape (n_samples_X, n_features)"

#: of sklearn.gaussian_process.kernels.NormalizedKernelMixin.diag:11
#: sklearn.gaussian_process.kernels.RBF.__call__:8
msgid "Left argument of the returned kernel k(X, Y)"
msgstr "Argumento izquierdo del núcleo devuelto k(X, Y)"

#: of sklearn.gaussian_process.kernels.RBF.__call__:12
msgid "**Y**"
msgstr "**Y**"

#: of
msgid "ndarray of shape (n_samples_Y, n_features), default=None"
msgstr "ndarray of shape (n_samples_Y, n_features), default=None"

#: of sklearn.gaussian_process.kernels.RBF.__call__:11
msgid "Right argument of the returned kernel k(X, Y). If None, k(X, X) if evaluated instead."
msgstr "Argumento derecho del núcleo devuelto k(X, Y). Si es None, se evalúa k(X, X) en su lugar."

#: of sklearn.gaussian_process.kernels.RBF.__call__:17
msgid "**eval_gradient**"
msgstr "**eval_gradient**"

#: of
msgid "bool, default=False"
msgstr "bool, default=False"

#: of sklearn.gaussian_process.kernels.RBF.__call__:15
msgid "Determines whether the gradient with respect to the log of the kernel hyperparameter is computed. Only supported when Y is None."
msgstr "Determina si se calcula el gradiente con respecto al logaritmo del hiperparámetro del núcleo. Sólo se admite cuando Y es None."

#: of sklearn.gaussian_process.kernels.Kernel.get_params
#: sklearn.gaussian_process.kernels.Kernel.set_params
#: sklearn.gaussian_process.kernels.NormalizedKernelMixin.diag
#: sklearn.gaussian_process.kernels.RBF.__call__
#: sklearn.gaussian_process.kernels.RBF.bounds
#: sklearn.gaussian_process.kernels.RBF.theta
msgid "Returns"
msgstr "Devuelve"

#: of sklearn.gaussian_process.kernels.RBF.__call__:22
msgid "**K**"
msgstr "**K**"

#: of
msgid "ndarray of shape (n_samples_X, n_samples_Y)"
msgstr "ndarray of shape (n_samples_X, n_samples_Y)"

#: of sklearn.gaussian_process.kernels.RBF.__call__:22
msgid "Kernel k(X, Y)"
msgstr "Núcleo k(X, Y)"

#: of sklearn.gaussian_process.kernels.RBF.__call__:38
msgid "**K_gradient**"
msgstr "**K_gradient**"

#: of
msgid "ndarray of shape (n_samples_X, n_samples_X, n_dims),                 optional"
msgstr "ndarray of shape (n_samples_X, n_samples_X, n_dims),                 optional"

#: of sklearn.gaussian_process.kernels.RBF.__call__:25
msgid "The gradient of the kernel k(X, X) with respect to the log of the hyperparameter of the kernel. Only returned when `eval_gradient` is True."
msgstr "El gradiente del núcleo k(X, X) con respecto al logaritmo del hiperparámetro del núcleo. Sólo se devuelve cuando `eval_gradient` es True."

#: of sklearn.gaussian_process.kernels.RBF.bounds:20
msgid "**bounds**"
msgstr "**bounds**"

#: of
msgid "ndarray of shape (n_dims, 2)"
msgstr "ndarray of shape (n_dims, 2)"

#: of sklearn.gaussian_process.kernels.RBF.bounds:9
msgid "The log-transformed bounds on the kernel's hyperparameters theta"
msgstr "Los límites transformados logarítmicamente de los hiperparámetros del núcleo theta"

#: of sklearn.gaussian_process.kernels.Kernel.clone_with_theta:20
#: sklearn.gaussian_process.kernels.RBF.theta:24
msgid "**theta**"
msgstr "**theta**"

#: of
msgid "ndarray of shape (n_dims,)"
msgstr "ndarray of shape (n_dims,)"

#: of sklearn.gaussian_process.kernels.Kernel.clone_with_theta:8
msgid "The hyperparameters"
msgstr "Hiperparámetros"

#: of sklearn.gaussian_process.kernels.NormalizedKernelMixin.diag:4
msgid "The result of this method is identical to np.diag(self(X)); however, it can be evaluated more efficiently since only the diagonal is evaluated."
msgstr "El resultado de este método es idéntico al de np.diag(self(X)); sin embargo, se puede evaluar de forma más eficiente ya que sólo se evalúa la diagonal."

#: of sklearn.gaussian_process.kernels.NormalizedKernelMixin.diag:27
msgid "**K_diag**"
msgstr "**K_diag**"

#: of
msgid "ndarray of shape (n_samples_X,)"
msgstr "ndarray of shape (n_samples_X,)"

#: of sklearn.gaussian_process.kernels.NormalizedKernelMixin.diag:16
msgid "Diagonal of kernel k(X, X)"
msgstr "Diagonal del núcleo k(X, X)"

#: of sklearn.gaussian_process.kernels.Kernel.get_params:9
msgid "**deep**"
msgstr "**deep**"

#: of
msgid "bool, default=True"
msgstr "bool, default=True"

#: of sklearn.gaussian_process.kernels.Kernel.get_params:8
msgid "If True, will return the parameters for this estimator and contained subobjects that are estimators."
msgstr "Si es True, devolverá los parámetros para este estimador y los subobjetos contenidos que son estimadores."

#: of sklearn.gaussian_process.kernels.Kernel.get_params:25
msgid "**params**"
msgstr "**params**"

#: of
msgid "dict"
msgstr "dict"

#: of sklearn.gaussian_process.kernels.Kernel.get_params:14
msgid "Parameter names mapped to their values."
msgstr "Nombres de parámetros mapeados a sus valores."

#: of sklearn.gaussian_process.kernels.RBF.requires_vector_input:2
msgid "Returns whether the kernel is defined on fixed-length feature vectors or generic objects. Defaults to True for backward compatibility."
msgstr "Devuelve si el núcleo está definido en vectores de características de longitud fija o en objetos genéricos. El valor predeterminado es True para la compatibilidad con versiones anteriores."

#: of sklearn.gaussian_process.kernels.Kernel.set_params:4
msgid "The method works on simple kernels as well as on nested kernels. The latter have parameters of the form ``<component>__<parameter>`` so that it's possible to update each component of a nested object."
msgstr "El método funciona tanto en núcleos simples como en núcleos anidados. Estos últimos tienen parámetros de la forma ``<component>__<parameter>`` para que sea posible actualizar cada componente de un objeto anidado."

#: of sklearn.gaussian_process.kernels.Kernel.set_params:23
msgid "self"
msgstr "self"

#: of sklearn.gaussian_process.kernels.RBF.theta:4
msgid "Note that theta are typically the log-transformed values of the kernel's hyperparameters as this representation of the search space is more amenable for hyperparameter search, as hyperparameters like length-scales naturally live on a log-scale."
msgstr "Ten en cuenta que theta suelen ser los valores transformados en logaritmos de los hiperparámetros del núcleo, ya que esta representación del espacio de búsqueda es más adecuada para la búsqueda de hiperparámetros, ya que los hiperparámetros como las escalas de longitud viven naturalmente en una escala logarítmica."

#: of sklearn.gaussian_process.kernels.RBF.theta:13
msgid "The non-fixed, log-transformed hyperparameters of the kernel"
msgstr "Los hiperparámetros no fijos y transformados en logaritmos del núcleo"

#: ../modules/generated/sklearn.gaussian_process.kernels.RBF.examples:4
msgid "Examples using ``sklearn.gaussian_process.kernels.RBF``"
msgstr "Ejemplos usando ``sklearn.gaussian_process.kernels.RBF``"

#: ../modules/generated/sklearn.gaussian_process.kernels.RBF.examples:15
#: ../modules/generated/sklearn.gaussian_process.kernels.RBF.examples:23
msgid ":ref:`sphx_glr_auto_examples_gaussian_process_plot_gpc_xor.py`"
msgstr ":ref:`sphx_glr_auto_examples_gaussian_process_plot_gpc_xor.py`"

#: ../modules/generated/sklearn.gaussian_process.kernels.RBF.examples:34
#: ../modules/generated/sklearn.gaussian_process.kernels.RBF.examples:42
msgid ":ref:`sphx_glr_auto_examples_gaussian_process_plot_gpc_iris.py`"
msgstr ":ref:`sphx_glr_auto_examples_gaussian_process_plot_gpc_iris.py`"

#: ../modules/generated/sklearn.gaussian_process.kernels.RBF.examples:53
#: ../modules/generated/sklearn.gaussian_process.kernels.RBF.examples:61
msgid ":ref:`sphx_glr_auto_examples_gaussian_process_plot_gpr_prior_posterior.py`"
msgstr ":ref:`sphx_glr_auto_examples_gaussian_process_plot_gpr_prior_posterior.py`"

#: ../modules/generated/sklearn.gaussian_process.kernels.RBF.examples:72
#: ../modules/generated/sklearn.gaussian_process.kernels.RBF.examples:80
msgid ":ref:`sphx_glr_auto_examples_gaussian_process_plot_gpc.py`"
msgstr ":ref:`sphx_glr_auto_examples_gaussian_process_plot_gpc.py`"

#: ../modules/generated/sklearn.gaussian_process.kernels.RBF.examples:91
#: ../modules/generated/sklearn.gaussian_process.kernels.RBF.examples:99
msgid ":ref:`sphx_glr_auto_examples_gaussian_process_plot_gpr_noisy.py`"
msgstr ":ref:`sphx_glr_auto_examples_gaussian_process_plot_gpr_noisy.py`"

#: ../modules/generated/sklearn.gaussian_process.kernels.RBF.examples:110
#: ../modules/generated/sklearn.gaussian_process.kernels.RBF.examples:118
msgid ":ref:`sphx_glr_auto_examples_gaussian_process_plot_gpr_noisy_targets.py`"
msgstr ":ref:`sphx_glr_auto_examples_gaussian_process_plot_gpr_noisy_targets.py`"

#: ../modules/generated/sklearn.gaussian_process.kernels.RBF.examples:129
#: ../modules/generated/sklearn.gaussian_process.kernels.RBF.examples:137
msgid ":ref:`sphx_glr_auto_examples_gaussian_process_plot_gpr_co2.py`"
msgstr ":ref:`sphx_glr_auto_examples_gaussian_process_plot_gpr_co2.py`"

