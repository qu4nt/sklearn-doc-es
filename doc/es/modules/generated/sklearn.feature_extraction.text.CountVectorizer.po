msgid ""
msgstr ""
"Project-Id-Version: scikit-learn\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-03-31 12:43-0400\n"
"PO-Revision-Date: 2021-05-31 17:27\n"
"Last-Translator: \n"
"Language-Team: Spanish\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Crowdin-Project: scikit-learn\n"
"X-Crowdin-Project-ID: 450526\n"
"X-Crowdin-Language: es-ES\n"
"X-Crowdin-File: /main/doc/en/modules/generated/sklearn.feature_extraction.text.CountVectorizer.po\n"
"X-Crowdin-File-ID: 4912\n"
"Language: es_ES\n"

#: ../modules/generated/sklearn.feature_extraction.text.CountVectorizer.rst:2
msgid ":mod:`sklearn.feature_extraction.text`.CountVectorizer"
msgstr ":mod:`sklearn.feature_extraction.text`.CountVectorizer"

#: of sklearn.feature_extraction.text.CountVectorizer:2
msgid "Convert a collection of text documents to a matrix of token counts"
msgstr "Convertir una colección de documentos de texto en una matriz de conteo de tokens"

#: of sklearn.feature_extraction.text.CountVectorizer:4
msgid "This implementation produces a sparse representation of the counts using scipy.sparse.csr_matrix."
msgstr "Esta implementación produce una representación dispersa de los conteos utilizando scipy.sparse.csr_matrix."

#: of sklearn.feature_extraction.text.CountVectorizer:7
msgid "If you do not provide an a-priori dictionary and you do not use an analyzer that does some kind of feature selection then the number of features will be equal to the vocabulary size found by analyzing the data."
msgstr "Si no proporcionas un diccionario a priori y no utilizas un analizador que haga algún tipo de selección de características, entonces el número de características será igual al tamaño del vocabulario encontrado al analizar los datos."

#: of sklearn.feature_extraction.text.CountVectorizer:11
msgid "Read more in the :ref:`User Guide <text_feature_extraction>`."
msgstr "Lee más en el :ref:`Manual de usuario <text_feature_extraction>`."

#: of sklearn.base.BaseEstimator.get_params
#: sklearn.base.BaseEstimator.set_params
#: sklearn.feature_extraction.text.CountVectorizer
#: sklearn.feature_extraction.text.CountVectorizer.fit
#: sklearn.feature_extraction.text.CountVectorizer.fit_transform
#: sklearn.feature_extraction.text.CountVectorizer.inverse_transform
#: sklearn.feature_extraction.text.CountVectorizer.transform
#: sklearn.feature_extraction.text._VectorizerMixin.decode
msgid "Parameters"
msgstr "Parámetros"

#: of sklearn.feature_extraction.text.CountVectorizer:24
msgid "**input**"
msgstr "**input**"

#: of
msgid "string {'filename', 'file', 'content'}, default='content'"
msgstr "string {'filename', 'file', 'content'}, default='content'"

#: of sklearn.feature_extraction.text.CountVectorizer:16
msgid "If 'filename', the sequence passed as an argument to fit is expected to be a list of filenames that need reading to fetch the raw content to analyze."
msgstr "Si es 'filename', se espera que la secuencia pasada como argumento a fit sea una lista de nombres de archivos que necesitan ser leídos para obtener el contenido en bruto a analizar."

#: of sklearn.feature_extraction.text.CountVectorizer:20
msgid "If 'file', the sequence items must have a 'read' method (file-like object) that is called to fetch the bytes in memory."
msgstr "Si es 'file', los elementos de la secuencia deben tener un método 'read' de lectura (objeto file-like) que se invoca para obtener los bytes en la memoria."

#: of sklearn.feature_extraction.text.CountVectorizer:23
msgid "Otherwise the input is expected to be a sequence of items that can be of type string or byte."
msgstr "En caso contrario, se espera que la entrada sea una secuencia de elementos que pueden ser de tipo cadena (string) o byte."

#: of sklearn.feature_extraction.text.CountVectorizer:28
msgid "**encoding**"
msgstr "**encoding**"

#: of
msgid "string, default='utf-8'"
msgstr "string, default='utf-8'"

#: of sklearn.feature_extraction.text.CountVectorizer:27
msgid "If bytes or files are given to analyze, this encoding is used to decode."
msgstr "Si se dan bytes o archivos para analizar, se utiliza esta codificación para decodificar."

#: of sklearn.feature_extraction.text.CountVectorizer:34
msgid "**decode_error**"
msgstr "**decode_error**"

#: of
msgid "{'strict', 'ignore', 'replace'}, default='strict'"
msgstr "{'strict', 'ignore', 'replace'}, default='strict'"

#: of sklearn.feature_extraction.text.CountVectorizer:31
msgid "Instruction on what to do if a byte sequence is given to analyze that contains characters not of the given `encoding`. By default, it is 'strict', meaning that a UnicodeDecodeError will be raised. Other values are 'ignore' and 'replace'."
msgstr "Instrucción sobre qué hacer si se proporciona una secuencia de bytes para analizar que contiene caracteres que no pertencen al `encoding` (codificación) dado. Por defecto, es 'strict', lo que significa que se producirá un UnicodeDecodeError. Otros valores son 'ignore' y 'replace'."

#: of sklearn.feature_extraction.text.CountVectorizer:45
msgid "**strip_accents**"
msgstr "**strip_accents**"

#: of
msgid "{'ascii', 'unicode'}, default=None"
msgstr "{'ascii', 'unicode'}, default=None"

#: of sklearn.feature_extraction.text.CountVectorizer:37
msgid "Remove accents and perform other character normalization during the preprocessing step. 'ascii' is a fast method that only works on characters that have an direct ASCII mapping. 'unicode' is a slightly slower method that works on any characters. None (default) does nothing."
msgstr "Elimina acentos y realiza otra normalización de caracteres durante el paso de preprocesamiento. 'ascii' es un método rápido que sólo funciona sobre caracteres que tienen un mapeo ASCII directo. 'unicode' es un método ligeramente más lento que funciona en cualquier carácter. None (por defecto) no hace nada."

#: of sklearn.feature_extraction.text.CountVectorizer:44
msgid "Both 'ascii' and 'unicode' use NFKD normalization from :func:`unicodedata.normalize`."
msgstr "Tanto 'ascii' como 'unicode' utilizan la normalización NFKD de :func:`unicodedata.normalize`."

#: of sklearn.feature_extraction.text.CountVectorizer:48
msgid "**lowercase**"
msgstr "**lowercase**"

#: of
msgid "bool, default=True"
msgstr "bool, default=True"

#: of sklearn.feature_extraction.text.CountVectorizer:48
msgid "Convert all characters to lowercase before tokenizing."
msgstr "Convierte todos los caracteres en minúsculas antes de la tokenización."

#: of sklearn.feature_extraction.text.CountVectorizer:53
msgid "**preprocessor**"
msgstr "**preprocessor**"

#: of
msgid "callable, default=None"
msgstr "callable, default=None"

#: of sklearn.feature_extraction.text.CountVectorizer:51
msgid "Override the preprocessing (strip_accents and lowercase) stage while preserving the tokenizing and n-grams generation steps. Only applies if ``analyzer is not callable``."
msgstr "Anula la etapa de preprocesamiento (strip_accents y lowercase) conservando las etapas de tokenización y generación de n-gramas. Sólo se aplica si ``analyzer is not callable``."

#: of sklearn.feature_extraction.text.CountVectorizer:58
msgid "**tokenizer**"
msgstr "**tokenizer**"

#: of sklearn.feature_extraction.text.CountVectorizer:56
msgid "Override the string tokenization step while preserving the preprocessing and n-grams generation steps. Only applies if ``analyzer == 'word'``."
msgstr "Anula el paso de tokenización de cadenas conservando los pasos de preprocesamiento y generación de n-gramas. Sólo se aplica si ``analyzer == 'word'``."

#: of sklearn.feature_extraction.text.CountVectorizer:71
msgid "**stop_words**"
msgstr "**stop_words**"

#: of
msgid "string {'english'}, list, default=None"
msgstr "string {'english'}, list, default=None"

#: of sklearn.feature_extraction.text.CountVectorizer:61
msgid "If 'english', a built-in stop word list for English is used. There are several known issues with 'english' and you should consider an alternative (see :ref:`stop_words`)."
msgstr "Si es 'english', se utiliza una lista de palabras funcionales incorporada para el inglés. Hay varias incidencias conocidas con 'english' y deberías considerar una alternativa (ver :ref:`stop_words`)."

#: of sklearn.feature_extraction.text.CountVectorizer:65
msgid "If a list, that list is assumed to contain stop words, all of which will be removed from the resulting tokens. Only applies if ``analyzer == 'word'``."
msgstr "Si es una lista (list), se asume que dicha lista contiene palabras funcionales, las cuales serán eliminadas de los tokens resultantes. Sólo se aplica si ``analyzer == 'word'``."

#: of sklearn.feature_extraction.text.CountVectorizer:69
msgid "If None, no stop words will be used. max_df can be set to a value in the range [0.7, 1.0) to automatically detect and filter stop words based on intra corpus document frequency of terms."
msgstr "Si es None, no se utilizará ninguna de las palabras funcionales. max_df puede establecerse en un valor en el rango [0.7, 1.0) para detectar y filtrar automáticamente las palabras funcionales basándose en la frecuencia de los términos del documento dentro del corpus."

#: of sklearn.feature_extraction.text.CountVectorizer:81
msgid "**token_pattern** : str, default=r\"(?u)\\\\b\\\\w\\\\w+\\\\b\""
msgstr "**token_pattern** : str, default=r\"(?u)\\\\b\\\\w\\\\w+\\\\b\""

#: of
msgid "str, default=r\"(?u)\\\\b\\\\w\\\\w+\\\\b\""
msgstr "str, default=r\"(?u)\\\\b\\\\w\\\\w+\\\\b\""

#: of sklearn.feature_extraction.text.CountVectorizer:74
msgid "Regular expression denoting what constitutes a \"token\", only used if ``analyzer == 'word'``. The default regexp select tokens of 2 or more alphanumeric characters (punctuation is completely ignored and always treated as a token separator)."
msgstr "Expresión regular que denota lo que constituye un \"token\", sólo se utiliza si ``analyzer == 'word'``. La regexp por defecto selecciona tokens de 2 o más caracteres alfanuméricos (la puntuación se ignora por completo y se trata siempre como un separador de tokens)."

#: of sklearn.feature_extraction.text.CountVectorizer:79
msgid "If there is a capturing group in token_pattern then the captured group content, not the entire match, becomes the token. At most one capturing group is permitted."
msgstr "Si hay un grupo de captura en token_pattern entonces el contenido del grupo capturado, no la correspondencia completa, se convierte en el token. Se permite como máximo un grupo de captura."

#: of sklearn.feature_extraction.text.CountVectorizer:89
msgid "**ngram_range**"
msgstr "**ngram_range**"

#: of
msgid "tuple (min_n, max_n), default=(1, 1)"
msgstr "tuple (min_n, max_n), default=(1, 1)"

#: of sklearn.feature_extraction.text.CountVectorizer:84
msgid "The lower and upper boundary of the range of n-values for different word n-grams or char n-grams to be extracted. All values of n such such that min_n <= n <= max_n will be used. For example an ``ngram_range`` of ``(1, 1)`` means only unigrams, ``(1, 2)`` means unigrams and bigrams, and ``(2, 2)`` means only bigrams. Only applies if ``analyzer is not callable``."
msgstr "El límite inferior y superior del rango de n-valores para los diferentes n-gramas de palabras o n-gramas de caracteres que se van a extraer. Se utilizarán todos los valores de n tales que min_n <= n <= max_n. Por ejemplo, un ``ngram_range`` de ``(1, 1)`` significa sólo unigramas, ``(1, 2)`` significa unigramas y bigramas, y ``(2, 2)`` significa sólo bigramas. Sólo se aplica si ``analyzer is not callable``."

#: of sklearn.feature_extraction.text.CountVectorizer:104
msgid "**analyzer**"
msgstr "**analyzer**"

#: of
msgid "{'word', 'char', 'char_wb'} or callable, default='word'"
msgstr "{'word', 'char', 'char_wb'} o callable, default='word'"

#: of sklearn.feature_extraction.text.CountVectorizer:92
msgid "Whether the feature should be made of word n-gram or character n-grams. Option 'char_wb' creates character n-grams only from text inside word boundaries; n-grams at the edges of words are padded with space."
msgstr "Si la característica debe estar hecha de n-gramas de palabras o de n-gramas de caracteres. La opción 'char_wb' crea n-gramas de caracteres sólo a partir del texto dentro de los límites de las palabras; los n-gramas en los bordes de las palabras se rellenan con espacio."

#: of sklearn.feature_extraction.text.CountVectorizer:97
msgid "If a callable is passed it is used to extract the sequence of features out of the raw, unprocessed input."
msgstr "Si se pasa un invocable, se utiliza para extraer la secuencia de características de la entrada en bruto y sin procesar."

#: of sklearn.feature_extraction.text.CountVectorizer:102
msgid "Since v0.21, if ``input`` is ``filename`` or ``file``, the data is first read from the file and then passed to the given callable analyzer."
msgstr "Desde la v0.21, si ``input`` es ``filename`` o ``file``, los datos se leen primero del archivo y luego se pasan al analizador invocable dado."

#: of sklearn.feature_extraction.text.CountVectorizer:112
msgid "**max_df**"
msgstr "**max_df**"

#: of
msgid "float in range [0.0, 1.0] or int, default=1.0"
msgstr "float en el rango [0.0, 1.0] o int, default=1.0"

#: of sklearn.feature_extraction.text.CountVectorizer:107
msgid "When building the vocabulary ignore terms that have a document frequency strictly higher than the given threshold (corpus-specific stop words). If float, the parameter represents a proportion of documents, integer absolute counts. This parameter is ignored if vocabulary is not None."
msgstr "Cuando se construye el vocabulario se ignoran los términos que tienen una frecuencia de documento estrictamente superior al umbral dado (palabras funcionales específicas del corpus). Si es un número de punto flotante (float), el parámetro representa una proporción de documentos, cuentas absolutas enteras. Este parámetro se ignora si vocabulary no es None."

#: of sklearn.feature_extraction.text.CountVectorizer:120
msgid "**min_df**"
msgstr "**min_df**"

#: of
msgid "float in range [0.0, 1.0] or int, default=1"
msgstr "float en el rango [0.0, 1.0] o int, default=1"

#: of sklearn.feature_extraction.text.CountVectorizer:115
msgid "When building the vocabulary ignore terms that have a document frequency strictly lower than the given threshold. This value is also called cut-off in the literature. If float, the parameter represents a proportion of documents, integer absolute counts. This parameter is ignored if vocabulary is not None."
msgstr "Al construir el vocabulario se ignoran los términos que tienen una frecuencia de documento estrictamente inferior al umbral dado. Este valor también se denomina cut-off en la literatura. Si es un número de punto flotante (float), el parámetro representa una proporción de documentos, conteo absoluto entero. Este parámetro se ignora si vocabulary no es None."

#: of sklearn.feature_extraction.text.CountVectorizer:126
msgid "**max_features**"
msgstr "**max_features**"

#: of
msgid "int, default=None"
msgstr "int, default=None"

#: of sklearn.feature_extraction.text.CountVectorizer:123
msgid "If not None, build a vocabulary that only consider the top max_features ordered by term frequency across the corpus."
msgstr "Si no es None, construye un vocabulario que sólo tenga en cuenta el top de max_features ordenado por la frecuencia de los términos en todo el corpus."

#: of sklearn.feature_extraction.text.CountVectorizer:126
msgid "This parameter is ignored if vocabulary is not None."
msgstr "Este parámetro es ignorado si vocabulary no es None."

#: of sklearn.feature_extraction.text.CountVectorizer:133
msgid "**vocabulary**"
msgstr "**vocabulary**"

#: of
msgid "Mapping or iterable, default=None"
msgstr "Mapping o iterable, default=None"

#: of sklearn.feature_extraction.text.CountVectorizer:129
msgid "Either a Mapping (e.g., a dict) where keys are terms and values are indices in the feature matrix, or an iterable over terms. If not given, a vocabulary is determined from the input documents. Indices in the mapping should not be repeated and should not have any gap between 0 and the largest index."
msgstr "Un mapeo (por ejemplo, un dict) donde las claves son términos y los valores son índices en la matriz de características, o un iterable sobre términos. Si no se da, se determina un vocabulario a partir de los documentos de entrada. Los índices en el mapeo no deben repetirse y no deben tener ninguna brecha entre 0 y el índice más grande."

#: of sklearn.feature_extraction.text.CountVectorizer:138
msgid "**binary**"
msgstr "**binary**"

#: of
msgid "bool, default=False"
msgstr "bool, default=False"

#: of sklearn.feature_extraction.text.CountVectorizer:136
msgid "If True, all non zero counts are set to 1. This is useful for discrete probabilistic models that model binary events rather than integer counts."
msgstr "Si es True, todos los contadores distintos de cero se establecen en 1. Esto es útil para modelos probabilísticos discretos que modelan eventos binarios en lugar de conteos enteros."

#: of sklearn.feature_extraction.text.CountVectorizer:144
msgid "**dtype**"
msgstr "**dtype**"

#: of
msgid "type, default=np.int64"
msgstr "type, default=np.int64"

#: of sklearn.feature_extraction.text.CountVectorizer:141
msgid "Type of the matrix returned by fit_transform() or transform()."
msgstr "Tipo de la matriz devuelta por fit_transform() o transform()."

#: of sklearn.feature_extraction.text.CountVectorizer
msgid "Attributes"
msgstr "Atributos"

#: of sklearn.feature_extraction.text.CountVectorizer:149
msgid "**vocabulary_**"
msgstr "**vocabulary_**"

#: of
msgid "dict"
msgstr "dict"

#: of sklearn.feature_extraction.text.CountVectorizer:149
msgid "A mapping of terms to feature indices."
msgstr "Un mapeo de términos para los índices de características."

#: of sklearn.feature_extraction.text.CountVectorizer:153
msgid "**fixed_vocabulary_: boolean**"
msgstr "**fixed_vocabulary_: boolean**"

#: of sklearn.feature_extraction.text.CountVectorizer:152
msgid "True if a fixed vocabulary of term to indices mapping is provided by the user"
msgstr "True si el usuario proporciona un vocabulario fijo de mapeo de términos a índices"

#: of sklearn.feature_extraction.text.CountVectorizer:165
msgid "**stop_words_**"
msgstr "**stop_words_**"

#: of
msgid "set"
msgstr "set"

#: of sklearn.feature_extraction.text.CountVectorizer:156
msgid "Terms that were ignored because they either:"
msgstr "Términos que fueron ignorados porque:"

#: of sklearn.feature_extraction.text.CountVectorizer:158
msgid "occurred in too many documents (`max_df`)"
msgstr "aparecen en demasiados documentos (`max_df`)"

#: of sklearn.feature_extraction.text.CountVectorizer:159
msgid "occurred in too few documents (`min_df`)"
msgstr "aparecen en muy pocos documentos (`min_df`)"

#: of sklearn.feature_extraction.text.CountVectorizer:160
msgid "were cut off by feature selection (`max_features`)."
msgstr "se han eliminado mediante la selección de características (max_features)."

#: of sklearn.feature_extraction.text.CountVectorizer:162
msgid "This is only available if no vocabulary was given."
msgstr "Esto sólo está disponible si no se ha dado ningún vocabulario."

#: of sklearn.feature_extraction.text.CountVectorizer:170
msgid ":obj:`HashingVectorizer`, :obj:`TfidfVectorizer`"
msgstr ":obj:`HashingVectorizer`, :obj:`TfidfVectorizer`"

#: of sklearn.feature_extraction.text.CountVectorizer:174
msgid "Notes"
msgstr "Notas"

#: of sklearn.feature_extraction.text.CountVectorizer:175
msgid "The ``stop_words_`` attribute can get large and increase the model size when pickling. This attribute is provided only for introspection and can be safely removed using delattr or set to None before pickling."
msgstr "El atributo ``stop_words_`` puede hacerse grande y aumentar el tamaño del modelo cuando se hace el pickling (serializar). Este atributo se proporciona sólo para la introspección y se puede eliminar de forma segura utilizando delattr o estableciendo None antes del pickling."

#: of sklearn.feature_extraction.text.CountVectorizer:181
msgid "Examples"
msgstr "Ejemplos"

#: of sklearn.feature_extraction.text.CountVectorizer:211
msgid "Methods"
msgstr "Métodos"

#: of sklearn.feature_extraction.text.CountVectorizer:226:<autosummary>:1
msgid ":obj:`build_analyzer <sklearn.feature_extraction.text.CountVectorizer.build_analyzer>`\\"
msgstr ":obj:`build_analyzer <sklearn.feature_extraction.text.CountVectorizer.build_analyzer>`\\"

#: of sklearn.feature_extraction.text.CountVectorizer:226:<autosummary>:1
#: sklearn.feature_extraction.text._VectorizerMixin.build_analyzer:2
msgid "Return a callable that handles preprocessing, tokenization and n-grams generation."
msgstr "Devuelve un invocable que maneja el preprocesamiento, tokenización y la generación de n-gramas."

#: of sklearn.feature_extraction.text.CountVectorizer:226:<autosummary>:1
msgid ":obj:`build_preprocessor <sklearn.feature_extraction.text.CountVectorizer.build_preprocessor>`\\"
msgstr ":obj:`build_preprocessor <sklearn.feature_extraction.text.CountVectorizer.build_preprocessor>`\\"

#: of sklearn.feature_extraction.text.CountVectorizer:226:<autosummary>:1
#: sklearn.feature_extraction.text._VectorizerMixin.build_preprocessor:2
msgid "Return a function to preprocess the text before tokenization."
msgstr "Devuelve una función para preprocesar el texto antes de la tokenización."

#: of sklearn.feature_extraction.text.CountVectorizer:226:<autosummary>:1
msgid ":obj:`build_tokenizer <sklearn.feature_extraction.text.CountVectorizer.build_tokenizer>`\\"
msgstr ":obj:`build_tokenizer <sklearn.feature_extraction.text.CountVectorizer.build_tokenizer>`\\"

#: of sklearn.feature_extraction.text.CountVectorizer:226:<autosummary>:1
#: sklearn.feature_extraction.text._VectorizerMixin.build_tokenizer:2
msgid "Return a function that splits a string into a sequence of tokens."
msgstr "Devuelve una función que divide una cadena en una secuencia de tokens."

#: of sklearn.feature_extraction.text.CountVectorizer:226:<autosummary>:1
msgid ":obj:`decode <sklearn.feature_extraction.text.CountVectorizer.decode>`\\"
msgstr ":obj:`decode <sklearn.feature_extraction.text.CountVectorizer.decode>`\\"

#: of sklearn.feature_extraction.text.CountVectorizer:226:<autosummary>:1
#: sklearn.feature_extraction.text._VectorizerMixin.decode:2
msgid "Decode the input into a string of unicode symbols."
msgstr "Decodifica la entrada en una cadena de símbolos Unicode."

#: of sklearn.feature_extraction.text.CountVectorizer:226:<autosummary>:1
msgid ":obj:`fit <sklearn.feature_extraction.text.CountVectorizer.fit>`\\"
msgstr ":obj:`fit <sklearn.feature_extraction.text.CountVectorizer.fit>`\\"

#: of sklearn.feature_extraction.text.CountVectorizer.fit:2
#: sklearn.feature_extraction.text.CountVectorizer:226:<autosummary>:1
msgid "Learn a vocabulary dictionary of all tokens in the raw documents."
msgstr "Aprende un diccionario de vocabulario de todos los tokens en los documentos en bruto."

#: of sklearn.feature_extraction.text.CountVectorizer:226:<autosummary>:1
msgid ":obj:`fit_transform <sklearn.feature_extraction.text.CountVectorizer.fit_transform>`\\"
msgstr ":obj:`fit_transform <sklearn.feature_extraction.text.CountVectorizer.fit_transform>`\\"

#: of sklearn.feature_extraction.text.CountVectorizer.fit_transform:2
#: sklearn.feature_extraction.text.CountVectorizer:226:<autosummary>:1
msgid "Learn the vocabulary dictionary and return document-term matrix."
msgstr "Aprende el diccionario de vocabulario y devuelve la matriz de términos y documentos (document-term)."

#: of sklearn.feature_extraction.text.CountVectorizer:226:<autosummary>:1
msgid ":obj:`get_feature_names <sklearn.feature_extraction.text.CountVectorizer.get_feature_names>`\\"
msgstr ":obj:`get_feature_names <sklearn.feature_extraction.text.CountVectorizer.get_feature_names>`\\"

#: of sklearn.feature_extraction.text.CountVectorizer.get_feature_names:2
#: sklearn.feature_extraction.text.CountVectorizer:226:<autosummary>:1
msgid "Array mapping from feature integer indices to feature name."
msgstr "Mapeo de arreglos de índices enteros de características a nombres de características."

#: of sklearn.feature_extraction.text.CountVectorizer:226:<autosummary>:1
msgid ":obj:`get_params <sklearn.feature_extraction.text.CountVectorizer.get_params>`\\"
msgstr ":obj:`get_params <sklearn.feature_extraction.text.CountVectorizer.get_params>`\\"

#: of sklearn.base.BaseEstimator.get_params:2
#: sklearn.feature_extraction.text.CountVectorizer:226:<autosummary>:1
msgid "Get parameters for this estimator."
msgstr "Obtiene los parámetros para este estimador."

#: of sklearn.feature_extraction.text.CountVectorizer:226:<autosummary>:1
msgid ":obj:`get_stop_words <sklearn.feature_extraction.text.CountVectorizer.get_stop_words>`\\"
msgstr ":obj:`get_stop_words <sklearn.feature_extraction.text.CountVectorizer.get_stop_words>`\\"

#: of sklearn.feature_extraction.text.CountVectorizer:226:<autosummary>:1
#: sklearn.feature_extraction.text._VectorizerMixin.get_stop_words:2
msgid "Build or fetch the effective stop words list."
msgstr "Construye o busca la lista efectiva de palabras funcionales."

#: of sklearn.feature_extraction.text.CountVectorizer:226:<autosummary>:1
msgid ":obj:`inverse_transform <sklearn.feature_extraction.text.CountVectorizer.inverse_transform>`\\"
msgstr ":obj:`inverse_transform <sklearn.feature_extraction.text.CountVectorizer.inverse_transform>`\\"

#: of sklearn.feature_extraction.text.CountVectorizer.inverse_transform:2
#: sklearn.feature_extraction.text.CountVectorizer:226:<autosummary>:1
msgid "Return terms per document with nonzero entries in X."
msgstr "Devuelve los términos por documento con entradas no nulas en X."

#: of sklearn.feature_extraction.text.CountVectorizer:226:<autosummary>:1
msgid ":obj:`set_params <sklearn.feature_extraction.text.CountVectorizer.set_params>`\\"
msgstr ":obj:`set_params <sklearn.feature_extraction.text.CountVectorizer.set_params>`\\"

#: of sklearn.base.BaseEstimator.set_params:2
#: sklearn.feature_extraction.text.CountVectorizer:226:<autosummary>:1
msgid "Set the parameters of this estimator."
msgstr "Establece los parámetros de este estimador."

#: of sklearn.feature_extraction.text.CountVectorizer:226:<autosummary>:1
msgid ":obj:`transform <sklearn.feature_extraction.text.CountVectorizer.transform>`\\"
msgstr ":obj:`transform <sklearn.feature_extraction.text.CountVectorizer.transform>`\\"

#: of sklearn.feature_extraction.text.CountVectorizer.transform:2
#: sklearn.feature_extraction.text.CountVectorizer:226:<autosummary>:1
msgid "Transform documents to document-term matrix."
msgstr "Transforma los documentos a la matriz documento-término (document-term)."

#: of sklearn.base.BaseEstimator.get_params
#: sklearn.base.BaseEstimator.set_params
#: sklearn.feature_extraction.text.CountVectorizer.fit
#: sklearn.feature_extraction.text.CountVectorizer.fit_transform
#: sklearn.feature_extraction.text.CountVectorizer.get_feature_names
#: sklearn.feature_extraction.text.CountVectorizer.inverse_transform
#: sklearn.feature_extraction.text.CountVectorizer.transform
#: sklearn.feature_extraction.text._VectorizerMixin.build_analyzer
#: sklearn.feature_extraction.text._VectorizerMixin.build_preprocessor
#: sklearn.feature_extraction.text._VectorizerMixin.build_tokenizer
#: sklearn.feature_extraction.text._VectorizerMixin.decode
#: sklearn.feature_extraction.text._VectorizerMixin.get_stop_words
msgid "Returns"
msgstr "Devuelve"

#: of sklearn.feature_extraction.text._VectorizerMixin.build_analyzer:22
msgid "analyzer: callable"
msgstr "analyzer: callable"

#: of sklearn.feature_extraction.text._VectorizerMixin.build_analyzer:10
msgid "A function to handle preprocessing, tokenization and n-grams generation."
msgstr "Una función para manejar el preprocesamiento, tokenización y la generación de n-gramas."

#: of sklearn.feature_extraction.text._VectorizerMixin.build_preprocessor:20
msgid "preprocessor: callable"
msgstr "preprocessor: callable"

#: of sklearn.feature_extraction.text._VectorizerMixin.build_preprocessor:9
msgid "A function to preprocess the text before tokenization."
msgstr "Una función para preprocesar el texto antes de la tokenización."

#: of sklearn.feature_extraction.text._VectorizerMixin.build_tokenizer:20
msgid "tokenizer: callable"
msgstr "tokenizer: callable"

#: of sklearn.feature_extraction.text._VectorizerMixin.build_tokenizer:9
msgid "A function to split a string into a sequence of tokens."
msgstr "Una función para dividir una cadena en una secuencia de tokens."

#: of sklearn.feature_extraction.text._VectorizerMixin.decode:4
msgid "The decoding strategy depends on the vectorizer parameters."
msgstr "La estrategia de decodificación depende de los parámetros del vectorizador."

#: of sklearn.feature_extraction.text._VectorizerMixin.decode:9
msgid "**doc**"
msgstr "**doc**"

#: of
msgid "str"
msgstr "str"

#: of sklearn.feature_extraction.text._VectorizerMixin.decode:9
msgid "The string to decode."
msgstr "La cadena a decodificar."

#: of sklearn.feature_extraction.text._VectorizerMixin.decode:25
msgid "doc: str"
msgstr "doc: str"

#: of sklearn.feature_extraction.text._VectorizerMixin.decode:14
msgid "A string of unicode symbols."
msgstr "Una cadena de símbolos Unicode."

#: of sklearn.feature_extraction.text.CountVectorizer.fit:8
#: sklearn.feature_extraction.text.CountVectorizer.fit_transform:10
#: sklearn.feature_extraction.text.CountVectorizer.transform:10
msgid "**raw_documents**"
msgstr "**raw_documents**"

#: of
msgid "iterable"
msgstr "iterable"

#: of sklearn.feature_extraction.text.CountVectorizer.fit:8
#: sklearn.feature_extraction.text.CountVectorizer.fit_transform:10
#: sklearn.feature_extraction.text.CountVectorizer.transform:10
msgid "An iterable which yields either str, unicode or file objects."
msgstr "Un iterable que produce objetos str, unicode o file."

#: of sklearn.feature_extraction.text.CountVectorizer.fit:24
msgid "self"
msgstr "self"

#: of sklearn.feature_extraction.text.CountVectorizer.fit_transform:4
msgid "This is equivalent to fit followed by transform, but more efficiently implemented."
msgstr "Esto es equivalente al ajuste (fit) seguido de la transformación (transform), pero se implementa de forma más eficiente."

#: of sklearn.feature_extraction.text.CountVectorizer.fit_transform:26
#: sklearn.feature_extraction.text.CountVectorizer.inverse_transform:8
#: sklearn.feature_extraction.text.CountVectorizer.transform:26
msgid "**X**"
msgstr "**X**"

#: of
msgid "array of shape (n_samples, n_features)"
msgstr "array de forma (n_samples, n_features)"

#: of sklearn.feature_extraction.text.CountVectorizer.fit_transform:15
#: sklearn.feature_extraction.text.CountVectorizer.inverse_transform:8
#: sklearn.feature_extraction.text.CountVectorizer.transform:15
msgid "Document-term matrix."
msgstr "Matriz documento-término (document-term)."

#: of sklearn.feature_extraction.text.CountVectorizer.get_feature_names:20
msgid "**feature_names**"
msgstr "**feature_names**"

#: of
msgid "list"
msgstr "list"

#: of sklearn.feature_extraction.text.CountVectorizer.get_feature_names:9
msgid "A list of feature names."
msgstr "Una lista de nombres de características."

#: of sklearn.base.BaseEstimator.get_params:9
msgid "**deep**"
msgstr "**deep**"

#: of sklearn.base.BaseEstimator.get_params:8
msgid "If True, will return the parameters for this estimator and contained subobjects that are estimators."
msgstr "Si es True, devolverá los parámetros para este estimador y los subobjetos contenidos que son estimadores."

#: of sklearn.base.BaseEstimator.get_params:25
msgid "**params**"
msgstr "**params**"

#: of sklearn.base.BaseEstimator.get_params:14
msgid "Parameter names mapped to their values."
msgstr "Nombres de parámetros mapeados a sus valores."

#: of sklearn.feature_extraction.text._VectorizerMixin.get_stop_words:20
msgid "stop_words: list or None"
msgstr "stop_words: list o None"

#: of sklearn.feature_extraction.text._VectorizerMixin.get_stop_words:9
msgid "A list of stop words."
msgstr "Una lista de palabras funcionales."

#: of
msgid "{array-like, sparse matrix} of shape (n_samples, n_features)"
msgstr "{array-like, sparse matrix} de forma (n_samples, n_features)"

#: of sklearn.feature_extraction.text.CountVectorizer.inverse_transform:24
msgid "**X_inv**"
msgstr "**X_inv**"

#: of
msgid "list of arrays of shape (n_samples,)"
msgstr "list de arrays de forma (n_samples,)"

#: of sklearn.feature_extraction.text.CountVectorizer.inverse_transform:13
msgid "List of arrays of terms."
msgstr "Lista de arreglos de términos."

#: of sklearn.base.BaseEstimator.set_params:4
msgid "The method works on simple estimators as well as on nested objects (such as :class:`~sklearn.pipeline.Pipeline`). The latter have parameters of the form ``<component>__<parameter>`` so that it's possible to update each component of a nested object."
msgstr "El método funciona tanto con estimadores simples como con objetos anidados (como :class:`~sklearn.pipeline.Pipeline`). Estos últimos tienen parámetros de la forma ``<component>__<parameter>`` para que sea posible actualizar cada componente de un objeto anidado."

#: of sklearn.base.BaseEstimator.set_params:12
msgid "**\\*\\*params**"
msgstr "**\\*\\*params**"

#: of sklearn.base.BaseEstimator.set_params:12
msgid "Estimator parameters."
msgstr "Parámetros del estimador."

#: of sklearn.base.BaseEstimator.set_params:28
msgid "**self**"
msgstr "**self**"

#: of
msgid "estimator instance"
msgstr "estimator instance"

#: of sklearn.base.BaseEstimator.set_params:17
msgid "Estimator instance."
msgstr "Instancia del estimador."

#: of sklearn.feature_extraction.text.CountVectorizer.transform:4
msgid "Extract token counts out of raw text documents using the vocabulary fitted with fit or the one provided to the constructor."
msgstr "Extrae los recuentos de tokens de los documentos de texto en bruto utilizando el vocabulario ajustado con fit o el proporcionado al constructor."

#: of
msgid "sparse matrix of shape (n_samples, n_features)"
msgstr "sparse matrix de forma (n_samples, n_features)"

#: ../modules/generated/sklearn.feature_extraction.text.CountVectorizer.examples:4
msgid "Examples using ``sklearn.feature_extraction.text.CountVectorizer``"
msgstr "Ejemplos utilizando ``sklearn.feature_extraction.text.CountVectorizer``"

#: ../modules/generated/sklearn.feature_extraction.text.CountVectorizer.examples:15
#: ../modules/generated/sklearn.feature_extraction.text.CountVectorizer.examples:23
msgid ":ref:`sphx_glr_auto_examples_model_selection_grid_search_text_feature_extraction.py`"
msgstr ":ref:`sphx_glr_auto_examples_model_selection_grid_search_text_feature_extraction.py`"

#~ msgid ":ref:`sphx_glr_auto_examples_semi_supervised_plot_semi_supervised_newsgroups.py`"
#~ msgstr ""

