msgid ""
msgstr ""
"Project-Id-Version: scikit-learn\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-03-31 11:24-0400\n"
"PO-Revision-Date: 2021-05-20 13:53\n"
"Last-Translator: \n"
"Language-Team: Spanish\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Crowdin-Project: scikit-learn\n"
"X-Crowdin-Project-ID: 450526\n"
"X-Crowdin-Language: es-ES\n"
"X-Crowdin-File: /main/doc/en/modules/generated/sklearn.gaussian_process.GaussianProcessRegressor.po\n"
"X-Crowdin-File-ID: 5638\n"
"Language: es_ES\n"

#: ../modules/generated/sklearn.gaussian_process.GaussianProcessRegressor.rst:2
msgid ":mod:`sklearn.gaussian_process`.GaussianProcessRegressor"
msgstr ":mod:`sklearn.gaussian_process`.GaussianProcessRegressor"

#: of sklearn.gaussian_process._gpr.GaussianProcessRegressor:2
msgid "Gaussian process regression (GPR)."
msgstr "Regresión de procesos gaussianos (Gaussian process regression, GPR)."

#: of sklearn.gaussian_process._gpr.GaussianProcessRegressor:4
msgid "The implementation is based on Algorithm 2.1 of Gaussian Processes for Machine Learning (GPML) by Rasmussen and Williams."
msgstr "La implementación se basa en los algoritmos 2.1, y de Gaussian Processes for Machine Learning (GPML) de Rasmussen y Williams."

#: of sklearn.gaussian_process._gpr.GaussianProcessRegressor:7
msgid "In addition to standard scikit-learn estimator API, GaussianProcessRegressor:"
msgstr "Además de la API del estimador estándar de scikit-learn, GaussianProcessRegressor:"

#: of sklearn.gaussian_process._gpr.GaussianProcessRegressor:10
msgid "allows prediction without prior fitting (based on the GP prior)"
msgstr "permite la predicción sin ajuste previo (basado en el previo GP)"

#: of sklearn.gaussian_process._gpr.GaussianProcessRegressor:11
msgid "provides an additional method sample_y(X), which evaluates samples drawn from the GPR (prior or posterior) at given inputs"
msgstr "proporciona un método adicional ``sample_y(X)``, que evalúa las muestras extraídas del GPR (a priori o a posteriori) en entradas específicas"

#: of sklearn.gaussian_process._gpr.GaussianProcessRegressor:13
msgid "exposes a method log_marginal_likelihood(theta), which can be used externally for other ways of selecting hyperparameters, e.g., via Markov chain Monte Carlo."
msgstr "expone un método ``log_marginal_likelihood(theta)``, que puede ser usado externamente para otras maneras de seleccionar hiperparámetros, por ejemplo, a través de la cadena de Markov Monte Carlo."

#: of sklearn.gaussian_process._gpr.GaussianProcessRegressor:17
msgid "Read more in the :ref:`User Guide <gaussian_process>`."
msgstr "Más información en el :ref:`User Guide <gaussian_process>`."

#: of sklearn.base.BaseEstimator.get_params
#: sklearn.base.BaseEstimator.set_params sklearn.base.RegressorMixin.score
#: sklearn.gaussian_process._gpr.GaussianProcessRegressor
#: sklearn.gaussian_process._gpr.GaussianProcessRegressor.fit
#: sklearn.gaussian_process._gpr.GaussianProcessRegressor.log_marginal_likelihood
#: sklearn.gaussian_process._gpr.GaussianProcessRegressor.predict
#: sklearn.gaussian_process._gpr.GaussianProcessRegressor.sample_y
msgid "Parameters"
msgstr "Parámetros"

#: of sklearn.gaussian_process._gpr.GaussianProcessRegressor:28
msgid "**kernel**"
msgstr "**kernel**"

#: of
msgid "kernel instance, default=None"
msgstr "instancia del núcleo, default=None"

#: of sklearn.gaussian_process._gpr.GaussianProcessRegressor:24
msgid "The kernel specifying the covariance function of the GP. If None is passed, the kernel ``ConstantKernel(1.0, constant_value_bounds=\"fixed\" * RBF(1.0, length_scale_bounds=\"fixed\")`` is used as default. Note that the kernel hyperparameters are optimized during fitting unless the bounds are marked as \"fixed\"."
msgstr "El núcleo que especifica la función de covarianza de la GP. Si se pasa None, el núcleo ``ConstantKernel(1.0, constant_value_bounds=\"fixed\" * RBF(1.0, length_scale_bounds=\"fixed\")`` se utiliza por defecto. Ten en cuenta que los hiperparámetros del núcleo se optimizan durante el ajuste a menos que los límites estén marcados como \"fijos\"."

#: of sklearn.gaussian_process._gpr.GaussianProcessRegressor:40
msgid "**alpha**"
msgstr "**alpha**"

#: of
msgid "float or ndarray of shape (n_samples,), default=1e-10"
msgstr "float or ndarray of shape (n_samples,), default=1e-10"

#: of sklearn.gaussian_process._gpr.GaussianProcessRegressor:31
msgid "Value added to the diagonal of the kernel matrix during fitting. This can prevent a potential numerical issue during fitting, by ensuring that the calculated values form a positive definite matrix. It can also be interpreted as the variance of additional Gaussian measurement noise on the training observations. Note that this is different from using a `WhiteKernel`. If an array is passed, it must have the same number of entries as the data used for fitting and is used as datapoint-dependent noise level. Allowing to specify the noise level directly as a parameter is mainly for convenience and for consistency with Ridge."
msgstr "Valor añadido a la diagonal de la matriz del núcleo durante el ajuste. Esto puede evitar un posible problema numérico durante el ajuste, garantizando que los valores calculados formen una matriz positiva definida. También puede interpretarse como la varianza del ruido de medición gaussiano adicional en las observaciones de entrenamiento. Ten en cuenta que esto es diferente de utilizar un `WhiteKernel`. Si se pasa un arreglo, debe tener el mismo número de entradas que los datos utilizados para el ajuste y se utiliza como nivel de ruido dependiente del punto de datos. Permitir especificar el nivel de ruido directamente como un parámetro es principalmente por conveniencia y por consistencia con Ridge."

#: of sklearn.gaussian_process._gpr.GaussianProcessRegressor:65
msgid "**optimizer**"
msgstr "**optimizer**"

#: of
msgid "\"fmin_l_bfgs_b\" or callable, default=\"fmin_l_bfgs_b\""
msgstr "\"fmin_l_bfgs_b\" or callable, default=\"fmin_l_bfgs_b\""

#: of sklearn.gaussian_process._gpr.GaussianProcessRegressor:43
msgid "Can either be one of the internally supported optimizers for optimizing the kernel's parameters, specified by a string, or an externally defined optimizer passed as a callable. If a callable is passed, it must have the signature::"
msgstr "Puede ser uno de los optimizadores soportados internamente para optimizar los parámetros del núcleo, especificado por una cadena, o un optimizador definido externamente pasado como invocable. Si se pasa un invocable, debe tener la firma (signature)::"

#: of sklearn.gaussian_process._gpr.GaussianProcessRegressor:61
msgid "Per default, the 'L-BGFS-B' algorithm from scipy.optimize.minimize is used. If None is passed, the kernel's parameters are kept fixed. Available internal optimizers are::"
msgstr "Por defecto, se utiliza el algoritmo 'L-BFGS-B' de scipy.optimize.minimize. Si se pasa None, los parámetros del núcleo se mantienen fijos. Los optimizadores internos disponibles son::"

#: of sklearn.gaussian_process._gpr.GaussianProcessRegressor:74
msgid "**n_restarts_optimizer**"
msgstr "**n_restarts_optimizer**"

#: of
msgid "int, default=0"
msgstr "int, default=0"

#: of sklearn.gaussian_process._gpr.GaussianProcessRegressor:68
msgid "The number of restarts of the optimizer for finding the kernel's parameters which maximize the log-marginal likelihood. The first run of the optimizer is performed from the kernel's initial parameters, the remaining ones (if any) from thetas sampled log-uniform randomly from the space of allowed theta-values. If greater than 0, all bounds must be finite. Note that n_restarts_optimizer == 0 implies that one run is performed."
msgstr "El número de reinicios del optimizador para encontrar los parámetros del núcleo que maximizan la verosimilitud logarítmica marginal. La primera ejecución del optimizador se realiza a partir de los parámetros iniciales del núcleo, los restantes (si los hay) a partir de los valores logarítmicos uniformes muestreados aleatoriamente del espacio de valores logarítmicos permitidos. Si es mayor que 0, todos los límites deben ser finitos. Nótese que n_restarts_optimizer == 0 implica que se realiza una ejecución."

#: of sklearn.gaussian_process._gpr.GaussianProcessRegressor:83
msgid "**normalize_y**"
msgstr "**normalize_y**"

#: of
msgid "bool, default=False"
msgstr "bool, default=False"

#: of sklearn.gaussian_process._gpr.GaussianProcessRegressor:77
msgid "Whether the target values y are normalized, the mean and variance of the target values are set equal to 0 and 1 respectively. This is recommended for cases where zero-mean, unit-variance priors are used. Note that, in this implementation, the normalisation is reversed before the GP predictions are reported."
msgstr "Si los valores objetivo y están normalizados, la media y la varianza de los valores objetivo se establecen igual a 0 y 1 respectivamente. Esto se recomienda para los casos en los que se utilicen distribuciones a priori de media cero y varianza unitaria. Ten en cuenta que, en esta implementación, la normalización se invierte antes de que se informen las predicciones GP."

#: of sklearn.gaussian_process._gpr.GaussianProcessRegressor:89
msgid "**copy_X_train**"
msgstr "**copy_X_train**"

#: of
msgid "bool, default=True"
msgstr "bool, default=True"

#: of sklearn.gaussian_process._gpr.GaussianProcessRegressor:86
msgid "If True, a persistent copy of the training data is stored in the object. Otherwise, just a reference to the training data is stored, which might cause predictions to change if the data is modified externally."
msgstr "Si es True, se almacena una copia persistente de los datos de entrenamiento en el objeto. De lo contrario, sólo se almacena una referencia a los datos de entrenamiento, lo que podría hacer que las predicciones cambien si los datos se modifican externamente."

#: of sklearn.gaussian_process._gpr.GaussianProcessRegressor:97
#: sklearn.gaussian_process._gpr.GaussianProcessRegressor.sample_y:17
msgid "**random_state**"
msgstr "**random_state**"

#: of
msgid "int, RandomState instance or None, default=None"
msgstr "int, RandomState instance or None, default=None"

#: of sklearn.gaussian_process._gpr.GaussianProcessRegressor:92
msgid "Determines random number generation used to initialize the centers. Pass an int for reproducible results across multiple function calls. See :term: `Glossary <random_state>`."
msgstr "Determina la generación de números aleatorios utilizados para inicializar los centros. Se pasa un int para obtener resultados reproducibles a través de múltiples invocaciones a la función. Ver :term: `Glossary <random_state>`."

#: of sklearn.gaussian_process._gpr.GaussianProcessRegressor
msgid "Attributes"
msgstr "Atributos"

#: of sklearn.gaussian_process._gpr.GaussianProcessRegressor:103
msgid "**X_train_**"
msgstr "**X_train_**"

#: of
msgid "array-like of shape (n_samples, n_features) or list of object"
msgstr "array-like of shape (n_samples, n_features) or list of object"

#: of sklearn.gaussian_process._gpr.GaussianProcessRegressor:102
msgid "Feature vectors or other representations of training data (also required for prediction)."
msgstr "Vectores de características u otras representaciones de los datos de entrenamiento (también necesarios para la predicción)."

#: of sklearn.gaussian_process._gpr.GaussianProcessRegressor:106
msgid "**y_train_**"
msgstr "**y_train_**"

#: of
msgid "array-like of shape (n_samples,) or (n_samples, n_targets)"
msgstr "array-like of shape (n_samples,) or (n_samples, n_targets)"

#: of sklearn.gaussian_process._gpr.GaussianProcessRegressor:106
msgid "Target values in training data (also required for prediction)"
msgstr "Valores objetivo en los datos de entrenamiento (también necesarios para la predicción)"

#: of sklearn.gaussian_process._gpr.GaussianProcessRegressor:110
msgid "**kernel_**"
msgstr "**kernel_**"

#: of
msgid "kernel instance"
msgstr "kernel instance"

#: of sklearn.gaussian_process._gpr.GaussianProcessRegressor:109
msgid "The kernel used for prediction. The structure of the kernel is the same as the one passed as parameter but with optimized hyperparameters"
msgstr "El núcleo (kernel) utilizado para la predicción. La estructura del núcleo es la misma que la pasada como parámetro pero con hiperparámetros optimizados"

#: of sklearn.gaussian_process._gpr.GaussianProcessRegressor:113
msgid "**L_**"
msgstr "**L_**"

#: of
msgid "array-like of shape (n_samples, n_samples)"
msgstr "array-like of shape (n_samples, n_samples)"

#: of sklearn.gaussian_process._gpr.GaussianProcessRegressor:113
msgid "Lower-triangular Cholesky decomposition of the kernel in ``X_train_``"
msgstr "Descomposición Cholesky triangular inferior del núcleo en ``X_train_``"

#: of sklearn.gaussian_process._gpr.GaussianProcessRegressor:116
msgid "**alpha_**"
msgstr "**alpha_**"

#: of
msgid "array-like of shape (n_samples,)"
msgstr "array-like of shape (n_samples,)"

#: of sklearn.gaussian_process._gpr.GaussianProcessRegressor:116
msgid "Dual coefficients of training data points in kernel space"
msgstr "Coeficientes duales de los puntos de datos de entrenamiento en el espacio del núcleo"

#: of sklearn.gaussian_process._gpr.GaussianProcessRegressor:125
msgid "**log_marginal_likelihood_value_**"
msgstr "**log_marginal_likelihood_value_**"

#: of
msgid "float"
msgstr "float"

#: of sklearn.gaussian_process._gpr.GaussianProcessRegressor:119
msgid "The log-marginal-likelihood of ``self.kernel_.theta``"
msgstr "La verosimilitud logarítmica marginal de ``self.kernel_.theta``"

#: of sklearn.gaussian_process._gpr.GaussianProcessRegressor:128
msgid "Examples"
msgstr "Ejemplos"

#: of sklearn.gaussian_process._gpr.GaussianProcessRegressor:142
msgid "Methods"
msgstr "Métodos"

#: of
#: sklearn.gaussian_process._gpr.GaussianProcessRegressor:152:<autosummary>:1
msgid ":obj:`fit <sklearn.gaussian_process.GaussianProcessRegressor.fit>`\\"
msgstr ":obj:`fit <sklearn.gaussian_process.GaussianProcessRegressor.fit>`\\"

#: of sklearn.gaussian_process._gpr.GaussianProcessRegressor.fit:2
#: sklearn.gaussian_process._gpr.GaussianProcessRegressor:152:<autosummary>:1
msgid "Fit Gaussian process regression model."
msgstr "Ajustar el modelo de regresión del proceso gaussiano."

#: of
#: sklearn.gaussian_process._gpr.GaussianProcessRegressor:152:<autosummary>:1
msgid ":obj:`get_params <sklearn.gaussian_process.GaussianProcessRegressor.get_params>`\\"
msgstr ":obj:`get_params <sklearn.gaussian_process.GaussianProcessRegressor.get_params>`\\"

#: of sklearn.base.BaseEstimator.get_params:2
#: sklearn.gaussian_process._gpr.GaussianProcessRegressor:152:<autosummary>:1
msgid "Get parameters for this estimator."
msgstr "Obtiene los parámetros para este estimador."

#: of
#: sklearn.gaussian_process._gpr.GaussianProcessRegressor:152:<autosummary>:1
msgid ":obj:`log_marginal_likelihood <sklearn.gaussian_process.GaussianProcessRegressor.log_marginal_likelihood>`\\"
msgstr ":obj:`log_marginal_likelihood <sklearn.gaussian_process.GaussianProcessRegressor.log_marginal_likelihood>`\\"

#: of
#: sklearn.gaussian_process._gpr.GaussianProcessRegressor.log_marginal_likelihood:2
#: sklearn.gaussian_process._gpr.GaussianProcessRegressor:152:<autosummary>:1
msgid "Returns log-marginal likelihood of theta for training data."
msgstr "Devuelve la verosimilitud logarítmica marginal de theta para los datos de entrenamiento."

#: of
#: sklearn.gaussian_process._gpr.GaussianProcessRegressor:152:<autosummary>:1
msgid ":obj:`predict <sklearn.gaussian_process.GaussianProcessRegressor.predict>`\\"
msgstr ":obj:`predict <sklearn.gaussian_process.GaussianProcessRegressor.predict>`\\"

#: of sklearn.gaussian_process._gpr.GaussianProcessRegressor.predict:2
#: sklearn.gaussian_process._gpr.GaussianProcessRegressor:152:<autosummary>:1
msgid "Predict using the Gaussian process regression model"
msgstr "Predicción mediante el modelo de regresión del proceso gaussiano"

#: of
#: sklearn.gaussian_process._gpr.GaussianProcessRegressor:152:<autosummary>:1
msgid ":obj:`sample_y <sklearn.gaussian_process.GaussianProcessRegressor.sample_y>`\\"
msgstr ":obj:`sample_y <sklearn.gaussian_process.GaussianProcessRegressor.sample_y>`\\"

#: of sklearn.gaussian_process._gpr.GaussianProcessRegressor.sample_y:2
#: sklearn.gaussian_process._gpr.GaussianProcessRegressor:152:<autosummary>:1
msgid "Draw samples from Gaussian process and evaluate at X."
msgstr "Extraer muestras del proceso gaussiano y evaluar en X."

#: of
#: sklearn.gaussian_process._gpr.GaussianProcessRegressor:152:<autosummary>:1
msgid ":obj:`score <sklearn.gaussian_process.GaussianProcessRegressor.score>`\\"
msgstr ":obj:`score <sklearn.gaussian_process.GaussianProcessRegressor.score>`\\"

#: of sklearn.base.RegressorMixin.score:2
#: sklearn.gaussian_process._gpr.GaussianProcessRegressor:152:<autosummary>:1
msgid "Return the coefficient of determination :math:`R^2` of the prediction."
msgstr "Devuelve el coeficiente de determinación :math:`R^2` de la predicción."

#: of
#: sklearn.gaussian_process._gpr.GaussianProcessRegressor:152:<autosummary>:1
msgid ":obj:`set_params <sklearn.gaussian_process.GaussianProcessRegressor.set_params>`\\"
msgstr ":obj:`set_params <sklearn.gaussian_process.GaussianProcessRegressor.set_params>`\\"

#: of sklearn.base.BaseEstimator.set_params:2
#: sklearn.gaussian_process._gpr.GaussianProcessRegressor:152:<autosummary>:1
msgid "Set the parameters of this estimator."
msgstr "Establece los parámetros de este estimador."

#: of sklearn.base.RegressorMixin.score:20
#: sklearn.gaussian_process._gpr.GaussianProcessRegressor.fit:8
#: sklearn.gaussian_process._gpr.GaussianProcessRegressor.predict:12
#: sklearn.gaussian_process._gpr.GaussianProcessRegressor.sample_y:8
msgid "**X**"
msgstr "**X**"

#: of sklearn.gaussian_process._gpr.GaussianProcessRegressor.fit:8
msgid "Feature vectors or other representations of training data."
msgstr "Vectores de características u otras representaciones de los datos de entrenamiento."

#: of sklearn.base.RegressorMixin.score:23
#: sklearn.gaussian_process._gpr.GaussianProcessRegressor.fit:11
msgid "**y**"
msgstr "**y**"

#: of sklearn.gaussian_process._gpr.GaussianProcessRegressor.fit:11
msgid "Target values"
msgstr "Valores objetivo"

#: of sklearn.base.BaseEstimator.get_params
#: sklearn.base.BaseEstimator.set_params sklearn.base.RegressorMixin.score
#: sklearn.gaussian_process._gpr.GaussianProcessRegressor.fit
#: sklearn.gaussian_process._gpr.GaussianProcessRegressor.log_marginal_likelihood
#: sklearn.gaussian_process._gpr.GaussianProcessRegressor.predict
#: sklearn.gaussian_process._gpr.GaussianProcessRegressor.sample_y
msgid "Returns"
msgstr "Devuelve"

#: of sklearn.base.BaseEstimator.set_params:28
#: sklearn.gaussian_process._gpr.GaussianProcessRegressor.fit:27
msgid "**self**"
msgstr "**self**"

#: of
msgid "returns an instance of self."
msgstr "devuelve una instancia de sí misma."

#: of sklearn.base.BaseEstimator.get_params:9
msgid "**deep**"
msgstr "**deep**"

#: of sklearn.base.BaseEstimator.get_params:8
msgid "If True, will return the parameters for this estimator and contained subobjects that are estimators."
msgstr "Si es True, devolverá los parámetros para este estimador y los subobjetos contenidos que son estimadores."

#: of sklearn.base.BaseEstimator.get_params:25
msgid "**params**"
msgstr "**params**"

#: of
msgid "dict"
msgstr "dict"

#: of sklearn.base.BaseEstimator.get_params:14
msgid "Parameter names mapped to their values."
msgstr "Nombres de parámetros mapeados a sus valores."

#: of
#: sklearn.gaussian_process._gpr.GaussianProcessRegressor.log_marginal_likelihood:10
msgid "**theta**"
msgstr "**theta**"

#: of
msgid "array-like of shape (n_kernel_params,) default=None"
msgstr "array-like of shape (n_kernel_params,) default=None"

#: of
#: sklearn.gaussian_process._gpr.GaussianProcessRegressor.log_marginal_likelihood:8
msgid "Kernel hyperparameters for which the log-marginal likelihood is evaluated. If None, the precomputed log_marginal_likelihood of ``self.kernel_.theta`` is returned."
msgstr "Hiperparámetros del núcleo para los que se evalúa la verosimilitud logarítmica marginal. Si es None, se devuelve la log_marginal_likelihood precalculada de ``self.kernel_.theta``."

#: of
#: sklearn.gaussian_process._gpr.GaussianProcessRegressor.log_marginal_likelihood:15
msgid "**eval_gradient**"
msgstr "**eval_gradient**"

#: of
#: sklearn.gaussian_process._gpr.GaussianProcessRegressor.log_marginal_likelihood:13
msgid "If True, the gradient of the log-marginal likelihood with respect to the kernel hyperparameters at position theta is returned additionally. If True, theta must not be None."
msgstr "Si es True, el gradiente de la verosimilitud logarítmica marginal con respecto a los hiperparámetros del núcleo en la posición theta se devuelve adicionalmente. Si es True, theta no debe ser None."

#: of
#: sklearn.gaussian_process._gpr.GaussianProcessRegressor.log_marginal_likelihood:19
msgid "**clone_kernel**"
msgstr "**clone_kernel**"

#: of
#: sklearn.gaussian_process._gpr.GaussianProcessRegressor.log_marginal_likelihood:18
msgid "If True, the kernel attribute is copied. If False, the kernel attribute is modified, but may result in a performance improvement."
msgstr "Si es True, se copia el atributo del núcleo. Si es False, el atributo del núcleo se modifica, pero puede dar lugar a una mejora del rendimiento."

#: of
#: sklearn.gaussian_process._gpr.GaussianProcessRegressor.log_marginal_likelihood:24
msgid "**log_likelihood**"
msgstr "**log_likelihood**"

#: of
#: sklearn.gaussian_process._gpr.GaussianProcessRegressor.log_marginal_likelihood:24
msgid "Log-marginal likelihood of theta for training data."
msgstr "Verosimilitud logarítmica marginal de theta para los datos de entrenamiento."

#: of
#: sklearn.gaussian_process._gpr.GaussianProcessRegressor.log_marginal_likelihood:40
msgid "**log_likelihood_gradient**"
msgstr "**log_likelihood_gradient**"

#: of
msgid "ndarray of shape (n_kernel_params,), optional"
msgstr "ndarray of shape (n_kernel_params,), optional"

#: of
#: sklearn.gaussian_process._gpr.GaussianProcessRegressor.log_marginal_likelihood:27
msgid "Gradient of the log-marginal likelihood with respect to the kernel hyperparameters at position theta. Only returned when eval_gradient is True."
msgstr "Gradiente de la verosimilitud logarítmica marginal con respecto a los hiperparámetros del núcleo en la posición theta. Sólo se devuelve cuando eval_gradient es True."

#: of sklearn.gaussian_process._gpr.GaussianProcessRegressor.predict:4
msgid "We can also predict based on an unfitted model by using the GP prior. In addition to the mean of the predictive distribution, also its standard deviation (return_std=True) or covariance (return_cov=True). Note that at most one of the two can be requested."
msgstr "También podemos predecir basándonos en un modelo no ajustado utilizando la prioridad GP. Además de la media de la distribución de predicción, también su desviación estándar (return_std=True) o covarianza (return_cov=True). Ten en cuenta que como máximo se puede solicitar una de las dos."

#: of sklearn.gaussian_process._gpr.GaussianProcessRegressor.predict:12
#: sklearn.gaussian_process._gpr.GaussianProcessRegressor.sample_y:8
msgid "Query points where the GP is evaluated."
msgstr "Puntos de consulta donde se evalúa el GP."

#: of sklearn.gaussian_process._gpr.GaussianProcessRegressor.predict:16
msgid "**return_std**"
msgstr "**return_std**"

#: of sklearn.gaussian_process._gpr.GaussianProcessRegressor.predict:15
msgid "If True, the standard-deviation of the predictive distribution at the query points is returned along with the mean."
msgstr "Si es True, se devuelve la desviación estándar de la distribución predictiva en los puntos de consulta junto con la media."

#: of sklearn.gaussian_process._gpr.GaussianProcessRegressor.predict:20
msgid "**return_cov**"
msgstr "**return_cov**"

#: of sklearn.gaussian_process._gpr.GaussianProcessRegressor.predict:19
msgid "If True, the covariance of the joint predictive distribution at the query points is returned along with the mean."
msgstr "Si es True, se devuelve la covarianza de la distribución predictiva conjunta en los puntos de consulta junto con la media."

#: of sklearn.gaussian_process._gpr.GaussianProcessRegressor.predict:25
msgid "**y_mean**"
msgstr "**y_mean**"

#: of
msgid "ndarray of shape (n_samples, [n_output_dims])"
msgstr "ndarray of shape (n_samples, [n_output_dims])"

#: of sklearn.gaussian_process._gpr.GaussianProcessRegressor.predict:25
msgid "Mean of predictive distribution a query points."
msgstr "Media de la distribución predictiva de los puntos de consulta."

#: of sklearn.gaussian_process._gpr.GaussianProcessRegressor.predict:29
msgid "**y_std**"
msgstr "**y_std**"

#: of
msgid "ndarray of shape (n_samples,), optional"
msgstr "ndarray of shape (n_samples,), optional"

#: of sklearn.gaussian_process._gpr.GaussianProcessRegressor.predict:28
msgid "Standard deviation of predictive distribution at query points. Only returned when `return_std` is True."
msgstr "Desviación estándar de la distribución predictiva en los puntos de consulta. Sólo se devuelve cuando `return_std` es True."

#: of sklearn.gaussian_process._gpr.GaussianProcessRegressor.predict:44
msgid "**y_cov**"
msgstr "**y_cov**"

#: of
msgid "ndarray of shape (n_samples, n_samples), optional"
msgstr "ndarray of shape (n_samples, n_samples), optional"

#: of sklearn.gaussian_process._gpr.GaussianProcessRegressor.predict:32
msgid "Covariance of joint predictive distribution a query points. Only returned when `return_cov` is True."
msgstr "Covarianza de la distribución predictiva conjunta de los puntos de la consulta. Sólo se devuelve cuando `return_cov` es True."

#: of sklearn.gaussian_process._gpr.GaussianProcessRegressor.sample_y:11
msgid "**n_samples**"
msgstr "**n_samples**"

#: of
msgid "int, default=1"
msgstr "int, default=1"

#: of sklearn.gaussian_process._gpr.GaussianProcessRegressor.sample_y:11
msgid "The number of samples drawn from the Gaussian process"
msgstr "El número de muestras extraídas del proceso gaussiano"

#: of
msgid "int, RandomState instance or None, default=0"
msgstr "int, RandomState instance or None, default=0"

#: of sklearn.gaussian_process._gpr.GaussianProcessRegressor.sample_y:14
msgid "Determines random number generation to randomly draw samples. Pass an int for reproducible results across multiple function calls. See :term: `Glossary <random_state>`."
msgstr "Determina la generación de números aleatorios para extraer muestras al azar. Pasa un int para obtener resultados reproducibles a través de múltiples llamadas a la función. Ver :term: `Glossary <random_state>`."

#: of sklearn.gaussian_process._gpr.GaussianProcessRegressor.sample_y:34
msgid "**y_samples**"
msgstr "**y_samples**"

#: of
msgid "ndarray of shape (n_samples_X, [n_output_dims], n_samples)"
msgstr "ndarray of shape (n_samples_X, [n_output_dims], n_samples)"

#: of sklearn.gaussian_process._gpr.GaussianProcessRegressor.sample_y:22
msgid "Values of n_samples samples drawn from Gaussian process and evaluated at query points."
msgstr "Valores de n_muestras extraídos del proceso gaussiano y evaluados en los puntos de consulta."

#: of sklearn.base.RegressorMixin.score:5
msgid "The coefficient :math:`R^2` is defined as :math:`(1 - \\frac{u}{v})`, where :math:`u` is the residual sum of squares ``((y_true - y_pred) ** 2).sum()`` and :math:`v` is the total sum of squares ``((y_true - y_true.mean()) ** 2).sum()``. The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of `y`, disregarding the input features, would get a :math:`R^2` score of 0.0."
msgstr "El coeficiente :math:`R^2` se define como :math:`(1 - \\frac{u}{v})`, donde :math:`u` es la suma residual de cuadrados ``((y_true - y_pred) ** 2).sum()`` y :math:`v` es la suma total de cuadrados ``((y_true - y_true.mean()) ** 2).sum()``. La mejor puntuación posible es 1.0 y puede ser negativa (porque el modelo puede ser arbitrariamente peor). Un modelo constante que siempre predice el valor esperado de `y`, sin tener en cuenta las características de entrada, obtendría una puntuación :math:`R^2` de 0,0."

#: of
msgid "array-like of shape (n_samples, n_features)"
msgstr "array-like of shape (n_samples, n_features)"

#: of sklearn.base.RegressorMixin.score:17
msgid "Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted`` is the number of samples used in the fitting for the estimator."
msgstr "Muestras de prueba. Para algunos estimadores puede ser una matriz de núcleo precalculada o una lista de objetos genéricos con forma ``(n_samples, n_samples_fitted)``, donde ``n_samples_fitted`` es el número de muestras utilizadas en el ajuste para el estimador."

#: of
msgid "array-like of shape (n_samples,) or (n_samples, n_outputs)"
msgstr "array-like of shape (n_samples,) or (n_samples, n_outputs)"

#: of sklearn.base.RegressorMixin.score:23
msgid "True values for `X`."
msgstr "Valores verdaderos para `X`."

#: of sklearn.base.RegressorMixin.score:26
msgid "**sample_weight**"
msgstr "**sample_weight**"

#: of
msgid "array-like of shape (n_samples,), default=None"
msgstr "array-like of shape (n_samples,), default=None"

#: of sklearn.base.RegressorMixin.score:26
msgid "Sample weights."
msgstr "Ponderaciones de la muestra."

#: of sklearn.base.RegressorMixin.score:38
msgid "**score**"
msgstr "**score**"

#: of sklearn.base.RegressorMixin.score:31
msgid ":math:`R^2` of ``self.predict(X)`` wrt. `y`."
msgstr ":math:`R^2` of ``self.predict(X)`` wrt. `y`."

#: of sklearn.base.RegressorMixin.score:41
msgid "Notes"
msgstr "Notas"

#: of sklearn.base.RegressorMixin.score:42
msgid "The :math:`R^2` score used when calling ``score`` on a regressor uses ``multioutput='uniform_average'`` from version 0.23 to keep consistent with default value of :func:`~sklearn.metrics.r2_score`. This influences the ``score`` method of all the multioutput regressors (except for :class:`~sklearn.multioutput.MultiOutputRegressor`)."
msgstr "La puntuación :math:`R^2` utilizada al llamar a ``score`` en un regresor utiliza ``multioutput='uniform_average'`` desde la versión 0.23 para mantener la coherencia con el valor por defecto de :func:`~sklearn.metrics.r2_score``. Esto influye en el método ``score`` de todos los regresores de salida múltiple (excepto para :class:`~sklearn.multioutput.MultiOutputRegressor`)."

#: of sklearn.base.BaseEstimator.set_params:4
msgid "The method works on simple estimators as well as on nested objects (such as :class:`~sklearn.pipeline.Pipeline`). The latter have parameters of the form ``<component>__<parameter>`` so that it's possible to update each component of a nested object."
msgstr "El método funciona tanto en estimadores simples como en objetos anidados (como :class:`~sklearn.pipeline.Pipeline`). Estos últimos tienen parámetros de la forma ``<component>__<parameter>``` para que sea posible actualizar cada componente de un objeto anidado."

#: of sklearn.base.BaseEstimator.set_params:12
msgid "**\\*\\*params**"
msgstr "**\\*\\*params**"

#: of sklearn.base.BaseEstimator.set_params:12
msgid "Estimator parameters."
msgstr "Parámetros del estimador."

#: of
msgid "estimator instance"
msgstr "estimator instance"

#: of sklearn.base.BaseEstimator.set_params:17
msgid "Estimator instance."
msgstr "Instancia del estimador."

#: ../modules/generated/sklearn.gaussian_process.GaussianProcessRegressor.examples:4
msgid "Examples using ``sklearn.gaussian_process.GaussianProcessRegressor``"
msgstr "Ejemplos usando ``sklearn.gaussian_process.GaussianProcessRegressor``"

#: ../modules/generated/sklearn.gaussian_process.GaussianProcessRegressor.examples:15
#: ../modules/generated/sklearn.gaussian_process.GaussianProcessRegressor.examples:23
msgid ":ref:`sphx_glr_auto_examples_gaussian_process_plot_compare_gpr_krr.py`"
msgstr ":ref:`sphx_glr_auto_examples_gaussian_process_plot_compare_gpr_krr.py`"

#: ../modules/generated/sklearn.gaussian_process.GaussianProcessRegressor.examples:34
#: ../modules/generated/sklearn.gaussian_process.GaussianProcessRegressor.examples:42
msgid ":ref:`sphx_glr_auto_examples_gaussian_process_plot_gpr_prior_posterior.py`"
msgstr ":ref:`sphx_glr_auto_examples_gaussian_process_plot_gpr_prior_posterior.py`"

#: ../modules/generated/sklearn.gaussian_process.GaussianProcessRegressor.examples:53
#: ../modules/generated/sklearn.gaussian_process.GaussianProcessRegressor.examples:61
msgid ":ref:`sphx_glr_auto_examples_gaussian_process_plot_gpr_noisy.py`"
msgstr ":ref:`sphx_glr_auto_examples_gaussian_process_plot_gpr_noisy.py`"

#: ../modules/generated/sklearn.gaussian_process.GaussianProcessRegressor.examples:72
#: ../modules/generated/sklearn.gaussian_process.GaussianProcessRegressor.examples:80
msgid ":ref:`sphx_glr_auto_examples_gaussian_process_plot_gpr_noisy_targets.py`"
msgstr ":ref:`sphx_glr_auto_examples_gaussian_process_plot_gpr_noisy_targets.py`"

#: ../modules/generated/sklearn.gaussian_process.GaussianProcessRegressor.examples:91
#: ../modules/generated/sklearn.gaussian_process.GaussianProcessRegressor.examples:99
msgid ":ref:`sphx_glr_auto_examples_gaussian_process_plot_gpr_co2.py`"
msgstr ":ref:`sphx_glr_auto_examples_gaussian_process_plot_gpr_co2.py`"

#: ../modules/generated/sklearn.gaussian_process.GaussianProcessRegressor.examples:110
#: ../modules/generated/sklearn.gaussian_process.GaussianProcessRegressor.examples:118
msgid ":ref:`sphx_glr_auto_examples_gaussian_process_plot_gpr_on_structured_data.py`"
msgstr ":ref:`sphx_glr_auto_examples_gaussian_process_plot_gpr_on_structured_data.py`"

