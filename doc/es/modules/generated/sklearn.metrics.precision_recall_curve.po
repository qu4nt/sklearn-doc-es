msgid ""
msgstr ""
"Project-Id-Version: scikit-learn\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-03-31 12:43-0400\n"
"PO-Revision-Date: 2021-04-15 00:05\n"
"Last-Translator: \n"
"Language-Team: Spanish\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Crowdin-Project: scikit-learn\n"
"X-Crowdin-Project-ID: 450526\n"
"X-Crowdin-Language: es-ES\n"
"X-Crowdin-File: /main/doc/en/modules/generated/sklearn.metrics.precision_recall_curve.po\n"
"X-Crowdin-File-ID: 3520\n"
"Language: es_ES\n"

#: ../modules/generated/sklearn.metrics.precision_recall_curve.rst:2
msgid ":mod:`sklearn.metrics`.precision_recall_curve"
msgstr ""

#: of sklearn.metrics._ranking.precision_recall_curve:2
msgid "Compute precision-recall pairs for different probability thresholds."
msgstr ""

#: of sklearn.metrics._ranking.precision_recall_curve:4
msgid "Note: this implementation is restricted to the binary classification task."
msgstr ""

#: of sklearn.metrics._ranking.precision_recall_curve:6
msgid "The precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of true positives and ``fp`` the number of false positives. The precision is intuitively the ability of the classifier not to label as positive a sample that is negative."
msgstr ""

#: of sklearn.metrics._ranking.precision_recall_curve:11
msgid "The recall is the ratio ``tp / (tp + fn)`` where ``tp`` is the number of true positives and ``fn`` the number of false negatives. The recall is intuitively the ability of the classifier to find all the positive samples."
msgstr ""

#: of sklearn.metrics._ranking.precision_recall_curve:15
msgid "The last precision and recall values are 1. and 0. respectively and do not have a corresponding threshold. This ensures that the graph starts on the y axis."
msgstr ""

#: of sklearn.metrics._ranking.precision_recall_curve:19
msgid "Read more in the :ref:`User Guide <precision_recall_f_measure_metrics>`."
msgstr ""

#: of sklearn.metrics._ranking.precision_recall_curve
msgid "Parameters"
msgstr ""

#: of sklearn.metrics._ranking.precision_recall_curve:25
msgid "**y_true**"
msgstr ""

#: of
msgid "ndarray of shape (n_samples,)"
msgstr ""

#: of sklearn.metrics._ranking.precision_recall_curve:24
msgid "True binary labels. If labels are not either {-1, 1} or {0, 1}, then pos_label should be explicitly given."
msgstr ""

#: of sklearn.metrics._ranking.precision_recall_curve:28
msgid "**probas_pred**"
msgstr ""

#: of sklearn.metrics._ranking.precision_recall_curve:28
msgid "Estimated probabilities or output of a decision function."
msgstr ""

#: of sklearn.metrics._ranking.precision_recall_curve:33
msgid "**pos_label**"
msgstr ""

#: of
msgid "int or str, default=None"
msgstr ""

#: of sklearn.metrics._ranking.precision_recall_curve:31
msgid "The label of the positive class. When ``pos_label=None``, if y_true is in {-1, 1} or {0, 1}, ``pos_label`` is set to 1, otherwise an error will be raised."
msgstr ""

#: of sklearn.metrics._ranking.precision_recall_curve:36
msgid "**sample_weight**"
msgstr ""

#: of
msgid "array-like of shape (n_samples,), default=None"
msgstr ""

#: of sklearn.metrics._ranking.precision_recall_curve:36
msgid "Sample weights."
msgstr ""

#: of sklearn.metrics._ranking.precision_recall_curve
msgid "Returns"
msgstr ""

#: of sklearn.metrics._ranking.precision_recall_curve:42
msgid "**precision**"
msgstr ""

#: of
msgid "ndarray of shape (n_thresholds + 1,)"
msgstr ""

#: of sklearn.metrics._ranking.precision_recall_curve:41
msgid "Precision values such that element i is the precision of predictions with score >= thresholds[i] and the last element is 1."
msgstr ""

#: of sklearn.metrics._ranking.precision_recall_curve:46
msgid "**recall**"
msgstr ""

#: of sklearn.metrics._ranking.precision_recall_curve:45
msgid "Decreasing recall values such that element i is the recall of predictions with score >= thresholds[i] and the last element is 0."
msgstr ""

#: of sklearn.metrics._ranking.precision_recall_curve:56
msgid "**thresholds**"
msgstr ""

#: of
msgid "ndarray of shape (n_thresholds,)"
msgstr ""

#: of sklearn.metrics._ranking.precision_recall_curve:49
msgid "Increasing thresholds on the decision function used to compute precision and recall. n_thresholds <= len(np.unique(probas_pred))."
msgstr ""

#: of sklearn.metrics._ranking.precision_recall_curve:61
msgid ":obj:`plot_precision_recall_curve`"
msgstr ""

#: of sklearn.metrics._ranking.precision_recall_curve:62
msgid "Plot Precision Recall Curve for binary classifiers."
msgstr ""

#: of sklearn.metrics._ranking.precision_recall_curve:63
msgid ":obj:`PrecisionRecallDisplay`"
msgstr ""

#: of sklearn.metrics._ranking.precision_recall_curve:64
msgid "Precision Recall visualization."
msgstr ""

#: of sklearn.metrics._ranking.precision_recall_curve:65
msgid ":obj:`average_precision_score`"
msgstr ""

#: of sklearn.metrics._ranking.precision_recall_curve:66
msgid "Compute average precision from prediction scores."
msgstr ""

#: of sklearn.metrics._ranking.precision_recall_curve:67
msgid ":obj:`det_curve`"
msgstr ""

#: of sklearn.metrics._ranking.precision_recall_curve:68
msgid "Compute error rates for different probability thresholds."
msgstr ""

#: of sklearn.metrics._ranking.precision_recall_curve:69
msgid ":obj:`roc_curve`"
msgstr ""

#: of sklearn.metrics._ranking.precision_recall_curve:70
msgid "Compute Receiver operating characteristic (ROC) curve."
msgstr ""

#: of sklearn.metrics._ranking.precision_recall_curve:76
msgid "Examples"
msgstr ""

#: ../modules/generated/sklearn.metrics.precision_recall_curve.examples:4
msgid "Examples using ``sklearn.metrics.precision_recall_curve``"
msgstr ""

#: ../modules/generated/sklearn.metrics.precision_recall_curve.examples:15
#: ../modules/generated/sklearn.metrics.precision_recall_curve.examples:23
msgid ":ref:`sphx_glr_auto_examples_miscellaneous_plot_display_object_visualization.py`"
msgstr ""

#~ msgid ":ref:`sphx_glr_auto_examples_model_selection_plot_precision_recall.py`"
#~ msgstr ""

