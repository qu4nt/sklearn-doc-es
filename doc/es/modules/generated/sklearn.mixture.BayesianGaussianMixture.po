msgid ""
msgstr ""
"Project-Id-Version: scikit-learn\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-03-31 11:24-0400\n"
"PO-Revision-Date: 2021-06-04 22:07\n"
"Last-Translator: \n"
"Language-Team: Spanish\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Crowdin-Project: scikit-learn\n"
"X-Crowdin-Project-ID: 450526\n"
"X-Crowdin-Language: es-ES\n"
"X-Crowdin-File: /main/doc/en/modules/generated/sklearn.mixture.BayesianGaussianMixture.po\n"
"X-Crowdin-File-ID: 5130\n"
"Language: es_ES\n"

#: ../modules/generated/sklearn.mixture.BayesianGaussianMixture.rst:2
msgid ":mod:`sklearn.mixture`.BayesianGaussianMixture"
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:2
msgid "Variational Bayesian estimation of a Gaussian mixture."
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:4
msgid "This class allows to infer an approximate posterior distribution over the parameters of a Gaussian mixture distribution. The effective number of components can be inferred from the data."
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:8
msgid "This class implements two types of prior for the weights distribution: a finite mixture model with Dirichlet distribution and an infinite mixture model with the Dirichlet Process. In practice Dirichlet Process inference algorithm is approximated and uses a truncated distribution with a fixed maximum number of components (called the Stick-breaking representation). The number of components actually used almost always depends on the data."
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:17
msgid "Read more in the :ref:`User Guide <bgmm>`."
msgstr ""

#: of sklearn.base.BaseEstimator.get_params
#: sklearn.base.BaseEstimator.set_params sklearn.mixture._base.BaseMixture.fit
#: sklearn.mixture._base.BaseMixture.fit_predict
#: sklearn.mixture._base.BaseMixture.predict
#: sklearn.mixture._base.BaseMixture.predict_proba
#: sklearn.mixture._base.BaseMixture.sample
#: sklearn.mixture._base.BaseMixture.score
#: sklearn.mixture._base.BaseMixture.score_samples
#: sklearn.mixture._bayesian_mixture.BayesianGaussianMixture
msgid "Parameters"
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:26
msgid "**n_components**"
msgstr "**n_components**"

#: of
msgid "int, default=1"
msgstr "int, default=1"

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:22
msgid "The number of mixture components. Depending on the data and the value of the `weight_concentration_prior` the model can decide to not use all the components by setting some component `weights_` to values very close to zero. The number of effective components is therefore smaller than n_components."
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:35
msgid "**covariance_type**"
msgstr "**covariance_type**"

#: of
msgid "{'full', 'tied', 'diag', 'spherical'}, default='full'"
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:29
msgid "String describing the type of covariance parameters to use. Must be one of::"
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:40
msgid "**tol**"
msgstr "**tol**"

#: of
msgid "float, default=1e-3"
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:38
msgid "The convergence threshold. EM iterations will stop when the lower bound average gain on the likelihood (of the training data with respect to the model) is below this threshold."
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:44
msgid "**reg_covar**"
msgstr "**reg_covar**"

#: of
msgid "float, default=1e-6"
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:43
msgid "Non-negative regularization added to the diagonal of covariance. Allows to assure that the covariance matrices are all positive."
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:47
msgid "**max_iter**"
msgstr "**max_iter**"

#: of
msgid "int, default=100"
msgstr "int, default=100"

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:47
msgid "The number of EM iterations to perform."
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:51
msgid "**n_init**"
msgstr "**n_init**"

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:50
msgid "The number of initializations to perform. The result with the highest lower bound value on the likelihood is kept."
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:59
msgid "**init_params**"
msgstr "**init_params**"

#: of
msgid "{'kmeans', 'random'}, default='kmeans'"
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:54
msgid "The method used to initialize the weights, the means and the covariances. Must be one of::"
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:66
msgid "**weight_concentration_prior_type**"
msgstr "**weight_concentration_prior_type**"

#: of
msgid "str, default='dirichlet_process'"
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:62
msgid "String describing the type of the weight concentration prior. Must be one of::"
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:75
msgid "**weight_concentration_prior**"
msgstr "**weight_concentration_prior**"

#: of
msgid "float | None, default=None."
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:69
msgid "The dirichlet concentration of each component on the weight distribution (Dirichlet). This is commonly called gamma in the literature. The higher concentration puts more mass in the center and will lead to more components being active, while a lower concentration parameter will lead to more mass at the edge of the mixture weights simplex. The value of the parameter must be greater than 0. If it is None, it's set to ``1. / n_components``."
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:82
msgid "**mean_precision_prior**"
msgstr "**mean_precision_prior**"

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:78
msgid "The precision prior on the mean distribution (Gaussian). Controls the extent of where means can be placed. Larger values concentrate the cluster means around `mean_prior`. The value of the parameter must be greater than 0. If it is None, it is set to 1."
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:86
msgid "**mean_prior**"
msgstr "**mean_prior**"

#: of
msgid "array-like, shape (n_features,), default=None."
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:85
msgid "The prior on the mean distribution (Gaussian). If it is None, it is set to the mean of X."
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:90
msgid "**degrees_of_freedom_prior**"
msgstr "**degrees_of_freedom_prior**"

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:89
msgid "The prior of the number of degrees of freedom on the covariance distributions (Wishart). If it is None, it's set to `n_features`."
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:100
msgid "**covariance_prior**"
msgstr "**covariance_prior**"

#: of
msgid "float or array-like, default=None."
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:93
msgid "The prior on the covariance distribution (Wishart). If it is None, the emiprical covariance prior is initialized using the covariance of X. The shape depends on `covariance_type`::"
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:108
msgid "**random_state**"
msgstr "**random_state**"

#: of
msgid "int, RandomState instance or None, default=None"
msgstr "int, instancia RandomState o None, default=None"

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:103
msgid "Controls the random seed given to the method chosen to initialize the parameters (see `init_params`). In addition, it controls the generation of random samples from the fitted distribution (see the method `sample`). Pass an int for reproducible output across multiple function calls. See :term:`Glossary <random_state>`."
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:114
msgid "**warm_start**"
msgstr "**warm_start**"

#: of
msgid "bool, default=False"
msgstr "bool, default=False"

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:111
msgid "If 'warm_start' is True, the solution of the last fitting is used as initialization for the next call of fit(). This can speed up convergence when fit is called several times on similar problems. See :term:`the Glossary <warm_start>`."
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:120
msgid "**verbose**"
msgstr "**verbose**"

#: of
msgid "int, default=0"
msgstr "int, default=0"

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:117
msgid "Enable verbose output. If 1 then it prints the current initialization and each iteration step. If greater than 1 then it prints also the log probability and the time needed for each step."
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:126
msgid "**verbose_interval**"
msgstr "**verbose_interval**"

#: of
msgid "int, default=10"
msgstr "int, default=10"

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:123
msgid "Number of iteration done before the next print."
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture
msgid "Attributes"
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:131
msgid "**weights_**"
msgstr "**weights_**"

#: of
msgid "array-like of shape (n_components,)"
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:131
msgid "The weights of each mixture components."
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:134
msgid "**means_**"
msgstr "**means_**"

#: of
msgid "array-like of shape (n_components, n_features)"
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:134
msgid "The mean of each mixture component."
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:143
msgid "**covariances_**"
msgstr "**covariances_**"

#: of
msgid "array-like"
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:137
msgid "The covariance of each mixture component. The shape depends on `covariance_type`::"
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:157
msgid "**precisions_**"
msgstr "**precisions_**"

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:146
msgid "The precision matrices for each component in the mixture. A precision matrix is the inverse of a covariance matrix. A covariance matrix is symmetric positive definite so the mixture of Gaussian can be equivalently parameterized by the precision matrices. Storing the precision matrices instead of the covariance matrices makes it more efficient to compute the log-likelihood of new samples at test time. The shape depends on ``covariance_type``::"
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:171
msgid "**precisions_cholesky_**"
msgstr "**precisions_cholesky_**"

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:160
msgid "The cholesky decomposition of the precision matrices of each mixture component. A precision matrix is the inverse of a covariance matrix. A covariance matrix is symmetric positive definite so the mixture of Gaussian can be equivalently parameterized by the precision matrices. Storing the precision matrices instead of the covariance matrices makes it more efficient to compute the log-likelihood of new samples at test time. The shape depends on ``covariance_type``::"
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:174
msgid "**converged_**"
msgstr "**converged_**"

#: of
msgid "bool"
msgstr "bool"

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:174
msgid "True when convergence was reached in fit(), False otherwise."
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:178
msgid "**n_iter_**"
msgstr "**n_iter_**"

#: of
msgid "int"
msgstr "int"

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:177
msgid "Number of step used by the best fit of inference to reach the convergence."
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:182
msgid "**lower_bound_**"
msgstr "**lower_bound_**"

#: of
msgid "float"
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:181
msgid "Lower bound value on the likelihood (of the training data with respect to the model) of the best fit of inference."
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:195
msgid "**weight_concentration_prior_**"
msgstr "**weight_concentration_prior_**"

#: of
msgid "tuple or float"
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:185
msgid "The dirichlet concentration of each component on the weight distribution (Dirichlet). The type depends on ``weight_concentration_prior_type``::"
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:192
msgid "The higher concentration puts more mass in the center and will lead to more components being active, while a lower concentration parameter will lead to more mass at the edge of the simplex."
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:199
msgid "**weight_concentration_**"
msgstr "**weight_concentration_**"

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:198
msgid "The dirichlet concentration of each component on the weight distribution (Dirichlet)."
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:206
msgid "**mean_precision_prior_**"
msgstr "**mean_precision_prior_**"

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:202
msgid "The precision prior on the mean distribution (Gaussian). Controls the extent of where means can be placed. Larger values concentrate the cluster means around `mean_prior`. If mean_precision_prior is set to None, `mean_precision_prior_` is set to 1."
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:209
msgid "**mean_precision_**"
msgstr "**mean_precision_**"

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:209
msgid "The precision of each components on the mean distribution (Gaussian)."
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:212
msgid "**mean_prior_**"
msgstr "**mean_prior_**"

#: of
msgid "array-like of shape (n_features,)"
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:212
msgid "The prior on the mean distribution (Gaussian)."
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:216
msgid "**degrees_of_freedom_prior_**"
msgstr "**degrees_of_freedom_prior_**"

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:215
msgid "The prior of the number of degrees of freedom on the covariance distributions (Wishart)."
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:219
msgid "**degrees_of_freedom_**"
msgstr "**degrees_of_freedom_**"

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:219
msgid "The number of degrees of freedom of each components in the model."
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:231
msgid "**covariance_prior_**"
msgstr "**covariance_prior_**"

#: of
msgid "float or array-like"
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:222
msgid "The prior on the covariance distribution (Wishart). The shape depends on `covariance_type`::"
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:236
msgid ":obj:`GaussianMixture`"
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:237
msgid "Finite Gaussian mixture fit with EM."
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:242
msgid "References"
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:243
msgid "`Bishop, Christopher M. (2006). \"Pattern recognition and machine learning\". Vol. 4 No. 4. New York: Springer. <https://www.springer.com/kr/book/9780387310732>`_"
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:247
msgid "`Hagai Attias. (2000). \"A Variational Bayesian Framework for Graphical Models\". In Advances in Neural Information Processing Systems 12. <http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.36.2841&rep=rep1&type=pdf>`_"
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:252
msgid "`Blei, David M. and Michael I. Jordan. (2006). \"Variational inference for Dirichlet process mixtures\". Bayesian analysis 1.1 <https://www.cs.princeton.edu/courses/archive/fall11/cos597C/reading/BleiJordan2005.pdf>`_"
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:258
msgid "[R16529824bff2-1]_, [R16529824bff2-2]_, [R16529824bff2-3]_"
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:261
msgid "Examples"
msgstr ""

#: of sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:273
msgid "Methods"
msgstr ""

#: of
#: sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:285:<autosummary>:1
msgid ":obj:`fit <sklearn.mixture.BayesianGaussianMixture.fit>`\\"
msgstr ""

#: of sklearn.mixture._base.BaseMixture.fit:2
#: sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:285:<autosummary>:1
msgid "Estimate model parameters with the EM algorithm."
msgstr ""

#: of
#: sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:285:<autosummary>:1
msgid ":obj:`fit_predict <sklearn.mixture.BayesianGaussianMixture.fit_predict>`\\"
msgstr ""

#: of sklearn.mixture._base.BaseMixture.fit_predict:2
#: sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:285:<autosummary>:1
msgid "Estimate model parameters using X and predict the labels for X."
msgstr ""

#: of
#: sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:285:<autosummary>:1
msgid ":obj:`get_params <sklearn.mixture.BayesianGaussianMixture.get_params>`\\"
msgstr ""

#: of sklearn.base.BaseEstimator.get_params:2
#: sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:285:<autosummary>:1
msgid "Get parameters for this estimator."
msgstr ""

#: of
#: sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:285:<autosummary>:1
msgid ":obj:`predict <sklearn.mixture.BayesianGaussianMixture.predict>`\\"
msgstr ""

#: of sklearn.mixture._base.BaseMixture.predict:2
#: sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:285:<autosummary>:1
msgid "Predict the labels for the data samples in X using trained model."
msgstr ""

#: of
#: sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:285:<autosummary>:1
msgid ":obj:`predict_proba <sklearn.mixture.BayesianGaussianMixture.predict_proba>`\\"
msgstr ""

#: of sklearn.mixture._base.BaseMixture.predict_proba:2
#: sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:285:<autosummary>:1
msgid "Predict posterior probability of each component given the data."
msgstr ""

#: of
#: sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:285:<autosummary>:1
msgid ":obj:`sample <sklearn.mixture.BayesianGaussianMixture.sample>`\\"
msgstr ""

#: of sklearn.mixture._base.BaseMixture.sample:2
#: sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:285:<autosummary>:1
msgid "Generate random samples from the fitted Gaussian distribution."
msgstr ""

#: of
#: sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:285:<autosummary>:1
msgid ":obj:`score <sklearn.mixture.BayesianGaussianMixture.score>`\\"
msgstr ""

#: of sklearn.mixture._base.BaseMixture.score:2
#: sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:285:<autosummary>:1
msgid "Compute the per-sample average log-likelihood of the given data X."
msgstr ""

#: of
#: sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:285:<autosummary>:1
msgid ":obj:`score_samples <sklearn.mixture.BayesianGaussianMixture.score_samples>`\\"
msgstr ""

#: of sklearn.mixture._base.BaseMixture.score_samples:2
#: sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:285:<autosummary>:1
msgid "Compute the weighted log probabilities for each sample."
msgstr ""

#: of
#: sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:285:<autosummary>:1
msgid ":obj:`set_params <sklearn.mixture.BayesianGaussianMixture.set_params>`\\"
msgstr ""

#: of sklearn.base.BaseEstimator.set_params:2
#: sklearn.mixture._bayesian_mixture.BayesianGaussianMixture:285:<autosummary>:1
msgid "Set the parameters of this estimator."
msgstr ""

#: of sklearn.mixture._base.BaseMixture.fit:4
msgid "The method fits the model ``n_init`` times and sets the parameters with which the model has the largest likelihood or lower bound. Within each trial, the method iterates between E-step and M-step for ``max_iter`` times until the change of likelihood or lower bound is less than ``tol``, otherwise, a ``ConvergenceWarning`` is raised. If ``warm_start`` is ``True``, then ``n_init`` is ignored and a single initialization is performed upon the first call. Upon consecutive calls, training starts where it left off."
msgstr ""

#: of sklearn.mixture._base.BaseMixture.fit:17
#: sklearn.mixture._base.BaseMixture.fit_predict:18
#: sklearn.mixture._base.BaseMixture.predict:9
#: sklearn.mixture._base.BaseMixture.predict_proba:9
#: sklearn.mixture._base.BaseMixture.sample:13
#: sklearn.mixture._base.BaseMixture.score:9
#: sklearn.mixture._base.BaseMixture.score_samples:9
msgid "**X**"
msgstr "**X**"

#: of
msgid "array-like of shape (n_samples, n_features)"
msgstr ""

#: of sklearn.mixture._base.BaseMixture.fit:16
#: sklearn.mixture._base.BaseMixture.fit_predict:17
#: sklearn.mixture._base.BaseMixture.predict:8
#: sklearn.mixture._base.BaseMixture.predict_proba:8
#: sklearn.mixture._base.BaseMixture.score:8
#: sklearn.mixture._base.BaseMixture.score_samples:8
msgid "List of n_features-dimensional data points. Each row corresponds to a single data point."
msgstr ""

#: of sklearn.base.BaseEstimator.get_params
#: sklearn.base.BaseEstimator.set_params sklearn.mixture._base.BaseMixture.fit
#: sklearn.mixture._base.BaseMixture.fit_predict
#: sklearn.mixture._base.BaseMixture.predict
#: sklearn.mixture._base.BaseMixture.predict_proba
#: sklearn.mixture._base.BaseMixture.sample
#: sklearn.mixture._base.BaseMixture.score
#: sklearn.mixture._base.BaseMixture.score_samples
msgid "Returns"
msgstr ""

#: of sklearn.mixture._base.BaseMixture.fit:33
msgid "self"
msgstr ""

#: of sklearn.mixture._base.BaseMixture.fit_predict:4
msgid "The method fits the model n_init times and sets the parameters with which the model has the largest likelihood or lower bound. Within each trial, the method iterates between E-step and M-step for `max_iter` times until the change of likelihood or lower bound is less than `tol`, otherwise, a :class:`~sklearn.exceptions.ConvergenceWarning` is raised. After fitting, it predicts the most probable label for the input data points."
msgstr ""

#: of sklearn.mixture._base.BaseMixture.fit_predict:34
#: sklearn.mixture._base.BaseMixture.predict:25
msgid "**labels**"
msgstr "**labels**"

#: of
msgid "array, shape (n_samples,)"
msgstr ""

#: of sklearn.mixture._base.BaseMixture.fit_predict:23
#: sklearn.mixture._base.BaseMixture.predict:14
msgid "Component labels."
msgstr ""

#: of sklearn.base.BaseEstimator.get_params:9
msgid "**deep**"
msgstr "**deep**"

#: of
msgid "bool, default=True"
msgstr "bool, default=True"

#: of sklearn.base.BaseEstimator.get_params:8
msgid "If True, will return the parameters for this estimator and contained subobjects that are estimators."
msgstr ""

#: of sklearn.base.BaseEstimator.get_params:25
msgid "**params**"
msgstr "**params**"

#: of
msgid "dict"
msgstr ""

#: of sklearn.base.BaseEstimator.get_params:14
msgid "Parameter names mapped to their values."
msgstr ""

#: of sklearn.mixture._base.BaseMixture.predict_proba:26
msgid "**resp**"
msgstr "**resp**"

#: of
msgid "array, shape (n_samples, n_components)"
msgstr ""

#: of sklearn.mixture._base.BaseMixture.predict_proba:14
msgid "Returns the probability each Gaussian (state) in the model given each sample."
msgstr ""

#: of sklearn.mixture._base.BaseMixture.sample:8
msgid "**n_samples**"
msgstr "**n_samples**"

#: of sklearn.mixture._base.BaseMixture.sample:8
msgid "Number of samples to generate."
msgstr ""

#: of
msgid "array, shape (n_samples, n_features)"
msgstr ""

#: of sklearn.mixture._base.BaseMixture.sample:13
msgid "Randomly generated sample"
msgstr ""

#: of sklearn.mixture._base.BaseMixture.sample:27
msgid "**y**"
msgstr "**y**"

#: of
msgid "array, shape (nsamples,)"
msgstr ""

#: of sklearn.mixture._base.BaseMixture.sample:16
msgid "Component labels"
msgstr ""

#: of
msgid "array-like of shape (n_samples, n_dimensions)"
msgstr ""

#: of sklearn.mixture._base.BaseMixture.score:25
msgid "**log_likelihood**"
msgstr "**log_likelihood**"

#: of sklearn.mixture._base.BaseMixture.score:14
msgid "Log likelihood of the Gaussian mixture given X."
msgstr ""

#: of sklearn.mixture._base.BaseMixture.score_samples:25
msgid "**log_prob**"
msgstr "**log_prob**"

#: of sklearn.mixture._base.BaseMixture.score_samples:14
msgid "Log probabilities of each data point in X."
msgstr ""

#: of sklearn.base.BaseEstimator.set_params:4
msgid "The method works on simple estimators as well as on nested objects (such as :class:`~sklearn.pipeline.Pipeline`). The latter have parameters of the form ``<component>__<parameter>`` so that it's possible to update each component of a nested object."
msgstr ""

#: of sklearn.base.BaseEstimator.set_params:12
msgid "**\\*\\*params**"
msgstr "**\\*\\*params**"

#: of sklearn.base.BaseEstimator.set_params:12
msgid "Estimator parameters."
msgstr ""

#: of sklearn.base.BaseEstimator.set_params:28
msgid "**self**"
msgstr "**self**"

#: of
msgid "estimator instance"
msgstr ""

#: of sklearn.base.BaseEstimator.set_params:17
msgid "Estimator instance."
msgstr ""

#: ../modules/generated/sklearn.mixture.BayesianGaussianMixture.examples:4
msgid "Examples using ``sklearn.mixture.BayesianGaussianMixture``"
msgstr ""

#: ../modules/generated/sklearn.mixture.BayesianGaussianMixture.examples:15
#: ../modules/generated/sklearn.mixture.BayesianGaussianMixture.examples:23
msgid ":ref:`sphx_glr_auto_examples_mixture_plot_gmm.py`"
msgstr ""

#: ../modules/generated/sklearn.mixture.BayesianGaussianMixture.examples:34
#: ../modules/generated/sklearn.mixture.BayesianGaussianMixture.examples:42
msgid ":ref:`sphx_glr_auto_examples_mixture_plot_gmm_sin.py`"
msgstr ""

#: ../modules/generated/sklearn.mixture.BayesianGaussianMixture.examples:53
#: ../modules/generated/sklearn.mixture.BayesianGaussianMixture.examples:61
msgid ":ref:`sphx_glr_auto_examples_mixture_plot_concentration_prior.py`"
msgstr ""

