msgid ""
msgstr ""
"Project-Id-Version: scikit-learn\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-03-31 11:24-0400\n"
"PO-Revision-Date: 2021-05-31 13:38\n"
"Last-Translator: \n"
"Language-Team: Spanish\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Crowdin-Project: scikit-learn\n"
"X-Crowdin-Project-ID: 450526\n"
"X-Crowdin-Language: es-ES\n"
"X-Crowdin-File: /main/doc/en/modules/generated/sklearn.metrics.cohen_kappa_score.po\n"
"X-Crowdin-File-ID: 5112\n"
"Language: es_ES\n"

#: ../modules/generated/sklearn.metrics.cohen_kappa_score.rst:2
msgid ":mod:`sklearn.metrics`.cohen_kappa_score"
msgstr ":mod:`sklearn.metrics`.cohen_kappa_score"

#: of sklearn.metrics._classification.cohen_kappa_score:2
msgid "Cohen's kappa: a statistic that measures inter-annotator agreement."
msgstr "Kappa de Cohen: estadística que mide el acuerdo entre anotadores."

#: of sklearn.metrics._classification.cohen_kappa_score:4
msgid "This function computes Cohen's kappa [R219a3b9132e1-1]_, a score that expresses the level of agreement between two annotators on a classification problem. It is defined as"
msgstr "Esta función calcula el Kappa de Cohen [R219a3b9132e1-1]_, una puntuación que expresa el nivel de acuerdo entre dos anotadores en un problema de clasificación. Se define como"

#: of sklearn.metrics._classification.cohen_kappa_score:8
msgid "\\kappa = (p_o - p_e) / (1 - p_e)\n\n"
msgstr "\\kappa = (p_o - p_e) / (1 - p_e)\n\n"

#: of sklearn.metrics._classification.cohen_kappa_score:11
msgid "where :math:`p_o` is the empirical probability of agreement on the label assigned to any sample (the observed agreement ratio), and :math:`p_e` is the expected agreement when both annotators assign labels randomly. :math:`p_e` is estimated using a per-annotator empirical prior over the class labels [R219a3b9132e1-2]_."
msgstr "donde :math:`p_o` es la probabilidad empírica de concordancia en la etiqueta asignada a cualquier muestra (el ratio de acuerdo observado), y :math:`p_e` es la concordancia esperado cuanda ambos anotadores asignan etiquetas al azar. :math:`p_e` se estima usando un prior empírico por anotador sobre las etiquetas [R219a3b9132e1-2]_."

#: of sklearn.metrics._classification.cohen_kappa_score:17
msgid "Read more in the :ref:`User Guide <cohen_kappa>`."
msgstr "Más información en el :ref:`Manual de usuario <cohen_kappa>`."

#: of sklearn.metrics._classification.cohen_kappa_score
msgid "Parameters"
msgstr "Parámetros"

#: of sklearn.metrics._classification.cohen_kappa_score:22
msgid "**y1**"
msgstr "**y1**"

#: of
msgid "array of shape (n_samples,)"
msgstr "arreglo de forma (n_samples,)"

#: of sklearn.metrics._classification.cohen_kappa_score:22
msgid "Labels assigned by the first annotator."
msgstr "Etiquetas asignadas por el primer anotador."

#: of sklearn.metrics._classification.cohen_kappa_score:26
msgid "**y2**"
msgstr "**y2**"

#: of sklearn.metrics._classification.cohen_kappa_score:25
msgid "Labels assigned by the second annotator. The kappa statistic is symmetric, so swapping ``y1`` and ``y2`` doesn't change the value."
msgstr "Etiquetas asignadas por el segundo anotador. La estadística kappa es simétrica, así que intercambiar ``y1`` y ``y2`` no cambia el valor."

#: of sklearn.metrics._classification.cohen_kappa_score:31
msgid "**labels**"
msgstr "**labels**"

#: of
msgid "array-like of shape (n_classes,), default=None"
msgstr "arreglo tipo de forma (n_classes,), default=None"

#: of sklearn.metrics._classification.cohen_kappa_score:29
msgid "List of labels to index the matrix. This may be used to select a subset of labels. If None, all labels that appear at least once in ``y1`` or ``y2`` are used."
msgstr "Lista de etiquetas para indexar la matriz. Esto puede utilizarse para seleccionar un subconjunto de etiquetas. Si es `None`, todas las etiquetas que aparecen al menos una vez en ``y1`` o ``y2`` son usadas."

#: of sklearn.metrics._classification.cohen_kappa_score:35
msgid "**weights**"
msgstr "**weights**"

#: of
msgid "{'linear', 'quadratic'}, default=None"
msgstr "{'linear', 'quadratic'}, default=None"

#: of sklearn.metrics._classification.cohen_kappa_score:34
msgid "Weighting type to calculate the score. None means no weighted; \"linear\" means linear weighted; \"quadratic\" means quadratic weighted."
msgstr "Tipo de ponderado para calcular el puntaje. None significa sin ponderado; \"linear\" significa ponderado lineal; \"quadratic\" significa ponderado cuadrático."

#: of sklearn.metrics._classification.cohen_kappa_score:38
msgid "**sample_weight**"
msgstr "**sample_weight**"

#: of
msgid "array-like of shape (n_samples,), default=None"
msgstr "arreglo tipo de forma (n_samples,), default=None"

#: of sklearn.metrics._classification.cohen_kappa_score:38
msgid "Sample weights."
msgstr "Ponderados de muestras."

#: of sklearn.metrics._classification.cohen_kappa_score
msgid "Returns"
msgstr "Salida"

#: of sklearn.metrics._classification.cohen_kappa_score:52
msgid "**kappa**"
msgstr "**kappa**"

#: of
msgid "float"
msgstr "flotante"

#: of sklearn.metrics._classification.cohen_kappa_score:43
msgid "The kappa statistic, which is a number between -1 and 1. The maximum value means complete agreement; zero or lower means chance agreement."
msgstr "La estadística kappa, que es un número entre -1 y 1. El valor máximo significa concordancia total; cero o menor significa acuerdo por azar."

#: of sklearn.metrics._classification.cohen_kappa_score:55
msgid "References"
msgstr "Referencias"

#: of sklearn.metrics._classification.cohen_kappa_score:56
msgid "J. Cohen (1960). \"A coefficient of agreement for nominal scales\". Educational and Psychological Measurement 20(1):37-46. doi:10.1177/001316446002000104."
msgstr "J. Cohen (1960). \"A coefficient of agreement for nominal scales\". Educational and Psychological Measurement 20(1):37-46. doi:10.1177/001316446002000104."

#: of sklearn.metrics._classification.cohen_kappa_score:59
msgid "`R. Artstein and M. Poesio (2008). \"Inter-coder agreement for computational linguistics\". Computational Linguistics 34(4):555-596 <https://www.mitpressjournals.org/doi/pdf/10.1162/coli.07-034-R2>`_."
msgstr "`R. Artstein and M. Poesio (2008). \"Inter-coder agreement for computational linguistics\". Computational Linguistics 34(4):555-596 <https://www.mitpressjournals.org/doi/pdf/10.1162/coli.07-034-R2>`_."

#: of sklearn.metrics._classification.cohen_kappa_score:62
#, python-format
msgid "`Wikipedia entry for the Cohen's kappa <https://en.wikipedia.org/wiki/Cohen%27s_kappa>`_."
msgstr "`Wikipedia entry for the Cohen's kappa <https://en.wikipedia.org/wiki/Cohen%27s_kappa>`_."

#: of sklearn.metrics._classification.cohen_kappa_score:67
msgid "[R219a3b9132e1-1]_, [R219a3b9132e1-2]_, [R219a3b9132e1-3]_"
msgstr "[R219a3b9132e1-1]_, [R219a3b9132e1-2]_, [R219a3b9132e1-3]_"

