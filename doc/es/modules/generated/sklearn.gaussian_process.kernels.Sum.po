msgid ""
msgstr ""
"Project-Id-Version: scikit-learn\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-03-31 11:24-0400\n"
"PO-Revision-Date: 2021-05-17 20:58\n"
"Last-Translator: \n"
"Language-Team: Spanish\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Crowdin-Project: scikit-learn\n"
"X-Crowdin-Project-ID: 450526\n"
"X-Crowdin-Language: es-ES\n"
"X-Crowdin-File: /main/doc/en/modules/generated/sklearn.gaussian_process.kernels.Sum.po\n"
"X-Crowdin-File-ID: 5844\n"
"Language: es_ES\n"

#: ../modules/generated/sklearn.gaussian_process.kernels.Sum.rst:2
msgid ":mod:`sklearn.gaussian_process.kernels`.Sum"
msgstr ":mod:`sklearn.gaussian_process.kernels`.Sum"

#: of sklearn.gaussian_process.kernels.Sum:2
msgid "The `Sum` kernel takes two kernels :math:`k_1` and :math:`k_2` and combines them via"
msgstr "El núcleo `Sum` toma dos núcleos :math:`k_1` y :math:`k_2` y los combina por medio de"

#: of sklearn.gaussian_process.kernels.Sum:5
msgid "k_{sum}(X, Y) = k_1(X, Y) + k_2(X, Y)\n\n"
msgstr "k_{sum}(X, Y) = k_1(X, Y) + k_2(X, Y)\n\n"

#: of sklearn.gaussian_process.kernels.Sum:8
msgid "Note that the `__add__` magic method is overridden, so `Sum(RBF(), RBF())` is equivalent to using the + operator with `RBF() + RBF()`."
msgstr "Nota que el método mágico `__add__` está anulado, por lo que `Sum(RBF(), RBF())` es equivalente a utilizar el operador + con `RBF() + RBF()`."

#: of sklearn.gaussian_process.kernels.Sum:12
msgid "Read more in the :ref:`User Guide <gp_kernels>`."
msgstr "Más información en :ref:`User Guide <gp_kernels>`."

#: of sklearn.gaussian_process.kernels.Kernel.clone_with_theta
#: sklearn.gaussian_process.kernels.KernelOperator.get_params
#: sklearn.gaussian_process.kernels.Sum
#: sklearn.gaussian_process.kernels.Sum.__call__
#: sklearn.gaussian_process.kernels.Sum.diag
msgid "Parameters"
msgstr "Parámetros"

#: of sklearn.gaussian_process.kernels.Sum:19
msgid "**k1**"
msgstr "**k1**"

#: of
msgid "Kernel"
msgstr "Kernel"

#: of sklearn.gaussian_process.kernels.Sum:19
msgid "The first base-kernel of the sum-kernel"
msgstr "El primer núcleo de base del núcleo de la suma"

#: of sklearn.gaussian_process.kernels.Sum:25
msgid "**k2**"
msgstr "**k2**"

#: of sklearn.gaussian_process.kernels.Sum:22
msgid "The second base-kernel of the sum-kernel"
msgstr "El segundo núcleo base del núcleo de la suma"

#: of sklearn.gaussian_process.kernels.Sum
msgid "Attributes"
msgstr "Atributos"

#: of sklearn.gaussian_process.kernels.Sum:30
msgid ":obj:`bounds <bounds>`"
msgstr ":obj:`bounds <bounds>`"

#: of sklearn.gaussian_process.kernels.Sum:30
#: sklearn.gaussian_process.kernels.Sum.bounds:2
msgid "Returns the log-transformed bounds on the theta."
msgstr "Devuelve los límites transformados en logaritmo de la theta."

#: of sklearn.gaussian_process.kernels.Sum:33
msgid ":obj:`hyperparameters <hyperparameters>`"
msgstr ":obj:`hyperparameters <hyperparameters>`"

#: of sklearn.gaussian_process.kernels.Sum:33
#: sklearn.gaussian_process.kernels.Sum.hyperparameters:2
msgid "Returns a list of all hyperparameter."
msgstr "Devuelve una lista de todos los hiperparámetros."

#: of sklearn.gaussian_process.kernels.Sum:36
msgid ":obj:`n_dims <n_dims>`"
msgstr ":obj:`n_dims <n_dims>`"

#: of sklearn.gaussian_process.kernels.Sum:36
#: sklearn.gaussian_process.kernels.Sum.n_dims:2
msgid "Returns the number of non-fixed hyperparameters of the kernel."
msgstr "Devuelve el número de hiperparámetros no fijos del núcleo."

#: of sklearn.gaussian_process.kernels.Sum:39
msgid ":obj:`requires_vector_input <requires_vector_input>`"
msgstr ":obj:`requires_vector_input <requires_vector_input>`"

#: of sklearn.gaussian_process.kernels.KernelOperator.is_stationary:2
#: sklearn.gaussian_process.kernels.Sum:39
#: sklearn.gaussian_process.kernels.Sum.requires_vector_input:2
#: sklearn.gaussian_process.kernels.Sum:74:<autosummary>:1
msgid "Returns whether the kernel is stationary."
msgstr "Devuelve si el núcleo es estacionario."

#: of sklearn.gaussian_process.kernels.Sum:48
msgid ":obj:`theta <theta>`"
msgstr ":obj:`theta <theta>`"

#: of sklearn.gaussian_process.kernels.Sum:42
#: sklearn.gaussian_process.kernels.Sum.theta:2
msgid "Returns the (flattened, log-transformed) non-fixed hyperparameters."
msgstr "Devuelve los hiperparámetros no fijos (aplanados y transformados en logaritmos)."

#: of sklearn.gaussian_process.kernels.Sum:51
msgid "Examples"
msgstr "Ejemplos"

#: of sklearn.gaussian_process.kernels.Sum:65
msgid "Methods"
msgstr "Métodos"

#: of sklearn.gaussian_process.kernels.Sum:74:<autosummary>:1
msgid ":obj:`__call__ <sklearn.gaussian_process.kernels.Sum.__call__>`\\"
msgstr ":obj:`__call__ <sklearn.gaussian_process.kernels.Sum.__call__>`\\"

#: of sklearn.gaussian_process.kernels.Sum.__call__:2
#: sklearn.gaussian_process.kernels.Sum:74:<autosummary>:1
msgid "Return the kernel k(X, Y) and optionally its gradient."
msgstr "Devuelve el núcleo k(X, Y) y opcionalmente su gradiente."

#: of sklearn.gaussian_process.kernels.Sum:74:<autosummary>:1
msgid ":obj:`clone_with_theta <sklearn.gaussian_process.kernels.Sum.clone_with_theta>`\\"
msgstr ":obj:`clone_with_theta <sklearn.gaussian_process.kernels.Sum.clone_with_theta>`\\"

#: of sklearn.gaussian_process.kernels.Kernel.clone_with_theta:2
#: sklearn.gaussian_process.kernels.Sum:74:<autosummary>:1
msgid "Returns a clone of self with given hyperparameters theta."
msgstr "Devuelve un clon de sí mismo con los hiperparámetros dados theta."

#: of sklearn.gaussian_process.kernels.Sum:74:<autosummary>:1
msgid ":obj:`diag <sklearn.gaussian_process.kernels.Sum.diag>`\\"
msgstr ":obj:`diag <sklearn.gaussian_process.kernels.Sum.diag>`\\"

#: of sklearn.gaussian_process.kernels.Sum.diag:2
#: sklearn.gaussian_process.kernels.Sum:74:<autosummary>:1
msgid "Returns the diagonal of the kernel k(X, X)."
msgstr "Devuelve la diagonal del núcleo k(X, X)."

#: of sklearn.gaussian_process.kernels.Sum:74:<autosummary>:1
msgid ":obj:`get_params <sklearn.gaussian_process.kernels.Sum.get_params>`\\"
msgstr ":obj:`get_params <sklearn.gaussian_process.kernels.Sum.get_params>`\\"

#: of sklearn.gaussian_process.kernels.KernelOperator.get_params:2
#: sklearn.gaussian_process.kernels.Sum:74:<autosummary>:1
msgid "Get parameters of this kernel."
msgstr "Obtener los parámetros de este núcleo."

#: of sklearn.gaussian_process.kernels.Sum:74:<autosummary>:1
msgid ":obj:`is_stationary <sklearn.gaussian_process.kernels.Sum.is_stationary>`\\"
msgstr ":obj:`is_stationary <sklearn.gaussian_process.kernels.Sum.is_stationary>`\\"

#: of sklearn.gaussian_process.kernels.Sum:74:<autosummary>:1
msgid ":obj:`set_params <sklearn.gaussian_process.kernels.Sum.set_params>`\\"
msgstr ":obj:`set_params <sklearn.gaussian_process.kernels.Sum.set_params>`\\"

#: of sklearn.gaussian_process.kernels.Kernel.set_params:2
#: sklearn.gaussian_process.kernels.Sum:74:<autosummary>:1
msgid "Set the parameters of this kernel."
msgstr "Establece los parámetros de este núcleo."

#: of sklearn.gaussian_process.kernels.Sum.__call__:8
#: sklearn.gaussian_process.kernels.Sum.diag:11
msgid "**X**"
msgstr "**X**"

#: of
msgid "array-like of shape (n_samples_X, n_features) or list of object"
msgstr "array-like de forma (n_samples_X, n_features) o lista de objeto"

#: of sklearn.gaussian_process.kernels.Sum.__call__:8
msgid "Left argument of the returned kernel k(X, Y)"
msgstr "Argumento izquierdo del núcleo devuelto k(X, Y)"

#: of sklearn.gaussian_process.kernels.Sum.__call__:12
msgid "**Y**"
msgstr "**Y**"

#: of
msgid "array-like of shape (n_samples_X, n_features) or list of object,                default=None"
msgstr "array-like de forma (n_samples_X, n_features) o lista de objetos, por defecto = None"

#: of sklearn.gaussian_process.kernels.Sum.__call__:11
msgid "Right argument of the returned kernel k(X, Y). If None, k(X, X) is evaluated instead."
msgstr "Argumento derecho del núcleo devuelto k(X, Y). Si es None, se evalúa k(X, X) en su lugar."

#: of sklearn.gaussian_process.kernels.Sum.__call__:16
msgid "**eval_gradient**"
msgstr "**eval_gradient**"

#: of
msgid "bool, default=False"
msgstr "bool, default=False"

#: of sklearn.gaussian_process.kernels.Sum.__call__:15
msgid "Determines whether the gradient with respect to the log of the kernel hyperparameter is computed."
msgstr "Determina si se calcula el gradiente con respecto al logaritmo del hiperparámetro del núcleo."

#: of sklearn.gaussian_process.kernels.Kernel.set_params
#: sklearn.gaussian_process.kernels.KernelOperator.get_params
#: sklearn.gaussian_process.kernels.Sum.__call__
#: sklearn.gaussian_process.kernels.Sum.bounds
#: sklearn.gaussian_process.kernels.Sum.diag
#: sklearn.gaussian_process.kernels.Sum.theta
msgid "Returns"
msgstr "Devuelve"

#: of sklearn.gaussian_process.kernels.Sum.__call__:21
msgid "**K**"
msgstr "**K**"

#: of
msgid "ndarray of shape (n_samples_X, n_samples_Y)"
msgstr "ndarray of shape (n_samples_X, n_samples_Y)"

#: of sklearn.gaussian_process.kernels.Sum.__call__:21
msgid "Kernel k(X, Y)"
msgstr "Núcleo k(X, Y)"

#: of sklearn.gaussian_process.kernels.Sum.__call__:37
msgid "**K_gradient**"
msgstr "**K_gradient**"

#: of
msgid "ndarray of shape (n_samples_X, n_samples_X, n_dims),                optional"
msgstr "ndarray of shape (n_samples_X, n_samples_X, n_dims),                optional"

#: of sklearn.gaussian_process.kernels.Sum.__call__:24
msgid "The gradient of the kernel k(X, X) with respect to the log of the hyperparameter of the kernel. Only returned when `eval_gradient` is True."
msgstr "El gradiente del núcleo k(X, X) con respecto al logaritmo del hiperparámetro del núcleo. Sólo se devuelve cuando `eval_gradient` es True."

#: of sklearn.gaussian_process.kernels.Sum.bounds:20
msgid "**bounds**"
msgstr "**bounds**"

#: of
msgid "ndarray of shape (n_dims, 2)"
msgstr "ndarray of shape (n_dims, 2)"

#: of sklearn.gaussian_process.kernels.Sum.bounds:9
msgid "The log-transformed bounds on the kernel's hyperparameters theta"
msgstr "Los límites transformados logarítmicamente de los hiperparámetros del núcleo theta"

#: of sklearn.gaussian_process.kernels.Kernel.clone_with_theta:20
#: sklearn.gaussian_process.kernels.Sum.theta:24
msgid "**theta**"
msgstr "**theta**"

#: of
msgid "ndarray of shape (n_dims,)"
msgstr "ndarray of shape (n_dims,)"

#: of sklearn.gaussian_process.kernels.Kernel.clone_with_theta:8
msgid "The hyperparameters"
msgstr "Hiperparámetros"

#: of sklearn.gaussian_process.kernels.Sum.diag:4
msgid "The result of this method is identical to `np.diag(self(X))`; however, it can be evaluated more efficiently since only the diagonal is evaluated."
msgstr "El resultado de este método es idéntico al de `np.diag(self(X))`; sin embargo, se puede evaluar de forma más eficiente ya que sólo se evalúa la diagonal."

#: of sklearn.gaussian_process.kernels.Sum.diag:11
msgid "Argument to the kernel."
msgstr "Argumento para el núcleo."

#: of sklearn.gaussian_process.kernels.Sum.diag:27
msgid "**K_diag**"
msgstr "**K_diag**"

#: of
msgid "ndarray of shape (n_samples_X,)"
msgstr "ndarray of shape (n_samples_X,)"

#: of sklearn.gaussian_process.kernels.Sum.diag:16
msgid "Diagonal of kernel k(X, X)"
msgstr "Diagonal del núcleo k(X, X)"

#: of sklearn.gaussian_process.kernels.KernelOperator.get_params:9
msgid "**deep**"
msgstr "**deep**"

#: of
msgid "bool, default=True"
msgstr "bool, default=True"

#: of sklearn.gaussian_process.kernels.KernelOperator.get_params:8
msgid "If True, will return the parameters for this estimator and contained subobjects that are estimators."
msgstr "Si es True, devolverá los parámetros para este estimador y los subobjetos contenidos que son estimadores."

#: of sklearn.gaussian_process.kernels.KernelOperator.get_params:25
msgid "**params**"
msgstr "**parámetros**"

#: of
msgid "dict"
msgstr "dict"

#: of sklearn.gaussian_process.kernels.KernelOperator.get_params:14
msgid "Parameter names mapped to their values."
msgstr "Nombres de parámetros mapeados a sus valores."

#: of sklearn.gaussian_process.kernels.Kernel.set_params:4
msgid "The method works on simple kernels as well as on nested kernels. The latter have parameters of the form ``<component>__<parameter>`` so that it's possible to update each component of a nested object."
msgstr "El método funciona tanto en núcleos simples como en núcleos anidados. Estos últimos tienen parámetros de la forma ``<component>__<parameter>`` para que sea posible actualizar cada componente de un objeto anidado."

#: of sklearn.gaussian_process.kernels.Kernel.set_params:23
msgid "self"
msgstr "self"

#: of sklearn.gaussian_process.kernels.Sum.theta:4
msgid "Note that theta are typically the log-transformed values of the kernel's hyperparameters as this representation of the search space is more amenable for hyperparameter search, as hyperparameters like length-scales naturally live on a log-scale."
msgstr "Ten en cuenta que theta suelen ser los valores transformados en logaritmos de los hiperparámetros del núcleo, ya que esta representación del espacio de búsqueda es más adecuada para la búsqueda de hiperparámetros, ya que los hiperparámetros como las escalas de longitud viven naturalmente en una escala logarítmica."

#: of sklearn.gaussian_process.kernels.Sum.theta:13
msgid "The non-fixed, log-transformed hyperparameters of the kernel"
msgstr "Los hiperparámetros no fijos y transformados en logaritmos del núcleo"

