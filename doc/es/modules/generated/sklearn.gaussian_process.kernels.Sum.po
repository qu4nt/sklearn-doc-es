msgid ""
msgstr ""
"Project-Id-Version: scikit-learn\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-03-31 11:24-0400\n"
"PO-Revision-Date: 2021-04-15 06:08\n"
"Last-Translator: \n"
"Language-Team: Spanish\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Crowdin-Project: scikit-learn\n"
"X-Crowdin-Project-ID: 450526\n"
"X-Crowdin-Language: es-ES\n"
"X-Crowdin-File: /main/doc/en/modules/generated/sklearn.gaussian_process.kernels.Sum.po\n"
"X-Crowdin-File-ID: 5844\n"
"Language: es_ES\n"

#: ../modules/generated/sklearn.gaussian_process.kernels.Sum.rst:2
msgid ":mod:`sklearn.gaussian_process.kernels`.Sum"
msgstr ""

#: of sklearn.gaussian_process.kernels.Sum:2
msgid "The `Sum` kernel takes two kernels :math:`k_1` and :math:`k_2` and combines them via"
msgstr ""

#: of sklearn.gaussian_process.kernels.Sum:5
msgid "k_{sum}(X, Y) = k_1(X, Y) + k_2(X, Y)\n\n"
msgstr ""

#: of sklearn.gaussian_process.kernels.Sum:8
msgid "Note that the `__add__` magic method is overridden, so `Sum(RBF(), RBF())` is equivalent to using the + operator with `RBF() + RBF()`."
msgstr ""

#: of sklearn.gaussian_process.kernels.Sum:12
msgid "Read more in the :ref:`User Guide <gp_kernels>`."
msgstr ""

#: of sklearn.gaussian_process.kernels.Kernel.clone_with_theta
#: sklearn.gaussian_process.kernels.KernelOperator.get_params
#: sklearn.gaussian_process.kernels.Sum
#: sklearn.gaussian_process.kernels.Sum.__call__
#: sklearn.gaussian_process.kernels.Sum.diag
msgid "Parameters"
msgstr ""

#: of sklearn.gaussian_process.kernels.Sum:19
msgid "**k1**"
msgstr ""

#: of
msgid "Kernel"
msgstr ""

#: of sklearn.gaussian_process.kernels.Sum:19
msgid "The first base-kernel of the sum-kernel"
msgstr ""

#: of sklearn.gaussian_process.kernels.Sum:25
msgid "**k2**"
msgstr ""

#: of sklearn.gaussian_process.kernels.Sum:22
msgid "The second base-kernel of the sum-kernel"
msgstr ""

#: of sklearn.gaussian_process.kernels.Sum
msgid "Attributes"
msgstr ""

#: of sklearn.gaussian_process.kernels.Sum:30
msgid ":obj:`bounds <bounds>`"
msgstr ""

#: of sklearn.gaussian_process.kernels.Sum:30
#: sklearn.gaussian_process.kernels.Sum.bounds:2
msgid "Returns the log-transformed bounds on the theta."
msgstr ""

#: of sklearn.gaussian_process.kernels.Sum:33
msgid ":obj:`hyperparameters <hyperparameters>`"
msgstr ""

#: of sklearn.gaussian_process.kernels.Sum:33
#: sklearn.gaussian_process.kernels.Sum.hyperparameters:2
msgid "Returns a list of all hyperparameter."
msgstr ""

#: of sklearn.gaussian_process.kernels.Sum:36
msgid ":obj:`n_dims <n_dims>`"
msgstr ""

#: of sklearn.gaussian_process.kernels.Sum:36
#: sklearn.gaussian_process.kernels.Sum.n_dims:2
msgid "Returns the number of non-fixed hyperparameters of the kernel."
msgstr ""

#: of sklearn.gaussian_process.kernels.Sum:39
msgid ":obj:`requires_vector_input <requires_vector_input>`"
msgstr ""

#: of sklearn.gaussian_process.kernels.KernelOperator.is_stationary:2
#: sklearn.gaussian_process.kernels.Sum:39
#: sklearn.gaussian_process.kernels.Sum.requires_vector_input:2
#: sklearn.gaussian_process.kernels.Sum:74:<autosummary>:1
msgid "Returns whether the kernel is stationary."
msgstr ""

#: of sklearn.gaussian_process.kernels.Sum:48
msgid ":obj:`theta <theta>`"
msgstr ""

#: of sklearn.gaussian_process.kernels.Sum:42
#: sklearn.gaussian_process.kernels.Sum.theta:2
msgid "Returns the (flattened, log-transformed) non-fixed hyperparameters."
msgstr ""

#: of sklearn.gaussian_process.kernels.Sum:51
msgid "Examples"
msgstr ""

#: of sklearn.gaussian_process.kernels.Sum:65
msgid "Methods"
msgstr ""

#: of sklearn.gaussian_process.kernels.Sum:74:<autosummary>:1
msgid ":obj:`__call__ <sklearn.gaussian_process.kernels.Sum.__call__>`\\"
msgstr ""

#: of sklearn.gaussian_process.kernels.Sum.__call__:2
#: sklearn.gaussian_process.kernels.Sum:74:<autosummary>:1
msgid "Return the kernel k(X, Y) and optionally its gradient."
msgstr ""

#: of sklearn.gaussian_process.kernels.Sum:74:<autosummary>:1
msgid ":obj:`clone_with_theta <sklearn.gaussian_process.kernels.Sum.clone_with_theta>`\\"
msgstr ""

#: of sklearn.gaussian_process.kernels.Kernel.clone_with_theta:2
#: sklearn.gaussian_process.kernels.Sum:74:<autosummary>:1
msgid "Returns a clone of self with given hyperparameters theta."
msgstr ""

#: of sklearn.gaussian_process.kernels.Sum:74:<autosummary>:1
msgid ":obj:`diag <sklearn.gaussian_process.kernels.Sum.diag>`\\"
msgstr ""

#: of sklearn.gaussian_process.kernels.Sum.diag:2
#: sklearn.gaussian_process.kernels.Sum:74:<autosummary>:1
msgid "Returns the diagonal of the kernel k(X, X)."
msgstr ""

#: of sklearn.gaussian_process.kernels.Sum:74:<autosummary>:1
msgid ":obj:`get_params <sklearn.gaussian_process.kernels.Sum.get_params>`\\"
msgstr ""

#: of sklearn.gaussian_process.kernels.KernelOperator.get_params:2
#: sklearn.gaussian_process.kernels.Sum:74:<autosummary>:1
msgid "Get parameters of this kernel."
msgstr ""

#: of sklearn.gaussian_process.kernels.Sum:74:<autosummary>:1
msgid ":obj:`is_stationary <sklearn.gaussian_process.kernels.Sum.is_stationary>`\\"
msgstr ""

#: of sklearn.gaussian_process.kernels.Sum:74:<autosummary>:1
msgid ":obj:`set_params <sklearn.gaussian_process.kernels.Sum.set_params>`\\"
msgstr ""

#: of sklearn.gaussian_process.kernels.Kernel.set_params:2
#: sklearn.gaussian_process.kernels.Sum:74:<autosummary>:1
msgid "Set the parameters of this kernel."
msgstr ""

#: of sklearn.gaussian_process.kernels.Sum.__call__:8
#: sklearn.gaussian_process.kernels.Sum.diag:11
msgid "**X**"
msgstr ""

#: of
msgid "array-like of shape (n_samples_X, n_features) or list of object"
msgstr ""

#: of sklearn.gaussian_process.kernels.Sum.__call__:8
msgid "Left argument of the returned kernel k(X, Y)"
msgstr ""

#: of sklearn.gaussian_process.kernels.Sum.__call__:12
msgid "**Y**"
msgstr ""

#: of
msgid "array-like of shape (n_samples_X, n_features) or list of object,                default=None"
msgstr ""

#: of sklearn.gaussian_process.kernels.Sum.__call__:11
msgid "Right argument of the returned kernel k(X, Y). If None, k(X, X) is evaluated instead."
msgstr ""

#: of sklearn.gaussian_process.kernels.Sum.__call__:16
msgid "**eval_gradient**"
msgstr ""

#: of
msgid "bool, default=False"
msgstr ""

#: of sklearn.gaussian_process.kernels.Sum.__call__:15
msgid "Determines whether the gradient with respect to the log of the kernel hyperparameter is computed."
msgstr ""

#: of sklearn.gaussian_process.kernels.Kernel.set_params
#: sklearn.gaussian_process.kernels.KernelOperator.get_params
#: sklearn.gaussian_process.kernels.Sum.__call__
#: sklearn.gaussian_process.kernels.Sum.bounds
#: sklearn.gaussian_process.kernels.Sum.diag
#: sklearn.gaussian_process.kernels.Sum.theta
msgid "Returns"
msgstr ""

#: of sklearn.gaussian_process.kernels.Sum.__call__:21
msgid "**K**"
msgstr ""

#: of
msgid "ndarray of shape (n_samples_X, n_samples_Y)"
msgstr ""

#: of sklearn.gaussian_process.kernels.Sum.__call__:21
msgid "Kernel k(X, Y)"
msgstr ""

#: of sklearn.gaussian_process.kernels.Sum.__call__:37
msgid "**K_gradient**"
msgstr ""

#: of
msgid "ndarray of shape (n_samples_X, n_samples_X, n_dims),                optional"
msgstr ""

#: of sklearn.gaussian_process.kernels.Sum.__call__:24
msgid "The gradient of the kernel k(X, X) with respect to the log of the hyperparameter of the kernel. Only returned when `eval_gradient` is True."
msgstr ""

#: of sklearn.gaussian_process.kernels.Sum.bounds:20
msgid "**bounds**"
msgstr ""

#: of
msgid "ndarray of shape (n_dims, 2)"
msgstr ""

#: of sklearn.gaussian_process.kernels.Sum.bounds:9
msgid "The log-transformed bounds on the kernel's hyperparameters theta"
msgstr ""

#: of sklearn.gaussian_process.kernels.Kernel.clone_with_theta:20
#: sklearn.gaussian_process.kernels.Sum.theta:24
msgid "**theta**"
msgstr ""

#: of
msgid "ndarray of shape (n_dims,)"
msgstr ""

#: of sklearn.gaussian_process.kernels.Kernel.clone_with_theta:8
msgid "The hyperparameters"
msgstr ""

#: of sklearn.gaussian_process.kernels.Sum.diag:4
msgid "The result of this method is identical to `np.diag(self(X))`; however, it can be evaluated more efficiently since only the diagonal is evaluated."
msgstr ""

#: of sklearn.gaussian_process.kernels.Sum.diag:11
msgid "Argument to the kernel."
msgstr ""

#: of sklearn.gaussian_process.kernels.Sum.diag:27
msgid "**K_diag**"
msgstr ""

#: of
msgid "ndarray of shape (n_samples_X,)"
msgstr ""

#: of sklearn.gaussian_process.kernels.Sum.diag:16
msgid "Diagonal of kernel k(X, X)"
msgstr ""

#: of sklearn.gaussian_process.kernels.KernelOperator.get_params:9
msgid "**deep**"
msgstr ""

#: of
msgid "bool, default=True"
msgstr ""

#: of sklearn.gaussian_process.kernels.KernelOperator.get_params:8
msgid "If True, will return the parameters for this estimator and contained subobjects that are estimators."
msgstr ""

#: of sklearn.gaussian_process.kernels.KernelOperator.get_params:25
msgid "**params**"
msgstr ""

#: of
msgid "dict"
msgstr ""

#: of sklearn.gaussian_process.kernels.KernelOperator.get_params:14
msgid "Parameter names mapped to their values."
msgstr ""

#: of sklearn.gaussian_process.kernels.Kernel.set_params:4
msgid "The method works on simple kernels as well as on nested kernels. The latter have parameters of the form ``<component>__<parameter>`` so that it's possible to update each component of a nested object."
msgstr ""

#: of sklearn.gaussian_process.kernels.Kernel.set_params:23
msgid "self"
msgstr ""

#: of sklearn.gaussian_process.kernels.Sum.theta:4
msgid "Note that theta are typically the log-transformed values of the kernel's hyperparameters as this representation of the search space is more amenable for hyperparameter search, as hyperparameters like length-scales naturally live on a log-scale."
msgstr ""

#: of sklearn.gaussian_process.kernels.Sum.theta:13
msgid "The non-fixed, log-transformed hyperparameters of the kernel"
msgstr ""

