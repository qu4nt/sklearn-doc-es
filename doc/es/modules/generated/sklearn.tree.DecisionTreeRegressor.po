msgid ""
msgstr ""
"Project-Id-Version: scikit-learn\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-03-31 12:43-0400\n"
"PO-Revision-Date: 2021-07-13 22:11\n"
"Last-Translator: \n"
"Language-Team: Spanish\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Crowdin-Project: scikit-learn\n"
"X-Crowdin-Project-ID: 450526\n"
"X-Crowdin-Language: es-ES\n"
"X-Crowdin-File: /main/doc/en/modules/generated/sklearn.tree.DecisionTreeRegressor.po\n"
"X-Crowdin-File-ID: 5612\n"
"Language: es_ES\n"

#: ../modules/generated/sklearn.tree.DecisionTreeRegressor.rst:2
msgid ":mod:`sklearn.tree`.DecisionTreeRegressor"
msgstr ":mod:`sklearn.tree`.DecisionTreeRegressor"

#: of sklearn.tree._classes.DecisionTreeRegressor:2
msgid "A decision tree regressor."
msgstr "Un regresor del árbol de decisión."

#: of sklearn.tree._classes.DecisionTreeRegressor:4
msgid "Read more in the :ref:`User Guide <tree>`."
msgstr "Lee más en el :ref:`Manual de usuario <tree>`."

#: of sklearn.base.BaseEstimator.get_params
#: sklearn.base.BaseEstimator.set_params sklearn.base.RegressorMixin.score
#: sklearn.tree._classes.BaseDecisionTree.apply
#: sklearn.tree._classes.BaseDecisionTree.cost_complexity_pruning_path
#: sklearn.tree._classes.BaseDecisionTree.decision_path
#: sklearn.tree._classes.BaseDecisionTree.predict
#: sklearn.tree._classes.DecisionTreeRegressor
#: sklearn.tree._classes.DecisionTreeRegressor.fit
msgid "Parameters"
msgstr "Parámetros"

#: of sklearn.tree._classes.DecisionTreeRegressor:22
msgid "**criterion**"
msgstr "**criterion**"

#: of
msgid "{\"mse\", \"friedman_mse\", \"mae\", \"poisson\"}, default=\"mse\""
msgstr "{\"mse\", \"friedman_mse\", \"mae\", \"poisson\"}, default=\"mse\""

#: of sklearn.tree._classes.DecisionTreeRegressor:9
msgid "The function to measure the quality of a split. Supported criteria are \"mse\" for the mean squared error, which is equal to variance reduction as feature selection criterion and minimizes the L2 loss using the mean of each terminal node, \"friedman_mse\", which uses mean squared error with Friedman's improvement score for potential splits, \"mae\" for the mean absolute error, which minimizes the L1 loss using the median of each terminal node, and \"poisson\" which uses reduction in Poisson deviance to find splits."
msgstr "La función para medir la calidad de una separación. Los criterios soportados son \"mse\" para el error cuadrático medio, que es igual a la reducción de la varianza como criterio de selección de características y minimiza la pérdida L2 utilizando la media de cada nodo terminal, \"friedman_mse\", que utiliza el error cuadrático medio con la puntuación de mejora de Friedman para las posibles separaciones, \"mae\" para el error absoluto medio, que minimiza la pérdida L1 utilizando la mediana de cada nodo terminal, y \"poisson\" que utiliza la reducción de la desviación de Poisson para encontrar separaciones."

#: of sklearn.tree._classes.DecisionTreeRegressor:18
msgid "Mean Absolute Error (MAE) criterion."
msgstr "Criterio de error absoluto medio (MAE)."

#: of sklearn.tree._classes.DecisionTreeRegressor:21
msgid "Poisson deviance criterion."
msgstr "Criterio de desviación de Poisson."

#: of sklearn.tree._classes.DecisionTreeRegressor:27
msgid "**splitter**"
msgstr "**splitter**"

#: of
msgid "{\"best\", \"random\"}, default=\"best\""
msgstr "{\"best\", \"random\"}, default=\"best\""

#: of sklearn.tree._classes.DecisionTreeRegressor:25
msgid "The strategy used to choose the split at each node. Supported strategies are \"best\" to choose the best split and \"random\" to choose the best random split."
msgstr "La estrategia utilizada para elegir la separación en cada nodo. Las estrategias soportadas son \"best\" para elegir la mejor separación y \"random\" para elegir la mejor separación aleatoria."

#: of sklearn.tree._classes.DecisionTreeRegressor:32
msgid "**max_depth**"
msgstr "**max_depth**"

#: of
msgid "int, default=None"
msgstr "int, default=None"

#: of sklearn.tree._classes.DecisionTreeRegressor:30
msgid "The maximum depth of the tree. If None, then nodes are expanded until all leaves are pure or until all leaves contain less than min_samples_split samples."
msgstr "La profundidad máxima del árbol. Si es None, los nodos se expanden hasta que todas las hojas sean puras o hasta que todas las hojas contengan menos muestras que min_samples_split."

#: of sklearn.tree._classes.DecisionTreeRegressor:43
msgid "**min_samples_split**"
msgstr "**min_samples_split**"

#: of
msgid "int or float, default=2"
msgstr "int o float, default=2"

#: of sklearn.tree._classes.DecisionTreeRegressor:35
msgid "The minimum number of samples required to split an internal node:"
msgstr "El número mínimo de muestras necesario para separar un nodo interno:"

#: of sklearn.tree._classes.DecisionTreeRegressor:37
msgid "If int, then consider `min_samples_split` as the minimum number."
msgstr "Si es int, entonces considere `min_samples_split` como el número mínimo."

#: of sklearn.tree._classes.DecisionTreeRegressor:38
msgid "If float, then `min_samples_split` is a fraction and `ceil(min_samples_split * n_samples)` are the minimum number of samples for each split."
msgstr "Si es float, `min_samples_split` es una fracción y `ceil(min_samples_split * n_samples)` es el número mínimo de muestras para cada separación."

#: of sklearn.tree._classes.DecisionTreeRegressor:42
#: sklearn.tree._classes.DecisionTreeRegressor:57
msgid "Added float values for fractions."
msgstr "Se han añadido valores flotantes para las fracciones."

#: of sklearn.tree._classes.DecisionTreeRegressor:58
msgid "**min_samples_leaf**"
msgstr "**min_samples_leaf**"

#: of
msgid "int or float, default=1"
msgstr "int o float, default=1"

#: of sklearn.tree._classes.DecisionTreeRegressor:46
msgid "The minimum number of samples required to be at a leaf node. A split point at any depth will only be considered if it leaves at least ``min_samples_leaf`` training samples in each of the left and right branches.  This may have the effect of smoothing the model, especially in regression."
msgstr "El número mínimo de muestras requerido para estar en un nodo hoja. Un punto de separación en cualquier profundidad sólo se considerará si deja al menos ``min_samples_leaf`` muestras de entrenamiento en cada una de las ramas izquierda y derecha.  Esto puede tener el efecto de suavizar el modelo, especialmente en la regresión."

#: of sklearn.tree._classes.DecisionTreeRegressor:52
msgid "If int, then consider `min_samples_leaf` as the minimum number."
msgstr "Si es int, entonces considere `min_samples_leaf` como el número mínimo."

#: of sklearn.tree._classes.DecisionTreeRegressor:53
msgid "If float, then `min_samples_leaf` is a fraction and `ceil(min_samples_leaf * n_samples)` are the minimum number of samples for each node."
msgstr "Si es float, entonces `min_samples_leaf` es una fracción y `ceil(min_samples_leaf * n_samples)` son el número mínimo de muestras para cada nodo."

#: of sklearn.tree._classes.DecisionTreeRegressor:63
msgid "**min_weight_fraction_leaf**"
msgstr "**min_weight_fraction_leaf**"

#: of
msgid "float, default=0.0"
msgstr "float, default=0.0"

#: of sklearn.tree._classes.DecisionTreeRegressor:61
msgid "The minimum weighted fraction of the sum total of weights (of all the input samples) required to be at a leaf node. Samples have equal weight when sample_weight is not provided."
msgstr "La fracción ponderada mínima de la suma total de pesos (de todas las muestras de entrada) requerida para estar en un nodo hoja. Las muestras tienen el mismo peso cuando no se proporciona sample_weight."

#: of sklearn.tree._classes.DecisionTreeRegressor:79
msgid "**max_features**"
msgstr "**max_features**"

#: of
msgid "int, float or {\"auto\", \"sqrt\", \"log2\"}, default=None"
msgstr "int, float or {\"auto\", \"sqrt\", \"log2\"}, default=None"

#: of sklearn.tree._classes.DecisionTreeRegressor:66
msgid "The number of features to consider when looking for the best split:"
msgstr "El número de características a considerar cuando se busca la mejor separación:"

#: of sklearn.tree._classes.DecisionTreeRegressor:68
msgid "If int, then consider `max_features` features at each split."
msgstr "Si es int, entonces se consideran las características `max_features` en cada separación."

#: of sklearn.tree._classes.DecisionTreeRegressor:69
msgid "If float, then `max_features` is a fraction and `int(max_features * n_features)` features are considered at each split."
msgstr "Si es float, entonces `max_features` es una fracción y las características `int(max_features * n_features)` se consideran en cada separación."

#: of sklearn.tree._classes.DecisionTreeRegressor:72
msgid "If \"auto\", then `max_features=n_features`."
msgstr "Si \"auto\", entonces `max_features=n_features`."

#: of sklearn.tree._classes.DecisionTreeRegressor:73
msgid "If \"sqrt\", then `max_features=sqrt(n_features)`."
msgstr "Si \"sqrt\", entonces `max_features=sqrt(n_features)`."

#: of sklearn.tree._classes.DecisionTreeRegressor:74
msgid "If \"log2\", then `max_features=log2(n_features)`."
msgstr "Si \"log2\", entonces `max_features=log2(n_features)`."

#: of sklearn.tree._classes.DecisionTreeRegressor:75
msgid "If None, then `max_features=n_features`."
msgstr "Si None, entonces `max_features=n_features`."

#: of sklearn.tree._classes.DecisionTreeRegressor:77
msgid "Note: the search for a split does not stop until at least one valid partition of the node samples is found, even if it requires to effectively inspect more than ``max_features`` features."
msgstr "Nota: la búsqueda de una partición no se detiene hasta que se encuentra al menos una partición válida de las muestras del nodo, incluso si requiere inspeccionar efectivamente más características de ``max_features``."

#: of sklearn.tree._classes.DecisionTreeRegressor:91
msgid "**random_state**"
msgstr "**random_state**"

#: of
msgid "int, RandomState instance or None, default=None"
msgstr "int, instancia de RandomState o None, default=None"

#: of sklearn.tree._classes.DecisionTreeRegressor:82
msgid "Controls the randomness of the estimator. The features are always randomly permuted at each split, even if ``splitter`` is set to ``\"best\"``. When ``max_features < n_features``, the algorithm will select ``max_features`` at random at each split before finding the best split among them. But the best found split may vary across different runs, even if ``max_features=n_features``. That is the case, if the improvement of the criterion is identical for several splits and one split has to be selected at random. To obtain a deterministic behaviour during fitting, ``random_state`` has to be fixed to an integer. See :term:`Glossary <random_state>` for details."
msgstr "Controla la aleatoriedad del estimador. Las características siempre se permutan aleatoriamente en cada separación, incluso si ``splitter`` se establece en ``\"best\"``. Cuando ``max_features < n_features``, el algoritmo seleccionará ``max_features`` al azar en cada división antes de encontrar la mejor división entre ellas. Pero la mejor división encontrada puede variar en diferentes ejecuciones, incluso si ``max_features=n_features``. Este es el caso, si la mejora del criterio es idéntica para varias separaciones y una de ellas tiene que ser seleccionada al azar. Para obtener un comportamiento determinista durante el ajuste, ``random_state`` debe fijarse en un número entero. Ver :term:`Glosario <random_state>` para más detalles."

#: of sklearn.tree._classes.DecisionTreeRegressor:96
msgid "**max_leaf_nodes**"
msgstr "**max_leaf_nodes**"

#: of sklearn.tree._classes.DecisionTreeRegressor:94
msgid "Grow a tree with ``max_leaf_nodes`` in best-first fashion. Best nodes are defined as relative reduction in impurity. If None then unlimited number of leaf nodes."
msgstr "Crece un árbol con ``max_leaf_nodes`` en modo best-first. Los mejores nodos se definen como la reducción relativa de la impureza. Si no hay ninguno, el número de nodos hoja es ilimitado."

#: of sklearn.tree._classes.DecisionTreeRegressor:114
msgid "**min_impurity_decrease**"
msgstr "**min_impurity_decrease**"

#: of sklearn.tree._classes.DecisionTreeRegressor:99
msgid "A node will be split if this split induces a decrease of the impurity greater than or equal to this value."
msgstr "Un nodo se separará si esta separación induce una disminución de la impureza mayor o igual a este valor."

#: of sklearn.tree._classes.DecisionTreeRegressor:102
msgid "The weighted impurity decrease equation is the following::"
msgstr "La ecuación de disminución de impurezas ponderada es la siguiente::"

#: of sklearn.tree._classes.DecisionTreeRegressor:107
msgid "where ``N`` is the total number of samples, ``N_t`` is the number of samples at the current node, ``N_t_L`` is the number of samples in the left child, and ``N_t_R`` is the number of samples in the right child."
msgstr "donde ``N`` es el número total de muestras, ``N_t`` es el número de muestras en el nodo actual, ``N_t_L`` es el número de muestras en el hijo izquierdo, y ``N_t_R`` es el número de muestras en el hijo derecho."

#: of sklearn.tree._classes.DecisionTreeRegressor:111
msgid "``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum, if ``sample_weight`` is passed."
msgstr "``N``, ``N_t``, ``N_t_R`` y ``N_t_L`` se refieren a la suma ponderada, si se pasa ``sample_weight``."

#: of sklearn.tree._classes.DecisionTreeRegressor:125
msgid "**min_impurity_split**"
msgstr "**min_impurity_split**"

#: of
msgid "float, default=0"
msgstr "float, default=0"

#: of sklearn.tree._classes.DecisionTreeRegressor:117
msgid "Threshold for early stopping in tree growth. A node will split if its impurity is above the threshold, otherwise it is a leaf."
msgstr "Umbral para la detención temprana en el crecimiento del árbol. Un nodo se separará si su impureza está por encima del umbral, de lo contrario será una hoja."

#: of sklearn.tree._classes.DecisionTreeRegressor:120
msgid "``min_impurity_split`` has been deprecated in favor of ``min_impurity_decrease`` in 0.19. The default value of ``min_impurity_split`` has changed from 1e-7 to 0 in 0.23 and it will be removed in 1.0 (renaming of 0.25). Use ``min_impurity_decrease`` instead."
msgstr "El valor de ``min_impurity_split`` ha quedado obsoleto en favor de ``min_impurity_decrease`` en 0.19. El valor predeterminado de ``min_impurity_split`` ha cambiado de 1e-7 a 0 en 0.23 y se eliminará en 1.0 (cambio de nombre de 0.25). Utilice ``min_impurity_decrease`` en su lugar."

#: of sklearn.tree._classes.DecisionTreeRegressor:136
msgid "**ccp_alpha**"
msgstr "**ccp_alpha**"

#: of
msgid "non-negative float, default=0.0"
msgstr "flotante no negativo, default=0.0"

#: of sklearn.tree._classes.DecisionTreeRegressor:128
msgid "Complexity parameter used for Minimal Cost-Complexity Pruning. The subtree with the largest cost complexity that is smaller than ``ccp_alpha`` will be chosen. By default, no pruning is performed. See :ref:`minimal_cost_complexity_pruning` for details."
msgstr "Parámetro de complejidad utilizado para la Poda de Mínima Complejidad de Costes. Se elegirá el subárbol con la mayor complejidad de costes que sea menor que ``ccp_alpha``. Por defecto, no se realiza ninguna poda. Ver :ref:`minimal_cost_complexity_pruning` para más detalles."

#: of sklearn.tree._classes.DecisionTreeRegressor
msgid "Attributes"
msgstr "Atributos"

#: of sklearn.tree._classes.DecisionTreeRegressor:141
msgid ":obj:`feature_importances_ <feature_importances_>`"
msgstr ":obj:`feature_importances_ <feature_importances_>`"

#: of
msgid "ndarray of shape (n_features,)"
msgstr "ndarray de forma (n_features,)"

#: of sklearn.tree.DecisionTreeRegressor.feature_importances_:2
#: sklearn.tree._classes.DecisionTreeRegressor:141
msgid "Return the feature importances."
msgstr "Devuelve las importancias de las características."

#: of sklearn.tree._classes.DecisionTreeRegressor:144
msgid "**max_features_**"
msgstr "**max_features_**"

#: of
msgid "int"
msgstr "int"

#: of sklearn.tree._classes.DecisionTreeRegressor:144
msgid "The inferred value of max_features."
msgstr "El valor inferido de max_features."

#: of sklearn.tree._classes.DecisionTreeRegressor:147
msgid "**n_features_**"
msgstr "**n_features_**"

#: of sklearn.tree._classes.DecisionTreeRegressor:147
msgid "The number of features when ``fit`` is performed."
msgstr "El número de características cuando se realiza ``fit``."

#: of sklearn.tree._classes.DecisionTreeRegressor:150
msgid "**n_outputs_**"
msgstr "**n_outputs_**"

#: of sklearn.tree._classes.DecisionTreeRegressor:150
msgid "The number of outputs when ``fit`` is performed."
msgstr "El número de salidas cuando se realiza ``fit``."

#: of sklearn.tree._classes.DecisionTreeRegressor:159
msgid "**tree_**"
msgstr "**tree_**"

#: of
msgid "Tree instance"
msgstr "Instancia del árbol"

#: of sklearn.tree._classes.DecisionTreeRegressor:153
msgid "The underlying Tree object. Please refer to ``help(sklearn.tree._tree.Tree)`` for attributes of Tree object and :ref:`sphx_glr_auto_examples_tree_plot_unveil_tree_structure.py` for basic usage of these attributes."
msgstr "El objeto Tree subyacente. Por favor, consulta ``help(sklearn.tree._tree.Tree)`` para los atributos del objeto Tree y :ref:`sphx_glr_auto_examples_tree_plot_unveil_tree_structure.py` para el uso básico de estos atributos."

#: of sklearn.tree._classes.DecisionTreeRegressor:164
msgid ":obj:`DecisionTreeClassifier`"
msgstr ":obj:`DecisionTreeClassifier`"

#: of sklearn.tree._classes.DecisionTreeRegressor:165
msgid "A decision tree classifier."
msgstr "Un clasificador de árbol de decisión."

#: of sklearn.base.RegressorMixin.score:41
#: sklearn.tree._classes.DecisionTreeRegressor:169
msgid "Notes"
msgstr "Notas"

#: of sklearn.tree._classes.DecisionTreeRegressor:170
msgid "The default values for the parameters controlling the size of the trees (e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and unpruned trees which can potentially be very large on some data sets. To reduce memory consumption, the complexity and size of the trees should be controlled by setting those parameter values."
msgstr "Los valores predeterminados de los parámetros que controlan el tamaño de los árboles (por ejemplo, ``max_depth``, ``min_samples_leaf``, etc.) conducen a árboles completamente crecidos y no podados que pueden ser potencialmente muy grandes en algunos conjuntos de datos. Para reducir el consumo de memoria, la complejidad y el tamaño de los árboles deben controlarse estableciendo los valores de esos parámetros."

#: of sklearn.tree._classes.DecisionTreeRegressor:177
msgid "References"
msgstr "Referencias"

#: of sklearn.tree._classes.DecisionTreeRegressor:178
msgid "https://en.wikipedia.org/wiki/Decision_tree_learning"
msgstr "https://en.wikipedia.org/wiki/Decision_tree_learning"

#: of sklearn.tree._classes.DecisionTreeRegressor:180
msgid "L. Breiman, J. Friedman, R. Olshen, and C. Stone, \"Classification and Regression Trees\", Wadsworth, Belmont, CA, 1984."
msgstr "L. Breiman, J. Friedman, R. Olshen, and C. Stone, \"Classification and Regression Trees\", Wadsworth, Belmont, CA, 1984."

#: of sklearn.tree._classes.DecisionTreeRegressor:183
msgid "T. Hastie, R. Tibshirani and J. Friedman. \"Elements of Statistical Learning\", Springer, 2009."
msgstr "T. Hastie, R. Tibshirani and J. Friedman. \"Elements of Statistical Learning\", Springer, 2009."

#: of sklearn.tree._classes.DecisionTreeRegressor:186
msgid "L. Breiman, and A. Cutler, \"Random Forests\", https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm"
msgstr "L. Breiman, and A. Cutler, \"Random Forests\", https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm"

#: of sklearn.tree._classes.DecisionTreeRegressor:191
msgid "[Ra37b7e3adb19-1]_, [Ra37b7e3adb19-2]_, [Ra37b7e3adb19-3]_, [Ra37b7e3adb19-4]_"
msgstr "[Ra37b7e3adb19-1]_, [Ra37b7e3adb19-2]_, [Ra37b7e3adb19-3]_, [Ra37b7e3adb19-4]_"

#: of sklearn.tree._classes.DecisionTreeRegressor:194
msgid "Examples"
msgstr "Ejemplos"

#: of sklearn.tree._classes.DecisionTreeRegressor:207
msgid "Methods"
msgstr "Métodos"

#: of sklearn.tree._classes.DecisionTreeRegressor:220:<autosummary>:1
msgid ":obj:`apply <sklearn.tree.DecisionTreeRegressor.apply>`\\"
msgstr ":obj:`apply <sklearn.tree.DecisionTreeRegressor.apply>`\\"

#: of sklearn.tree._classes.BaseDecisionTree.apply:2
#: sklearn.tree._classes.DecisionTreeRegressor:220:<autosummary>:1
msgid "Return the index of the leaf that each sample is predicted as."
msgstr "Devuelve el índice de la hoja en la que se predice cada muestra."

#: of sklearn.tree._classes.DecisionTreeRegressor:220:<autosummary>:1
msgid ":obj:`cost_complexity_pruning_path <sklearn.tree.DecisionTreeRegressor.cost_complexity_pruning_path>`\\"
msgstr ":obj:`cost_complexity_pruning_path <sklearn.tree.DecisionTreeRegressor.cost_complexity_pruning_path>`\\"

#: of sklearn.tree._classes.BaseDecisionTree.cost_complexity_pruning_path:2
#: sklearn.tree._classes.DecisionTreeRegressor:220:<autosummary>:1
msgid "Compute the pruning path during Minimal Cost-Complexity Pruning."
msgstr "Calcular la ruta de poda durante la Poda de Mínima Complejidad de costes."

#: of sklearn.tree._classes.DecisionTreeRegressor:220:<autosummary>:1
msgid ":obj:`decision_path <sklearn.tree.DecisionTreeRegressor.decision_path>`\\"
msgstr ":obj:`decision_path <sklearn.tree.DecisionTreeRegressor.decision_path>`\\"

#: of sklearn.tree._classes.BaseDecisionTree.decision_path:2
#: sklearn.tree._classes.DecisionTreeRegressor:220:<autosummary>:1
msgid "Return the decision path in the tree."
msgstr "Devuelve la ruta de decisión en el árbol."

#: of sklearn.tree._classes.DecisionTreeRegressor:220:<autosummary>:1
msgid ":obj:`fit <sklearn.tree.DecisionTreeRegressor.fit>`\\"
msgstr ":obj:`fit <sklearn.tree.DecisionTreeRegressor.fit>`\\"

#: of sklearn.tree._classes.DecisionTreeRegressor.fit:2
#: sklearn.tree._classes.DecisionTreeRegressor:220:<autosummary>:1
msgid "Build a decision tree regressor from the training set (X, y)."
msgstr "Construye un regresor de árbol de decisión a partir del conjunto de entrenamiento (X, y)."

#: of sklearn.tree._classes.DecisionTreeRegressor:220:<autosummary>:1
msgid ":obj:`get_depth <sklearn.tree.DecisionTreeRegressor.get_depth>`\\"
msgstr ":obj:`get_depth <sklearn.tree.DecisionTreeRegressor.get_depth>`\\"

#: of sklearn.tree._classes.BaseDecisionTree.get_depth:2
#: sklearn.tree._classes.DecisionTreeRegressor:220:<autosummary>:1
msgid "Return the depth of the decision tree."
msgstr "Devuelve la profundidad del árbol de decisión."

#: of sklearn.tree._classes.DecisionTreeRegressor:220:<autosummary>:1
msgid ":obj:`get_n_leaves <sklearn.tree.DecisionTreeRegressor.get_n_leaves>`\\"
msgstr ":obj:`get_n_leaves <sklearn.tree.DecisionTreeRegressor.get_n_leaves>`\\"

#: of sklearn.tree._classes.BaseDecisionTree.get_n_leaves:2
#: sklearn.tree._classes.DecisionTreeRegressor:220:<autosummary>:1
msgid "Return the number of leaves of the decision tree."
msgstr "Devuelve el número de hojas del árbol de decisión."

#: of sklearn.tree._classes.DecisionTreeRegressor:220:<autosummary>:1
msgid ":obj:`get_params <sklearn.tree.DecisionTreeRegressor.get_params>`\\"
msgstr ":obj:`get_params <sklearn.tree.DecisionTreeRegressor.get_params>`\\"

#: of sklearn.base.BaseEstimator.get_params:2
#: sklearn.tree._classes.DecisionTreeRegressor:220:<autosummary>:1
msgid "Get parameters for this estimator."
msgstr "Obtiene los parámetros para este estimador."

#: of sklearn.tree._classes.DecisionTreeRegressor:220:<autosummary>:1
msgid ":obj:`predict <sklearn.tree.DecisionTreeRegressor.predict>`\\"
msgstr ":obj:`predict <sklearn.tree.DecisionTreeRegressor.predict>`\\"

#: of sklearn.tree._classes.BaseDecisionTree.predict:2
#: sklearn.tree._classes.DecisionTreeRegressor:220:<autosummary>:1
msgid "Predict class or regression value for X."
msgstr "Predice la clase de regresión para X."

#: of sklearn.tree._classes.DecisionTreeRegressor:220:<autosummary>:1
msgid ":obj:`score <sklearn.tree.DecisionTreeRegressor.score>`\\"
msgstr ":obj:`score <sklearn.tree.DecisionTreeRegressor.score>`\\"

#: of sklearn.base.RegressorMixin.score:2
#: sklearn.tree._classes.DecisionTreeRegressor:220:<autosummary>:1
msgid "Return the coefficient of determination :math:`R^2` of the prediction."
msgstr "Devuelve el coeficiente de determinación :math:`R^2` de la predicción."

#: of sklearn.tree._classes.DecisionTreeRegressor:220:<autosummary>:1
msgid ":obj:`set_params <sklearn.tree.DecisionTreeRegressor.set_params>`\\"
msgstr ":obj:`set_params <sklearn.tree.DecisionTreeRegressor.set_params>`\\"

#: of sklearn.base.BaseEstimator.set_params:2
#: sklearn.tree._classes.DecisionTreeRegressor:220:<autosummary>:1
msgid "Set the parameters of this estimator."
msgstr "Establece los parámetros de este estimador."

#: of sklearn.base.RegressorMixin.score:20
#: sklearn.tree._classes.BaseDecisionTree.apply:11
#: sklearn.tree._classes.BaseDecisionTree.cost_complexity_pruning_path:12
#: sklearn.tree._classes.BaseDecisionTree.decision_path:11
#: sklearn.tree._classes.BaseDecisionTree.predict:13
#: sklearn.tree._classes.DecisionTreeRegressor.fit:10
msgid "**X**"
msgstr "**X**"

#: of
msgid "{array-like, sparse matrix} of shape (n_samples, n_features)"
msgstr "{array-like, sparse matrix} de forma (n_samples, n_features)"

#: of sklearn.tree._classes.BaseDecisionTree.apply:9
#: sklearn.tree._classes.BaseDecisionTree.decision_path:9
#: sklearn.tree._classes.BaseDecisionTree.predict:11
msgid "The input samples. Internally, it will be converted to ``dtype=np.float32`` and if a sparse matrix is provided to a sparse ``csr_matrix``."
msgstr "Las muestras de entrada. Internamente, se convertirá a ``dtype=np.float32`` y si se proporciona una matriz dispersa a una ``csr_matrix`` dispersa."

#: of sklearn.tree._classes.BaseDecisionTree.apply:15
#: sklearn.tree._classes.BaseDecisionTree.decision_path:15
#: sklearn.tree._classes.BaseDecisionTree.predict:17
#: sklearn.tree._classes.DecisionTreeRegressor.fit:23
msgid "**check_input**"
msgstr "**check_input**"

#: of
msgid "bool, default=True"
msgstr "bool, default=True"

#: of sklearn.tree._classes.BaseDecisionTree.apply:14
#: sklearn.tree._classes.BaseDecisionTree.decision_path:14
#: sklearn.tree._classes.BaseDecisionTree.predict:16
#: sklearn.tree._classes.DecisionTreeRegressor.fit:22
msgid "Allow to bypass several input checking. Don't use this parameter unless you know what you do."
msgstr "Permite eludir varias comprobaciones de entrada. No uses este parámetro a menos que sepas lo que haces."

#: of sklearn.base.BaseEstimator.get_params
#: sklearn.base.BaseEstimator.set_params sklearn.base.RegressorMixin.score
#: sklearn.tree.DecisionTreeRegressor.feature_importances_
#: sklearn.tree._classes.BaseDecisionTree.apply
#: sklearn.tree._classes.BaseDecisionTree.cost_complexity_pruning_path
#: sklearn.tree._classes.BaseDecisionTree.decision_path
#: sklearn.tree._classes.BaseDecisionTree.get_depth
#: sklearn.tree._classes.BaseDecisionTree.get_n_leaves
#: sklearn.tree._classes.BaseDecisionTree.predict
#: sklearn.tree._classes.DecisionTreeRegressor.fit
msgid "Returns"
msgstr "Devuelve"

#: of sklearn.tree._classes.BaseDecisionTree.apply:34
msgid "**X_leaves**"
msgstr "**X_leaves**"

#: of
msgid "array-like of shape (n_samples,)"
msgstr "array-like de forma (n_samples,)"

#: of sklearn.tree._classes.BaseDecisionTree.apply:20
msgid "For each datapoint x in X, return the index of the leaf x ends up in. Leaves are numbered within ``[0; self.tree_.node_count)``, possibly with gaps in the numbering."
msgstr "Para cada punto de datos x en X, devuelve el índice de la hoja en la que termina x. Las hojas se numeran dentro de ``[0; self.tree_.node_count)``, posiblemente con huecos en la numeración."

#: of sklearn.tree._classes.BaseDecisionTree.cost_complexity_pruning_path:4
msgid "See :ref:`minimal_cost_complexity_pruning` for details on the pruning process."
msgstr "Ver :ref:`minimal_cost_complexity_pruning` para más detalles sobre el proceso de poda."

#: of sklearn.tree._classes.BaseDecisionTree.cost_complexity_pruning_path:10
#: sklearn.tree._classes.DecisionTreeRegressor.fit:8
msgid "The training input samples. Internally, it will be converted to ``dtype=np.float32`` and if a sparse matrix is provided to a sparse ``csc_matrix``."
msgstr "Las muestras de entrada de entrenamiento. Internamente, se convertirán a ``dtype=np.float32`` y si se proporciona una matriz dispersa a una ``csc_matrix`` dispersa."

#: of sklearn.base.RegressorMixin.score:23
#: sklearn.tree._classes.BaseDecisionTree.cost_complexity_pruning_path:15
#: sklearn.tree._classes.BaseDecisionTree.predict:33
#: sklearn.tree._classes.DecisionTreeRegressor.fit:14
msgid "**y**"
msgstr "**y**"

#: of
msgid "array-like of shape (n_samples,) or (n_samples, n_outputs)"
msgstr "array-like de forma (n_samples,) o (n_samples, n_outputs)"

#: of sklearn.tree._classes.BaseDecisionTree.cost_complexity_pruning_path:15
msgid "The target values (class labels) as integers or strings."
msgstr "Los valores objetivo (etiquetas de clase) como enteros o cadenas."

#: of sklearn.base.RegressorMixin.score:26
#: sklearn.tree._classes.BaseDecisionTree.cost_complexity_pruning_path:22
#: sklearn.tree._classes.DecisionTreeRegressor.fit:19
msgid "**sample_weight**"
msgstr "**sample_weight**"

#: of
msgid "array-like of shape (n_samples,), default=None"
msgstr "array-like de forma (n_samples,) default=None"

#: of sklearn.tree._classes.BaseDecisionTree.cost_complexity_pruning_path:18
msgid "Sample weights. If None, then samples are equally weighted. Splits that would create child nodes with net zero or negative weight are ignored while searching for a split in each node. Splits are also ignored if they would result in any single class carrying a negative weight in either child node."
msgstr "Pesos de las muestras. Si es None, las muestras se ponderan por igual. Las separaciones que crearían nodos hijos con peso neto cero o negativo se ignoran al buscar una separación en cada nodo. Las separaciones también se ignoran si dan lugar a que una sola clase tenga un peso negativo en cualquiera de los nodos hijos."

#: of sklearn.tree._classes.BaseDecisionTree.cost_complexity_pruning_path:45
msgid "**ccp_path** : :class:`~sklearn.utils.Bunch`"
msgstr "**ccp_path** : :class:`~sklearn.utils.Bunch`"

#: of sklearn.tree._classes.BaseDecisionTree.cost_complexity_pruning_path:44
msgid "Bunch"
msgstr "Bunch"

#: of sklearn.tree._classes.BaseDecisionTree.cost_complexity_pruning_path:27
msgid "Dictionary-like object, with the following attributes."
msgstr "Objeto tipo diccionario, con los siguientes atributos."

#: of sklearn.tree._classes.BaseDecisionTree.cost_complexity_pruning_path:30
msgid "ccp_alphas"
msgstr "ccp_alphas"

#: of
msgid "ndarray"
msgstr "ndarray"

#: of sklearn.tree._classes.BaseDecisionTree.cost_complexity_pruning_path:30
msgid "Effective alphas of subtree during pruning."
msgstr "Alfas efectivas del subárbol durante la poda."

#: of sklearn.tree._classes.BaseDecisionTree.cost_complexity_pruning_path:45
msgid "impurities"
msgstr "impurezas"

#: of sklearn.tree._classes.BaseDecisionTree.cost_complexity_pruning_path:33
msgid "Sum of the impurities of the subtree leaves for the corresponding alpha value in ``ccp_alphas``."
msgstr "Suma de las impurezas de las hojas del subárbol para el valor alfa correspondiente en ``ccp_alphas``."

#: of sklearn.tree._classes.BaseDecisionTree.decision_path:32
msgid "**indicator**"
msgstr "**indicator**"

#: of
msgid "sparse matrix of shape (n_samples, n_nodes)"
msgstr "matriz dispersa de forma (n_samples, n_nodes)"

#: of sklearn.tree._classes.BaseDecisionTree.decision_path:20
msgid "Return a node indicator CSR matrix where non zero elements indicates that the samples goes through the nodes."
msgstr "Devuelve una matriz CSR indicadora de nodos donde los elementos no nulos indican que las muestras pasan por los nodos."

#: of sklearn.tree.DecisionTreeRegressor.feature_importances_:4
msgid "The importance of a feature is computed as the (normalized) total reduction of the criterion brought by that feature. It is also known as the Gini importance."
msgstr "La importancia de una característica se calcula como la reducción total (normalizada) del criterio aportado por esa característica. También se conoce como la importancia de Gini."

#: of sklearn.tree.DecisionTreeRegressor.feature_importances_:8
msgid "Warning: impurity-based feature importances can be misleading for high cardinality features (many unique values). See :func:`sklearn.inspection.permutation_importance` as an alternative."
msgstr "Advertencia: las importancias de las características basadas en la impureza pueden ser engañosas para características de alta cardinalidad (muchos valores únicos). Ver :func:`sklearn.inspection.permutation_importance` como alternativa."

#: of sklearn.tree.DecisionTreeRegressor.feature_importances_:28
msgid "**feature_importances_**"
msgstr "**feature_importances_**"

#: of sklearn.tree.DecisionTreeRegressor.feature_importances_:16
msgid "Normalized total reduction of criteria by feature (Gini importance)."
msgstr "Reducción total normalizada de criterios por característica (importancia Gini)."

#: of sklearn.tree._classes.DecisionTreeRegressor.fit:13
msgid "The target values (real numbers). Use ``dtype=np.float64`` and ``order='C'`` for maximum efficiency."
msgstr "Los valores objetivo (números reales). Utilice ``dtype=np.float64`` y ``order='C'`` para obtener la máxima eficiencia."

#: of sklearn.tree._classes.DecisionTreeRegressor.fit:17
msgid "Sample weights. If None, then samples are equally weighted. Splits that would create child nodes with net zero or negative weight are ignored while searching for a split in each node."
msgstr "Pesos de las muestras. Si es None, las muestras se ponderan por igual. Las separaciones que crearían nodos hijos con peso neto cero o negativo se ignoran al buscar una separación en cada nodo."

#: of sklearn.tree._classes.DecisionTreeRegressor.fit:29
msgid "**X_idx_sorted**"
msgstr "**X_idx_sorted**"

#: of
msgid "deprecated, default=\"deprecated\""
msgstr "obsoleto, default=\"deprecated\""

#: of sklearn.tree._classes.DecisionTreeRegressor.fit:26
msgid "This parameter is deprecated and has no effect. It will be removed in 1.1 (renaming of 0.26)."
msgstr "Este parámetro está obsoleto y no tiene ningún efecto. Se eliminará en la versión 1.1 (cambio de nombre de la versión 0.26)."

#: of sklearn.base.BaseEstimator.set_params:28
#: sklearn.tree._classes.DecisionTreeRegressor.fit:45
msgid "**self**"
msgstr "**self**"

#: of
msgid "DecisionTreeRegressor"
msgstr "DecisionTreeRegressor"

#: of sklearn.tree._classes.DecisionTreeRegressor.fit:34
msgid "Fitted estimator."
msgstr "Estimador"

#: of sklearn.tree._classes.BaseDecisionTree.get_depth:4
msgid "The depth of a tree is the maximum distance between the root and any leaf."
msgstr "La profundidad de un árbol es la distancia máxima entre la raíz y cualquier hoja."

#: of sklearn.tree._classes.BaseDecisionTree.get_depth:22
msgid "**self.tree_.max_depth**"
msgstr "**self.tree_.max_depth**"

#: of sklearn.tree._classes.BaseDecisionTree.get_depth:11
msgid "The maximum depth of the tree."
msgstr "La profundidad máxima del árbol."

#: of sklearn.tree._classes.BaseDecisionTree.get_n_leaves:20
msgid "**self.tree_.n_leaves**"
msgstr "**self.tree_.n_leaves**"

#: of sklearn.tree._classes.BaseDecisionTree.get_n_leaves:9
msgid "Number of leaves."
msgstr "Número de hojas."

#: of sklearn.base.BaseEstimator.get_params:9
msgid "**deep**"
msgstr "**deep**"

#: of sklearn.base.BaseEstimator.get_params:8
msgid "If True, will return the parameters for this estimator and contained subobjects that are estimators."
msgstr "Si es True, devolverá los parámetros para este estimador y los subobjetos contenidos que son estimadores."

#: of sklearn.base.BaseEstimator.get_params:25
msgid "**params**"
msgstr "**params**"

#: of
msgid "dict"
msgstr "dict"

#: of sklearn.base.BaseEstimator.get_params:14
msgid "Parameter names mapped to their values."
msgstr "Los nombres de los parámetros asignados a sus valores."

#: of sklearn.tree._classes.BaseDecisionTree.predict:4
msgid "For a classification model, the predicted class for each sample in X is returned. For a regression model, the predicted value based on X is returned."
msgstr "Para un modelo de clasificación, se devuelve la clase predicha para cada muestra en X. Para un modelo de regresión, se devuelve el valor predicho basado en X."

#: of sklearn.tree._classes.BaseDecisionTree.predict:22
msgid "The predicted classes, or the predict values."
msgstr "Las clases predichas, o los valores predichos."

#: of sklearn.base.RegressorMixin.score:5
msgid "The coefficient :math:`R^2` is defined as :math:`(1 - \\frac{u}{v})`, where :math:`u` is the residual sum of squares ``((y_true - y_pred) ** 2).sum()`` and :math:`v` is the total sum of squares ``((y_true - y_true.mean()) ** 2).sum()``. The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of `y`, disregarding the input features, would get a :math:`R^2` score of 0.0."
msgstr "El coeficiente :math:`R^2` se define como :math:`(1 - \\frac{u}{v})`, donde :math:`u` es la suma residual de cuadrados ``((y_true - y_pred) ** 2).sum()`` y :math:`v` es la suma total de cuadrados ``((y_true - y_true.mean()) ** 2).sum()``. La mejor puntuación posible es 1,0 y puede ser negativa (porque el modelo puede ser arbitrariamente peor). Un modelo constante que siempre predice el valor esperado de `y`, sin tener en cuenta las características de entrada, obtendría una puntuación :math:`R^2` de 0,0."

#: of
msgid "array-like of shape (n_samples, n_features)"
msgstr "array-like de forma (n_samples, n_features)"

#: of sklearn.base.RegressorMixin.score:17
msgid "Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted`` is the number of samples used in the fitting for the estimator."
msgstr "Muestras de prueba. Para algunos estimadores puede ser una matriz de núcleo precalculada o una lista de objetos genéricos con forma ``(n_samples, n_samples_fitted)``, donde ``n_samples_fitted`` es el número de muestras utilizadas en el ajuste para el estimador."

#: of sklearn.base.RegressorMixin.score:23
msgid "True values for `X`."
msgstr "Valores verdaderos para `X`."

#: of sklearn.base.RegressorMixin.score:26
msgid "Sample weights."
msgstr "Ponderaciones de la muestra."

#: of sklearn.base.RegressorMixin.score:38
msgid "**score**"
msgstr "**score**"

#: of
msgid "float"
msgstr "float"

#: of sklearn.base.RegressorMixin.score:31
msgid ":math:`R^2` of ``self.predict(X)`` wrt. `y`."
msgstr ":math:`R^2` of ``self.predict(X)`` wrt. `y`."

#: of sklearn.base.RegressorMixin.score:42
msgid "The :math:`R^2` score used when calling ``score`` on a regressor uses ``multioutput='uniform_average'`` from version 0.23 to keep consistent with default value of :func:`~sklearn.metrics.r2_score`. This influences the ``score`` method of all the multioutput regressors (except for :class:`~sklearn.multioutput.MultiOutputRegressor`)."
msgstr "La puntuación :math:`R^2` utilizada al llamar a ``score`` en un regresor utiliza ``multioutput='uniform_average'`` desde la versión 0.23 para mantener la coherencia con el valor predeterminado de :func:`~sklearn.metrics.r2_score``. Esto influye en el método ``score`` de todos los regresores de salida múltiple (excepto para :class:`~sklearn.multioutput.MultiOutputRegressor`)."

#: of sklearn.base.BaseEstimator.set_params:4
msgid "The method works on simple estimators as well as on nested objects (such as :class:`~sklearn.pipeline.Pipeline`). The latter have parameters of the form ``<component>__<parameter>`` so that it's possible to update each component of a nested object."
msgstr "El método funciona tanto en estimadores simples como en objetos anidados (como :class:`~sklearn.pipeline.Pipeline`). Estos últimos tienen parámetros de la forma ``<component>__<parameter>` para que sea posible actualizar cada componente de un objeto anidado."

#: of sklearn.base.BaseEstimator.set_params:12
msgid "**\\*\\*params**"
msgstr "**\\*\\*params**"

#: of sklearn.base.BaseEstimator.set_params:12
msgid "Estimator parameters."
msgstr "Parámetros del estimador."

#: of
msgid "estimator instance"
msgstr "instancia del estimador"

#: of sklearn.base.BaseEstimator.set_params:17
msgid "Estimator instance."
msgstr "Instancia del estimador."

#: ../modules/generated/sklearn.tree.DecisionTreeRegressor.examples:4
msgid "Examples using ``sklearn.tree.DecisionTreeRegressor``"
msgstr "Ejemplos con ``sklearn.tree.DecisionTreeRegressor``"

#: ../modules/generated/sklearn.tree.DecisionTreeRegressor.examples:15
#: ../modules/generated/sklearn.tree.DecisionTreeRegressor.examples:23
msgid ":ref:`sphx_glr_auto_examples_release_highlights_plot_release_highlights_0_24_0.py`"
msgstr ":ref:`sphx_glr_auto_examples_release_highlights_plot_release_highlights_0_24_0.py`"

#: ../modules/generated/sklearn.tree.DecisionTreeRegressor.examples:34
#: ../modules/generated/sklearn.tree.DecisionTreeRegressor.examples:42
msgid ":ref:`sphx_glr_auto_examples_release_highlights_plot_release_highlights_0_22_0.py`"
msgstr ":ref:`sphx_glr_auto_examples_release_highlights_plot_release_highlights_0_22_0.py`"

#: ../modules/generated/sklearn.tree.DecisionTreeRegressor.examples:53
#: ../modules/generated/sklearn.tree.DecisionTreeRegressor.examples:61
msgid ":ref:`sphx_glr_auto_examples_miscellaneous_plot_partial_dependence_visualization_api.py`"
msgstr ":ref:`sphx_glr_auto_examples_miscellaneous_plot_partial_dependence_visualization_api.py`"

#: ../modules/generated/sklearn.tree.DecisionTreeRegressor.examples:72
#: ../modules/generated/sklearn.tree.DecisionTreeRegressor.examples:80
msgid ":ref:`sphx_glr_auto_examples_impute_plot_iterative_imputer_variants_comparison.py`"
msgstr ":ref:`sphx_glr_auto_examples_impute_plot_iterative_imputer_variants_comparison.py`"

#~ msgid ":ref:`sphx_glr_auto_examples_preprocessing_plot_discretization.py`"
#~ msgstr ""

