msgid ""
msgstr ""
"Project-Id-Version: scikit-learn\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-03-31 12:43-0400\n"
"PO-Revision-Date: 2021-06-01 15:08\n"
"Last-Translator: \n"
"Language-Team: Spanish\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Crowdin-Project: scikit-learn\n"
"X-Crowdin-Project-ID: 450526\n"
"X-Crowdin-Language: es-ES\n"
"X-Crowdin-File: /main/doc/en/modules/generated/sklearn.datasets.make_classification.po\n"
"X-Crowdin-File-ID: 5244\n"
"Language: es_ES\n"

#: ../modules/generated/sklearn.datasets.make_classification.rst:2
msgid ":mod:`sklearn.datasets`.make_classification"
msgstr ":mod:`sklearn.datasets`.make_classification"

#: of sklearn.datasets._samples_generator.make_classification:2
msgid "Generate a random n-class classification problem."
msgstr ""

#: of sklearn.datasets._samples_generator.make_classification:4
msgid "This initially creates clusters of points normally distributed (std=1) about vertices of an ``n_informative``-dimensional hypercube with sides of length ``2*class_sep`` and assigns an equal number of clusters to each class. It introduces interdependence between these features and adds various types of further noise to the data."
msgstr ""

#: of sklearn.datasets._samples_generator.make_classification:10
msgid "Without shuffling, ``X`` horizontally stacks features in the following order: the primary ``n_informative`` features, followed by ``n_redundant`` linear combinations of the informative features, followed by ``n_repeated`` duplicates, drawn randomly with replacement from the informative and redundant features. The remaining features are filled with random noise. Thus, without shuffling, all useful features are contained in the columns ``X[:, :n_informative + n_redundant + n_repeated]``."
msgstr ""

#: of sklearn.datasets._samples_generator.make_classification:18
msgid "Read more in the :ref:`User Guide <sample_generators>`."
msgstr "Leer más en el :ref:`Manual de Usuario <sample_generators>`."

#: of sklearn.datasets._samples_generator.make_classification
msgid "Parameters"
msgstr "Parámetros"

#: of sklearn.datasets._samples_generator.make_classification:23
msgid "**n_samples**"
msgstr "**n_samples**"

#: of
msgid "int, default=100"
msgstr "int, default=100"

#: of sklearn.datasets._samples_generator.make_classification:23
msgid "The number of samples."
msgstr ""

#: of sklearn.datasets._samples_generator.make_classification:30
msgid "**n_features**"
msgstr ""

#: of
msgid "int, default=20"
msgstr "int, default=20"

#: of sklearn.datasets._samples_generator.make_classification:26
msgid "The total number of features. These comprise ``n_informative`` informative features, ``n_redundant`` redundant features, ``n_repeated`` duplicated features and ``n_features-n_informative-n_redundant-n_repeated`` useless features drawn at random."
msgstr ""

#: of sklearn.datasets._samples_generator.make_classification:39
msgid "**n_informative**"
msgstr ""

#: of
msgid "int, default=2"
msgstr "int, default=2"

#: of sklearn.datasets._samples_generator.make_classification:33
msgid "The number of informative features. Each class is composed of a number of gaussian clusters each located around the vertices of a hypercube in a subspace of dimension ``n_informative``. For each cluster, informative features are drawn independently from  N(0, 1) and then randomly linearly combined within each cluster in order to add covariance. The clusters are then placed on the vertices of the hypercube."
msgstr ""

#: of sklearn.datasets._samples_generator.make_classification:43
msgid "**n_redundant**"
msgstr ""

#: of sklearn.datasets._samples_generator.make_classification:42
msgid "The number of redundant features. These features are generated as random linear combinations of the informative features."
msgstr ""

#: of sklearn.datasets._samples_generator.make_classification:47
msgid "**n_repeated**"
msgstr ""

#: of
msgid "int, default=0"
msgstr "int, default=0"

#: of sklearn.datasets._samples_generator.make_classification:46
msgid "The number of duplicated features, drawn randomly from the informative and the redundant features."
msgstr ""

#: of sklearn.datasets._samples_generator.make_classification:50
msgid "**n_classes**"
msgstr ""

#: of sklearn.datasets._samples_generator.make_classification:50
msgid "The number of classes (or labels) of the classification problem."
msgstr ""

#: of sklearn.datasets._samples_generator.make_classification:53
msgid "**n_clusters_per_class**"
msgstr ""

#: of sklearn.datasets._samples_generator.make_classification:53
msgid "The number of clusters per class."
msgstr ""

#: of sklearn.datasets._samples_generator.make_classification:61
msgid "**weights**"
msgstr ""

#: of
msgid "array-like of shape (n_classes,) or (n_classes - 1,),              default=None"
msgstr ""

#: of sklearn.datasets._samples_generator.make_classification:56
msgid "The proportions of samples assigned to each class. If None, then classes are balanced. Note that if ``len(weights) == n_classes - 1``, then the last class weight is automatically inferred. More than ``n_samples`` samples may be returned if the sum of ``weights`` exceeds 1. Note that the actual class proportions will not exactly match ``weights`` when ``flip_y`` isn't 0."
msgstr ""

#: of sklearn.datasets._samples_generator.make_classification:67
msgid "**flip_y**"
msgstr ""

#: of
msgid "float, default=0.01"
msgstr "float, default=0.01"

#: of sklearn.datasets._samples_generator.make_classification:64
msgid "The fraction of samples whose class is assigned randomly. Larger values introduce noise in the labels and make the classification task harder. Note that the default setting flip_y > 0 might lead to less than ``n_classes`` in y in some cases."
msgstr ""

#: of sklearn.datasets._samples_generator.make_classification:71
msgid "**class_sep**"
msgstr ""

#: of
msgid "float, default=1.0"
msgstr "float, default=1.0"

#: of sklearn.datasets._samples_generator.make_classification:70
msgid "The factor multiplying the hypercube size.  Larger values spread out the clusters/classes and make the classification task easier."
msgstr ""

#: of sklearn.datasets._samples_generator.make_classification:75
msgid "**hypercube**"
msgstr ""

#: of
msgid "bool, default=True"
msgstr "bool, default=True"

#: of sklearn.datasets._samples_generator.make_classification:74
msgid "If True, the clusters are put on the vertices of a hypercube. If False, the clusters are put on the vertices of a random polytope."
msgstr ""

#: of sklearn.datasets._samples_generator.make_classification:79
msgid "**shift**"
msgstr ""

#: of
msgid "float, ndarray of shape (n_features,) or None, default=0.0"
msgstr ""

#: of sklearn.datasets._samples_generator.make_classification:78
msgid "Shift features by the specified value. If None, then features are shifted by a random value drawn in [-class_sep, class_sep]."
msgstr ""

#: of sklearn.datasets._samples_generator.make_classification:84
msgid "**scale**"
msgstr ""

#: of
msgid "float, ndarray of shape (n_features,) or None, default=1.0"
msgstr ""

#: of sklearn.datasets._samples_generator.make_classification:82
msgid "Multiply features by the specified value. If None, then features are scaled by a random value drawn in [1, 100]. Note that scaling happens after shifting."
msgstr ""

#: of sklearn.datasets._samples_generator.make_classification:87
msgid "**shuffle**"
msgstr ""

#: of sklearn.datasets._samples_generator.make_classification:87
msgid "Shuffle the samples and the features."
msgstr ""

#: of sklearn.datasets._samples_generator.make_classification:92
msgid "**random_state**"
msgstr ""

#: of
msgid "int, RandomState instance or None, default=None"
msgstr ""

#: of sklearn.datasets._samples_generator.make_classification:90
msgid "Determines random number generation for dataset creation. Pass an int for reproducible output across multiple function calls. See :term:`Glossary <random_state>`."
msgstr ""

#: of sklearn.datasets._samples_generator.make_classification
msgid "Returns"
msgstr "Devuelve"

#: of sklearn.datasets._samples_generator.make_classification:97
msgid "**X**"
msgstr ""

#: of
msgid "ndarray of shape (n_samples, n_features)"
msgstr ""

#: of sklearn.datasets._samples_generator.make_classification:97
msgid "The generated samples."
msgstr "Las muestras generadas."

#: of sklearn.datasets._samples_generator.make_classification:106
msgid "**y**"
msgstr ""

#: of
msgid "ndarray of shape (n_samples,)"
msgstr "ndarray de forma (n_samples,)"

#: of sklearn.datasets._samples_generator.make_classification:100
msgid "The integer labels for class membership of each sample."
msgstr ""

#: of sklearn.datasets._samples_generator.make_classification:111
msgid ":obj:`make_blobs`"
msgstr ":obj:`make_blobs`"

#: of sklearn.datasets._samples_generator.make_classification:112
msgid "Simplified variant."
msgstr ""

#: of sklearn.datasets._samples_generator.make_classification:113
msgid ":obj:`make_multilabel_classification`"
msgstr ":obj:`make_multilabel_classification`"

#: of sklearn.datasets._samples_generator.make_classification:114
msgid "Unrelated generator for multilabel tasks."
msgstr ""

#: of sklearn.datasets._samples_generator.make_classification:118
msgid "Notes"
msgstr "Notas"

#: of sklearn.datasets._samples_generator.make_classification:119
msgid "The algorithm is adapted from Guyon [1] and was designed to generate the \"Madelon\" dataset."
msgstr ""

#: of sklearn.datasets._samples_generator.make_classification:123
msgid "References"
msgstr "Referencias"

#: of sklearn.datasets._samples_generator.make_classification:124
msgid "I. Guyon, \"Design of experiments for the NIPS 2003 variable selection benchmark\", 2003."
msgstr "I. Guyon, \"Design of experiments for the NIPS 2003 variable selection benchmark\", 2003."

#: of sklearn.datasets._samples_generator.make_classification:129
msgid "[R36a464cc3878-1]_"
msgstr "[R36a464cc3878-1]_"

#: ../modules/generated/sklearn.datasets.make_classification.examples:4
msgid "Examples using ``sklearn.datasets.make_classification``"
msgstr "Ejemplos usando ``sklearn.datasets.make_classification``"

#: ../modules/generated/sklearn.datasets.make_classification.examples:15
#: ../modules/generated/sklearn.datasets.make_classification.examples:23
msgid ":ref:`sphx_glr_auto_examples_release_highlights_plot_release_highlights_0_24_0.py`"
msgstr ":ref:`sphx_glr_auto_examples_release_highlights_plot_release_highlights_0_24_0.py`"

#: ../modules/generated/sklearn.datasets.make_classification.examples:34
#: ../modules/generated/sklearn.datasets.make_classification.examples:42
msgid ":ref:`sphx_glr_auto_examples_release_highlights_plot_release_highlights_0_22_0.py`"
msgstr ":ref:`sphx_glr_auto_examples_release_highlights_plot_release_highlights_0_22_0.py`"

#: ../modules/generated/sklearn.datasets.make_classification.examples:53
#: ../modules/generated/sklearn.datasets.make_classification.examples:61
msgid ":ref:`sphx_glr_auto_examples_model_selection_plot_successive_halving_iterations.py`"
msgstr ":ref:`sphx_glr_auto_examples_model_selection_plot_successive_halving_iterations.py`"

#: ../modules/generated/sklearn.datasets.make_classification.examples:72
#: ../modules/generated/sklearn.datasets.make_classification.examples:80
msgid ":ref:`sphx_glr_auto_examples_model_selection_plot_successive_halving_heatmap.py`"
msgstr ":ref:`sphx_glr_auto_examples_model_selection_plot_successive_halving_heatmap.py`"

#~ msgid ":ref:`sphx_glr_auto_examples_feature_selection_plot_feature_selection_pipeline.py`"
#~ msgstr ""

#~ msgid ":ref:`sphx_glr_auto_examples_feature_selection_plot_rfe_with_cross_validation.py`"
#~ msgstr ""

#~ msgid ":ref:`sphx_glr_auto_examples_model_selection_plot_det.py`"
#~ msgstr ""

#~ msgid ":ref:`sphx_glr_auto_examples_neighbors_plot_nca_illustration.py`"
#~ msgstr ""

#~ msgid ":ref:`sphx_glr_auto_examples_neural_networks_plot_mlp_alpha.py`"
#~ msgstr ""

#~ msgid ":ref:`sphx_glr_auto_examples_preprocessing_plot_discretization_classification.py`"
#~ msgstr ""

#~ msgid ":ref:`sphx_glr_auto_examples_svm_plot_svm_scale_c.py`"
#~ msgstr ""

