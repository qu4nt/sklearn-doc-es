msgid ""
msgstr ""
"Project-Id-Version: scikit-learn\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-03-31 11:24-0400\n"
"PO-Revision-Date: 2021-05-27 13:15\n"
"Last-Translator: \n"
"Language-Team: Spanish\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Crowdin-Project: scikit-learn\n"
"X-Crowdin-Project-ID: 450526\n"
"X-Crowdin-Language: es-ES\n"
"X-Crowdin-File: /main/doc/en/modules/generated/sklearn.linear_model.SGDRegressor.po\n"
"X-Crowdin-File-ID: 5776\n"
"Language: es_ES\n"

#: ../modules/generated/sklearn.linear_model.SGDRegressor.rst:2
msgid ":mod:`sklearn.linear_model`.SGDRegressor"
msgstr ":mod:`sklearn.linear_model`.SGDRegressor"

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:2
msgid "Linear model fitted by minimizing a regularized empirical loss with SGD"
msgstr "Modelo lineal ajustado minimizando una pérdida empírica regularizada con SGD"

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:4
msgid "SGD stands for Stochastic Gradient Descent: the gradient of the loss is estimated each sample at a time and the model is updated along the way with a decreasing strength schedule (aka learning rate)."
msgstr "SGD son las siglas de Stochastic Gradient Descent: el gradiente de la pérdida se estima cada muestra a la vez y el modelo se actualiza por el camino con un programa de fuerza decreciente (también conocido como tasa de aprendizaje)."

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:8
msgid "The regularizer is a penalty added to the loss function that shrinks model parameters towards the zero vector using either the squared euclidean norm L2 or the absolute norm L1 or a combination of both (Elastic Net). If the parameter update crosses the 0.0 value because of the regularizer, the update is truncated to 0.0 to allow for learning sparse models and achieve online feature selection."
msgstr "El regularizador es una penalización añadida a la función de pérdida que encoge los parámetros del modelo hacia el vector cero utilizando la norma euclidiana cuadrada L2 o la norma absoluta L1 o una combinación de ambas (red elástica). Si la actualización de los parámetros cruza el valor 0.0 debido al regularizador, la actualización se trunca a 0.0 para permitir el aprendizaje de modelos dispersos y lograr la selección de características en línea."

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:15
msgid "This implementation works with data represented as dense numpy arrays of floating point values for the features."
msgstr "Esta implementación funciona con datos representados como arreglo de numpy denso de valores de punto flotante para las características."

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:18
msgid "Read more in the :ref:`User Guide <sgd>`."
msgstr "Más información en el :ref:`Manual de usuario <sgd>`."

#: of sklearn.base.BaseEstimator.get_params sklearn.base.RegressorMixin.score
#: sklearn.linear_model._stochastic_gradient.BaseSGD.set_params
#: sklearn.linear_model._stochastic_gradient.BaseSGDRegressor.fit
#: sklearn.linear_model._stochastic_gradient.BaseSGDRegressor.partial_fit
#: sklearn.linear_model._stochastic_gradient.BaseSGDRegressor.predict
#: sklearn.linear_model._stochastic_gradient.SGDRegressor
msgid "Parameters"
msgstr "Parámetros"

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:35
msgid "**loss**"
msgstr "**loss**"

#: of
msgid "str, default='squared_loss'"
msgstr "str, default='squared_loss'"

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:23
msgid "The loss function to be used. The possible values are 'squared_loss', 'huber', 'epsilon_insensitive', or 'squared_epsilon_insensitive'"
msgstr "La función de pérdida que se utilizará. Los valores posibles son 'squared_loss', 'huber', 'epsilon_insensitive', o 'squared_epsilon_insensitive'"

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:26
msgid "The 'squared_loss' refers to the ordinary least squares fit. 'huber' modifies 'squared_loss' to focus less on getting outliers correct by switching from squared to linear loss past a distance of epsilon. 'epsilon_insensitive' ignores errors less than epsilon and is linear past that; this is the loss function used in SVR. 'squared_epsilon_insensitive' is the same but becomes squared loss past a tolerance of epsilon."
msgstr "La 'squared_loss' se refiere al ajuste ordinario por mínimos cuadrados. 'huber' modifica 'squared_loss' para centrarse menos en la corrección de los valores atípicos, pasando de la pérdida cuadrada a la lineal a partir de una distancia de épsilon. 'epsilon_insensible' ignora los errores menores que epsilon y es lineal más allá de eso; esta es la función de pérdida utilizada en SVR. 'squared_epsilon_insensitive' es lo mismo pero se convierte en pérdida cuadrada más allá de una tolerancia de épsilon."

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:34
msgid "More details about the losses formulas can be found in the :ref:`User Guide <sgd_mathematical_formulation>`."
msgstr "Puedes encontrar más detalles sobre las fórmulas de pérdidas en la :ref:`Manual de usuario <sgd_mathematical_formulation>`."

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:41
msgid "**penalty**"
msgstr "**penalty**"

#: of
msgid "{'l2', 'l1', 'elasticnet'}, default='l2'"
msgstr "{'l2', 'l1', 'elasticnet'}, default='l2'"

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:38
msgid "The penalty (aka regularization term) to be used. Defaults to 'l2' which is the standard regularizer for linear SVM models. 'l1' and 'elasticnet' might bring sparsity to the model (feature selection) not achievable with 'l2'."
msgstr "La penalización (término de regularización) que se utilizará. Por defecto es 'l2' que es el regularizador estándar para los modelos SVM lineales. 'l1' y 'elasticnet' pueden aportar una dispersión al modelo (selección de características) que no se consigue con 'l2'."

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:47
msgid "**alpha**"
msgstr "**alpha**"

#: of
msgid "float, default=0.0001"
msgstr "float, default=0.0001"

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:44
msgid "Constant that multiplies the regularization term. The higher the value, the stronger the regularization. Also used to compute the learning rate when set to `learning_rate` is set to 'optimal'."
msgstr "Constante que multiplica el término de regularización. Cuanto mayor sea el valor, más fuerte será la regularización. También se utiliza para calcular la tasa de aprendizaje cuando se establece en `learning_rate` se establece en 'optimal'."

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:52
msgid "**l1_ratio**"
msgstr "**l1_ratio**"

#: of
msgid "float, default=0.15"
msgstr "float, default=0.15"

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:50
msgid "The Elastic Net mixing parameter, with 0 <= l1_ratio <= 1. l1_ratio=0 corresponds to L2 penalty, l1_ratio=1 to L1. Only used if `penalty` is 'elasticnet'."
msgstr "El parámetro de mezcla de la red elástica, con 0 <= l1_ratio <= 1. l1_ratio=0 corresponde a la penalización L2, l1_ratio=1 a la L1. Sólo se utiliza si `penalty` es 'elasticnet'."

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:56
msgid "**fit_intercept**"
msgstr "**fit_intercept**"

#: of
msgid "bool, default=True"
msgstr "bool, default=True"

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:55
msgid "Whether the intercept should be estimated or not. If False, the data is assumed to be already centered."
msgstr "Si el intercepto debe ser estimado o no. Si es False, se asume que los datos ya están centrados."

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:63
msgid "**max_iter**"
msgstr "**max_iter**"

#: of
msgid "int, default=1000"
msgstr "int, default=1000"

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:59
msgid "The maximum number of passes over the training data (aka epochs). It only impacts the behavior in the ``fit`` method, and not the :meth:`partial_fit` method."
msgstr "El número máximo de pasadas sobre los datos de entrenamiento (también conocido como épocas o epochs). Sólo afecta al comportamiento del método ``fit``, y no al método :meth:`partial_fit`."

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:70
msgid "**tol**"
msgstr "**tol**"

#: of
msgid "float, default=1e-3"
msgstr "flotante, default=1e-3"

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:66
msgid "The stopping criterion. If it is not None, training will stop when (loss > best_loss - tol) for ``n_iter_no_change`` consecutive epochs."
msgstr "El criterio de parada. Si no es None, el entrenamiento se detendrá cuando (loss > best_loss - tol) para ``n_iter_no_change`` épocas consecutivas."

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:73
msgid "**shuffle**"
msgstr "**shuffle**"

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:73
msgid "Whether or not the training data should be shuffled after each epoch."
msgstr "Si los datos de entrenamiento deben ser aleatorizados o no después de cada época."

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:76
msgid "**verbose**"
msgstr "**verbose**"

#: of
msgid "int, default=0"
msgstr "int, default=0"

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:76
msgid "The verbosity level."
msgstr "Nivel de verbosidad."

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:84
msgid "**epsilon**"
msgstr "**epsilon**"

#: of
msgid "float, default=0.1"
msgstr "float, default=0.1"

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:79
msgid "Epsilon in the epsilon-insensitive loss functions; only if `loss` is 'huber', 'epsilon_insensitive', or 'squared_epsilon_insensitive'. For 'huber', determines the threshold at which it becomes less important to get the prediction exactly right. For epsilon-insensitive, any differences between the current prediction and the correct label are ignored if they are less than this threshold."
msgstr "Epsilon en las funciones de pérdida insensibles a épsilon; sólo si `loss` es 'huber', 'epsilon_insensitive', o 'squared_epsilon_insensitive'. En el caso de 'huber', determina el umbral a partir del cual es menos importante acertar la predicción. En el caso de insensible a épsilon, cualquier diferencia entre la predicción actual y la etiqueta correcta se ignora si es menor que este umbral."

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:89
msgid "**random_state**"
msgstr "**random_state**"

#: of
msgid "int, RandomState instance, default=None"
msgstr "int, RandomState instance, default=None"

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:87
msgid "Used for shuffling the data, when ``shuffle`` is set to ``True``. Pass an int for reproducible output across multiple function calls. See :term:`Glossary <random_state>`."
msgstr "Se utiliza para barajar los datos, cuando ``shuffle`` se establece en ``True``. Pase un int para una salida reproducible a través de múltiples llamadas a la función. Consulta :term:`Glosario <random_state>`."

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:104
msgid "**learning_rate**"
msgstr "**learning_rate**"

#: of
msgid "string, default='invscaling'"
msgstr "string, default='invscaling'"

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:92
msgid "The learning rate schedule:"
msgstr "El programa de la tasa de aprendizaje:"

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:94
msgid "'constant': `eta = eta0`"
msgstr "'constant': `eta = eta0`"

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:95
msgid "'optimal': `eta = 1.0 / (alpha * (t + t0))` where t0 is chosen by a heuristic proposed by Leon Bottou."
msgstr "'optimal': `eta = 1.0 / (alpha * (t + t0))` donde t0 se elige mediante una heurística propuesta por Leon Bottou."

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:97
msgid "'invscaling': `eta = eta0 / pow(t, power_t)`"
msgstr "'invscaling': `eta = eta0 / pow(t, power_t)`"

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:98
msgid "'adaptive': eta = eta0, as long as the training keeps decreasing. Each time n_iter_no_change consecutive epochs fail to decrease the training loss by tol or fail to increase validation score by tol if early_stopping is True, the current learning rate is divided by 5."
msgstr "'adaptive': eta = eta0, siempre que el entrenamiento siga disminuyendo. Cada vez que n_iter_no_change consecutivo no consigue disminuir la pérdida asociada al entrenamiento en tol o no consigue aumentar la puntuación de validación en tol si early_stopping es True, la tasa de aprendizaje actual se divide por 5."

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:103
msgid "Added 'adaptive' option"
msgstr "Added 'adaptive' option"

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:108
msgid "**eta0**"
msgstr "**eta0**"

#: of
msgid "double, default=0.01"
msgstr "double, default=0.01"

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:107
msgid "The initial learning rate for the 'constant', 'invscaling' or 'adaptive' schedules. The default value is 0.01."
msgstr "La tasa de aprendizaje inicial para las programaciones 'constant', 'invscaling' o 'adaptative'. El valor por defecto es 0.01."

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:111
msgid "**power_t**"
msgstr "**power_t**"

#: of
msgid "double, default=0.25"
msgstr "double, default=0.25"

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:111
msgid "The exponent for inverse scaling learning rate."
msgstr "El exponente de la tasa de aprendizaje de escala inversa."

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:122
msgid "**early_stopping**"
msgstr "**early_stopping**"

#: of
msgid "bool, default=False"
msgstr "bool, default=False"

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:114
msgid "Whether to use early stopping to terminate training when validation score is not improving. If set to True, it will automatically set aside a fraction of training data as validation and terminate training when validation score returned by the `score` method is not improving by at least `tol` for `n_iter_no_change` consecutive epochs."
msgstr "Si se utiliza la parada temprana para terminar el entrenamiento cuando la puntuación de validación no está mejorando. Si se establece como True, se apartará automáticamente una fracción de los datos de entrenamiento como validación y se terminará el entrenamiento cuando la puntuación de validación devuelta por el método `score` no mejore en al menos `tol` durante `n_iter_no_change` épocas consecutivas."

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:121
msgid "Added 'early_stopping' option"
msgstr "Opción 'early_stopping' añadida"

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:130
msgid "**validation_fraction**"
msgstr "**validation_fraction**"

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:125
msgid "The proportion of training data to set aside as validation set for early stopping. Must be between 0 and 1. Only used if `early_stopping` is True."
msgstr "La proporción de los datos de entrenamiento que se establecen como conjunto de validación para la parada anticipada. Debe estar entre 0 y 1. Sólo se utiliza si `early_stopping` es True."

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:129
msgid "Added 'validation_fraction' option"
msgstr "Opción 'validation_fraction' añadida"

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:136
msgid "**n_iter_no_change**"
msgstr "**n_iter_no_change**"

#: of
msgid "int, default=5"
msgstr "int, default=5"

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:133
msgid "Number of iterations with no improvement to wait before early stopping."
msgstr "Número de iteraciones sin mejora que hay que esperar antes de la parada anticipada."

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:135
msgid "Added 'n_iter_no_change' option"
msgstr "Opción 'n_iter_no_change' añadida"

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:149
msgid "**warm_start**"
msgstr "**warm_start**"

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:139
msgid "When set to True, reuse the solution of the previous call to fit as initialization, otherwise, just erase the previous solution. See :term:`the Glossary <warm_start>`."
msgstr "Cuando se establece a True, reutiliza la solución de la llamada anterior para ajustar como inicialización, de lo contrario, solamente borrará la solución anterior. Ver :term:`Glossary <warm_start>`."

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:143
msgid "Repeatedly calling fit or partial_fit when warm_start is True can result in a different solution than when calling fit a single time because of the way the data is shuffled. If a dynamic learning rate is used, the learning rate is adapted depending on the number of samples already seen. Calling ``fit`` resets this counter, while ``partial_fit``  will result in increasing the existing counter."
msgstr "Llamar repetidamente a fit o partial_fit cuando warm_start es True puede dar lugar a una solución diferente que cuando se llama a fit una sola vez debido a la forma en que se barajan los datos. Si se utiliza una tasa de aprendizaje dinámico, la tasa de aprendizaje se adapta en función del número de muestras ya vistas. Llamar a ``fit`` reinicia este contador, mientras que ``partial_fit`` resultará en el aumento del contador existente."

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:159
msgid "**average**"
msgstr "**average**"

#: of
msgid "bool or int, default=False"
msgstr "bool or int, default=False"

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:152
msgid "When set to True, computes the averaged SGD weights accross all updates and stores the result in the ``coef_`` attribute. If set to an int greater than 1, averaging will begin once the total number of samples seen reaches `average`. So ``average=10`` will begin averaging after seeing 10 samples."
msgstr "Si se establece como True, calcula el promedio de los ponderados SGD en todas las actualizaciones y almacena el resultado en el atributo ``coef_``. Si se establece como un int mayor que 1, el promedio comenzará una vez que el número total de muestras vistas alcance el `average`. Así, ``average=10`` se empieza a promediar después de ver 10 muestras."

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor
msgid "Attributes"
msgstr "Atributos"

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:164
msgid "**coef_**"
msgstr "**coef_**"

#: of
msgid "ndarray of shape (n_features,)"
msgstr "ndarray of shape (n_features,)"

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:164
msgid "Weights assigned to the features."
msgstr "Ponderaciones asignadas a las características."

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:167
msgid "**intercept_**"
msgstr "**intercept_**"

#: of
msgid "ndarray of shape (1,)"
msgstr "ndarray of shape (1,)"

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:167
msgid "The intercept term."
msgstr "Término de intercepción."

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:175
msgid "**average_coef_**"
msgstr "**average_coef_**"

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:170
msgid "Averaged weights assigned to the features. Only available if ``average=True``."
msgstr "Pesos promediados asignados a las características. Sólo está disponible si ``average=True``."

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:173
msgid "Attribute ``average_coef_`` was deprecated in version 0.23 and will be removed in 1.0 (renaming of 0.25)."
msgstr "El atributo ``average_coef_`` quedó obsoleto en la versión 0.23 y se eliminará en la 1.0 (cambio de nombre de la 0.25)."

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:182
msgid "**average_intercept_**"
msgstr "**average_intercept_**"

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:178
msgid "The averaged intercept term. Only available if ``average=True``."
msgstr "El término de intercepción promediado. Sólo está disponible si ``average=True``."

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:180
msgid "Attribute ``average_intercept_`` was deprecated in version 0.23 and will be removed in 1.0 (renaming of 0.25)."
msgstr "El atributo ``average_intercept_`` quedó obsoleto en la versión 0.23 y se eliminará en la 1.0 (cambio de nombre de la 0.25)."

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:185
msgid "**n_iter_**"
msgstr "**n_iter_**"

#: of
msgid "int"
msgstr "int"

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:185
msgid "The actual number of iterations before reaching the stopping criterion."
msgstr "El número real de iteraciones antes de alcanzar el criterio de parada."

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:192
msgid "**t_**"
msgstr "**t_**"

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:188
msgid "Number of weight updates performed during training. Same as ``(n_iter_ * n_samples)``."
msgstr "Número de actualizaciones de ponderación realizadas durante el entrenamiento. Igual que``(n_iter_ * n_samples)``."

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:197
msgid ":obj:`Ridge`, :obj:`ElasticNet`, :obj:`Lasso`, :obj:`sklearn.svm.SVR`"
msgstr ":obj:`Ridge`, :obj:`ElasticNet`, :obj:`Lasso`, :obj:`sklearn.svm.SVR`"

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:203
msgid "Examples"
msgstr "Ejemplos"

#: of sklearn.linear_model._stochastic_gradient.SGDRegressor:220
msgid "Methods"
msgstr "Métodos"

#: of
#: sklearn.linear_model._stochastic_gradient.SGDRegressor:231:<autosummary>:1
msgid ":obj:`densify <sklearn.linear_model.SGDRegressor.densify>`\\"
msgstr ":obj:`densify <sklearn.linear_model.SGDRegressor.densify>`\\"

#: of sklearn.linear_model._base.SparseCoefMixin.densify:2
#: sklearn.linear_model._stochastic_gradient.SGDRegressor:231:<autosummary>:1
msgid "Convert coefficient matrix to dense array format."
msgstr "Convierte la matriz de coeficientes en formato de arreglo denso."

#: of
#: sklearn.linear_model._stochastic_gradient.SGDRegressor:231:<autosummary>:1
msgid ":obj:`fit <sklearn.linear_model.SGDRegressor.fit>`\\"
msgstr ":obj:`fit <sklearn.linear_model.SGDRegressor.fit>`\\"

#: of sklearn.linear_model._stochastic_gradient.BaseSGDRegressor.fit:2
#: sklearn.linear_model._stochastic_gradient.SGDRegressor:231:<autosummary>:1
msgid "Fit linear model with Stochastic Gradient Descent."
msgstr "Ajustar el modelo lineal con el Descenso Gradiente Estocástico."

#: of
#: sklearn.linear_model._stochastic_gradient.SGDRegressor:231:<autosummary>:1
msgid ":obj:`get_params <sklearn.linear_model.SGDRegressor.get_params>`\\"
msgstr ":obj:`get_params <sklearn.linear_model.SGDRegressor.get_params>`\\"

#: of sklearn.base.BaseEstimator.get_params:2
#: sklearn.linear_model._stochastic_gradient.SGDRegressor:231:<autosummary>:1
msgid "Get parameters for this estimator."
msgstr "Obtiene los parámetros para este estimador."

#: of
#: sklearn.linear_model._stochastic_gradient.SGDRegressor:231:<autosummary>:1
msgid ":obj:`partial_fit <sklearn.linear_model.SGDRegressor.partial_fit>`\\"
msgstr ":obj:`partial_fit <sklearn.linear_model.SGDRegressor.partial_fit>`\\"

#: of sklearn.linear_model._stochastic_gradient.BaseSGDRegressor.partial_fit:2
#: sklearn.linear_model._stochastic_gradient.SGDRegressor:231:<autosummary>:1
msgid "Perform one epoch of stochastic gradient descent on given samples."
msgstr "Realiza una época de descenso de gradiente estocástico en las muestras dadas."

#: of
#: sklearn.linear_model._stochastic_gradient.SGDRegressor:231:<autosummary>:1
msgid ":obj:`predict <sklearn.linear_model.SGDRegressor.predict>`\\"
msgstr ":obj:`predict <sklearn.linear_model.SGDRegressor.predict>`\\"

#: of sklearn.linear_model._stochastic_gradient.BaseSGDRegressor.predict:2
#: sklearn.linear_model._stochastic_gradient.SGDRegressor:231:<autosummary>:1
msgid "Predict using the linear model"
msgstr "Predice utilizando el modelo lineal"

#: of
#: sklearn.linear_model._stochastic_gradient.SGDRegressor:231:<autosummary>:1
msgid ":obj:`score <sklearn.linear_model.SGDRegressor.score>`\\"
msgstr ":obj:`score <sklearn.linear_model.SGDRegressor.score>`\\"

#: of sklearn.base.RegressorMixin.score:2
#: sklearn.linear_model._stochastic_gradient.SGDRegressor:231:<autosummary>:1
msgid "Return the coefficient of determination :math:`R^2` of the prediction."
msgstr "Devuelve el coeficiente de determinación :math:`R^2` de la predicción."

#: of
#: sklearn.linear_model._stochastic_gradient.SGDRegressor:231:<autosummary>:1
msgid ":obj:`set_params <sklearn.linear_model.SGDRegressor.set_params>`\\"
msgstr ":obj:`set_params <sklearn.linear_model.SGDRegressor.set_params>`\\"

#: of sklearn.linear_model._stochastic_gradient.BaseSGD.set_params:2
#: sklearn.linear_model._stochastic_gradient.SGDRegressor:231:<autosummary>:1
msgid "Set and validate the parameters of estimator."
msgstr "Establecer y validar los parámetros del estimador."

#: of
#: sklearn.linear_model._stochastic_gradient.SGDRegressor:231:<autosummary>:1
msgid ":obj:`sparsify <sklearn.linear_model.SGDRegressor.sparsify>`\\"
msgstr ":obj:`sparsify <sklearn.linear_model.SGDRegressor.sparsify>`\\"

#: of sklearn.linear_model._base.SparseCoefMixin.sparsify:2
#: sklearn.linear_model._stochastic_gradient.SGDRegressor:231:<autosummary>:1
msgid "Convert coefficient matrix to sparse format."
msgstr "Convierte la matriz de coeficientes en formato disperso."

#: of sklearn.linear_model._base.SparseCoefMixin.densify:4
msgid "Converts the ``coef_`` member (back) to a numpy.ndarray. This is the default format of ``coef_`` and is required for fitting, so calling this method is only required on models that have previously been sparsified; otherwise, it is a no-op."
msgstr "Convierte el miembro ``coef_`` (de vuelta) en un numpy.ndarray. Este es el formato por defecto de ``coef_`` y se requiere para el ajuste, por lo que invocar este método sólo es necesario en los modelos que han sido previamente dispersados (sparsified); de lo contrario, es un no-op."

#: of sklearn.base.BaseEstimator.get_params sklearn.base.RegressorMixin.score
#: sklearn.linear_model._base.SparseCoefMixin.densify
#: sklearn.linear_model._base.SparseCoefMixin.sparsify
#: sklearn.linear_model._stochastic_gradient.BaseSGD.set_params
#: sklearn.linear_model._stochastic_gradient.BaseSGDRegressor.fit
#: sklearn.linear_model._stochastic_gradient.BaseSGDRegressor.partial_fit
#: sklearn.linear_model._stochastic_gradient.BaseSGDRegressor.predict
msgid "Returns"
msgstr "Devuelve"

#: of sklearn.linear_model._base.SparseCoefMixin.densify:24
#: sklearn.linear_model._base.SparseCoefMixin.sparsify:21
msgid "self"
msgstr "self"

#: of sklearn.linear_model._base.SparseCoefMixin.densify:13
#: sklearn.linear_model._base.SparseCoefMixin.sparsify:14
msgid "Fitted estimator."
msgstr "Estimador ajustado."

#: of sklearn.base.RegressorMixin.score:20
#: sklearn.linear_model._stochastic_gradient.BaseSGDRegressor.fit:8
#: sklearn.linear_model._stochastic_gradient.BaseSGDRegressor.partial_fit:12
#: sklearn.linear_model._stochastic_gradient.BaseSGDRegressor.predict:8
msgid "**X**"
msgstr "**X**"

#: of
msgid "{array-like, sparse matrix}, shape (n_samples, n_features)"
msgstr "{array-like, sparse matrix}, shape (n_samples, n_features)"

#: of sklearn.linear_model._stochastic_gradient.BaseSGDRegressor.fit:8
msgid "Training data"
msgstr "Datos de entrenamiento"

#: of sklearn.base.RegressorMixin.score:23
#: sklearn.linear_model._stochastic_gradient.BaseSGDRegressor.fit:11
#: sklearn.linear_model._stochastic_gradient.BaseSGDRegressor.partial_fit:15
msgid "**y**"
msgstr "**y**"

#: of sklearn.linear_model._stochastic_gradient.BaseSGDRegressor.predict:24
msgid "ndarray of shape (n_samples,)"
msgstr "ndarray of shape (n_samples,)"

#: of sklearn.linear_model._stochastic_gradient.BaseSGDRegressor.fit:11
msgid "Target values"
msgstr "Valores objetivo"

#: of sklearn.linear_model._stochastic_gradient.BaseSGDRegressor.fit:14
msgid "**coef_init**"
msgstr "**coef_init**"

#: of
msgid "ndarray of shape (n_features,), default=None"
msgstr "ndarray of shape (n_features,), default=None"

#: of sklearn.linear_model._stochastic_gradient.BaseSGDRegressor.fit:14
msgid "The initial coefficients to warm-start the optimization."
msgstr "Los coeficientes iniciales para iniciar la optimización en caliente."

#: of sklearn.linear_model._stochastic_gradient.BaseSGDRegressor.fit:17
msgid "**intercept_init**"
msgstr "**intercept_init**"

#: of
msgid "ndarray of shape (1,), default=None"
msgstr "ndarray of shape (1,), default=None"

#: of sklearn.linear_model._stochastic_gradient.BaseSGDRegressor.fit:17
msgid "The initial intercept to warm-start the optimization."
msgstr "La intercepción inicial la optimización en caliente."

#: of sklearn.base.RegressorMixin.score:26
#: sklearn.linear_model._stochastic_gradient.BaseSGDRegressor.fit:20
#: sklearn.linear_model._stochastic_gradient.BaseSGDRegressor.partial_fit:19
msgid "**sample_weight**"
msgstr "**sample_weight**"

#: of
msgid "array-like, shape (n_samples,), default=None"
msgstr "array-like, shape (n_samples,), default=None"

#: of sklearn.linear_model._stochastic_gradient.BaseSGDRegressor.fit:20
msgid "Weights applied to individual samples (1. for unweighted)."
msgstr "Ponderaciones aplicadas a las muestras individuales (1. para las no ponderadas)."

#: of sklearn.linear_model._stochastic_gradient.BaseSGD.set_params:24
#: sklearn.linear_model._stochastic_gradient.BaseSGDRegressor.fit:36
#: sklearn.linear_model._stochastic_gradient.BaseSGDRegressor.partial_fit:35
msgid "**self**"
msgstr "**self**"

#: of
msgid "returns an instance of self."
msgstr "devuelve una instancia de sí misma."

#: of sklearn.base.BaseEstimator.get_params:9
msgid "**deep**"
msgstr "**deep**"

#: of sklearn.base.BaseEstimator.get_params:8
msgid "If True, will return the parameters for this estimator and contained subobjects that are estimators."
msgstr "Si es True, devolverá los parámetros para este estimador y los sub objetos contenidos que son estimadores."

#: of sklearn.base.BaseEstimator.get_params:25
msgid "**params**"
msgstr "**params**"

#: of
msgid "dict"
msgstr "dict"

#: of sklearn.base.BaseEstimator.get_params:14
msgid "Parameter names mapped to their values."
msgstr "Nombres de parámetros mapeados a sus valores."

#: of sklearn.linear_model._stochastic_gradient.BaseSGDRegressor.partial_fit:4
msgid "Internally, this method uses ``max_iter = 1``. Therefore, it is not guaranteed that a minimum of the cost function is reached after calling it once. Matters such as objective convergence and early stopping should be handled by the user."
msgstr "Internamente, este método utiliza ``max_iter = 1``. Por lo tanto, no se garantiza que se alcance un mínimo de la función de coste después de llamarlo una vez. Cuestiones como la convergencia del objetivo y la parada anticipada deben ser manejadas por el usuario."

#: of sklearn.linear_model._stochastic_gradient.BaseSGDRegressor.partial_fit:12
msgid "Subset of training data"
msgstr "Subconjunto de los datos de entrenamiento"

#: of
msgid "numpy array of shape (n_samples,)"
msgstr "numpy array of shape (n_samples,)"

#: of sklearn.linear_model._stochastic_gradient.BaseSGDRegressor.partial_fit:15
msgid "Subset of target values"
msgstr "Subconjunto de los valores objetivos"

#: of sklearn.linear_model._stochastic_gradient.BaseSGDRegressor.partial_fit:18
msgid "Weights applied to individual samples. If not provided, uniform weights are assumed."
msgstr "Ponderaciones aplicadas a las muestras individuales. Si no se proporciona, se suponen ponderados uniformes."

#: of sklearn.linear_model._stochastic_gradient.BaseSGDRegressor.predict:13
msgid "Predicted target values per element in X."
msgstr "Valores objetivo previstos por elemento en X."

#: of sklearn.base.RegressorMixin.score:5
msgid "The coefficient :math:`R^2` is defined as :math:`(1 - \\frac{u}{v})`, where :math:`u` is the residual sum of squares ``((y_true - y_pred) ** 2).sum()`` and :math:`v` is the total sum of squares ``((y_true - y_true.mean()) ** 2).sum()``. The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). A constant model that always predicts the expected value of `y`, disregarding the input features, would get a :math:`R^2` score of 0.0."
msgstr "El coeficiente :math:`R^2` se define como :math:`(1 - \\frac{u}{v})`, donde :math:`u` es la suma residual de cuadrados ``((y_true - y_pred) ** 2).sum()`` y :math:`v` es la suma total de cuadrados ``((y_true - y_true.mean()) ** 2).sum()``. La mejor puntuación posible es 1.0 y puede ser negativo (porque el modelo puede ser arbitrariamente peor). Un modelo constante que siempre predice el valor esperado de `y`, sin tener en cuenta las características de entrada, obtendría un valor :math:`R^2` de 0.0."

#: of
msgid "array-like of shape (n_samples, n_features)"
msgstr "array-like of shape (n_samples, n_features)"

#: of sklearn.base.RegressorMixin.score:17
msgid "Test samples. For some estimators this may be a precomputed kernel matrix or a list of generic objects instead with shape ``(n_samples, n_samples_fitted)``, where ``n_samples_fitted`` is the number of samples used in the fitting for the estimator."
msgstr "Muestras de prueba. Para algunos estimadores puede ser una matriz de núcleo precalculada o una lista de objetos genéricos con forma ``(n_samples, n_samples_fitted)``, donde ``n_samples_fitted`` es el número de muestras utilizadas en el ajuste para el estimador."

#: of
msgid "array-like of shape (n_samples,) or (n_samples, n_outputs)"
msgstr "array-like of shape (n_samples,) or (n_samples, n_outputs)"

#: of sklearn.base.RegressorMixin.score:23
msgid "True values for `X`."
msgstr "Valores verdaderos para `X`."

#: of
msgid "array-like of shape (n_samples,), default=None"
msgstr "array-like of shape (n_samples,), default=None"

#: of sklearn.base.RegressorMixin.score:26
msgid "Sample weights."
msgstr "Ponderaciones de muestra."

#: of sklearn.base.RegressorMixin.score:38
msgid "**score**"
msgstr "**score**"

#: of
msgid "float"
msgstr "float"

#: of sklearn.base.RegressorMixin.score:31
msgid ":math:`R^2` of ``self.predict(X)`` wrt. `y`."
msgstr ":math:`R^2` of ``self.predict(X)`` wrt. `y`."

#: of sklearn.base.RegressorMixin.score:41
#: sklearn.linear_model._base.SparseCoefMixin.sparsify:24
msgid "Notes"
msgstr "Notas"

#: of sklearn.base.RegressorMixin.score:42
msgid "The :math:`R^2` score used when calling ``score`` on a regressor uses ``multioutput='uniform_average'`` from version 0.23 to keep consistent with default value of :func:`~sklearn.metrics.r2_score`. This influences the ``score`` method of all the multioutput regressors (except for :class:`~sklearn.multioutput.MultiOutputRegressor`)."
msgstr "El valor :math:`R^2` utilizado al llamar a ``score`` en un regresor utiliza ``multioutput='uniform_average'`` desde la versión 0.23 para mantener la coherencia con el valor por defecto de :func:`~sklearn.metrics.r2_score`. Esto influye en el método ``score`` de todos los regresores de salida múltiple (excepto para :class:`~sklearn.multioutput.MultiOutputRegressor`)."

#: of sklearn.linear_model._stochastic_gradient.BaseSGD.set_params:8
msgid "**\\*\\*kwargs**"
msgstr "**\\*\\*kwargs**"

#: of sklearn.linear_model._stochastic_gradient.BaseSGD.set_params:8
msgid "Estimator parameters."
msgstr "Parámetros del estimador."

#: of
msgid "object"
msgstr "object"

#: of sklearn.linear_model._stochastic_gradient.BaseSGD.set_params:13
msgid "Estimator instance."
msgstr "Instancia de estimador."

#: of sklearn.linear_model._base.SparseCoefMixin.sparsify:4
msgid "Converts the ``coef_`` member to a scipy.sparse matrix, which for L1-regularized models can be much more memory- and storage-efficient than the usual numpy.ndarray representation."
msgstr "Convierte el miembro ``coef_`` en una matriz scipy.sparse, que para los modelos L1-regularizados puede ser mucho más eficiente en cuanto a memoria y almacenamiento que la representación numpy.ndarray habitual."

#: of sklearn.linear_model._base.SparseCoefMixin.sparsify:8
msgid "The ``intercept_`` member is not converted."
msgstr "El miembro ``intercept_`` no se convierte."

#: of sklearn.linear_model._base.SparseCoefMixin.sparsify:25
#, python-format
msgid "For non-sparse models, i.e. when there are not many zeros in ``coef_``, this may actually *increase* memory usage, so use this method with care. A rule of thumb is that the number of zero elements, which can be computed with ``(coef_ == 0).sum()``, must be more than 50% for this to provide significant benefits."
msgstr "Para los modelos no dispersos, es decir, cuando no hay muchos ceros en ``coef_``, esto puede en realidad *aumentar* el uso de la memoria, así que utilice este método con cuidado. Una regla general es que el número de elementos cero, que puede ser calculado con ``(coef_ == 0).sum()``, debe ser más del 50% para que esto proporcione beneficios significativos."

#: of sklearn.linear_model._base.SparseCoefMixin.sparsify:31
msgid "After calling this method, further fitting with the partial_fit method (if any) will not work until you call densify."
msgstr "Después de invocar a este método, el ajuste posterior con el método partial_fit (si lo hay) no funcionará hasta que llame a densify."

#: ../modules/generated/sklearn.linear_model.SGDRegressor.examples:4
msgid "Examples using ``sklearn.linear_model.SGDRegressor``"
msgstr "Ejemplos usando ``sklearn.linear_model.SGDRegressor``"

#: ../modules/generated/sklearn.linear_model.SGDRegressor.examples:15
#: ../modules/generated/sklearn.linear_model.SGDRegressor.examples:23
msgid ":ref:`sphx_glr_auto_examples_applications_plot_prediction_latency.py`"
msgstr ":ref:`sphx_glr_auto_examples_applications_plot_stock_market.py`"

#: ../modules/generated/sklearn.linear_model.SGDRegressor.examples:34
#: ../modules/generated/sklearn.linear_model.SGDRegressor.examples:42
msgid ":ref:`sphx_glr_auto_examples_linear_model_plot_sgd_penalties.py`"
msgstr ":ref:`sphx_glr_auto_examples_linear_model_plot_theilsen.py`"

