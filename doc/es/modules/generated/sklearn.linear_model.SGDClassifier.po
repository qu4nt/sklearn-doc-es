msgid ""
msgstr ""
"Project-Id-Version: scikit-learn\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-03-31 12:56-0400\n"
"PO-Revision-Date: 2021-05-26 20:22\n"
"Last-Translator: \n"
"Language-Team: Spanish\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Crowdin-Project: scikit-learn\n"
"X-Crowdin-Project-ID: 450526\n"
"X-Crowdin-Language: es-ES\n"
"X-Crowdin-File: /main/doc/en/modules/generated/sklearn.linear_model.SGDClassifier.po\n"
"X-Crowdin-File-ID: 4990\n"
"Language: es_ES\n"

#: ../modules/generated/sklearn.linear_model.SGDClassifier.rst:2
msgid ":mod:`sklearn.linear_model`.SGDClassifier"
msgstr ":mod:`sklearn.linear_model`.SGDClassifier"

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:2
msgid "Linear classifiers (SVM, logistic regression, etc.) with SGD training."
msgstr "Clasificadores lineales (SVM, regresión logística, etc.) con entrenamiento SGD."

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:4
msgid "This estimator implements regularized linear models with stochastic gradient descent (SGD) learning: the gradient of the loss is estimated each sample at a time and the model is updated along the way with a decreasing strength schedule (aka learning rate). SGD allows minibatch (online/out-of-core) learning via the `partial_fit` method. For best results using the default learning rate schedule, the data should have zero mean and unit variance."
msgstr "Este estimador implementa modelos lineales regularizados con aprendizaje de descenso de gradiente estocástico (SGD): el gradiente de la pérdida se estima cada muestra a la vez y el modelo se actualiza a lo largo del camino con un programa de fuerza decreciente (aka tasa de aprendizaje). El SGD permite el aprendizaje por minilotes (en línea y fuera del núcleo) mediante el método `partial_fit`. Para obtener los mejores resultados con la tasa de aprendizaje predeterminada, los datos deben tener media cero y varianza unitaria."

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:12
msgid "This implementation works with data represented as dense or sparse arrays of floating point values for the features. The model it fits can be controlled with the loss parameter; by default, it fits a linear support vector machine (SVM)."
msgstr "Esta implementación funciona con datos representados como arreglos densos o dispersos de valores de punto flotante para las características. El modelo que ajusta se puede controlar con el parámetro de pérdida; por defecto, ajusta una máquina de vectores de soporte lineal (SVM)."

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:17
msgid "The regularizer is a penalty added to the loss function that shrinks model parameters towards the zero vector using either the squared euclidean norm L2 or the absolute norm L1 or a combination of both (Elastic Net). If the parameter update crosses the 0.0 value because of the regularizer, the update is truncated to 0.0 to allow for learning sparse models and achieve online feature selection."
msgstr "El regularizador es una penalización añadida a la función de pérdida que encoge los parámetros del modelo hacia el vector cero utilizando la norma euclidiana cuadrada L2 o la norma absoluta L1 o una combinación de ambas (red elástica). Si la actualización de los parámetros cruza el valor 0.0 debido al regularizador, la actualización se trunca a 0.0 para permitir el aprendizaje de modelos dispersos y lograr la selección de características en línea."

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:24
msgid "Read more in the :ref:`User Guide <sgd>`."
msgstr "Más información en el :ref:`Manual de usuario <sgd>`."

#: of sklearn.base.BaseEstimator.get_params sklearn.base.ClassifierMixin.score
#: sklearn.linear_model.SGDClassifier.predict_log_proba
#: sklearn.linear_model.SGDClassifier.predict_proba
#: sklearn.linear_model._base.LinearClassifierMixin.decision_function
#: sklearn.linear_model._base.LinearClassifierMixin.predict
#: sklearn.linear_model._stochastic_gradient.BaseSGD.set_params
#: sklearn.linear_model._stochastic_gradient.BaseSGDClassifier.fit
#: sklearn.linear_model._stochastic_gradient.BaseSGDClassifier.partial_fit
#: sklearn.linear_model._stochastic_gradient.SGDClassifier
msgid "Parameters"
msgstr "Parámetros"

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:46
msgid "**loss**"
msgstr "**loss**"

#: of
msgid "str, default='hinge'"
msgstr "str, default='hinge'"

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:29
msgid "The loss function to be used. Defaults to 'hinge', which gives a linear SVM."
msgstr "La función de pérdida a utilizar. Por defecto es 'hinge', que da un SVM lineal."

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:32
msgid "The possible options are 'hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron', or a regression loss: 'squared_loss', 'huber', 'epsilon_insensitive', or 'squared_epsilon_insensitive'."
msgstr "Las opciones posibles son 'hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron', o una pérdida de regresión: 'squared_loss', 'huber', 'epsilon_insensitive', o 'squared_epsilon_insensitive'."

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:36
msgid "The 'log' loss gives logistic regression, a probabilistic classifier. 'modified_huber' is another smooth loss that brings tolerance to outliers as well as probability estimates. 'squared_hinge' is like hinge but is quadratically penalized. 'perceptron' is the linear loss used by the perceptron algorithm. The other losses are designed for regression but can be useful in classification as well; see :class:`~sklearn.linear_model.SGDRegressor` for a description."
msgstr "La pérdida 'log' proporciona una regresión logística, un clasificador probabilístico. 'modified_huber' es otra pérdida suave que aporta tolerancia a los valores atípicos, así como a las estimaciones de probabilidad. 'squared_hinge' es como hinge pero se penaliza cuadráticamente. 'perceptron' es la pérdida lineal utilizada por el algoritmo perceptrón. Las otras pérdidas están diseñadas para la regresión, pero también pueden ser útiles en la clasificación; consulta :class:`~sklearn.linear_model.SGDRegressor` para una descripción."

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:45
msgid "More details about the losses formulas can be found in the :ref:`User Guide <sgd_mathematical_formulation>`."
msgstr "Puedes encontrar más detalles sobre las fórmulas de pérdidas en la :ref:`Manual de usuario <sgd_mathematical_formulation>`."

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:52
msgid "**penalty**"
msgstr "**penalty**"

#: of
msgid "{'l2', 'l1', 'elasticnet'}, default='l2'"
msgstr "{'l2', 'l1', 'elasticnet'}, default='l2'"

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:49
msgid "The penalty (aka regularization term) to be used. Defaults to 'l2' which is the standard regularizer for linear SVM models. 'l1' and 'elasticnet' might bring sparsity to the model (feature selection) not achievable with 'l2'."
msgstr "La penalización (término de regularización) que se utilizará. Por defecto es 'l2' que es el regularizador estándar para los modelos SVM lineales. l1' y 'elasticnet' pueden aportar una dispersión al modelo (selección de características) que no se consigue con 'l2'."

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:58
msgid "**alpha**"
msgstr "**alpha**"

#: of
msgid "float, default=0.0001"
msgstr "float, default=0.0001"

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:55
msgid "Constant that multiplies the regularization term. The higher the value, the stronger the regularization. Also used to compute the learning rate when set to `learning_rate` is set to 'optimal'."
msgstr "Constante que multiplica el término de regularización. Cuanto mayor sea el valor, más fuerte será la regularización. También se utiliza para calcular la tasa de aprendizaje cuando se establece en `learning_rate` se establece en 'optimal'."

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:63
msgid "**l1_ratio**"
msgstr "**l1_ratio**"

#: of
msgid "float, default=0.15"
msgstr "float, default=0.15"

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:61
msgid "The Elastic Net mixing parameter, with 0 <= l1_ratio <= 1. l1_ratio=0 corresponds to L2 penalty, l1_ratio=1 to L1. Only used if `penalty` is 'elasticnet'."
msgstr "El parámetro de mezcla de la red elástica, con 0 <= l1_ratio <= 1. l1_ratio=0 corresponde a la penalización L2, l1_ratio=1 a la L1. Sólo se utiliza si `penalty` es 'elasticnet'."

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:67
msgid "**fit_intercept**"
msgstr "**fit_intercept**"

#: of
msgid "bool, default=True"
msgstr "bool, default=True"

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:66
msgid "Whether the intercept should be estimated or not. If False, the data is assumed to be already centered."
msgstr "Si el intercepto debe ser estimado o no. Si es False, se asume que los datos ya están centrados."

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:74
msgid "**max_iter**"
msgstr "**max_iter**"

#: of
msgid "int, default=1000"
msgstr "int, default=1000"

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:70
msgid "The maximum number of passes over the training data (aka epochs). It only impacts the behavior in the ``fit`` method, and not the :meth:`partial_fit` method."
msgstr "El número máximo de pasadas sobre los datos de entrenamiento (también conocido como épocas o epochs). Sólo afecta al comportamiento del método ``fit``, y no al método :meth:`partial_fit`."

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:81
msgid "**tol**"
msgstr "**tol**"

#: of
msgid "float, default=1e-3"
msgstr "float, default=1e-3"

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:77
msgid "The stopping criterion. If it is not None, training will stop when (loss > best_loss - tol) for ``n_iter_no_change`` consecutive epochs."
msgstr "El criterio de parada. Si no es None, el entrenamiento se detendrá cuando (loss > best_loss - tol) para ``n_iter_no_change`` épocas consecutivas."

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:84
msgid "**shuffle**"
msgstr "**shuffle**"

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:84
msgid "Whether or not the training data should be shuffled after each epoch."
msgstr "Si los datos de entrenamiento deben ser aleatorizados o no después de cada época."

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:87
msgid "**verbose**"
msgstr "**verbose**"

#: of
msgid "int, default=0"
msgstr "int, default=0"

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:87
msgid "The verbosity level."
msgstr "Nivel de verbosidad."

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:95
msgid "**epsilon**"
msgstr "**epsilon**"

#: of
msgid "float, default=0.1"
msgstr "float, default=0.1"

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:90
msgid "Epsilon in the epsilon-insensitive loss functions; only if `loss` is 'huber', 'epsilon_insensitive', or 'squared_epsilon_insensitive'. For 'huber', determines the threshold at which it becomes less important to get the prediction exactly right. For epsilon-insensitive, any differences between the current prediction and the correct label are ignored if they are less than this threshold."
msgstr "Epsilon en las funciones de pérdida insensibles a epsilon; sólo si `loss` es 'huber', 'epsilon_insensitive', o 'squared_epsilon_insensitive'. En el caso de 'huber', determina el umbral a partir del cual es menos importante acertar la predicción. En el caso de insensible a épsilon, cualquier diferencia entre la predicción actual y la etiqueta correcta se ignora si es menor que este umbral."

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:102
msgid "**n_jobs**"
msgstr "**n_jobs**"

#: of
msgid "int, default=None"
msgstr "int, default=None"

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:98
msgid "The number of CPUs to use to do the OVA (One Versus All, for multi-class problems) computation. ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context. ``-1`` means using all processors. See :term:`Glossary <n_jobs>` for more details."
msgstr "El número de CPUs a utilizar para realizar el cálculo OVA (Uno Contra Todos, One Versus All, para problemas multiclase). ``None`` significa 1 a menos que esté en un contexto :obj:`joblib.parallel_backend`. ``-1`` significa utilizar todos los procesadores. Ver :term:`Glossary <n_jobs>` para más detalles."

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:107
msgid "**random_state**"
msgstr "**random_state**"

#: of
msgid "int, RandomState instance, default=None"
msgstr "int, RandomState instance, default=None"

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:105
msgid "Used for shuffling the data, when ``shuffle`` is set to ``True``. Pass an int for reproducible output across multiple function calls. See :term:`Glossary <random_state>`."
msgstr "Se utiliza para barajar los datos, cuando ``shuffle`` se establece en ``True``. Pase un int para una salida reproducible a través de múltiples llamadas a la función. Consulta :term:`Glosario <random_state>`."

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:122
msgid "**learning_rate**"
msgstr "**learning_rate**"

#: of
msgid "str, default='optimal'"
msgstr "str, default='optimal'"

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:110
msgid "The learning rate schedule:"
msgstr "El programa de la tasa de aprendizaje:"

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:112
msgid "'constant': `eta = eta0`"
msgstr "'constant': `eta = eta0`"

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:113
msgid "'optimal': `eta = 1.0 / (alpha * (t + t0))` where t0 is chosen by a heuristic proposed by Leon Bottou."
msgstr "'optimal': `eta = 1.0 / (alpha * (t + t0))` donde t0 se elige mediante una heurística propuesta por Leon Bottou."

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:115
msgid "'invscaling': `eta = eta0 / pow(t, power_t)`"
msgstr "'invscaling': `eta = eta0 / pow(t, power_t)`"

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:116
msgid "'adaptive': eta = eta0, as long as the training keeps decreasing. Each time n_iter_no_change consecutive epochs fail to decrease the training loss by tol or fail to increase validation score by tol if early_stopping is True, the current learning rate is divided by 5."
msgstr "'adaptive': eta = eta0, siempre que el entrenamiento siga disminuyendo. Cada vez que n_iter_no_change consecutivo no consigue disminuir la pérdida asociada al entrenamiento en tol o no consigue aumentar la puntuación de validación en tol si early_stopping es True, la tasa de aprendizaje actual se divide por 5."

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:121
msgid "Added 'adaptive' option"
msgstr "Added 'adaptive' option"

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:127
msgid "**eta0**"
msgstr "**eta0**"

#: of
msgid "double, default=0.0"
msgstr "double, default=0.0"

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:125
msgid "The initial learning rate for the 'constant', 'invscaling' or 'adaptive' schedules. The default value is 0.0 as eta0 is not used by the default schedule 'optimal'."
msgstr "La tasa de aprendizaje inicial para los programas 'constant', 'invscaling' o 'adaptive'. El valor por defecto es 0.0 ya que eta0 no es utilizado por el programa por defecto 'optimal'."

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:130
msgid "**power_t**"
msgstr "**power_t**"

#: of
msgid "double, default=0.5"
msgstr "double, default=0.5"

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:130
msgid "The exponent for inverse scaling learning rate [default 0.5]."
msgstr "El exponente de la tasa de aprendizaje de escala inversa [por defecto 0.5]."

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:140
msgid "**early_stopping**"
msgstr "**early_stopping**"

#: of
msgid "bool, default=False"
msgstr "bool, default=False"

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:133
msgid "Whether to use early stopping to terminate training when validation score is not improving. If set to True, it will automatically set aside a stratified fraction of training data as validation and terminate training when validation score returned by the `score` method is not improving by at least tol for n_iter_no_change consecutive epochs."
msgstr "Si se utiliza la parada temprana para terminar el entrenamiento cuando la puntuación de validación no está mejorando. Si se establece como True, se apartará automáticamente una fracción estratificada de los datos de entrenamiento como validación y terminará el entrenamiento cuando la puntuación de validación devuelta por el método `score` no mejore en al menos tol para n_iter_no_change épocas consecutivas."

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:139
msgid "Added 'early_stopping' option"
msgstr "Opción 'early_stopping' añadida"

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:148
msgid "**validation_fraction**"
msgstr "**validation_fraction**"

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:143
msgid "The proportion of training data to set aside as validation set for early stopping. Must be between 0 and 1. Only used if `early_stopping` is True."
msgstr "La proporción de los datos de entrenamiento que se reservan como conjunto de validación para la parada anticipada. Debe estar entre 0 y 1. Sólo se utiliza si `early_stopping` es True."

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:147
msgid "Added 'validation_fraction' option"
msgstr "Opción 'validation_fraction' añadida"

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:154
msgid "**n_iter_no_change**"
msgstr "**n_iter_no_change**"

#: of
msgid "int, default=5"
msgstr "int, default=5"

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:151
msgid "Number of iterations with no improvement to wait before early stopping."
msgstr "Número de iteraciones sin mejora que hay que esperar antes de la parada anticipada."

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:153
msgid "Added 'n_iter_no_change' option"
msgstr "Opción 'n_iter_no_change' añadida"

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:164
msgid "**class_weight**"
msgstr "**class_weight**"

#: of
msgid "dict, {class_label: weight} or \"balanced\", default=None"
msgstr "dict, {class_label: weight} or \"balanced\", default=None"

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:157
msgid "Preset for the class_weight fit parameter."
msgstr "Preajuste para el parámetro de ajuste class_weight."

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:159
msgid "Weights associated with classes. If not given, all classes are supposed to have weight one."
msgstr "Ponderación asociada a las clases. Si no se da, se supone que todas las clases tienen ponderación uno."

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:162
msgid "The \"balanced\" mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as ``n_samples / (n_classes * np.bincount(y))``."
msgstr "El modo \"balanced\" utiliza los valores de y para ajustar automáticamente las ponderaciones inversamente proporcionales a las frecuencias de clase en los datos de entrada como ``n_samples / (n_classes * np.bincount(y))``."

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:177
msgid "**warm_start**"
msgstr "**warm_start**"

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:167
msgid "When set to True, reuse the solution of the previous call to fit as initialization, otherwise, just erase the previous solution. See :term:`the Glossary <warm_start>`."
msgstr "Cuando se establece a True, reutiliza la solución de la llamada anterior para ajustar como inicialización, de lo contrario, solamente borrará la solución anterior. Ver :term:`Glossary <warm_start>`."

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:171
msgid "Repeatedly calling fit or partial_fit when warm_start is True can result in a different solution than when calling fit a single time because of the way the data is shuffled. If a dynamic learning rate is used, the learning rate is adapted depending on the number of samples already seen. Calling ``fit`` resets this counter, while ``partial_fit`` will result in increasing the existing counter."
msgstr "Llamar repetidamente a fit o partial_fit cuando warm_start es True puede dar lugar a una solución diferente que cuando se llama a fit una sola vez debido a la forma en que se revolver los datos. Si se utiliza una tasa de aprendizaje dinámico, la tasa de aprendizaje se adapta en función del número de muestras ya vistas. Llamar a ``fit`` reinicia este contador, mientras que ``partial_fit`` resultará en el aumento del contador existente."

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:187
msgid "**average**"
msgstr "**average**"

#: of
msgid "bool or int, default=False"
msgstr "bool or int, default=False"

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:180
msgid "When set to True, computes the averaged SGD weights accross all updates and stores the result in the ``coef_`` attribute. If set to an int greater than 1, averaging will begin once the total number of samples seen reaches `average`. So ``average=10`` will begin averaging after seeing 10 samples."
msgstr "Si se establece como True, calcula el promedio de los ponderados SGD en todas las actualizaciones y almacena el resultado en el atributo ``coef_``. Si se establece como un int mayor que 1, el promedio comenzará una vez que el número total de muestras vistas alcance el `average`. Así, ``average=10`` se empieza a promediar después de ver 10 muestras."

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier
msgid "Attributes"
msgstr "Atributos"

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:192
msgid "**coef_**"
msgstr "**coef_**"

#: of
msgid "ndarray of shape (1, n_features) if n_classes == 2 else             (n_classes, n_features)"
msgstr "ndarray of shape (1, n_features) if n_classes == 2 else             (n_classes, n_features)"

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:192
msgid "Weights assigned to the features."
msgstr "Ponderaciones asignadas a las características."

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:195
msgid "**intercept_**"
msgstr "**intercept_**"

#: of
msgid "ndarray of shape (1,) if n_classes == 2 else (n_classes,)"
msgstr "ndarray of shape (1,) if n_classes == 2 else (n_classes,)"

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:195
msgid "Constants in decision function."
msgstr "Constantes en la función de decisión."

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:199
msgid "**n_iter_**"
msgstr "**n_iter_**"

#: of
msgid "int"
msgstr "int"

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:198
msgid "The actual number of iterations before reaching the stopping criterion. For multiclass fits, it is the maximum over every binary fit."
msgstr "El número real de iteraciones antes de alcanzar el criterio de parada. Para los ajustes multiclase, es el máximo sobre cada ajuste binario."

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:202
msgid "**loss_function_** : concrete ``LossFunction``"
msgstr "**loss_function_** : concrete ``LossFunction``"

#: of
msgid "concrete"
msgstr "concreto"

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:205
msgid "**classes_**"
msgstr "**classes_**"

#: of
msgid "array of shape (n_classes,)"
msgstr "array of shape (n_classes,)"

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:212
msgid "**t_**"
msgstr "**t_**"

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:208
msgid "Number of weight updates performed during training. Same as ``(n_iter_ * n_samples)``."
msgstr "Número de actualizaciones de ponderación realizadas durante el entrenamiento. Igual que``(n_iter_ * n_samples)``."

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:217
msgid ":obj:`sklearn.svm.LinearSVC`"
msgstr ":obj:`sklearn.svm.LinearSVC`"

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:218
msgid "Linear support vector classification."
msgstr "Clasificación lineal de vectores de soporte."

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:219
msgid ":obj:`LogisticRegression`"
msgstr ":obj:`LogisticRegression`"

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:220
msgid "Logistic regression."
msgstr "Regresión logística."

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:221
msgid ":obj:`Perceptron`"
msgstr ":obj:`Perceptron`"

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:222
msgid "Inherits from SGDClassifier. ``Perceptron()`` is equivalent to ``SGDClassifier(loss=\"perceptron\", eta0=1, learning_rate=\"constant\", penalty=None)``."
msgstr "Hereda de SGDClassifier. ``Perceptron()`` es equivalente a ``SGDClassifier(loss=\"perceptron\", eta0=1, learning_rate=\"constant\", penalty=None)``."

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:228
msgid "Examples"
msgstr "Ejemplos"

#: of sklearn.linear_model._stochastic_gradient.SGDClassifier:245
msgid "Methods"
msgstr "Métodos"

#: of
#: sklearn.linear_model._stochastic_gradient.SGDClassifier:257:<autosummary>:1
msgid ":obj:`decision_function <sklearn.linear_model.SGDClassifier.decision_function>`\\"
msgstr ":obj:`decision_function <sklearn.linear_model.SGDClassifier.decision_function>`\\"

#: of sklearn.linear_model._base.LinearClassifierMixin.decision_function:2
#: sklearn.linear_model._stochastic_gradient.SGDClassifier:257:<autosummary>:1
msgid "Predict confidence scores for samples."
msgstr "Predecir las puntuaciones de confianza de las muestras."

#: of
#: sklearn.linear_model._stochastic_gradient.SGDClassifier:257:<autosummary>:1
msgid ":obj:`densify <sklearn.linear_model.SGDClassifier.densify>`\\"
msgstr ":obj:`densify <sklearn.linear_model.SGDClassifier.densify>`\\"

#: of sklearn.linear_model._base.SparseCoefMixin.densify:2
#: sklearn.linear_model._stochastic_gradient.SGDClassifier:257:<autosummary>:1
msgid "Convert coefficient matrix to dense array format."
msgstr "Convierte la matriz de coeficientes en formato de arreglo denso."

#: of
#: sklearn.linear_model._stochastic_gradient.SGDClassifier:257:<autosummary>:1
msgid ":obj:`fit <sklearn.linear_model.SGDClassifier.fit>`\\"
msgstr ":obj:`fit <sklearn.linear_model.SGDClassifier.fit>`\\"

#: of sklearn.linear_model._stochastic_gradient.BaseSGDClassifier.fit:2
#: sklearn.linear_model._stochastic_gradient.SGDClassifier:257:<autosummary>:1
msgid "Fit linear model with Stochastic Gradient Descent."
msgstr "Ajustar el modelo lineal con el Descenso Gradiente Estocástico."

#: of
#: sklearn.linear_model._stochastic_gradient.SGDClassifier:257:<autosummary>:1
msgid ":obj:`get_params <sklearn.linear_model.SGDClassifier.get_params>`\\"
msgstr ":obj:`get_params <sklearn.linear_model.SGDClassifier.get_params>`\\"

#: of sklearn.base.BaseEstimator.get_params:2
#: sklearn.linear_model._stochastic_gradient.SGDClassifier:257:<autosummary>:1
msgid "Get parameters for this estimator."
msgstr "Obtiene los parámetros para este estimador."

#: of
#: sklearn.linear_model._stochastic_gradient.SGDClassifier:257:<autosummary>:1
msgid ":obj:`partial_fit <sklearn.linear_model.SGDClassifier.partial_fit>`\\"
msgstr ":obj:`partial_fit <sklearn.linear_model.SGDClassifier.partial_fit>`\\"

#: of sklearn.linear_model._stochastic_gradient.BaseSGDClassifier.partial_fit:2
#: sklearn.linear_model._stochastic_gradient.SGDClassifier:257:<autosummary>:1
msgid "Perform one epoch of stochastic gradient descent on given samples."
msgstr "Realiza una época de descenso de gradiente estocástico en las muestras dadas."

#: of
#: sklearn.linear_model._stochastic_gradient.SGDClassifier:257:<autosummary>:1
msgid ":obj:`predict <sklearn.linear_model.SGDClassifier.predict>`\\"
msgstr ":obj:`predict <sklearn.linear_model.SGDClassifier.predict>`\\"

#: of sklearn.linear_model._base.LinearClassifierMixin.predict:2
#: sklearn.linear_model._stochastic_gradient.SGDClassifier:257:<autosummary>:1
msgid "Predict class labels for samples in X."
msgstr "Predice las etiquetas de clase para las muestras en X."

#: of
#: sklearn.linear_model._stochastic_gradient.SGDClassifier:257:<autosummary>:1
msgid ":obj:`score <sklearn.linear_model.SGDClassifier.score>`\\"
msgstr ":obj:`score <sklearn.linear_model.SGDClassifier.score>`\\"

#: of sklearn.base.ClassifierMixin.score:2
#: sklearn.linear_model._stochastic_gradient.SGDClassifier:257:<autosummary>:1
msgid "Return the mean accuracy on the given test data and labels."
msgstr "Devuelve la precisión media en los datos de prueba y las etiquetas dados."

#: of
#: sklearn.linear_model._stochastic_gradient.SGDClassifier:257:<autosummary>:1
msgid ":obj:`set_params <sklearn.linear_model.SGDClassifier.set_params>`\\"
msgstr ":obj:`set_params <sklearn.linear_model.SGDClassifier.set_params>`\\"

#: of sklearn.linear_model._stochastic_gradient.BaseSGD.set_params:2
#: sklearn.linear_model._stochastic_gradient.SGDClassifier:257:<autosummary>:1
msgid "Set and validate the parameters of estimator."
msgstr "Establecer y validar los parámetros del estimador."

#: of
#: sklearn.linear_model._stochastic_gradient.SGDClassifier:257:<autosummary>:1
msgid ":obj:`sparsify <sklearn.linear_model.SGDClassifier.sparsify>`\\"
msgstr ":obj:`sparsify <sklearn.linear_model.SGDClassifier.sparsify>`\\"

#: of sklearn.linear_model._base.SparseCoefMixin.sparsify:2
#: sklearn.linear_model._stochastic_gradient.SGDClassifier:257:<autosummary>:1
msgid "Convert coefficient matrix to sparse format."
msgstr "Convierte la matriz de coeficientes en formato disperso."

#: of sklearn.linear_model._base.LinearClassifierMixin.decision_function:4
msgid "The confidence score for a sample is proportional to the signed distance of that sample to the hyperplane."
msgstr "La puntuación de confianza de una muestra es proporcional a la distancia con signo de esa muestra al hiperplano."

#: of sklearn.base.ClassifierMixin.score:11
#: sklearn.linear_model.SGDClassifier.predict_log_proba:14
#: sklearn.linear_model.SGDClassifier.predict_proba:19
#: sklearn.linear_model._base.LinearClassifierMixin.decision_function:10
#: sklearn.linear_model._base.LinearClassifierMixin.predict:8
#: sklearn.linear_model._stochastic_gradient.BaseSGDClassifier.fit:8
#: sklearn.linear_model._stochastic_gradient.BaseSGDClassifier.partial_fit:12
msgid "**X**"
msgstr "**X**"

#: of
msgid "array-like or sparse matrix, shape (n_samples, n_features)"
msgstr "array-like or sparse matrix, shape (n_samples, n_features)"

#: of sklearn.linear_model._base.LinearClassifierMixin.decision_function:10
#: sklearn.linear_model._base.LinearClassifierMixin.predict:8
msgid "Samples."
msgstr "Muestras."

#: of sklearn.base.BaseEstimator.get_params sklearn.base.ClassifierMixin.score
#: sklearn.linear_model.SGDClassifier.predict_log_proba
#: sklearn.linear_model.SGDClassifier.predict_proba
#: sklearn.linear_model._base.LinearClassifierMixin.decision_function
#: sklearn.linear_model._base.LinearClassifierMixin.predict
#: sklearn.linear_model._base.SparseCoefMixin.densify
#: sklearn.linear_model._base.SparseCoefMixin.sparsify
#: sklearn.linear_model._stochastic_gradient.BaseSGD.set_params
#: sklearn.linear_model._stochastic_gradient.BaseSGDClassifier.fit
#: sklearn.linear_model._stochastic_gradient.BaseSGDClassifier.partial_fit
msgid "Returns"
msgstr "Devuelve"

#: of sklearn.linear_model._base.LinearClassifierMixin.decision_function:28
msgid "array, shape=(n_samples,) if n_classes == 2 else (n_samples, n_classes)"
msgstr "array, shape=(n_samples,) if n_classes == 2 else (n_samples, n_classes)"

#: of sklearn.linear_model._base.LinearClassifierMixin.decision_function:15
msgid "Confidence scores per (sample, class) combination. In the binary case, confidence score for self.classes_[1] where >0 means this class would be predicted."
msgstr "Puntuaciones de confianza por combinación (muestra, clase). En el caso binario, la puntuación de confianza para self.classes_[1] donde >0 significa que esta clase sería predicha."

#: of sklearn.linear_model._base.SparseCoefMixin.densify:4
msgid "Converts the ``coef_`` member (back) to a numpy.ndarray. This is the default format of ``coef_`` and is required for fitting, so calling this method is only required on models that have previously been sparsified; otherwise, it is a no-op."
msgstr "Convierte el miembro ``coef_`` (de vuelta) en un numpy.ndarray. Este es el formato por defecto de ``coef_`` y se requiere para el ajuste, por lo que llamar a este método sólo es necesario en los modelos que han sido previamente sparsified; de lo contrario, es un no-op."

#: of sklearn.linear_model._base.SparseCoefMixin.densify:24
#: sklearn.linear_model._base.SparseCoefMixin.sparsify:21
msgid "self"
msgstr "self"

#: of sklearn.linear_model._base.SparseCoefMixin.densify:13
#: sklearn.linear_model._base.SparseCoefMixin.sparsify:14
msgid "Fitted estimator."
msgstr "Estimador ajustado."

#: of
msgid "{array-like, sparse matrix}, shape (n_samples, n_features)"
msgstr "{array-like, sparse matrix}, shape (n_samples, n_features)"

#: of sklearn.linear_model._stochastic_gradient.BaseSGDClassifier.fit:8
msgid "Training data."
msgstr "Datos de entrenamiento."

#: of sklearn.base.ClassifierMixin.score:14
#: sklearn.linear_model._stochastic_gradient.BaseSGDClassifier.fit:11
#: sklearn.linear_model._stochastic_gradient.BaseSGDClassifier.partial_fit:15
msgid "**y**"
msgstr "**y**"

#: of
msgid "ndarray of shape (n_samples,)"
msgstr "ndarray of shape (n_samples,)"

#: of sklearn.linear_model._stochastic_gradient.BaseSGDClassifier.fit:11
msgid "Target values."
msgstr "Valores objetivo."

#: of sklearn.linear_model._stochastic_gradient.BaseSGDClassifier.fit:14
msgid "**coef_init**"
msgstr "**coef_init**"

#: of
msgid "ndarray of shape (n_classes, n_features), default=None"
msgstr "ndarray of shape (n_classes, n_features), default=None"

#: of sklearn.linear_model._stochastic_gradient.BaseSGDClassifier.fit:14
msgid "The initial coefficients to warm-start the optimization."
msgstr "Los coeficientes iniciales para iniciar la optimización en caliente."

#: of sklearn.linear_model._stochastic_gradient.BaseSGDClassifier.fit:17
msgid "**intercept_init**"
msgstr "**intercept_init**"

#: of
msgid "ndarray of shape (n_classes,), default=None"
msgstr "ndarray of shape (n_classes,), default=None"

#: of sklearn.linear_model._stochastic_gradient.BaseSGDClassifier.fit:17
msgid "The initial intercept to warm-start the optimization."
msgstr "La intercepción inicial la optimización en caliente."

#: of sklearn.base.ClassifierMixin.score:17
#: sklearn.linear_model._stochastic_gradient.BaseSGDClassifier.fit:23
#: sklearn.linear_model._stochastic_gradient.BaseSGDClassifier.partial_fit:27
msgid "**sample_weight**"
msgstr "**sample_weight**"

#: of
msgid "array-like, shape (n_samples,), default=None"
msgstr "array-like, shape (n_samples,), default=None"

#: of sklearn.linear_model._stochastic_gradient.BaseSGDClassifier.fit:20
msgid "Weights applied to individual samples. If not provided, uniform weights are assumed. These weights will be multiplied with class_weight (passed through the constructor) if class_weight is specified."
msgstr "Ponderaciones aplicadas a las muestras individuales. Si no se proporciona, se asumen ponderados uniformes. Estas ponderaciones se multiplicarán por el peso de la clase (pasado a través del constructor) si se especifica el peso de la clase."

#: of sklearn.linear_model._stochastic_gradient.BaseSGDClassifier.fit:39
#: sklearn.linear_model._stochastic_gradient.BaseSGDClassifier.partial_fit:43
msgid "self :"
msgstr "self :"

#: of sklearn.linear_model._stochastic_gradient.BaseSGDClassifier.fit:28
#: sklearn.linear_model._stochastic_gradient.BaseSGDClassifier.partial_fit:32
msgid "Returns an instance of self."
msgstr "Devuelve una instancia de sí misma."

#: of sklearn.base.BaseEstimator.get_params:9
msgid "**deep**"
msgstr "**deep**"

#: of sklearn.base.BaseEstimator.get_params:8
msgid "If True, will return the parameters for this estimator and contained subobjects that are estimators."
msgstr "Si es True, devolverá los parámetros para este estimador y los sub objetos contenidos que son estimadores."

#: of sklearn.base.BaseEstimator.get_params:25
msgid "**params**"
msgstr "**params**"

#: of
msgid "dict"
msgstr "dict"

#: of sklearn.base.BaseEstimator.get_params:14
msgid "Parameter names mapped to their values."
msgstr "Nombres de parámetros mapeados a sus valores."

#: of sklearn.linear_model._stochastic_gradient.BaseSGDClassifier.partial_fit:4
msgid "Internally, this method uses ``max_iter = 1``. Therefore, it is not guaranteed that a minimum of the cost function is reached after calling it once. Matters such as objective convergence and early stopping should be handled by the user."
msgstr "Internamente, este método utiliza ``max_iter = 1``. Por lo tanto, no se garantiza que se alcance un mínimo de la función de coste después de llamarlo una vez. Cuestiones como la convergencia del objetivo y la parada anticipada deben ser manejadas por el usuario."

#: of
#: sklearn.linear_model._stochastic_gradient.BaseSGDClassifier.partial_fit:12
msgid "Subset of the training data."
msgstr "Subconjunto de los datos de entrenamiento."

#: of
#: sklearn.linear_model._stochastic_gradient.BaseSGDClassifier.partial_fit:15
msgid "Subset of the target values."
msgstr "Subconjunto de los valores objetivos."

#: of
#: sklearn.linear_model._stochastic_gradient.BaseSGDClassifier.partial_fit:23
msgid "**classes**"
msgstr "**classes**"

#: of
#: sklearn.linear_model._stochastic_gradient.BaseSGDClassifier.partial_fit:18
msgid "Classes across all calls to partial_fit. Can be obtained by via `np.unique(y_all)`, where y_all is the target vector of the entire dataset. This argument is required for the first call to partial_fit and can be omitted in the subsequent calls. Note that y doesn't need to contain all labels in `classes`."
msgstr "Clases a través de todas las llamadas a partial_fit. Puede obtenerse mediante `np.unique(y_all)`, donde y_all es el vector objetivo de todo el conjunto de datos. Este argumento es necesario para la primera llamada a partial_fit y puede omitirse en las siguientes. Tenga en cuenta que no es necesario que y contenga todas las etiquetas de `classes`."

#: of
#: sklearn.linear_model._stochastic_gradient.BaseSGDClassifier.partial_fit:26
msgid "Weights applied to individual samples. If not provided, uniform weights are assumed."
msgstr "Ponderaciones aplicadas a las muestras individuales. Si no se proporciona, se suponen ponderados uniformes."

#: of sklearn.linear_model._base.LinearClassifierMixin.predict:24
msgid "**C**"
msgstr "**C**"

#: of
msgid "array, shape [n_samples]"
msgstr "array, shape [n_samples]"

#: of sklearn.linear_model._base.LinearClassifierMixin.predict:13
msgid "Predicted class label per sample."
msgstr "Etiqueta de clase predicha por muestra."

#: of sklearn.linear_model.SGDClassifier.predict_log_proba:2
msgid "Log of probability estimates."
msgstr "Registro de estimaciones de probabilidad."

#: of sklearn.linear_model.SGDClassifier.predict_log_proba:4
#: sklearn.linear_model.SGDClassifier.predict_proba:4
msgid "This method is only available for log loss and modified Huber loss."
msgstr "Este método sólo está disponible para la pérdida de registro y la pérdida de Huber modificada."

#: of sklearn.linear_model.SGDClassifier.predict_log_proba:6
msgid "When loss=\"modified_huber\", probability estimates may be hard zeros and ones, so taking the logarithm is not possible."
msgstr "Cuando loss=\"modified_huber\", las estimaciones de probabilidad pueden ser ceros y unos enteros, por lo que no es posible tomar el logaritmo."

#: of sklearn.linear_model.SGDClassifier.predict_log_proba:9
msgid "See ``predict_proba`` for details."
msgstr "Ver ``predict_proba`` para más detalles."

#: of
msgid "{array-like, sparse matrix} of shape (n_samples, n_features)"
msgstr "{array-like, sparse matrix} of shape (n_samples, n_features)"

#: of sklearn.linear_model.SGDClassifier.predict_log_proba:14
#: sklearn.linear_model.SGDClassifier.predict_proba:19
msgid "Input data for prediction."
msgstr "Datos de entrada para predicción."

#: of sklearn.linear_model.SGDClassifier.predict_log_proba:32
msgid "**T**"
msgstr "**T**"

#: of
msgid "array-like, shape (n_samples, n_classes)"
msgstr "array-like, shape (n_samples, n_classes)"

#: of sklearn.linear_model.SGDClassifier.predict_log_proba:19
msgid "Returns the log-probability of the sample for each class in the model, where classes are ordered as they are in `self.classes_`."
msgstr "Devuelve la probabilidad logarítmica de la muestra para cada clase en el modelo, donde las clases están ordenadas como lo están en `self.classes_`."

#: of sklearn.linear_model.SGDClassifier.predict_proba:2
msgid "Probability estimates."
msgstr "Estimaciones de probabilidad."

#: of sklearn.linear_model.SGDClassifier.predict_proba:6
msgid "Multiclass probability estimates are derived from binary (one-vs.-rest) estimates by simple normalization, as recommended by Zadrozny and Elkan."
msgstr "Las estimaciones de probabilidad multiclase se derivan de las estimaciones binarias (uno contra resto) mediante una simple normalización, como recomiendan Zadrozny y Elkan."

#: of sklearn.linear_model.SGDClassifier.predict_proba:10
msgid "Binary probability estimates for loss=\"modified_huber\" are given by (clip(decision_function(X), -1, 1) + 1) / 2. For other loss functions it is necessary to perform proper probability calibration by wrapping the classifier with :class:`~sklearn.calibration.CalibratedClassifierCV` instead."
msgstr "Las estimaciones de probabilidad binarias para loss=\"modified_huber\" vienen dadas por (clip(decision_function(X), -1, 1) + 1) / 2. Para otras funciones de pérdida es necesario realizar una calibración de probabilidad adecuada envolviendo el clasificador con :class:`~sklearn.calibration.CalibratedClassifierCV` en su lugar."

#: of sklearn.linear_model.SGDClassifier.predict_proba:33
msgid "ndarray of shape (n_samples, n_classes)"
msgstr "ndarray of shape (n_samples, n_classes)"

#: of sklearn.linear_model.SGDClassifier.predict_proba:24
msgid "Returns the probability of the sample for each class in the model, where classes are ordered as they are in `self.classes_`."
msgstr "Devuelve la probabilidad de la muestra para cada clase en el modelo, donde las clases se ordenan como están en `self.classes_`."

#: of sklearn.linear_model.SGDClassifier.predict_proba:36
msgid "References"
msgstr "Referencias"

#: of sklearn.linear_model.SGDClassifier.predict_proba:37
msgid "Zadrozny and Elkan, \"Transforming classifier scores into multiclass probability estimates\", SIGKDD'02, http://www.research.ibm.com/people/z/zadrozny/kdd2002-Transf.pdf"
msgstr "Zadrozny and Elkan, \"Transforming classifier scores into multiclass probability estimates\", SIGKDD'02, http://www.research.ibm.com/people/z/zadrozny/kdd2002-Transf.pdf"

#: of sklearn.linear_model.SGDClassifier.predict_proba:41
msgid "The justification for the formula in the loss=\"modified_huber\" case is in the appendix B in: http://jmlr.csail.mit.edu/papers/volume2/zhang02c/zhang02c.pdf"
msgstr "The justification for the formula in the loss=\"modified_huber\" case is in the appendix B in: http://jmlr.csail.mit.edu/papers/volume2/zhang02c/zhang02c.pdf"

#: of sklearn.base.ClassifierMixin.score:4
msgid "In multi-label classification, this is the subset accuracy which is a harsh metric since you require for each sample that each label set be correctly predicted."
msgstr "En la clasificación multietiqueta, se trata de la precisión del subconjunto, que es una métrica dura, ya que se requiere para cada muestra que cada conjunto de etiquetas se prediga correctamente."

#: of
msgid "array-like of shape (n_samples, n_features)"
msgstr "array-like of shape (n_samples, n_features)"

#: of sklearn.base.ClassifierMixin.score:11
msgid "Test samples."
msgstr "Muestras de prueba."

#: of
msgid "array-like of shape (n_samples,) or (n_samples, n_outputs)"
msgstr "array-like of shape (n_samples,) or (n_samples, n_outputs)"

#: of sklearn.base.ClassifierMixin.score:14
msgid "True labels for `X`."
msgstr "Etiquetas verdaderas para `X`."

#: of
msgid "array-like of shape (n_samples,), default=None"
msgstr "array-like of shape (n_samples,), default=None"

#: of sklearn.base.ClassifierMixin.score:17
msgid "Sample weights."
msgstr "Ponderados de muestras."

#: of sklearn.base.ClassifierMixin.score:33
msgid "**score**"
msgstr "**score**"

#: of
msgid "float"
msgstr "float"

#: of sklearn.base.ClassifierMixin.score:22
msgid "Mean accuracy of ``self.predict(X)`` wrt. `y`."
msgstr "Precisión media de ``self.predict(X)`` con relación a `y`."

#: of sklearn.linear_model._stochastic_gradient.BaseSGD.set_params:8
msgid "**\\*\\*kwargs**"
msgstr "**\\*\\*kwargs**"

#: of sklearn.linear_model._stochastic_gradient.BaseSGD.set_params:8
msgid "Estimator parameters."
msgstr "Parámetros del estimador."

#: of sklearn.linear_model._stochastic_gradient.BaseSGD.set_params:24
msgid "**self**"
msgstr "**self**"

#: of
msgid "object"
msgstr "object"

#: of sklearn.linear_model._stochastic_gradient.BaseSGD.set_params:13
msgid "Estimator instance."
msgstr "Instancia de estimador."

#: of sklearn.linear_model._base.SparseCoefMixin.sparsify:4
msgid "Converts the ``coef_`` member to a scipy.sparse matrix, which for L1-regularized models can be much more memory- and storage-efficient than the usual numpy.ndarray representation."
msgstr "Convierte el miembro ``coef_`` en una matriz scipy.sparse, que para los modelos L1-regularizados puede ser mucho más eficiente en cuanto a memoria y almacenamiento que la representación numpy.ndarray habitual."

#: of sklearn.linear_model._base.SparseCoefMixin.sparsify:8
msgid "The ``intercept_`` member is not converted."
msgstr "El miembro ``intercept_`` no se convierte."

#: of sklearn.linear_model._base.SparseCoefMixin.sparsify:24
msgid "Notes"
msgstr "Notas"

#: of sklearn.linear_model._base.SparseCoefMixin.sparsify:25
#, python-format
msgid "For non-sparse models, i.e. when there are not many zeros in ``coef_``, this may actually *increase* memory usage, so use this method with care. A rule of thumb is that the number of zero elements, which can be computed with ``(coef_ == 0).sum()``, must be more than 50% for this to provide significant benefits."
msgstr "Para los modelos no dispersos, es decir, cuando no hay muchos ceros en ``coef_``, esto puede en realidad *aumentar* el uso de la memoria, así que utilice este método con cuidado. Una regla general es que el número de elementos cero, que puede ser calculado con ``(coef_ == 0).sum()``, debe ser más del 50% para que esto proporcione beneficios significativos."

#: of sklearn.linear_model._base.SparseCoefMixin.sparsify:31
msgid "After calling this method, further fitting with the partial_fit method (if any) will not work until you call densify."
msgstr "Después de llamar a este método, el ajuste posterior con el método partial_fit (si lo hay) no funcionará hasta que llame a densify."

#: ../modules/generated/sklearn.linear_model.SGDClassifier.examples:4
msgid "Examples using ``sklearn.linear_model.SGDClassifier``"
msgstr "Ejemplos usando ``sklearn.linear_model.SGDClassifier``"

#: ../modules/generated/sklearn.linear_model.SGDClassifier.examples:15
#: ../modules/generated/sklearn.linear_model.SGDClassifier.examples:23
msgid ":ref:`sphx_glr_auto_examples_model_selection_grid_search_text_feature_extraction.py`"
msgstr ":ref:`sphx_glr_auto_examples_model_selection_grid_search_text_feature_extraction.py`"

#~ msgid ":ref:`sphx_glr_auto_examples_linear_model_plot_sgd_iris.py`"
#~ msgstr ""

#~ msgid ":ref:`sphx_glr_auto_examples_linear_model_plot_sgd_early_stopping.py`"
#~ msgstr ""

#~ msgid ":ref:`sphx_glr_auto_examples_miscellaneous_plot_kernel_approximation.py`"
#~ msgstr ""

#~ msgid ":ref:`sphx_glr_auto_examples_model_selection_plot_randomized_search.py`"
#~ msgstr ""

#~ msgid ":ref:`sphx_glr_auto_examples_semi_supervised_plot_semi_supervised_newsgroups.py`"
#~ msgstr ""

#~ msgid ":ref:`sphx_glr_auto_examples_text_plot_document_classification_20newsgroups.py`"
#~ msgstr ""

