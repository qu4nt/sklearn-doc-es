msgid ""
msgstr ""
"Project-Id-Version: scikit-learn\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-03-31 11:24-0400\n"
"PO-Revision-Date: 2021-07-17 16:18\n"
"Last-Translator: \n"
"Language-Team: Spanish\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Crowdin-Project: scikit-learn\n"
"X-Crowdin-Project-ID: 450526\n"
"X-Crowdin-Language: es-ES\n"
"X-Crowdin-File: /main/doc/en/modules/generated/sklearn.preprocessing.power_transform.po\n"
"X-Crowdin-File-ID: 5242\n"
"Language: es_ES\n"

#: ../modules/generated/sklearn.preprocessing.power_transform.rst:2
msgid ":mod:`sklearn.preprocessing`.power_transform"
msgstr ":mod:`sklearn.preprocessing`.power_transform"

#: of sklearn.preprocessing._data.power_transform:2
msgid "Power transforms are a family of parametric, monotonic transformations that are applied to make data more Gaussian-like. This is useful for modeling issues related to heteroscedasticity (non-constant variance), or other situations where normality is desired."
msgstr "Las transformaciones de potencia son una familia de transformaciones paramétricas y monótonas que se aplican para que los datos sean más Gaussianos. Esto es útil para modelar problemas relacionados con la heteroscedasticidad (varianza no constante), u otras situaciones en las que se desea la normalidad."

#: of sklearn.preprocessing._data.power_transform:7
msgid "Currently, power_transform supports the Box-Cox transform and the Yeo-Johnson transform. The optimal parameter for stabilizing variance and minimizing skewness is estimated through maximum likelihood."
msgstr "Actualmente, power_transform admite la transformación Box-Cox y la transformación Yeo-Johnson. El parámetro óptimo para estabilizar la varianza y minimizar la asimetría se estima mediante la máxima verosimilitud."

#: of sklearn.preprocessing._data.power_transform:11
msgid "Box-Cox requires input data to be strictly positive, while Yeo-Johnson supports both positive or negative data."
msgstr "Box-Cox requiere que los datos de entrada sean estrictamente positivos, mientras que Yeo-Johnson admite tanto datos positivos como negativos."

#: of sklearn.preprocessing._data.power_transform:14
msgid "By default, zero-mean, unit-variance normalization is applied to the transformed data."
msgstr "Por defecto, se aplica a los datos transformados una normalización de media cero y varianza unitaria."

#: of sklearn.preprocessing._data.power_transform:17
msgid "Read more in the :ref:`User Guide <preprocessing_transformer>`."
msgstr "Lee más en el :ref:`Manual de usuario <preprocessing_transformer>`."

#: of sklearn.preprocessing._data.power_transform
msgid "Parameters"
msgstr "Parámetros"

#: of sklearn.preprocessing._data.power_transform:22
msgid "**X**"
msgstr "**X**"

#: of
msgid "array-like of shape (n_samples, n_features)"
msgstr "array-like de forma (n_samples, n_features)"

#: of sklearn.preprocessing._data.power_transform:22
msgid "The data to be transformed using a power transformation."
msgstr "Los datos a transformar mediante una transformación de potencia."

#: of sklearn.preprocessing._data.power_transform:32
msgid "**method**"
msgstr "**method**"

#: of
msgid "{'yeo-johnson', 'box-cox'}, default='yeo-johnson'"
msgstr "{'yeo-johnson', 'box-cox'}, default='yeo-johnson'"

#: of sklearn.preprocessing._data.power_transform:25
msgid "The power transform method. Available methods are:"
msgstr "El método de transformación de potencia. Los métodos disponibles son:"

#: of sklearn.preprocessing._data.power_transform:27
msgid "'yeo-johnson' [R742a88cfa144-1]_, works with positive and negative values"
msgstr "'yeo-johnson' [R742a88cfa144-1]_, funciona con valores positivos y negativos"

#: of sklearn.preprocessing._data.power_transform:28
msgid "'box-cox' [R742a88cfa144-2]_, only works with strictly positive values"
msgstr "'box-cox' [R742a88cfa144-2]_, sólo funciona con valores estrictamente positivos"

#: of sklearn.preprocessing._data.power_transform:30
msgid "The default value of the `method` parameter changed from 'box-cox' to 'yeo-johnson' in 0.23."
msgstr "El valor predeterminado del parámetro `method` cambió de 'box-cox' a 'yeo-johnson' en 0.23."

#: of sklearn.preprocessing._data.power_transform:36
msgid "**standardize**"
msgstr "**standardize**"

#: of
msgid "bool, default=True"
msgstr "bool, default=True"

#: of sklearn.preprocessing._data.power_transform:35
msgid "Set to True to apply zero-mean, unit-variance normalization to the transformed output."
msgstr "Establecélo en True para aplicar una normalización de media cero y varianza unitaria a la salida transformada."

#: of sklearn.preprocessing._data.power_transform:39
msgid "**copy**"
msgstr "**copy**"

#: of sklearn.preprocessing._data.power_transform:39
msgid "Set to False to perform inplace computation during transformation."
msgstr "Establécelo en False para realizar cálculos in situ durante la transformación."

#: of sklearn.preprocessing._data.power_transform
msgid "Returns"
msgstr "Devuelve"

#: of sklearn.preprocessing._data.power_transform:50
msgid "**X_trans**"
msgstr "**X_trans**"

#: of
msgid "ndarray of shape (n_samples, n_features)"
msgstr "ndarray de forma (n_samples, n_features)"

#: of sklearn.preprocessing._data.power_transform:44
msgid "The transformed data."
msgstr "Los datos transformados."

#: of sklearn.preprocessing._data.power_transform:55
msgid ":obj:`PowerTransformer`"
msgstr ":obj:`PowerTransformer`"

#: of sklearn.preprocessing._data.power_transform:56
msgid "Equivalent transformation with the Transformer API (e.g. as part of a preprocessing :class:`~sklearn.pipeline.Pipeline`)."
msgstr "Transformación equivalente con la API Transformer (por ejemplo, como parte de un :class:`~sklearn.pipeline.Pipeline` de preprocesamiento)."

#: of sklearn.preprocessing._data.power_transform:57
msgid ":obj:`quantile_transform`"
msgstr ":obj:`quantile_transform`"

#: of sklearn.preprocessing._data.power_transform:58
msgid "Maps data to a standard normal distribution with the parameter `output_distribution='normal'`."
msgstr "Mapea los datos a una distribución normal estándar con el parámetro `output_distribution='normal'`."

#: of sklearn.preprocessing._data.power_transform:62
msgid "Notes"
msgstr "Notas"

#: of sklearn.preprocessing._data.power_transform:63
msgid "NaNs are treated as missing values: disregarded in ``fit``, and maintained in ``transform``."
msgstr "Los NaNs son tratados como valores faltantes: no se tienen en cuenta en ``fit`` y se mantienen en ``transform``."

#: of sklearn.preprocessing._data.power_transform:66
msgid "For a comparison of the different scalers, transformers, and normalizers, see :ref:`examples/preprocessing/plot_all_scaling.py <sphx_glr_auto_examples_preprocessing_plot_all_scaling.py>`."
msgstr "Para una comparación de los diferentes escaladores, transformadores y normalizadores, consulta :ref:`examples/preprocessing/plot_all_scaling.py <sphx_glr_auto_examples_preprocessing_plot_all_scaling.py>`."

#: of sklearn.preprocessing._data.power_transform:71
msgid "References"
msgstr "Referencias"

#: of sklearn.preprocessing._data.power_transform:72
msgid "I.K. Yeo and R.A. Johnson, \"A new family of power transformations to improve normality or symmetry.\" Biometrika, 87(4), pp.954-959, (2000)."
msgstr "I.K. Yeo and R.A. Johnson, \"A new family of power transformations to improve normality or symmetry.\" Biometrika, 87(4), pp.954-959, (2000)."

#: of sklearn.preprocessing._data.power_transform:76
msgid "G.E.P. Box and D.R. Cox, \"An Analysis of Transformations\", Journal of the Royal Statistical Society B, 26, 211-252 (1964)."
msgstr "G.E.P. Box and D.R. Cox, \"An Analysis of Transformations\", Journal of the Royal Statistical Society B, 26, 211-252 (1964)."

#: of sklearn.preprocessing._data.power_transform:81
msgid "[R742a88cfa144-1]_, [R742a88cfa144-2]_"
msgstr "[R742a88cfa144-1]_, [R742a88cfa144-2]_"

#: of sklearn.preprocessing._data.power_transform:84
msgid "Examples"
msgstr "Ejemplos"

#: of sklearn.preprocessing._data.power_transform:93
msgid "Risk of data leak. Do not use :func:`~sklearn.preprocessing.power_transform` unless you know what you are doing. A common mistake is to apply it to the entire data *before* splitting into training and test sets. This will bias the model evaluation because information would have leaked from the test set to the training set. In general, we recommend using :class:`~sklearn.preprocessing.PowerTransformer` within a :ref:`Pipeline <pipeline>` in order to prevent most risks of data leaking, e.g.: `pipe = make_pipeline(PowerTransformer(), LogisticRegression())`."
msgstr "Riesgo de fuga de datos. No utilices :func:`~sklearn.preprocessing.power_transform` a menos que sepas lo que estás haciendo. Un error común es aplicarlo a todos los datos *antes* de dividirlos en conjuntos de entrenamiento y prueba. Esto sesgará la evaluación del modelo porque la información se habrá filtrado del conjunto de prueba al conjunto de entrenamiento. En general, recomendamos utilizar :class:`~sklearn.preprocessing.PowerTransformer` dentro de un :ref:`Pipeline <pipeline>` para evitar la mayoría de los riesgos de fuga de datos, por ejemplo `pipe = make_pipeline(PowerTransformer(), LogisticRegression())`."

