msgid ""
msgstr ""
"Project-Id-Version: scikit-learn\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-03-31 11:24-0400\n"
"PO-Revision-Date: 2021-05-18 03:31\n"
"Last-Translator: \n"
"Language-Team: Spanish\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Crowdin-Project: scikit-learn\n"
"X-Crowdin-Project-ID: 450526\n"
"X-Crowdin-Language: es-ES\n"
"X-Crowdin-File: /main/doc/en/modules/generated/sklearn.decomposition.LatentDirichletAllocation.po\n"
"X-Crowdin-File-ID: 5730\n"
"Language: es_ES\n"

#: ../modules/generated/sklearn.decomposition.LatentDirichletAllocation.rst:2
msgid ":mod:`sklearn.decomposition`.LatentDirichletAllocation"
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:2
msgid "Latent Dirichlet Allocation with online variational Bayes algorithm"
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:6
msgid "Read more in the :ref:`User Guide <LatentDirichletAllocation>`."
msgstr ""

#: of sklearn.base.BaseEstimator.get_params
#: sklearn.base.BaseEstimator.set_params
#: sklearn.base.TransformerMixin.fit_transform
#: sklearn.decomposition._lda.LatentDirichletAllocation
#: sklearn.decomposition._lda.LatentDirichletAllocation.fit
#: sklearn.decomposition._lda.LatentDirichletAllocation.partial_fit
#: sklearn.decomposition._lda.LatentDirichletAllocation.perplexity
#: sklearn.decomposition._lda.LatentDirichletAllocation.score
#: sklearn.decomposition._lda.LatentDirichletAllocation.transform
msgid "Parameters"
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:14
msgid "**n_components**"
msgstr "**n_components**"

#: of
msgid "int, default=10"
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:11
msgid "Number of topics."
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:13
msgid "``n_topics`` was renamed to ``n_components``"
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:19
msgid "**doc_topic_prior**"
msgstr ""

#: of
msgid "float, default=None"
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:17
msgid "Prior of document topic distribution `theta`. If the value is None, defaults to `1 / n_components`. In [Re25e5648fc37-1]_, this is called `alpha`."
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:24
msgid "**topic_word_prior**"
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:22
msgid "Prior of topic word distribution `beta`. If the value is None, defaults to `1 / n_components`. In [Re25e5648fc37-1]_, this is called `eta`."
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:42
msgid "**learning_method**"
msgstr ""

#: of
msgid "{'batch', 'online'}, default='batch'"
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:27
msgid "Method used to update `_component`. Only used in :meth:`fit` method. In general, if the data size is large, the online update will be much faster than the batch update."
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:31
msgid "Valid options::"
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:41
msgid "The default learning method is now ``\"batch\"``."
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:49
msgid "**learning_decay**"
msgstr ""

#: of
msgid "float, default=0.7"
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:45
msgid "It is a parameter that control learning rate in the online learning method. The value should be set between (0.5, 1.0] to guarantee asymptotic convergence. When the value is 0.0 and batch_size is ``n_samples``, the update method is same as batch learning. In the literature, this is called kappa."
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:54
msgid "**learning_offset**"
msgstr ""

#: of
msgid "float, default=10."
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:52
msgid "A (positive) parameter that downweights early iterations in online learning.  It should be greater than 1.0. In the literature, this is called tau_0."
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:57
msgid "**max_iter**"
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:57
msgid "The maximum number of iterations."
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:61
msgid "**batch_size**"
msgstr ""

#: of
msgid "int, default=128"
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:60
msgid "Number of documents to use in each EM iteration. Only used in online learning."
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:69
msgid "**evaluate_every**"
msgstr ""

#: of
msgid "int, default=-1"
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:64
msgid "How often to evaluate perplexity. Only used in `fit` method. set it to 0 or negative number to not evaluate perplexity in training at all. Evaluating perplexity can help you check convergence in training process, but it will also increase total training time. Evaluating perplexity in every iteration might increase training time up to two-fold."
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:72
msgid "**total_samples**"
msgstr ""

#: of
msgid "int, default=1e6"
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:72
msgid "Total number of documents. Only used in the :meth:`partial_fit` method."
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:76
msgid "**perp_tol**"
msgstr ""

#: of
msgid "float, default=1e-1"
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:75
msgid "Perplexity tolerance in batch learning. Only used when ``evaluate_every`` is greater than 0."
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:79
msgid "**mean_change_tol**"
msgstr ""

#: of
msgid "float, default=1e-3"
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:79
msgid "Stopping tolerance for updating document topic distribution in E-step."
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:83
msgid "**max_doc_update_iter**"
msgstr ""

#: of
msgid "int, default=100"
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:82
msgid "Max number of iterations for updating document topic distribution in the E-step."
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:89
msgid "**n_jobs**"
msgstr ""

#: of
msgid "int, default=None"
msgstr "int, default=None"

#: of sklearn.decomposition._lda.LatentDirichletAllocation:86
msgid "The number of jobs to use in the E-step. ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context. ``-1`` means using all processors. See :term:`Glossary <n_jobs>` for more details."
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:92
msgid "**verbose**"
msgstr ""

#: of
msgid "int, default=0"
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:92
msgid "Verbosity level."
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:99
msgid "**random_state**"
msgstr ""

#: of
msgid "int, RandomState instance or None, default=None"
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:95
msgid "Pass an int for reproducible results across multiple function calls. See :term:`Glossary <random_state>`."
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation
msgid "Attributes"
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:110
msgid "**components_**"
msgstr ""

#: of
msgid "ndarray of shape (n_components, n_features)"
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:104
msgid "Variational parameters for topic word distribution. Since the complete conditional for topic word distribution is a Dirichlet, ``components_[i, j]`` can be viewed as pseudocount that represents the number of times word `j` was assigned to topic `i`. It can also be viewed as distribution over the words for each topic after normalization: ``model.components_ / model.components_.sum(axis=1)[:, np.newaxis]``."
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:114
msgid "**exp_dirichlet_component_**"
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:113
msgid "Exponential value of expectation of log topic word distribution. In the literature, this is `exp(E[log(beta)])`."
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:117
msgid "**n_batch_iter_**"
msgstr ""

#: of
msgid "int"
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:117
msgid "Number of iterations of the EM step."
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:120
msgid "**n_iter_**"
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:120
msgid "Number of passes over the dataset."
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:123
msgid "**bound_**"
msgstr ""

#: of
msgid "float"
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:123
msgid "Final perplexity score on training set."
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:127
msgid "**doc_topic_prior_**"
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:126
msgid "Prior of document topic distribution `theta`. If the value is None, it is `1 / n_components`."
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:131
msgid "**random_state_**"
msgstr ""

#: of
msgid "RandomState instance"
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:130
msgid "RandomState instance that is generated either from a seed, the random number generator or by `np.random`."
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:140
msgid "**topic_word_prior_**"
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:134
msgid "Prior of topic word distribution `beta`. If the value is None, it is `1 / n_components`."
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:143
msgid "References"
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:144
msgid "\"Online Learning for Latent Dirichlet Allocation\", Matthew D. Hoffman, David M. Blei, Francis Bach, 2010"
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:148
msgid "[2] \"Stochastic Variational Inference\", Matthew D. Hoffman, David M. Blei,"
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:148
msgid "Chong Wang, John Paisley, 2013"
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:151
msgid "[3] Matthew D. Hoffman's onlineldavb code. Link:"
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:151
msgid "https://github.com/blei-lab/onlineldavb"
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:155
msgid "[Re25e5648fc37-1]_"
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:158
msgid "Examples"
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:174
msgid "Methods"
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:185:<autosummary>:1
msgid ":obj:`fit <sklearn.decomposition.LatentDirichletAllocation.fit>`\\"
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation.fit:2
#: sklearn.decomposition._lda.LatentDirichletAllocation:185:<autosummary>:1
msgid "Learn model for the data X with variational Bayes method."
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:185:<autosummary>:1
msgid ":obj:`fit_transform <sklearn.decomposition.LatentDirichletAllocation.fit_transform>`\\"
msgstr ""

#: of sklearn.base.TransformerMixin.fit_transform:2
#: sklearn.decomposition._lda.LatentDirichletAllocation:185:<autosummary>:1
msgid "Fit to data, then transform it."
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:185:<autosummary>:1
msgid ":obj:`get_params <sklearn.decomposition.LatentDirichletAllocation.get_params>`\\"
msgstr ""

#: of sklearn.base.BaseEstimator.get_params:2
#: sklearn.decomposition._lda.LatentDirichletAllocation:185:<autosummary>:1
msgid "Get parameters for this estimator."
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:185:<autosummary>:1
msgid ":obj:`partial_fit <sklearn.decomposition.LatentDirichletAllocation.partial_fit>`\\"
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation.partial_fit:2
#: sklearn.decomposition._lda.LatentDirichletAllocation:185:<autosummary>:1
msgid "Online VB with Mini-Batch update."
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:185:<autosummary>:1
msgid ":obj:`perplexity <sklearn.decomposition.LatentDirichletAllocation.perplexity>`\\"
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation.perplexity:2
#: sklearn.decomposition._lda.LatentDirichletAllocation:185:<autosummary>:1
msgid "Calculate approximate perplexity for data X."
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:185:<autosummary>:1
msgid ":obj:`score <sklearn.decomposition.LatentDirichletAllocation.score>`\\"
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation.score:2
#: sklearn.decomposition._lda.LatentDirichletAllocation:185:<autosummary>:1
msgid "Calculate approximate log-likelihood as score."
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:185:<autosummary>:1
msgid ":obj:`set_params <sklearn.decomposition.LatentDirichletAllocation.set_params>`\\"
msgstr ""

#: of sklearn.base.BaseEstimator.set_params:2
#: sklearn.decomposition._lda.LatentDirichletAllocation:185:<autosummary>:1
msgid "Set the parameters of this estimator."
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation:185:<autosummary>:1
msgid ":obj:`transform <sklearn.decomposition.LatentDirichletAllocation.transform>`\\"
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation.transform:2
#: sklearn.decomposition._lda.LatentDirichletAllocation:185:<autosummary>:1
msgid "Transform data X according to the fitted model."
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation.fit:4
msgid "When `learning_method` is 'online', use mini-batch update. Otherwise, use batch update."
msgstr ""

#: of sklearn.base.TransformerMixin.fit_transform:10
#: sklearn.decomposition._lda.LatentDirichletAllocation.fit:10
#: sklearn.decomposition._lda.LatentDirichletAllocation.partial_fit:8
#: sklearn.decomposition._lda.LatentDirichletAllocation.perplexity:13
#: sklearn.decomposition._lda.LatentDirichletAllocation.score:8
#: sklearn.decomposition._lda.LatentDirichletAllocation.transform:10
msgid "**X**"
msgstr ""

#: of
msgid "{array-like, sparse matrix} of shape (n_samples, n_features)"
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation.fit:10
#: sklearn.decomposition._lda.LatentDirichletAllocation.partial_fit:8
#: sklearn.decomposition._lda.LatentDirichletAllocation.perplexity:13
#: sklearn.decomposition._lda.LatentDirichletAllocation.score:8
#: sklearn.decomposition._lda.LatentDirichletAllocation.transform:10
msgid "Document word matrix."
msgstr ""

#: of sklearn.base.TransformerMixin.fit_transform:13
#: sklearn.decomposition._lda.LatentDirichletAllocation.fit:13
#: sklearn.decomposition._lda.LatentDirichletAllocation.partial_fit:11
#: sklearn.decomposition._lda.LatentDirichletAllocation.score:11
msgid "**y**"
msgstr ""

#: of
msgid "Ignored"
msgstr ""

#: of sklearn.base.BaseEstimator.get_params
#: sklearn.base.BaseEstimator.set_params
#: sklearn.base.TransformerMixin.fit_transform
#: sklearn.decomposition._lda.LatentDirichletAllocation.fit
#: sklearn.decomposition._lda.LatentDirichletAllocation.partial_fit
#: sklearn.decomposition._lda.LatentDirichletAllocation.perplexity
#: sklearn.decomposition._lda.LatentDirichletAllocation.score
#: sklearn.decomposition._lda.LatentDirichletAllocation.transform
msgid "Returns"
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation.fit:29
#: sklearn.decomposition._lda.LatentDirichletAllocation.partial_fit:27
msgid "self"
msgstr ""

#: of sklearn.base.TransformerMixin.fit_transform:4
msgid "Fits transformer to `X` and `y` with optional parameters `fit_params` and returns a transformed version of `X`."
msgstr ""

#: of
msgid "array-like of shape (n_samples, n_features)"
msgstr ""

#: of sklearn.base.TransformerMixin.fit_transform:10
msgid "Input samples."
msgstr ""

#: of
msgid "array-like of shape (n_samples,) or (n_samples, n_outputs),                 default=None"
msgstr ""

#: of sklearn.base.TransformerMixin.fit_transform:13
msgid "Target values (None for unsupervised transformations)."
msgstr ""

#: of sklearn.base.TransformerMixin.fit_transform:16
msgid "**\\*\\*fit_params**"
msgstr ""

#: of
msgid "dict"
msgstr ""

#: of sklearn.base.TransformerMixin.fit_transform:16
msgid "Additional fit parameters."
msgstr ""

#: of sklearn.base.TransformerMixin.fit_transform:32
msgid "**X_new**"
msgstr ""

#: of
msgid "ndarray array of shape (n_samples, n_features_new)"
msgstr ""

#: of sklearn.base.TransformerMixin.fit_transform:21
msgid "Transformed array."
msgstr "Arreglo transformado."

#: of sklearn.base.BaseEstimator.get_params:9
msgid "**deep**"
msgstr ""

#: of
msgid "bool, default=True"
msgstr "bool, default=True"

#: of sklearn.base.BaseEstimator.get_params:8
msgid "If True, will return the parameters for this estimator and contained subobjects that are estimators."
msgstr "Si es True, devolverá los parámetros para este estimador y los subobjetos contenidos que son estimadores."

#: of sklearn.base.BaseEstimator.get_params:25
msgid "**params**"
msgstr "**params**"

#: of sklearn.base.BaseEstimator.get_params:14
msgid "Parameter names mapped to their values."
msgstr "Nombres de parámetros mapeados a sus valores."

#: of sklearn.decomposition._lda.LatentDirichletAllocation.perplexity:4
msgid "Perplexity is defined as exp(-1. * log-likelihood per word)"
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation.perplexity:6
msgid "*doc_topic_distr* argument has been deprecated and is ignored because user no longer has access to unnormalized distribution"
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation.perplexity:16
msgid "**sub_sampling**"
msgstr ""

#: of
msgid "bool"
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation.perplexity:16
msgid "Do sub-sampling or not."
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation.perplexity:32
#: sklearn.decomposition._lda.LatentDirichletAllocation.score:27
msgid "**score**"
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation.perplexity:21
msgid "Perplexity score."
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation.score:16
msgid "Use approximate bound as score."
msgstr ""

#: of sklearn.base.BaseEstimator.set_params:4
msgid "The method works on simple estimators as well as on nested objects (such as :class:`~sklearn.pipeline.Pipeline`). The latter have parameters of the form ``<component>__<parameter>`` so that it's possible to update each component of a nested object."
msgstr "El método funciona tanto en estimadores simples como en objetos anidados (como :class:`~sklearn.pipeline.Pipeline`). Estos últimos tienen parámetros de la forma ``<component>__<parameter>`` para que sea posible actualizar cada componente de un objeto anidado."

#: of sklearn.base.BaseEstimator.set_params:12
msgid "**\\*\\*params**"
msgstr ""

#: of sklearn.base.BaseEstimator.set_params:12
msgid "Estimator parameters."
msgstr ""

#: of sklearn.base.BaseEstimator.set_params:28
msgid "**self**"
msgstr ""

#: of
msgid "estimator instance"
msgstr ""

#: of sklearn.base.BaseEstimator.set_params:17
msgid "Estimator instance."
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation.transform:4
msgid "*doc_topic_distr* is now normalized"
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation.transform:26
msgid "**doc_topic_distr**"
msgstr ""

#: of
msgid "ndarray of shape (n_samples, n_components)"
msgstr ""

#: of sklearn.decomposition._lda.LatentDirichletAllocation.transform:15
msgid "Document topic distribution for X."
msgstr ""

