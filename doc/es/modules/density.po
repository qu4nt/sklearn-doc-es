msgid ""
msgstr ""
"Project-Id-Version: scikit-learn\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-03-31 11:24-0400\n"
"PO-Revision-Date: 2021-04-28 19:00\n"
"Last-Translator: \n"
"Language-Team: Spanish\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Crowdin-Project: scikit-learn\n"
"X-Crowdin-Project-ID: 450526\n"
"X-Crowdin-Language: es-ES\n"
"X-Crowdin-File: /main/doc/en/modules/density.po\n"
"X-Crowdin-File-ID: 5938\n"
"Language: es_ES\n"

#: ../modules/density.rst:5
msgid "Density Estimation"
msgstr "Estimación de densidad"

#: ../modules/density.rst:8
msgid "Density estimation walks the line between unsupervised learning, feature engineering, and data modeling.  Some of the most popular and useful density estimation techniques are mixture models such as Gaussian Mixtures (:class:`~sklearn.mixture.GaussianMixture`), and neighbor-based approaches such as the kernel density estimate (:class:`~sklearn.neighbors.KernelDensity`). Gaussian Mixtures are discussed more fully in the context of :ref:`clustering <clustering>`, because the technique is also useful as an unsupervised clustering scheme."
msgstr "La estimación de densidad recorre la línea entre el aprendizaje no supervisado, la ingeniería de características y el modelado de datos. Algunas de las técnicas de estimación de densidad más populares y útiles son los modelos de mezcla tales como Mezclas Gaussianas (:class:`~sklearn.mixture.GaussianMixture`), y enfoques basados en vecinos, como la estimación de densidad del kernel (:class:`~sklearn.neighbors.KernelDensity`). Las Mezclas Gaussianas se discuten más ampliamente en el contexto de :ref:`Análisis de conglomerados <clustering>`, porque la técnica también es útil como un esquema de análisis de conglomerados no supervisado."

#: ../modules/density.rst:18
msgid "Density estimation is a very simple concept, and most people are already familiar with one common density estimation technique: the histogram."
msgstr "La estimación de densidad es un concepto muy simple, y la mayoría de personas ya está familiarizada con una técnica común de estimación de densidad: el histograma."

#: ../modules/density.rst:22
msgid "Density Estimation: Histograms"
msgstr "Estimación de Densidad: Histogramas"

#: ../modules/density.rst:23
msgid "A histogram is a simple visualization of data where bins are defined, and the number of data points within each bin is tallied.  An example of a histogram can be seen in the upper-left panel of the following figure:"
msgstr "Un histograma es una visualización de datos simple donde se definen los intervalos y se cuenta el número de puntos de datos dentro de cada intervalo. Un ejemplo de un histograma puedes verlo en el panel superior izquierdo de la siguiente figura:"

#: ../modules/density.rst:32
msgid "hist_to_kde"
msgstr "hist_to_kde"

#: ../modules/density.rst:33
msgid "A major problem with histograms, however, is that the choice of binning can have a disproportionate effect on the resulting visualization.  Consider the upper-right panel of the above figure.  It shows a histogram over the same data, with the bins shifted right.  The results of the two visualizations look entirely different, and might lead to different interpretations of the data."
msgstr "Sin embargo, un problema importante con los histogramas es que la elección de la agrupación de los intervalos puede tener un efecto desproporcionado en la visualización resultante. Considera el panel superior derecho de la figura anterior. Muestra un histograma sobre los mismos datos, con los intervalos desplazados a la derecha. Los resultados de las dos visualizaciones se ven completamente diferentes y pueden llevar a diferentes interpretaciones de los datos."

#: ../modules/density.rst:39
msgid "Intuitively, one can also think of a histogram as a stack of blocks, one block per point.  By stacking the blocks in the appropriate grid space, we recover the histogram.  But what if, instead of stacking the blocks on a regular grid, we center each block on the point it represents, and sum the total height at each location?  This idea leads to the lower-left visualization.  It is perhaps not as clean as a histogram, but the fact that the data drive the block locations mean that it is a much better representation of the underlying data."
msgstr "Intuitivamente, también se puede pensar en un histograma como una pila de bloques, un bloque por punto.  Apilando los bloques en el espacio de la cuadrícula apropiado, recuperamos el histograma.  ¿Pero qué pasa si, en lugar de apilar los bloques en una cuadrícula regular, centramos cada bloque en el punto que representa y sumamos la altura total en cada lugar?  Esta idea conduce a la visualización de la parte inferior izquierda. Tal vez no sea tan limpia como un histograma, pero el hecho de que los datos dirijan las ubicaciones de los bloques significa que es una representación mucho mejor de los datos subyacentes."

#: ../modules/density.rst:48
msgid "This visualization is an example of a *kernel density estimation*, in this case with a top-hat kernel (i.e. a square block at each point).  We can recover a smoother distribution by using a smoother kernel.  The bottom-right plot shows a Gaussian kernel density estimate, in which each point contributes a Gaussian curve to the total.  The result is a smooth density estimate which is derived from the data, and functions as a powerful non-parametric model of the distribution of points."
msgstr "Esta visualización es un ejemplo de *estimación de la densidad del kernel*, en este caso con un kernel superior estimado (es decir, un bloque cuadrado en cada punto).  Podemos recuperar una distribución más suave utilizando un kernel más suave.  El gráfico de abajo a la derecha muestra una estimación de la densidad del kernel Gaussiano, en la que cada punto contribuye con una curva Gaussiana al total.  El resultado es una estimación de densidad suave que se deriva de los datos, y funciones como un potente modelo no paramétrico de la distribución de puntos."

#: ../modules/density.rst:59
msgid "Kernel Density Estimation"
msgstr "Estimación de densidad del Kernel"

#: ../modules/density.rst:60
msgid "Kernel density estimation in scikit-learn is implemented in the :class:`~sklearn.neighbors.KernelDensity` estimator, which uses the Ball Tree or KD Tree for efficient queries (see :ref:`neighbors` for a discussion of these).  Though the above example uses a 1D data set for simplicity, kernel density estimation can be performed in any number of dimensions, though in practice the curse of dimensionality causes its performance to degrade in high dimensions."
msgstr "La estimación de densidad del kernel en scikit-learn está implementada en el estimador :class:`~sklearn.neighbors.KernelDensity`, que utiliza el Árbol de Bolas o el Árbol KD para consultas eficientes (ver :ref:`neighbors` para una discusión de estos).  Aunque el ejemplo anterior utiliza un conjunto de datos unidimensional por simplicidad, la estimación de densidad del kernel puede realizarse en cualquier número de dimensiones, aunque en la práctica la maldición de la dimensionalidad hace que su rendimiento se degrade en altas dimensiones altas."

#: ../modules/density.rst:68
msgid "In the following figure, 100 points are drawn from a bimodal distribution, and the kernel density estimates are shown for three choices of kernels:"
msgstr "En la siguiente figura, se extraen 100 puntos de una distribución bimodal, y se muestran las estimaciones de densidad del kernel para tres opciones de kernels:"

#: ../modules/density.rst:76
msgid "kde_1d_distribution"
msgstr "kde_1d_distribution"

#: ../modules/density.rst:77
msgid "It's clear how the kernel shape affects the smoothness of the resulting distribution.  The scikit-learn kernel density estimator can be used as follows:"
msgstr "Está claro cómo la forma del núcleo afecta a la suavidad de la distribución resultante. El estimador de densidad del núcleo de aprendizaje de ciencia puede utilizarse de la siguiente manera:"

#: ../modules/density.rst:89
msgid "Here we have used ``kernel='gaussian'``, as seen above. Mathematically, a kernel is a positive function :math:`K(x;h)` which is controlled by the bandwidth parameter :math:`h`. Given this kernel form, the density estimate at a point :math:`y` within a group of points :math:`x_i; i=1\\cdots N` is given by:"
msgstr "Aquí hemos utilizado ``kernel='gaussian'``, como has visto anteriormente. Matemáticamente, un kernel es una función positiva :math:`K(x;h)` que está controlada por el parámetro de ancho de banda :math:`h`. Dada esta forma del kernel, la estimación de la densidad en un punto :math:`y` dentro de un grupo de puntos :math:`x_i; i=1\\cdots N` viene dada por:"

#: ../modules/density.rst:95
msgid "\\rho_K(y) = \\sum_{i=1}^{N} K(y - x_i; h)\n\n"
msgstr "\\rho_K(y) = \\sum_{i=1}^{N} K(y - x_i; h)\n\n"

#: ../modules/density.rst:98
msgid "The bandwidth here acts as a smoothing parameter, controlling the tradeoff between bias and variance in the result.  A large bandwidth leads to a very smooth (i.e. high-bias) density distribution.  A small bandwidth leads to an unsmooth (i.e. high-variance) density distribution."
msgstr "El ancho de banda actúa aquí como un parámetro de suavización, controlando el equilibrio entre el sesgo y la varianza en el resultado.  Un ancho de banda grande conduce a una distribución de densidad muy suave (es decir, de alto sesgo).  Un ancho de banda pequeño conduce a una distribución de densidad poco suave (es decir, de alta varianza)."

#: ../modules/density.rst:103
msgid ":class:`~sklearn.neighbors.KernelDensity` implements several common kernel forms, which are shown in the following figure:"
msgstr ":class:`~sklearn.neighbors.KernelDensity` implementa varias formas de kernel comunes, que se muestran en la siguiente figura:"

#: ../modules/density.rst:111
msgid "kde_kernels"
msgstr "kde_kernels"

#: ../modules/density.rst:112
msgid "The form of these kernels is as follows:"
msgstr "La forma de estos kernels es la siguiente:"

#: ../modules/density.rst:114
msgid "Gaussian kernel (``kernel = 'gaussian'``)"
msgstr "Kernel Gaussiano (``kernel = 'gaussian'``)"

#: ../modules/density.rst:116
msgid ":math:`K(x; h) \\propto \\exp(- \\frac{x^2}{2h^2} )`"
msgstr ":math:`K(x; h) \\propto \\exp(- \\frac{x^2}{2h^2} )`"

#: ../modules/density.rst:118
msgid "Tophat kernel (``kernel = 'tophat'``)"
msgstr "Kernel superior estimado (``kernel = 'tophat'``)"

#: ../modules/density.rst:120
msgid ":math:`K(x; h) \\propto 1` if :math:`x < h`"
msgstr ":math:`K(x; h) \\propto 1` if :math:`x < h`"

#: ../modules/density.rst:122
msgid "Epanechnikov kernel (``kernel = 'epanechnikov'``)"
msgstr "Kernel de Epanechnikov (``kernel = 'epanechnikov'``)"

#: ../modules/density.rst:124
msgid ":math:`K(x; h) \\propto 1 - \\frac{x^2}{h^2}`"
msgstr ":math:`K(x; h) \\propto 1 - \\frac{x^2}{h^2}`"

#: ../modules/density.rst:126
msgid "Exponential kernel (``kernel = 'exponential'``)"
msgstr "Kernel exponencial (``kernel = 'exponential'``)"

#: ../modules/density.rst:128
msgid ":math:`K(x; h) \\propto \\exp(-x/h)`"
msgstr ":math:`K(x; h) \\propto \\exp(-x/h)`"

#: ../modules/density.rst:130
msgid "Linear kernel (``kernel = 'linear'``)"
msgstr "Kernel lineal (``kernel = 'linear'``)"

#: ../modules/density.rst:132
msgid ":math:`K(x; h) \\propto 1 - x/h` if :math:`x < h`"
msgstr ":math:`K(x; h) \\propto 1 - x/h` if :math:`x < h`"

#: ../modules/density.rst:134
msgid "Cosine kernel (``kernel = 'cosine'``)"
msgstr "Kernel del coseno (``kernel = 'cosine'``)"

#: ../modules/density.rst:136
msgid ":math:`K(x; h) \\propto \\cos(\\frac{\\pi x}{2h})` if :math:`x < h`"
msgstr ":math:`K(x; h) \\propto \\cos(\\frac{\\pi x}{2h})` if :math:`x < h`"

#: ../modules/density.rst:138
msgid "The kernel density estimator can be used with any of the valid distance metrics (see :class:`~sklearn.neighbors.DistanceMetric` for a list of available metrics), though the results are properly normalized only for the Euclidean metric.  One particularly useful metric is the `Haversine distance <https://en.wikipedia.org/wiki/Haversine_formula>`_ which measures the angular distance between points on a sphere.  Here is an example of using a kernel density estimate for a visualization of geospatial data, in this case the distribution of observations of two different species on the South American continent:"
msgstr "El estimador de densidad del kernel puede ser usado con cualquiera de las métricas de distancia válidas (ver :class:`~sklearn.neighbors.DistanceMetric` para una lista de métricas disponibles), aunque los resultados están normalizados adecuadamente sólo para la métrica Euclideana. Una métrica particularmente útil es la `Haversine distance  <https://en.wikipedia.org/wiki/Haversine_formula>`_ que mide la distancia angular entre puntos en una esfera. Aquí hay un ejemplo de uso de una estimación de densidad del kernel para una visualización de datos geoespaciales, en este caso la distribución de observaciones de dos especies diferentes en el continente sudamericano:"

#: ../modules/density.rst:153
msgid "species_kde"
msgstr "species_kde"

#: ../modules/density.rst:154
msgid "One other useful application of kernel density estimation is to learn a non-parametric generative model of a dataset in order to efficiently draw new samples from this generative model. Here is an example of using this process to create a new set of hand-written digits, using a Gaussian kernel learned on a PCA projection of the data:"
msgstr "Otra aplicación útil de la estimación de densidad del kernel es aprender de un modelo generativo no paramétrico de un conjunto de datos con el fin de extraer eficientemente nuevas muestras de este modelo generativo. Aquí hay un ejemplo de uso de este proceso para crear un nuevo conjunto de dígitos manuscritos, usando un kernel Gaussiano aprendido en una proyección PCA de los datos:"

#: ../modules/density.rst:166
msgid "digits_kde"
msgstr "digits_kde"

#: ../modules/density.rst:167
msgid "The \"new\" data consists of linear combinations of the input data, with weights probabilistically drawn given the KDE model."
msgstr "Los datos \"new\" consisten en combinaciones lineales de los datos de entrada, con pesos extraídos probabilísticamente dado el modelo KDE."

#: ../modules/density.rst:172
msgid ":ref:`sphx_glr_auto_examples_neighbors_plot_kde_1d.py`: computation of simple kernel density estimates in one dimension."
msgstr ":ref:`sphx_glr_auto_examples_neighbors_plot_kde_1d.py`: cálculo de estimaciones de densidad del kernel simples en una dimensión."

#: ../modules/density.rst:175
msgid ":ref:`sphx_glr_auto_examples_neighbors_plot_digits_kde_sampling.py`: an example of using Kernel Density estimation to learn a generative model of the hand-written digits data, and drawing new samples from this model."
msgstr ":ref:`sphx_glr_auto_examples_neighbors_plot_digits_kde_sampling.py`: un ejemplo de uso de la estimación de Densidad del Kernel para aprender de un modelo generativo de los datos de los dígitos escritos a mano, y extraer nuevas muestras de este modelo."

#: ../modules/density.rst:179
msgid ":ref:`sphx_glr_auto_examples_neighbors_plot_species_kde.py`: an example of Kernel Density estimation using the Haversine distance metric to visualize geospatial data"
msgstr ":ref:`sphx_glr_auto_examples_neighbors_plot_species_kde.py`: un ejemplo de estimación de Densidad del Kernel utilizando la métrica de distancia Haversine para visualizar datos geoespaciales"

