msgid ""
msgstr ""
"Project-Id-Version: scikit-learn\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-03-31 11:24-0400\n"
"PO-Revision-Date: 2021-05-05 01:08\n"
"Last-Translator: \n"
"Language-Team: Spanish\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Crowdin-Project: scikit-learn\n"
"X-Crowdin-Project-ID: 450526\n"
"X-Crowdin-Language: es-ES\n"
"X-Crowdin-File: /main/doc/en/modules/semi_supervised.po\n"
"X-Crowdin-File-ID: 4822\n"
"Language: es_ES\n"

#: ../modules/semi_supervised.rst:5
msgid "Semi-supervised learning"
msgstr "Aprendizaje semi supervisado"

#: ../modules/semi_supervised.rst:9
msgid "`Semi-supervised learning <https://en.wikipedia.org/wiki/Semi-supervised_learning>`_ is a situation in which in your training data some of the samples are not labeled. The semi-supervised estimators in :mod:`sklearn.semi_supervised` are able to make use of this additional unlabeled data to better capture the shape of the underlying data distribution and generalize better to new samples. These algorithms can perform well when we have a very small amount of labeled points and a large amount of unlabeled points."
msgstr "`El aprendizaje semi supervisado <https://en.wikipedia.org/wiki/Semi-supervised_learning>`_ es una situación en la que en los datos de entrenamiento algunas de las muestras no están etiquetadas. Los estimadores semi supervisados en :mod:`sklearn.semi_supervised` son capaces de hacer uso de estos datos adicionales no etiquetados para capturar mejor la forma de la distribución de datos subyacente y generalizar mejor a las nuevas muestras. Estos algoritmos pueden funcionar bien cuando tenemos una cantidad muy pequeña de puntos etiquetados y una gran cantidad de puntos no etiquetados."

msgid "Unlabeled entries in `y`"
msgstr "Entradas sin etiquetar en `y`"

#: ../modules/semi_supervised.rst:20
msgid "It is important to assign an identifier to unlabeled points along with the labeled data when training the model with the ``fit`` method. The identifier that this implementation uses is the integer value :math:`-1`. Note that for string labels, the dtype of `y` should be object so that it can contain both strings and integers."
msgstr "Es importante asignar un identificador a los puntos no etiquetados junto con los datos etiquetados cuando se entrena el modelo con el método ``fit``. El identificador que utiliza esta implementación es el valor entero :math:`-1`. Ten en cuenta que para las etiquetas de cadena, el dtype de `y` debe ser object para que pueda contener tanto cadenas como enteros."

#: ../modules/semi_supervised.rst:28
msgid "Semi-supervised algorithms need to make assumptions about the distribution of the dataset in order to achieve performance gains. See `here <https://en.wikipedia.org/wiki/Semi-supervised_learning#Assumptions_used>`_ for more details."
msgstr "Los algoritmos semi supervisados necesitan hacer suposiciones sobre la distribución del conjunto de datos para lograr ganancias de rendimiento. Véase `aquí <https://en.wikipedia.org/wiki/Semi-supervised_learning#Assumptions_used>`_ para más detalles."

#: ../modules/semi_supervised.rst:36
msgid "Self Training"
msgstr "Auto entrenamiento"

#: ../modules/semi_supervised.rst:38
msgid "This self-training implementation is based on Yarowsky's [1]_ algorithm. Using this algorithm, a given supervised classifier can function as a semi-supervised classifier, allowing it to learn from unlabeled data."
msgstr "Esta implementación de auto entrenamiento se basa en el algoritmo de Yarowsky [1]_. Usando este algoritmo, un determinado clasificador supervisado puede funcionar como un clasificador semi supervisado, permitiéndole aprender de datos no etiquetados."

#: ../modules/semi_supervised.rst:42
msgid ":class:`SelfTrainingClassifier` can be called with any classifier that implements `predict_proba`, passed as the parameter `base_classifier`. In each iteration, the `base_classifier` predicts labels for the unlabeled samples and adds a subset of these labels to the labeled dataset."
msgstr ":class:`SelfTrainingClassifier` puede ser llamado con cualquier clasificador que implemente `predict_proba`, pasado como parámetro `base_classifier`. En cada iteración, el `base_classifier` predice etiquetas para las muestras no etiquetadas y añade un subconjunto de estas etiquetas al conjunto de datos etiquetados."

#: ../modules/semi_supervised.rst:47
msgid "The choice of this subset is determined by the selection criterion. This selection can be done using a `threshold` on the prediction probabilities, or by choosing the `k_best` samples according to the prediction probabilities."
msgstr "La elección de este subconjunto está determinada por el criterio de selección. Esta selección se puede hacer utilizando un `threshold` en las probabilidades de predicción, o eligiendo las `k_best` muestras de acuerdo con las probabilidades de predicción."

#: ../modules/semi_supervised.rst:51
msgid "The labels used for the final fit as well as the iteration in which each sample was labeled are available as attributes. The optional `max_iter` parameter specifies how many times the loop is executed at most."
msgstr "Las etiquetas utilizadas para el ajuste final, así como la iteración en la que cada muestra fue etiquetada están disponibles como atributos. El parámetro opcional `max_iter` especifica cuántas veces se ejecuta el bucle como máximo."

#: ../modules/semi_supervised.rst:55
msgid "The `max_iter` parameter may be set to `None`, causing the algorithm to iterate until all samples have labels or no new samples are selected in that iteration."
msgstr "El parámetro `max_iter` puede establecerse en `None`, haciendo iterar el algoritmo hasta que todas las muestras tengan etiquetas o no se seleccionen nuevas muestras en esa iteración."

#: ../modules/semi_supervised.rst:60
msgid "When using the self-training classifier, the :ref:`calibration <calibration>` of the classifier is important."
msgstr "Cuando se utiliza el clasificador de auto entrenamiento, la :ref:`calibración <calibration>` del clasificador es importante."

#: ../modules/semi_supervised.rst:65
msgid ":ref:`sphx_glr_auto_examples_semi_supervised_plot_self_training_varying_threshold.py`"
msgstr ":ref:`sphx_glr_auto_examples_semi_supervised_plot_self_training_varying_threshold.py`"

#: ../modules/semi_supervised.rst:66 ../modules/semi_supervised.rst:139
msgid ":ref:`sphx_glr_auto_examples_semi_supervised_plot_semi_supervised_versus_svm_iris.py`"
msgstr ":ref:`sphx_glr_auto_examples_semi_supervised_plot_semi_supervised_versus_svm_iris.py`"

#: ../modules/semi_supervised.rst:70
msgid "David Yarowsky. 1995. Unsupervised word sense disambiguation rivaling supervised methods. In Proceedings of the 33rd annual meeting on Association for Computational Linguistics (ACL '95). Association for Computational Linguistics, Stroudsburg, PA, USA, 189-196. DOI: https://doi.org/10.3115/981658.981684"
msgstr "David Yarowsky. 1995. Unsupervised word sense disambiguation rivaling supervised methods. In Proceedings of the 33rd annual meeting on Association for Computational Linguistics (ACL '95). Association for Computational Linguistics, Stroudsburg, PA, USA, 189-196. DOI: https://doi.org/10.3115/981658.981684"

#: ../modules/semi_supervised.rst:79
msgid "Label Propagation"
msgstr "Propagación de etiquetas"

#: ../modules/semi_supervised.rst:81
msgid "Label propagation denotes a few variations of semi-supervised graph inference algorithms."
msgstr "La propagación de etiquetas denota algunas variaciones de los algoritmos de inferencia de grafos semi supervisados."

#: ../modules/semi_supervised.rst:86
msgid "A few features available in this model:"
msgstr "Algunas características disponibles en este modelo:"

#: ../modules/semi_supervised.rst:85
msgid "Used for classification tasks"
msgstr "Utilizado para tareas de clasificación"

#: ../modules/semi_supervised.rst:86
msgid "Kernel methods to project data into alternate dimensional spaces"
msgstr "Métodos Kernel para proyectar datos en espacios dimensionales alternativos"

#: ../modules/semi_supervised.rst:88
msgid "`scikit-learn` provides two label propagation models: :class:`LabelPropagation` and :class:`LabelSpreading`. Both work by constructing a similarity graph over all items in the input dataset."
msgstr "`scikit-learn` proporciona dos modelos de propagación de etiquetas: :class:`LabelPropagation` y :class:`LabelSpreading`. Ambos trabajan construyendo una gráfica de similitud sobre todos los elementos en el conjunto de datos de entrada."

#: ../modules/semi_supervised.rst:97
msgid "**An illustration of label-propagation:** *the structure of unlabeled observations is consistent with the class structure, and thus the class label can be propagated to the unlabeled observations of the training set.*"
msgstr "**Una ilustración de la propagación de etiquetas:** *la estructura de observaciones sin etiquetar es coherente con la estructura de la clase, y por lo tanto la etiqueta de la clase puede propagarse a las observaciones sin etiquetar del conjunto de entrenamiento.*"

#: ../modules/semi_supervised.rst:102
msgid ":class:`LabelPropagation` and :class:`LabelSpreading` differ in modifications to the similarity matrix that graph and the clamping effect on the label distributions. Clamping allows the algorithm to change the weight of the true ground labeled data to some degree. The :class:`LabelPropagation` algorithm performs hard clamping of input labels, which means :math:`\\alpha=0`. This clamping factor can be relaxed, to say :math:`\\alpha=0.2`, which means that we will always retain 80 percent of our original label distribution, but the algorithm gets to change its confidence of the distribution within 20 percent."
msgstr ":class:`LabelPropagation` y :class:`LabelSpreading` difieren en las modificaciones de la matriz de similitud que grafican y como restringen la distribución de las etiquetas\". La restricción permite que el algoritmo cambie el peso de los datos etiquetados reales en cierto grado. El algoritmo :class:`LabelPropagation` realiza una restricción dura de las etiquetas de entrada, lo que significa :math:`\\alpha=0`. Este factor de restricción puede ser relajado, por ejemplo :math:`\\alpha=0.2`, lo que significa que siempre mantendremos el 80 por ciento de nuestra distribución de etiquetas original, pero el algoritmo puede cambiar su confianza en la distribución dentro del 20 por ciento."

#: ../modules/semi_supervised.rst:112
msgid ":class:`LabelPropagation` uses the raw similarity matrix constructed from the data with no modifications. In contrast, :class:`LabelSpreading` minimizes a loss function that has regularization properties, as such it is often more robust to noise. The algorithm iterates on a modified version of the original graph and normalizes the edge weights by computing the normalized graph Laplacian matrix. This procedure is also used in :ref:`spectral_clustering`."
msgstr ":class:`LabelPropagation` utiliza la matriz de similitud cruda construida a partir de los datos sin modificaciones. En cambio, :class:`LabelSpreading` minimiza una función de pérdida que tiene propiedades de regularización, por lo que a menudo es más robusto al ruido. El algoritmo itera sobre una versión modificada del gráfico original y normaliza los pesos de las aristas calculando la matriz Laplaciana normalizada del gráfico. Este procedimiento también se utiliza en :ref:`spectral_clustering`."

#: ../modules/semi_supervised.rst:120
msgid "Label propagation models have two built-in kernel methods. Choice of kernel effects both scalability and performance of the algorithms. The following are available:"
msgstr "Los modelos de propagación de etiquetas tienen dos métodos de kernel integrados. La elección del kernel afecta tanto la escalabilidad como el rendimiento de los algoritmos. Están disponibles los siguientes:"

#: ../modules/semi_supervised.rst:124
msgid "rbf (:math:`\\exp(-\\gamma |x-y|^2), \\gamma > 0`). :math:`\\gamma` is specified by keyword gamma."
msgstr "rbf (:math:`\\exp(-\\gamma |x-y|^2), \\gamma > 0`). :math:`\\gamma` se especifica con la palabra clave gamma."

#: ../modules/semi_supervised.rst:127
msgid "knn (:math:`1[x' \\in kNN(x)]`). :math:`k` is specified by keyword n_neighbors."
msgstr "knn (:math:`1[x' \\in kNN(x)]`). :math:`k` se especifica con la palabra clave n_neighbors."

#: ../modules/semi_supervised.rst:130
msgid "The RBF kernel will produce a fully connected graph which is represented in memory by a dense matrix. This matrix may be very large and combined with the cost of performing a full matrix multiplication calculation for each iteration of the algorithm can lead to prohibitively long running times. On the other hand, the KNN kernel will produce a much more memory-friendly sparse matrix which can drastically reduce running times."
msgstr "El kernel RBF producirá un gráfico completamente conectado que está representado en memoria por una matriz densa. Esta matriz puede ser muy grande y, combinada con el costo de realizar un cálculo completo de multiplicación de la matriz para cada iteración del algoritmo, puede llevar a tiempos de ejecución prohibitivamente largos. Por otro lado, el núcleo KNN producirá una matriz dispersa mucho más amigable con la memoria que puede reducir drásticamente los tiempos de ejecución."

#: ../modules/semi_supervised.rst:140
msgid ":ref:`sphx_glr_auto_examples_semi_supervised_plot_label_propagation_structure.py`"
msgstr ":ref:`sphx_glr_auto_examples_semi_supervised_plot_label_propagation_structure.py`"

#: ../modules/semi_supervised.rst:141
msgid ":ref:`sphx_glr_auto_examples_semi_supervised_plot_label_propagation_digits.py`"
msgstr ":ref:`sphx_glr_auto_examples_semi_supervised_plot_label_propagation_digits.py`"

#: ../modules/semi_supervised.rst:142
msgid ":ref:`sphx_glr_auto_examples_semi_supervised_plot_label_propagation_digits_active_learning.py`"
msgstr ":ref:`sphx_glr_auto_examples_semi_supervised_plot_label_propagation_digits_active_learning.py`"

msgid "References"
msgstr "Referencias"

#: ../modules/semi_supervised.rst:146
msgid "[2] Yoshua Bengio, Olivier Delalleau, Nicolas Le Roux. In Semi-Supervised Learning (2006), pp. 193-216"
msgstr "[2] Yoshua Bengio, Olivier Delalleau, Nicolas Le Roux. In Semi-Supervised Learning (2006), pp. 193-216"

#: ../modules/semi_supervised.rst:149
msgid "[3] Olivier Delalleau, Yoshua Bengio, Nicolas Le Roux. Efficient Non-Parametric Function Induction in Semi-Supervised Learning. AISTAT 2005 https://research.microsoft.com/en-us/people/nicolasl/efficient_ssl.pdf"
msgstr "[3] Olivier Delalleau, Yoshua Bengio, Nicolas Le Roux. Efficient Non-Parametric Function Induction in Semi-Supervised Learning. AISTAT 2005 https://research.microsoft.com/en-us/people/nicolasl/efficient_ssl.pdf"

