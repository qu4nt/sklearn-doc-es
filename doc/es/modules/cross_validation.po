msgid ""
msgstr ""
"Project-Id-Version: scikit-learn\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-03-31 11:24-0400\n"
"PO-Revision-Date: 2021-04-25 01:23\n"
"Last-Translator: \n"
"Language-Team: Spanish\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Crowdin-Project: scikit-learn\n"
"X-Crowdin-Project-ID: 450526\n"
"X-Crowdin-Language: es-ES\n"
"X-Crowdin-File: /main/doc/en/modules/cross_validation.po\n"
"X-Crowdin-File-ID: 4864\n"
"Language: es_ES\n"

#: ../modules/cross_validation.rst:6
msgid "Cross-validation: evaluating estimator performance"
msgstr "Validación cruzada: evaluación del rendimiento del estimador"

#: ../modules/cross_validation.rst:10
msgid "Learning the parameters of a prediction function and testing it on the same data is a methodological mistake: a model that would just repeat the labels of the samples that it has just seen would have a perfect score but would fail to predict anything useful on yet-unseen data. This situation is called **overfitting**. To avoid it, it is common practice when performing a (supervised) machine learning experiment to hold out part of the available data as a **test set** ``X_test, y_test``. Note that the word \"experiment\" is not intended to denote academic use only, because even in commercial settings machine learning usually starts out experimentally. Here is a flowchart of typical cross validation workflow in model training. The best parameters can be determined by :ref:`grid search <grid_search>` techniques."
msgstr "Aprender los parámetros de una función de predicción y probarla sobre los mismos datos es un error metodológico: un modelo que se limitase a repetir las etiquetas de las muestras que acaba de ver tendría una puntuación perfecta, pero no lograría predecir nada útil sobre datos aún no vistos. Esta situación se llama **sobreajuste**. Para evitarla, es práctica común cuando se realiza un experimento de aprendizaje automático (supervisado), el mantener una parte de los datos disponibles como un **conjunto de prueba** ``X_test, y_test`. Tenga en cuenta que la palabra \"experimento\" no pretende denotar un uso académico únicamente, ya que incluso en entornos comerciales el aprendizaje automático suele comenzar de forma experimental. Este es un diagrama de flujo del proceso de trabajo típico de validación cruzada en el entrenamiento de modelos. Los mejores parámetros pueden determinarse mediante las técnicas de :ref:`búsqueda exhaustiva <grid_search>`."

#: ../modules/cross_validation.rst:32
msgid "In scikit-learn a random split into training and test sets can be quickly computed with the :func:`train_test_split` helper function. Let's load the iris data set to fit a linear support vector machine on it::"
msgstr "En scikit-learn una división aleatoria en conjuntos de entrenamiento y prueba puede ser rápidamente calculada con la función de ayuda :func:`train_test_split`. Carguemos el conjunto de datos del iris para ajustar una máquina de vectores de soporte lineal en él::"

#: ../modules/cross_validation.rst:45
#, python-format
msgid "We can now quickly sample a training set while holding out 40% of the data for testing (evaluating) our classifier::"
msgstr "Ahora podemos hacer un muestreo rápido de un conjunto de entrenamiento y reservar el 40% de los datos para probar (evaluar) nuestro clasificador::"

#: ../modules/cross_validation.rst:60
msgid "When evaluating different settings (\"hyperparameters\") for estimators, such as the ``C`` setting that must be manually set for an SVM, there is still a risk of overfitting *on the test set* because the parameters can be tweaked until the estimator performs optimally. This way, knowledge about the test set can \"leak\" into the model and evaluation metrics no longer report on generalization performance. To solve this problem, yet another part of the dataset can be held out as a so-called \"validation set\": training proceeds on the training set, after which evaluation is done on the validation set, and when the experiment seems to be successful, final evaluation can be done on the test set."
msgstr "Cuando se evalúan diferentes ajustes (\"hiperparámetros\") para los estimadores, como el ajuste ``C`` que debe establecerse manualmente para una SVM, sigue existiendo el riesgo de sobreajuste *en el conjunto de prueba* porque los parámetros pueden ajustarse hasta que el estimador tenga un rendimiento óptimo. De este modo, el conocimiento sobre el conjunto de pruebas puede \"filtrarse\" en el modelo y las métricas de evaluación ya no reportan el rendimiento de la generalización. Para resolver este problema, otra parte del conjunto de datos puede mantenerse como el llamado \"conjunto de validación\": el entrenamiento se lleva a cabo en el conjunto de entrenamiento, tras lo cual la evaluación se realiza en el conjunto de validación, y cuando el experimento parece ser exitoso, la evaluación final puede realizarse en el conjunto de prueba."

#: ../modules/cross_validation.rst:72
msgid "However, by partitioning the available data into three sets, we drastically reduce the number of samples which can be used for learning the model, and the results can depend on a particular random choice for the pair of (train, validation) sets."
msgstr "Sin embargo, al dividir los datos disponibles en tres conjuntos, reducimos drásticamente el número de muestras que pueden utilizarse para el aprendizaje del modelo, y los resultados pueden depender de una determinada elección aleatoria del par de conjuntos (de entrenamiento, de validación)."

#: ../modules/cross_validation.rst:78
msgid "A solution to this problem is a procedure called `cross-validation <https://en.wikipedia.org/wiki/Cross-validation_(statistics)>`_ (CV for short). A test set should still be held out for final evaluation, but the validation set is no longer needed when doing CV. In the basic approach, called *k*-fold CV, the training set is split into *k* smaller sets (other approaches are described below, but generally follow the same principles). The following procedure is followed for each of the *k* \"folds\":"
msgstr "Una solución a este problema es un procedimiento llamado `validación cruzada <https://es.wikipedia.org/wiki/Validaci%C3%B3n_cruzada)>`_ (VC para abreviar). El conjunto de pruebas debe seguir siendo utilizado para la evaluación final, pero el conjunto de validación ya no es necesario cuando se realiza la VC. En el enfoque básico, llamado *k*-parte VC, el conjunto de entrenamiento se divide en *k* conjuntos más pequeños (más adelante se describen otros enfoques, pero en general siguen los mismos principios). Se sigue el siguiente procedimiento para cada uno de las *k* \"partes\":"

#: ../modules/cross_validation.rst:89
msgid "A model is trained using :math:`k-1` of the folds as training data;"
msgstr "Se entrena un modelo utilizando :math:`k-1` de las partes como datos de entrenamiento;"

#: ../modules/cross_validation.rst:90
msgid "the resulting model is validated on the remaining part of the data (i.e., it is used as a test set to compute a performance measure such as accuracy)."
msgstr "el modelo resultante se valida en la parte restante de los datos (es decir, se utiliza como conjunto de pruebas para calcular una medida de rendimiento como la precisión)."

#: ../modules/cross_validation.rst:94
msgid "The performance measure reported by *k*-fold cross-validation is then the average of the values computed in the loop. This approach can be computationally expensive, but does not waste too much data (as is the case when fixing an arbitrary validation set), which is a major advantage in problems such as inverse inference where the number of samples is very small."
msgstr "La medida de rendimiento obtenida mediante la validación cruzada de *k* partes es entonces la media de los valores calculados en el bucle. Este enfoque puede ser costoso desde el punto de vista computacional, pero no desperdicia demasiados datos (como ocurre cuando se fija un conjunto de validación arbitrario), lo que supone una gran ventaja en problemas como la inferencia inversa, donde el número de muestras es muy pequeño."

#: ../modules/cross_validation.rst:108
msgid "Computing cross-validated metrics"
msgstr "Cálculo de métricas de validación cruzada"

#: ../modules/cross_validation.rst:110
msgid "The simplest way to use cross-validation is to call the :func:`cross_val_score` helper function on the estimator and the dataset."
msgstr "La forma más sencilla de utilizar la validación cruzada es llamar a la función de ayuda :func:`cross_val_score` sobre el estimador y el conjunto de datos."

#: ../modules/cross_validation.rst:113
msgid "The following example demonstrates how to estimate the accuracy of a linear kernel support vector machine on the iris dataset by splitting the data, fitting a model and computing the score 5 consecutive times (with different splits each time)::"
msgstr "El siguiente ejemplo muestra cómo estimar la precisión de una máquina de vectores de soporte de núcleo lineal en el conjunto de datos del iris dividiendo los datos, ajustando un modelo y calculando la puntuación 5 veces consecutivas (con diferentes divisiones cada vez)::"

#: ../modules/cross_validation.rst:124
msgid "The mean score and the standard deviation are hence given by::"
msgstr "La puntuación media y la desviación estándar vienen dadas por::"

#: ../modules/cross_validation.rst:129
msgid "By default, the score computed at each CV iteration is the ``score`` method of the estimator. It is possible to change this by using the scoring parameter::"
msgstr "Por defecto, la puntuación calculada en cada iteración del CV es el método ``score`` del estimador. Es posible cambiar esto utilizando el parámetro de puntuación::"

#: ../modules/cross_validation.rst:139
msgid "See :ref:`scoring_parameter` for details. In the case of the Iris dataset, the samples are balanced across target classes hence the accuracy and the F1-score are almost equal."
msgstr "Observa el :ref:`scoring_parameter` para más detalles. En el caso del conjunto de datos Iris, las muestras están equilibradas entre las clases objetivo, por lo que la precisión y la puntuación F1 son casi iguales."

#: ../modules/cross_validation.rst:143
msgid "When the ``cv`` argument is an integer, :func:`cross_val_score` uses the :class:`KFold` or :class:`StratifiedKFold` strategies by default, the latter being used if the estimator derives from :class:`ClassifierMixin <sklearn.base.ClassifierMixin>`."
msgstr "Cuando el argumento ``cv`` es un entero, :func:`cross_val_score` utiliza por defecto las estrategias :class:`KFold` o :class:`StratifiedKFold`, usándose esta última si el estimador deriva de :class:`ClassifierMixin <sklearn.base.ClassifierMixin>`."

#: ../modules/cross_validation.rst:148
msgid "It is also possible to use other cross validation strategies by passing a cross validation iterator instead, for instance::"
msgstr "También es posible utilizar otras estrategias de validación cruzada pasando un iterador de validación cruzada en su lugar, por ejemplo::"

#: ../modules/cross_validation.rst:157
msgid "Another option is to use an iterable yielding (train, test) splits as arrays of indices, for example::"
msgstr "Otra opción es utilizar un iterable que produzca divisiones (entrenamiento, prueba) como matrices de índices, por ejemplo::"

msgid "Data transformation with held out data"
msgstr "Transformación de datos con datos retenidos"

#: ../modules/cross_validation.rst:174
msgid "Just as it is important to test a predictor on data held-out from training, preprocessing (such as standardization, feature selection, etc.) and similar :ref:`data transformations <data-transforms>` similarly should be learnt from a training set and applied to held-out data for prediction::"
msgstr "Al igual que es importante probar un predictor en los datos retenidos del entrenamiento, el preprocesamiento (como la estandarización, la selección de características, etc.) y las transformaciones de datos similares :ref:` <data-transforms>` deberían aprenderse de un conjunto de entrenamiento y aplicarse a los datos retenidos para la predicción::"

#: ../modules/cross_validation.rst:189
msgid "A :class:`Pipeline <sklearn.pipeline.Pipeline>` makes it easier to compose estimators, providing this behavior under cross-validation::"
msgstr "Un :class:`Pipeline <sklearn.pipeline.Pipeline>` facilita la composición de los estimadores, proporcionando este comportamiento bajo validación cruzada::"

#: ../modules/cross_validation.rst:197
msgid "See :ref:`combining_estimators`."
msgstr "Véase :ref:`combining_estimators`."

#: ../modules/cross_validation.rst:203
msgid "The cross_validate function and multiple metric evaluation"
msgstr "La función cross_validate y la evaluación de métricas múltiples"

#: ../modules/cross_validation.rst:205
msgid "The :func:`cross_validate` function differs from :func:`cross_val_score` in two ways:"
msgstr "La función :func:`cross_validate` difiere de :func:`cross_val_score` en dos aspectos:"

#: ../modules/cross_validation.rst:208
msgid "It allows specifying multiple metrics for evaluation."
msgstr "Permite especificar múltiples métricas para su evaluación."

#: ../modules/cross_validation.rst:210
msgid "It returns a dict containing fit-times, score-times (and optionally training scores as well as fitted estimators) in addition to the test score."
msgstr "Devuelve un diccionario que contiene tiempos de ajuste, tiempos de puntuación (y opcionalmente puntuaciones de entrenamiento así como estimadores ajustados) además de la puntuación de la prueba."

#: ../modules/cross_validation.rst:214
msgid "For single metric evaluation, where the scoring parameter is a string, callable or None, the keys will be - ``['test_score', 'fit_time', 'score_time']``"
msgstr "Para la evaluación de una sola métrica, en la que el parámetro de puntuación es una cadena, invocable o None, las claves serán - ``['test_score', 'fit_time', 'score_time']``"

#: ../modules/cross_validation.rst:217
msgid "And for multiple metric evaluation, the return value is a dict with the following keys - ``['test_<scorer1_name>', 'test_<scorer2_name>', 'test_<scorer...>', 'fit_time', 'score_time']``"
msgstr "Y para la evaluación de métricas múltiples, el valor de retorno es un diccionario con las siguientes claves - ``['test_<scorer1_name>', 'test_<scorer2_name>', 'test_<scorer...>', 'fit_time', 'score_time']``"

#: ../modules/cross_validation.rst:221
msgid "``return_train_score`` is set to ``False`` by default to save computation time. To evaluate the scores on the training set as well you need to be set to ``True``."
msgstr "``retornar_puntuación_de_entrenamiento`` se establece por defecto en ``False`` para ahorrar tiempo de cálculo. Para evaluar las puntuaciones en el conjunto de entrenamiento también es necesario que se establezca en ``True``."

#: ../modules/cross_validation.rst:225
msgid "You may also retain the estimator fitted on each training set by setting ``return_estimator=True``."
msgstr "También puede conservar el estimador ajustado en cada conjunto de entrenamiento estableciendo ``return_estimator=True``."

#: ../modules/cross_validation.rst:228
msgid "The multiple metrics can be specified either as a list, tuple or set of predefined scorer names::"
msgstr "Las métricas múltiples se pueden especificar como una lista, tupla o conjunto de nombres de puntuadores predefinidos::"

#: ../modules/cross_validation.rst:241
msgid "Or as a dict mapping scorer name to a predefined or custom scoring function::"
msgstr "O como un diccionario que asigna el nombre del calificador a una función de calificación predefinida o personalizada::"

#: ../modules/cross_validation.rst:254
msgid "Here is an example of ``cross_validate`` using a single metric::"
msgstr "Este es un ejemplo de ``validación_cruzada`` utilizando una sola métrica::"

#: ../modules/cross_validation.rst:264
msgid "Obtaining predictions by cross-validation"
msgstr "Obtención de predicciones por validación cruzada"

#: ../modules/cross_validation.rst:266
msgid "The function :func:`cross_val_predict` has a similar interface to :func:`cross_val_score`, but returns, for each element in the input, the prediction that was obtained for that element when it was in the test set. Only cross-validation strategies that assign all elements to a test set exactly once can be used (otherwise, an exception is raised)."
msgstr "La función :func:`cross_val_predict` tiene una interfaz similar a la de :func:`cross_val_score`, pero devuelve, para cada elemento de la entrada, la predicción que se obtuvo para ese elemento cuando estaba en el conjunto de prueba. Sólo pueden utilizarse las estrategias de validación cruzada que asignan todos los elementos a un conjunto de prueba exactamente una vez (en caso contrario, se produce una excepción)."

#: ../modules/cross_validation.rst:273
msgid "Note on inappropriate usage of cross_val_predict"
msgstr "Nota sobre el uso inadecuado de cross_val_predict"

#: ../modules/cross_validation.rst:275
msgid "The result of :func:`cross_val_predict` may be different from those obtained using :func:`cross_val_score` as the elements are grouped in different ways. The function :func:`cross_val_score` takes an average over cross-validation folds, whereas :func:`cross_val_predict` simply returns the labels (or probabilities) from several distinct models undistinguished. Thus, :func:`cross_val_predict` is not an appropriate measure of generalisation error."
msgstr "La función :func:`cross_val_predict` tiene una interfaz similar a la de :func:`cross_val_score`, pero devuelve, para cada elemento de la entrada, la predicción que se obtuvo para ese elemento cuando estaba en el conjunto de prueba. Sólo pueden utilizarse las estrategias de validación cruzada que asignan todos los elementos a un conjunto de prueba exactamente una vez (en caso contrario, se produce una excepción)."

#: ../modules/cross_validation.rst:288
msgid "The function :func:`cross_val_predict` is appropriate for:"
msgstr "La función :func:`cross_val_predict` es apropiada para:"

#: ../modules/cross_validation.rst:285
msgid "Visualization of predictions obtained from different models."
msgstr "Visualización de las predicciones obtenidas a partir de diferentes modelos."

#: ../modules/cross_validation.rst:286
msgid "Model blending: When predictions of one supervised estimator are used to train another estimator in ensemble methods."
msgstr "Mezcla de modelos: Cuando las predicciones de un estimador supervisado se utilizan para entrenar a otro estimador en métodos de conjunto."

#: ../modules/cross_validation.rst:290
msgid "The available cross validation iterators are introduced in the following section."
msgstr "Los iteradores de validación cruzada disponibles se presentan en la siguiente sección."

#: ../modules/cross_validation.rst:295
msgid ":ref:`sphx_glr_auto_examples_model_selection_plot_roc_crossval.py`,"
msgstr ":ref:`sphx_glr_auto_examples_model_selection_plot_roc_crossval.py`,"

#: ../modules/cross_validation.rst:296
msgid ":ref:`sphx_glr_auto_examples_feature_selection_plot_rfe_with_cross_validation.py`,"
msgstr ":ref:`sphx_glr_auto_examples_feature_selection_plot_rfe_with_cross_validation.py`,"

#: ../modules/cross_validation.rst:297
msgid ":ref:`sphx_glr_auto_examples_model_selection_plot_grid_search_digits.py`,"
msgstr ":ref:`sphx_glr_auto_examples_model_selection_plot_grid_search_digits.py`,"

#: ../modules/cross_validation.rst:298
msgid ":ref:`sphx_glr_auto_examples_model_selection_grid_search_text_feature_extraction.py`,"
msgstr ":ref:`sphx_glr_auto_examples_model_selection_grid_search_text_feature_extraction.py`,"

#: ../modules/cross_validation.rst:299
msgid ":ref:`sphx_glr_auto_examples_model_selection_plot_cv_predict.py`,"
msgstr ":ref:`sphx_glr_auto_examples_model_selection_plot_cv_predict.py`,"

#: ../modules/cross_validation.rst:300
msgid ":ref:`sphx_glr_auto_examples_model_selection_plot_nested_cross_validation_iris.py`."
msgstr ":ref:`sphx_glr_auto_examples_model_selection_plot_nested_cross_validation_iris.py`."

#: ../modules/cross_validation.rst:303
msgid "Cross validation iterators"
msgstr "Iteradores de validación cruzada"

#: ../modules/cross_validation.rst:305
msgid "The following sections list utilities to generate indices that can be used to generate dataset splits according to different cross validation strategies."
msgstr "En las siguientes secciones se enumeran las utilidades para generar índices que pueden utilizarse para generar divisiones de conjuntos de datos según diferentes estrategias de validación cruzada."

#: ../modules/cross_validation.rst:312
msgid "Cross-validation iterators for i.i.d. data"
msgstr "Iteradores de validación cruzada para datos i.i.d"

#: ../modules/cross_validation.rst:314
msgid "Assuming that some data is Independent and Identically Distributed (i.i.d.) is making the assumption that all samples stem from the same generative process and that the generative process is assumed to have no memory of past generated samples."
msgstr "Asumir que unos datos son independientes e idénticamente distribuidos (i.i.d.) es hacer la suposición de que todas las muestras provienen del mismo proceso generativo y que se supone que el proceso generativo no tiene memoria de las muestras generadas anteriormente."

#: ../modules/cross_validation.rst:319
msgid "The following cross-validators can be used in such cases."
msgstr "En estos casos se pueden utilizar los siguientes validadores cruzados."

#: ../modules/cross_validation.rst:323
msgid "While i.i.d. data is a common assumption in machine learning theory, it rarely holds in practice. If one knows that the samples have been generated using a time-dependent process, it is safer to use a :ref:`time-series aware cross-validation scheme <timeseries_cv>`. Similarly, if we know that the generative process has a group structure (samples collected from different subjects, experiments, measurement devices), it is safer to use :ref:`group-wise cross-validation <group_cv>`."
msgstr "Aunque los datos i.i.d. son una suposición común en la teoría del aprendizaje automático, rara vez ésto se cumple en la práctica. Si se sabe que las muestras se han generado utilizando un proceso dependiente del tiempo, es más seguro utilizar un :ref:`esquema de validación cruzada <timeseries_cv>` que tenga en cuenta las series temporales. Del mismo modo, si sabemos que el proceso generativo tiene una estructura de grupo (muestras recogidas de diferentes sujetos, experimentos, dispositivos de medición), es más seguro utilizar :ref:`validación cruzada en función del grupo <group_cv>`."

#: ../modules/cross_validation.rst:334
msgid "K-fold"
msgstr "K-fold"

#: ../modules/cross_validation.rst:336
msgid ":class:`KFold` divides all the samples in :math:`k` groups of samples, called folds (if :math:`k = n`, this is equivalent to the *Leave One Out* strategy), of equal sizes (if possible). The prediction function is learned using :math:`k - 1` folds, and the fold left out is used for test."
msgstr ":class:`KFold` divide todas las muestras en :math:`k` grupos de muestras, llamados partes (si :math:`k = n`, esto equivale a la estrategia *Leave One Out*), de igual tamaño (si es posible). La función de predicción se aprende utilizando :math:`k - 1` partes, y la parte que se deja fuera se utiliza para la prueba."

#: ../modules/cross_validation.rst:341
msgid "Example of 2-fold cross-validation on a dataset with 4 samples::"
msgstr "Ejemplo de validación cruzada de 2 partes en un conjunto de datos con 4 muestras::"

#: ../modules/cross_validation.rst:353
msgid "Here is a visualization of the cross-validation behavior. Note that :class:`KFold` is not affected by classes or groups."
msgstr "Aquí hay una visualización del comportamiento de la validación cruzada. Ten en cuenta que :class:`KFold` no se ve afectado por las clases o grupos."

#: ../modules/cross_validation.rst:361
msgid "Each fold is constituted by two arrays: the first one is related to the *training set*, and the second one to the *test set*. Thus, one can create the training/test sets using numpy indexing::"
msgstr "Cada parte está constituida por dos matrices: la primera está relacionada con el *conjunto de entrenamiento*, y la segunda con el *conjunto de prueba*. Así, se pueden crear los conjuntos de entrenamiento/prueba utilizando la indexación de numpy::"

#: ../modules/cross_validation.rst:372
msgid "Repeated K-Fold"
msgstr "K-Fold repetido"

#: ../modules/cross_validation.rst:374
msgid ":class:`RepeatedKFold` repeats K-Fold n times. It can be used when one requires to run :class:`KFold` n times, producing different splits in each repetition."
msgstr ":class:`RepeatedKFold` repite K-Fold n veces. Se puede utilizar cuando se requiere ejecutar :class:`KFold` n veces, produciendo diferentes divisiones en cada repetición."

#: ../modules/cross_validation.rst:378
msgid "Example of 2-fold K-Fold repeated 2 times::"
msgstr "Ejemplo de K-Fold repetido 2 veces::"

#: ../modules/cross_validation.rst:394
msgid "Similarly, :class:`RepeatedStratifiedKFold` repeats Stratified K-Fold n times with different randomization in each repetition."
msgstr "Del mismo modo, :class:`RepeatedStratifiedKFold` repite el K-Fold estratificado n veces con una aleatorización diferente en cada repetición."

#: ../modules/cross_validation.rst:400
msgid "Leave One Out (LOO)"
msgstr "Leave One Out (LOO)"

#: ../modules/cross_validation.rst:402
msgid ":class:`LeaveOneOut` (or LOO) is a simple cross-validation. Each learning set is created by taking all the samples except one, the test set being the sample left out. Thus, for :math:`n` samples, we have :math:`n` different training sets and :math:`n` different tests set. This cross-validation procedure does not waste much data as only one sample is removed from the training set::"
msgstr ":class:`LeaveOneOut` (o LOO) es una simple validación cruzada. Cada conjunto de aprendizaje se crea tomando todas las muestras excepto una, siendo el conjunto de prueba la muestra que se deja fuera. Así, para :math:`n` muestras, tenemos :math:`n` conjuntos de entrenamiento diferentes y :math:`n` conjuntos de prueba diferentes. Este procedimiento de validación cruzada no desperdicia muchos datos, ya que sólo se elimina una muestra del conjunto de entrenamiento::"

#: ../modules/cross_validation.rst:421
msgid "Potential users of LOO for model selection should weigh a few known caveats. When compared with :math:`k`-fold cross validation, one builds :math:`n` models from :math:`n` samples instead of :math:`k` models, where :math:`n > k`. Moreover, each is trained on :math:`n - 1` samples rather than :math:`(k-1) n / k`. In both ways, assuming :math:`k` is not too large and :math:`k < n`, LOO is more computationally expensive than :math:`k`-fold cross validation."
msgstr "Los usuarios potenciales de LOO para la selección de modelos deben sopesar algunas advertencias conocidas. Cuando se compara con la validación cruzada :math:`k`, se construyen modelos :math:`n` a partir de muestras :math:`n` en lugar de modelos :math:`k`, donde :math:`n > k`. Además, cada uno se entrena con muestras :math:`n - 1` en lugar de :math:`(k-1) n / k`. En ambos casos, asumiendo que :math:`k` no es demasiado grande y que :math:`k < n`, LOO es más costoso computacionalmente que la validación cruzada de :math:`k`."

#: ../modules/cross_validation.rst:429
msgid "In terms of accuracy, LOO often results in high variance as an estimator for the test error. Intuitively, since :math:`n - 1` of the :math:`n` samples are used to build each model, models constructed from folds are virtually identical to each other and to the model built from the entire training set."
msgstr "En términos de precisión, la LOO suele dar lugar a una alta varianza como estimador del error de la prueba. Intuitivamente, dado que :math:`n - 1` de las muestras :math:`n` se utilizan para construir cada modelo, los modelos construidos a partir de partes son prácticamente idénticos entre sí y al modelo construido a partir del conjunto de entrenamiento completo."

#: ../modules/cross_validation.rst:435
msgid "However, if the learning curve is steep for the training size in question, then 5- or 10- fold cross validation can overestimate the generalization error."
msgstr "Sin embargo, si la curva de aprendizaje es pronunciada para el volumen de entrenamiento en cuestión, la validación cruzada de 5 o 10 partes puede sobreestimar el error de generalización."

#: ../modules/cross_validation.rst:438
msgid "As a general rule, most authors, and empirical evidence, suggest that 5- or 10- fold cross validation should be preferred to LOO."
msgstr "Como regla general, la mayoría de los autores, y la evidencia empírica, sugieren que la validación cruzada de 5 o 10 partes debería preferirse a la LOO."

#: ../modules/cross_validation.rst:444
msgid "`<http://www.faqs.org/faqs/ai-faq/neural-nets/part3/section-12.html>`_;"
msgstr "`<http://www.faqs.org/faqs/ai-faq/neural-nets/part3/section-12.html>`_;"

#: ../modules/cross_validation.rst:445
msgid "T. Hastie, R. Tibshirani, J. Friedman,  `The Elements of Statistical Learning <https://web.stanford.edu/~hastie/ElemStatLearn/>`_, Springer 2009"
msgstr "T. Hastie, R. Tibshirani, J. Friedman,  `The Elements of Statistical Learning <https://web.stanford.edu/~hastie/ElemStatLearn/>`_, Springer 2009"

#: ../modules/cross_validation.rst:447
msgid "L. Breiman, P. Spector `Submodel selection and evaluation in regression: The X-random case <http://digitalassets.lib.berkeley.edu/sdtr/ucb/text/197.pdf>`_, International Statistical Review 1992;"
msgstr "L. Breiman, P. Spector `Submodel selection and evaluation in regression: The X-random case <http://digitalassets.lib.berkeley.edu/sdtr/ucb/text/197.pdf>`_, International Statistical Review 1992;"

#: ../modules/cross_validation.rst:449
msgid "R. Kohavi, `A Study of Cross-Validation and Bootstrap for Accuracy Estimation and Model Selection <http://web.cs.iastate.edu/~jtian/cs573/Papers/Kohavi-IJCAI-95.pdf>`_, Intl. Jnt. Conf. AI"
msgstr "R. Kohavi, `A Study of Cross-Validation and Bootstrap for Accuracy Estimation and Model Selection <http://web.cs.iastate.edu/~jtian/cs573/Papers/Kohavi-IJCAI-95.pdf>`_, Intl. Jnt. Conf. AI"

#: ../modules/cross_validation.rst:451
msgid "R. Bharat Rao, G. Fung, R. Rosales, `On the Dangers of Cross-Validation. An Experimental Evaluation <https://people.csail.mit.edu/romer/papers/CrossVal_SDM08.pdf>`_, SIAM 2008;"
msgstr "R. Bharat Rao, G. Fung, R. Rosales, `On the Dangers of Cross-Validation. An Experimental Evaluation <https://people.csail.mit.edu/romer/papers/CrossVal_SDM08.pdf>`_, SIAM 2008;"

#: ../modules/cross_validation.rst:453
msgid "G. James, D. Witten, T. Hastie, R Tibshirani, `An Introduction to Statistical Learning <https://www-bcf.usc.edu/~gareth/ISL/>`_, Springer 2013."
msgstr "G. James, D. Witten, T. Hastie, R Tibshirani, `An Introduction to Statistical Learning <https://www-bcf.usc.edu/~gareth/ISL/>`_, Springer 2013."

#: ../modules/cross_validation.rst:459
msgid "Leave P Out (LPO)"
msgstr "Leave P Out (LPO)"

#: ../modules/cross_validation.rst:461
msgid ":class:`LeavePOut` is very similar to :class:`LeaveOneOut` as it creates all the possible training/test sets by removing :math:`p` samples from the complete set. For :math:`n` samples, this produces :math:`{n \\choose p}` train-test pairs. Unlike :class:`LeaveOneOut` and :class:`KFold`, the test sets will overlap for :math:`p > 1`."
msgstr ":class:`LeavePOut` es muy similar a :class:`LeaveOneOut` ya que crea todos los posibles conjuntos de entrenamiento/prueba eliminando las muestras :math:`p` del conjunto completo. Para las muestras de :math:`n`, esto produce pares de entrenamiento-prueba de :math:`{n \\choose p}`. A diferencia de :class:`LeaveOneOut` y :class:`KFold`, los conjuntos de prueba se superponen para :math:`p > 1`."

#: ../modules/cross_validation.rst:467
msgid "Example of Leave-2-Out on a dataset with 4 samples::"
msgstr "Ejemplo de Leave-2-Out en un conjunto de datos con 4 muestras::"

#: ../modules/cross_validation.rst:486
msgid "Random permutations cross-validation a.k.a. Shuffle & Split"
msgstr "Validación cruzada de permutaciones aleatorias, también conocida como Mezcla y División"

#: ../modules/cross_validation.rst:488
msgid "The :class:`ShuffleSplit` iterator will generate a user defined number of independent train / test dataset splits. Samples are first shuffled and then split into a pair of train and test sets."
msgstr "El iterador :class:`ShuffleSplit` generará un número definido por el usuario de divisiones independientes del conjunto de datos de entrenamiento/prueba. Las muestras se barajan primero y luego se dividen en un par de conjuntos de entrenamiento y prueba."

#: ../modules/cross_validation.rst:492
msgid "It is possible to control the randomness for reproducibility of the results by explicitly seeding the ``random_state`` pseudo random number generator."
msgstr "Es posible controlar la aleatoriedad para la reproducibilidad de los resultados sembrando explícitamente el generador de números pseudoaleatorios ``random_state``."

#: ../modules/cross_validation.rst:496 ../modules/cross_validation.rst:718
msgid "Here is a usage example::"
msgstr "Este es un ejemplo de uso::"

#: ../modules/cross_validation.rst:509
msgid "Here is a visualization of the cross-validation behavior. Note that :class:`ShuffleSplit` is not affected by classes or groups."
msgstr "Aquí hay una visualización del comportamiento de la validación cruzada. Tenga en cuenta que :class:`ShuffleSplit` no se ve afectado por las clases o grupos."

#: ../modules/cross_validation.rst:517
msgid ":class:`ShuffleSplit` is thus a good alternative to :class:`KFold` cross validation that allows a finer control on the number of iterations and the proportion of samples on each side of the train / test split."
msgstr "Por tanto, :class:`ShuffleSplit` es una buena alternativa a la validación cruzada :class:`KFold` que permite un control más fino del número de iteraciones y de la proporción de muestras en cada lado de la división entrenamiento/prueba."

#: ../modules/cross_validation.rst:524
msgid "Cross-validation iterators with stratification based on class labels."
msgstr "Iteradores de validación cruzada con estratificación basada en las etiquetas de clase."

#: ../modules/cross_validation.rst:526
msgid "Some classification problems can exhibit a large imbalance in the distribution of the target classes: for instance there could be several times more negative samples than positive samples. In such cases it is recommended to use stratified sampling as implemented in :class:`StratifiedKFold` and :class:`StratifiedShuffleSplit` to ensure that relative class frequencies is approximately preserved in each train and validation fold."
msgstr "Algunos problemas de clasificación pueden presentar un gran desequilibrio en la distribución de las clases objetivo: por ejemplo, puede haber varias veces más muestras negativas que positivas. En estos casos se recomienda utilizar el muestreo estratificado como se implementa en :class:`StratifiedKFold` y :class:`StratifiedShuffleSplit` para asegurar que las frecuencias relativas de las clases se conserven aproximadamente en cada parte de entrenamiento y validación."

#: ../modules/cross_validation.rst:536
msgid "Stratified k-fold"
msgstr "K-fold estratificado"

#: ../modules/cross_validation.rst:538
msgid ":class:`StratifiedKFold` is a variation of *k-fold* which returns *stratified* folds: each set contains approximately the same percentage of samples of each target class as the complete set."
msgstr ":class:`StratifiedKFold` es una variación de *k-fold* que devuelve partes *estratificadas*: cada conjunto contiene aproximadamente el mismo porcentaje de muestras de cada clase objetivo que el conjunto completo."

#: ../modules/cross_validation.rst:542
msgid "Here is an example of stratified 3-fold cross-validation on a dataset with 50 samples from two unbalanced classes.  We show the number of samples in each class and compare with :class:`KFold`."
msgstr "Este es un ejemplo de validación cruzada estratificada de 3 partes en un conjunto de datos con 50 muestras de dos clases no equilibradas.  Se presenta el número de muestras de cada clase y se compara con :class:`KFold`."

#: ../modules/cross_validation.rst:564
msgid "We can see that :class:`StratifiedKFold` preserves the class ratios (approximately 1 / 10) in both train and test dataset."
msgstr "Podemos ver que :class:`StratifiedKFold` preserva los ratios de clase (aproximadamente 1 / 10) tanto en el conjunto de datos de entrenamiento como en el de prueba."

#: ../modules/cross_validation.rst:567 ../modules/cross_validation.rst:586
#: ../modules/cross_validation.rst:646 ../modules/cross_validation.rst:734
#: ../modules/cross_validation.rst:836
msgid "Here is a visualization of the cross-validation behavior."
msgstr "Aquí hay una visualización del comportamiento de la validación cruzada."

#: ../modules/cross_validation.rst:574
msgid ":class:`RepeatedStratifiedKFold` can be used to repeat Stratified K-Fold n times with different randomization in each repetition."
msgstr ":class:`RepeatedStratifiedKFold` se puede utilizar para repetir el K-Fold Estratificado n veces con diferente aleatorización en cada repetición."

#: ../modules/cross_validation.rst:580
msgid "Stratified Shuffle Split"
msgstr "División aleatoria estratificada"

#: ../modules/cross_validation.rst:582
msgid ":class:`StratifiedShuffleSplit` is a variation of *ShuffleSplit*, which returns stratified splits, *i.e* which creates splits by preserving the same percentage for each target class as in the complete set."
msgstr ":class:`StratifiedShuffleSplit` es una variación de *Mezcla y División*, que devuelve divisiones estratificadas, *es decir* que crea divisiones conservando el mismo porcentaje para cada clase objetivo que en el conjunto completo."

#: ../modules/cross_validation.rst:596
msgid "Cross-validation iterators for grouped data."
msgstr "Iteradores de validación cruzada para datos agrupados."

#: ../modules/cross_validation.rst:598
msgid "The i.i.d. assumption is broken if the underlying generative process yield groups of dependent samples."
msgstr "La suposición i.i.d. se rompe si el proceso generativo subyacente produce grupos de muestras dependientes."

#: ../modules/cross_validation.rst:601
msgid "Such a grouping of data is domain specific. An example would be when there is medical data collected from multiple patients, with multiple samples taken from each patient. And such data is likely to be dependent on the individual group. In our example, the patient id for each sample will be its group identifier."
msgstr "Tal agrupación de datos es específica del dominio. Un ejemplo sería cuando hay datos médicos recogidos de múltiples pacientes, con múltiples muestras tomadas de cada paciente. Y es probable que esos datos sean dependientes del grupo individual. En nuestro ejemplo, el identificador del paciente de cada muestra será su identificador de grupo."

#: ../modules/cross_validation.rst:606
msgid "In this case we would like to know if a model trained on a particular set of groups generalizes well to the unseen groups. To measure this, we need to ensure that all the samples in the validation fold come from groups that are not represented at all in the paired training fold."
msgstr "En este caso, nos gustaría saber si un modelo entrenado en un determinado conjunto de grupos generaliza bien a los grupos no vistos. Para medirlo, tenemos que asegurarnos de que todas las muestras en esa parte de la validación proceden de grupos que no están representados en absoluto en la parte de entrenamiento emparejado."

#: ../modules/cross_validation.rst:611
msgid "The following cross-validation splitters can be used to do that. The grouping identifier for the samples is specified via the ``groups`` parameter."
msgstr "Para ello, se pueden utilizar los siguientes divisores de validación cruzada. El identificador de agrupación de las muestras se especifica mediante el parámetro ``groups``."

#: ../modules/cross_validation.rst:618
msgid "Group k-fold"
msgstr "K-fold de grupos"

#: ../modules/cross_validation.rst:620
msgid ":class:`GroupKFold` is a variation of k-fold which ensures that the same group is not represented in both testing and training sets. For example if the data is obtained from different subjects with several samples per-subject and if the model is flexible enough to learn from highly person specific features it could fail to generalize to new subjects. :class:`GroupKFold` makes it possible to detect this kind of overfitting situations."
msgstr ":class:`GroupKFold` es una variación de k-fold que garantiza que el mismo grupo no esté representado en los conjuntos de prueba y de entrenamiento. Por ejemplo, si los datos se obtienen de diferentes sujetos con varias muestras por sujeto y si el modelo es lo suficientemente flexible como para aprender de características muy específicas de la persona, podría fallar al generalizar para nuevos sujetos. :class:`GroupKFold` permite detectar este tipo de situaciones de sobreajuste."

#: ../modules/cross_validation.rst:627
msgid "Imagine you have three subjects, each with an associated number from 1 to 3::"
msgstr "Imagina que tienes tres sujetos, cada uno con un número asociado del 1 al 3::"

#: ../modules/cross_validation.rst:642
msgid "Each subject is in a different testing fold, and the same subject is never in both testing and training. Notice that the folds do not have exactly the same size due to the imbalance in the data."
msgstr "Cada sujeto está en un pliegue de prueba diferente, y el mismo sujeto nunca está tanto en la prueba como en el entrenamiento. Observa que las partes no tienen exactamente el mismo tamaño debido al desequilibrio de los datos."

#: ../modules/cross_validation.rst:656
msgid "Leave One Group Out"
msgstr "Dejar un grupo afuera (Leave One Group Out)"

#: ../modules/cross_validation.rst:658
msgid ":class:`LeaveOneGroupOut` is a cross-validation scheme which holds out the samples according to a third-party provided array of integer groups. This group information can be used to encode arbitrary domain specific pre-defined cross-validation folds."
msgstr ":class:`LeaveOneGroupOut` es un esquema de validación cruzada que mantiene las muestras según una matriz de grupos enteros proporcionada por terceros. Esta información de grupo puede utilizarse para codificar partes de validación cruzada predefinidas y específicas del dominio."

#: ../modules/cross_validation.rst:663
msgid "Each training set is thus constituted by all the samples except the ones related to a specific group."
msgstr "De este modo, cada conjunto de entrenamiento está constituido por todas las muestras excepto las relacionadas con un grupo específico."

#: ../modules/cross_validation.rst:666
msgid "For example, in the cases of multiple experiments, :class:`LeaveOneGroupOut` can be used to create a cross-validation based on the different experiments: we create a training set using the samples of all the experiments except one::"
msgstr "Por ejemplo, en los casos de experimentos múltiples, se puede utilizar :class:`LeaveOneGroupOut` para crear una validación cruzada basada en los diferentes experimentos: creamos un conjunto de entrenamiento utilizando las muestras de todos los experimentos excepto uno::"

#: ../modules/cross_validation.rst:682
msgid "Another common application is to use time information: for instance the groups could be the year of collection of the samples and thus allow for cross-validation against time-based splits."
msgstr "Otra aplicación común es utilizar información temporal: por ejemplo, los grupos podrían ser el año de recogida de las muestras y así permitir la validación cruzada contra divisiones basadas en el tiempo."

#: ../modules/cross_validation.rst:689
msgid "Leave P Groups Out"
msgstr "Dejar fuera los grupos P"

#: ../modules/cross_validation.rst:691
msgid ":class:`LeavePGroupsOut` is similar as :class:`LeaveOneGroupOut`, but removes samples related to :math:`P` groups for each training/test set."
msgstr ":class:`LeavePGroupsOut` es similar a :class:`LeaveOneGroupOut`, pero elimina las muestras relacionadas con los grupos de :math:`P` para cada conjunto de entrenamiento/prueba."

#: ../modules/cross_validation.rst:694
msgid "Example of Leave-2-Group Out::"
msgstr "Ejemplo de Dejar-2-Grupos Afuera::"

#: ../modules/cross_validation.rst:711
msgid "Group Shuffle Split"
msgstr "Dividir grupos de forma aleatoria"

#: ../modules/cross_validation.rst:713
msgid "The :class:`GroupShuffleSplit` iterator behaves as a combination of :class:`ShuffleSplit` and :class:`LeavePGroupsOut`, and generates a sequence of randomized partitions in which a subset of groups are held out for each split."
msgstr "El iterador :class:`GroupShuffleSplit` se comporta como una combinación de :class:`ShuffleSplit` y :class:`LeavePGroupsOut`, y genera una secuencia de particiones aleatorias en las que se mantiene un subconjunto de grupos para cada partición."

#: ../modules/cross_validation.rst:741
msgid "This class is useful when the behavior of :class:`LeavePGroupsOut` is desired, but the number of groups is large enough that generating all possible partitions with :math:`P` groups withheld would be prohibitively expensive. In such a scenario, :class:`GroupShuffleSplit` provides a random sample (with replacement) of the train / test splits generated by :class:`LeavePGroupsOut`."
msgstr "Esta clase es útil cuando se desea el comportamiento de :class:`LeavePGroupsOut`, pero el número de grupos es lo suficientemente grande como para que generar todas las posibles particiones con grupos retenidos de :math:`P` sea prohibitivamente costoso. En este caso, :class:`GroupShuffleSplit` proporciona una muestra aleatoria (con reemplazo) de las particiones de entrenamiento/prueba generadas por :class:`LeavePGroupsOut`."

#: ../modules/cross_validation.rst:751
msgid "Predefined Fold-Splits / Validation-Sets"
msgstr "Divisiones predefinidas/ Conjuntos de validación"

#: ../modules/cross_validation.rst:753
msgid "For some datasets, a pre-defined split of the data into training- and validation fold or into several cross-validation folds already exists. Using :class:`PredefinedSplit` it is possible to use these folds e.g. when searching for hyperparameters."
msgstr "Para algunos conjuntos de datos, ya existe una división predefinida de los datos en partes de entrenamiento y validación o en varias partes de validación cruzada. Utilizando :class:`PredefinedSplit` es posible utilizar estas partes, por ejemplo, cuando se buscan hiperparámetros."

#: ../modules/cross_validation.rst:758
msgid "For example, when using a validation set, set the ``test_fold`` to 0 for all samples that are part of the validation set, and to -1 for all other samples."
msgstr "Por ejemplo, cuando se utiliza un conjunto de validación, establezca el ``test_fold`` a 0 para todas las muestras que forman parte del conjunto de validación, y a -1 para todas las demás muestras."

#: ../modules/cross_validation.rst:762
msgid "Using cross-validation iterators to split train and test"
msgstr "Uso de los iteradores de validación cruzada para dividir el entrenamiento y la prueba"

#: ../modules/cross_validation.rst:764
msgid "The above group cross-validation functions may also be useful for spitting a dataset into training and testing subsets. Note that the convenience function :func:`train_test_split` is a wrapper around :func:`ShuffleSplit` and thus only allows for stratified splitting (using the class labels) and cannot account for groups."
msgstr "Las anteriores funciones de validación cruzada de grupo también pueden ser útiles para dividir un conjunto de datos en subconjuntos de entrenamiento y prueba. Ten en cuenta que la función :func:`train_test_split` es un envoltorio de :func:`ShuffleSplit` y, por tanto, sólo permite la división estratificada (utilizando las etiquetas de clase) y no puede tener en cuenta los grupos."

#: ../modules/cross_validation.rst:770
msgid "To perform the train and test split, use the indices for the train and test subsets yielded by the generator output by the `split()` method of the cross-validation splitter. For example::"
msgstr "Para realizar la división de entrenamiento y prueba, utiliza los índices de los subconjuntos de entrenamiento y prueba producidos por la salida del generador mediante el método `split()` del divisor de validación cruzada. Por ejemplo::"

#: ../modules/cross_validation.rst:793
msgid "Cross validation of time series data"
msgstr "Validación cruzada de datos de series de tiempo"

#: ../modules/cross_validation.rst:795
msgid "Time series data is characterised by the correlation between observations that are near in time (*autocorrelation*). However, classical cross-validation techniques such as :class:`KFold` and :class:`ShuffleSplit` assume the samples are independent and identically distributed, and would result in unreasonable correlation between training and testing instances (yielding poor estimates of generalisation error) on time series data. Therefore, it is very important to evaluate our model for time series data on the \"future\" observations least like those that are used to train the model. To achieve this, one solution is provided by :class:`TimeSeriesSplit`."
msgstr "Los datos de las series de tiempo se caracterizan por la correlación entre observaciones cercanas en el tiempo (*autocorrelación*). Sin embargo, las técnicas clásicas de validación cruzada, como :class:`KFold` y :class:`ShuffleSplit`, suponen que las muestras son independientes y están idénticamente distribuidas, y darían lugar a una correlación poco razonable entre las instancias de entrenamiento y las de prueba (lo que daría lugar a malas estimaciones del error de generalización) en los datos de series de tiempo. Por lo tanto, es muy importante evaluar nuestro modelo para datos de series de tiempo en las observaciones \"futuras\" menos parecidas a las que se utilizan para entrenar el modelo. Para conseguirlo, una solución es la que proporciona :class:`TimeSeriesSplit`."

#: ../modules/cross_validation.rst:809
msgid "Time Series Split"
msgstr "División de series de tiempo"

#: ../modules/cross_validation.rst:811
msgid ":class:`TimeSeriesSplit` is a variation of *k-fold* which returns first :math:`k` folds as train set and the :math:`(k+1)` th fold as test set. Note that unlike standard cross-validation methods, successive training sets are supersets of those that come before them. Also, it adds all surplus data to the first training partition, which is always used to train the model."
msgstr ":class:`TimeSeriesSplit` es una variación de *k-fold* que devuelve los primeros pliegues de :math:`k` como conjunto de entrenamiento y el :math:`(k+1)` última parte como conjunto de prueba. Tenga en cuenta que, a diferencia de los métodos estándar de validación cruzada, los conjuntos de entrenamiento sucesivos son superconjuntos de los que vienen antes. Además, añade todos los datos sobrantes a la primera partición de entrenamiento, que siempre se utiliza para entrenar el modelo."

#: ../modules/cross_validation.rst:818
msgid "This class can be used to cross-validate time series data samples that are observed at fixed time intervals."
msgstr "Esta clase puede utilizarse para la validación cruzada de muestras de datos de series de tiempo que se observan en intervalos de tiempo fijos."

#: ../modules/cross_validation.rst:821
msgid "Example of 3-split time series cross-validation on a dataset with 6 samples::"
msgstr "Ejemplo de validación cruzada de series de tiempo con 3 divisiones en un conjunto de datos con 6 muestras::"

#: ../modules/cross_validation.rst:844
msgid "A note on shuffling"
msgstr "Nota sobre la mezcla"

#: ../modules/cross_validation.rst:846
msgid "If the data ordering is not arbitrary (e.g. samples with the same class label are contiguous), shuffling it first may be essential to get a meaningful cross- validation result. However, the opposite may be true if the samples are not independently and identically distributed. For example, if samples correspond to news articles, and are ordered by their time of publication, then shuffling the data will likely lead to a model that is overfit and an inflated validation score: it will be tested on samples that are artificially similar (close in time) to training samples."
msgstr "Si el orden de los datos no es arbitrario (por ejemplo, las muestras con la misma etiqueta de clase son contiguas), mezclarlas primero puede ser esencial para obtener un resultado de validación cruzada significativo. Sin embargo, puede ocurrir lo contrario si las muestras no están distribuidas de forma independiente e idéntica. Por ejemplo, si las muestras corresponden a artículos de noticias, y están ordenadas por su hora de publicación, entonces barajar los datos probablemente conducirá a un modelo que está sobreajustado y a una puntuación de validación inflada: se probará en muestras que son artificialmente similares (cercanas en el tiempo) a las muestras de entrenamiento."

#: ../modules/cross_validation.rst:855
msgid "Some cross validation iterators, such as :class:`KFold`, have an inbuilt option to shuffle the data indices before splitting them. Note that:"
msgstr "Algunos iteradores de validación cruzada, como :class:`KFold`, tienen una opción incorporada para revolver los índices de datos antes de dividirlos. Tenga en cuenta que:"

#: ../modules/cross_validation.rst:858
msgid "This consumes less memory than shuffling the data directly."
msgstr "Esto consume menos memoria que revolver los datos directamente."

#: ../modules/cross_validation.rst:859
msgid "By default no shuffling occurs, including for the (stratified) K fold cross- validation performed by specifying ``cv=some_integer`` to :func:`cross_val_score`, grid search, etc. Keep in mind that :func:`train_test_split` still returns a random split."
msgstr "Por defecto no se revuelve, incluso para la validación cruzada (estratificada) de K partes que se realiza especificando ``cv=algunos_integros`` a :func:`cross_val_score`, búsqueda en cuadrícula, etc. Tenga en cuenta que :func:`train_test_split` sigue devolviendo una división aleatoria."

#: ../modules/cross_validation.rst:863
msgid "The ``random_state`` parameter defaults to ``None``, meaning that the shuffling will be different every time ``KFold(..., shuffle=True)`` is iterated. However, ``GridSearchCV`` will use the same shuffling for each set of parameters validated by a single call to its ``fit`` method."
msgstr "El parámetro ``random_state`` es por defecto ``None``, lo que significa que la forma de revolver será diferente cada vez que se itere ``KFold(..., shuffle=True)``. Sin embargo, ``GridSearchCV`` utilizará el mismo proceso de revolver para cada conjunto de parámetros validados por una única llamada a su método ``fit``."

#: ../modules/cross_validation.rst:867
msgid "To get identical results for each split, set ``random_state`` to an integer."
msgstr "Para obtener resultados idénticos para cada división, establezca ``random_state`` a un número entero."

#: ../modules/cross_validation.rst:869
msgid "For more details on how to control the randomness of cv splitters and avoid common pitfalls, see :ref:`randomness`."
msgstr "Para más detalles sobre cómo controlar la aleatoriedad de los divisores de cv y evitar errores comunes, véase :ref:`randomness`."

#: ../modules/cross_validation.rst:873
msgid "Cross validation and model selection"
msgstr "Validación cruzada y selección de modelos"

#: ../modules/cross_validation.rst:875
msgid "Cross validation iterators can also be used to directly perform model selection using Grid Search for the optimal hyperparameters of the model. This is the topic of the next section: :ref:`grid_search`."
msgstr "Los iteradores de validación cruzada también pueden utilizarse para realizar directamente la selección del modelo mediante la búsqueda en cuadrícula de los hiperparámetros óptimos del modelo. Este es el tema de la siguiente sección: :ref:`grid_search`."

#: ../modules/cross_validation.rst:882
msgid "Permutation test score"
msgstr "Puntuación de la prueba de permutación"

#: ../modules/cross_validation.rst:884
msgid ":func:`~sklearn.model_selection.permutation_test_score` offers another way to evaluate the performance of classifiers. It provides a permutation-based p-value, which represents how likely an observed performance of the classifier would be obtained by chance. The null hypothesis in this test is that the classifier fails to leverage any statistical dependency between the features and the labels to make correct predictions on left out data. :func:`~sklearn.model_selection.permutation_test_score` generates a null distribution by calculating `n_permutations` different permutations of the data. In each permutation the labels are randomly shuffled, thereby removing any dependency between the features and the labels. The p-value output is the fraction of permutations for which the average cross-validation score obtained by the model is better than the cross-validation score obtained by the model using the original data. For reliable results ``n_permutations`` should typically be larger than 100 and ``cv`` between 3-10 folds."
msgstr ":func:`~sklearn.model_selection.permutation_test_score` ofrece otra forma de evaluar el rendimiento de los clasificadores. Proporciona un valor p basado en la permutación, que representa la probabilidad de que un rendimiento observado del clasificador se obtenga por azar. La hipótesis nula en esta prueba es que el clasificador no aprovecha ninguna dependencia estadística entre las características y las etiquetas para hacer predicciones correctas en los datos omitidos. :func:`~sklearn.model_selection.permutation_test_score` genera una distribución nula calculando `n_permutaciones` diferentes de los datos. En cada permutación las etiquetas se revuelven aleatoriamente, eliminando así cualquier dependencia entre las características y las etiquetas. El valor p resultante es la fracción de permutaciones para las que la puntuación media de validación cruzada obtenida por el modelo es mejor que la puntuación de validación cruzada obtenida por el modelo utilizando los datos originales. Para obtener resultados fiables, ``n_permutaciones`` debe ser normalmente superior a 100 y ``cv`` entre 3-10 partes."

#: ../modules/cross_validation.rst:899
msgid "A low p-value provides evidence that the dataset contains real dependency between features and labels and the classifier was able to utilize this to obtain good results. A high p-value could be due to a lack of dependency between features and labels (there is no difference in feature values between the classes) or because the classifier was not able to use the dependency in the data. In the latter case, using a more appropriate classifier that is able to utilize the structure in the data, would result in a low p-value."
msgstr "Un valor p bajo demuestra que el conjunto de datos contiene una dependencia real entre las características y las etiquetas y que el clasificador ha sido capaz de utilizarla para obtener buenos resultados. Un valor p alto podría deberse a la falta de dependencia entre las características y las etiquetas (no hay diferencias en los valores de las características entre las clases) o a que el clasificador no fue capaz de utilizar la dependencia en los datos. En este último caso, el uso de un clasificador más adecuado que sea capaz de utilizar la estructura de los datos daría lugar a un valor p bajo."

#: ../modules/cross_validation.rst:908
msgid "Cross-validation provides information about how well a classifier generalizes, specifically the range of expected errors of the classifier. However, a classifier trained on a high dimensional dataset with no structure may still perform better than expected on cross-validation, just by chance. This can typically happen with small datasets with less than a few hundred samples. :func:`~sklearn.model_selection.permutation_test_score` provides information on whether the classifier has found a real class structure and can help in evaluating the performance of the classifier."
msgstr "La validación cruzada proporciona información sobre el grado de generalización de un clasificador, concretamente el rango de errores esperados del clasificador. Sin embargo, un clasificador entrenado en un conjunto de datos de alta dimensión sin estructura puede tener un rendimiento mejor de lo esperado en la validación cruzada, por pura casualidad. Esto puede ocurrir típicamente con conjuntos de datos pequeños con menos de unos cientos de muestras. :func:`~sklearn.model_selection.permutation_test_score` proporciona información sobre si el clasificador ha encontrado una estructura de clase real y puede ayudar a evaluar el rendimiento del clasificador."

#: ../modules/cross_validation.rst:918
msgid "It is important to note that this test has been shown to produce low p-values even if there is only weak structure in the data because in the corresponding permutated datasets there is absolutely no structure. This test is therefore only able to show when the model reliably outperforms random guessing."
msgstr "Es importante señalar que se ha demostrado que esta prueba produce valores p bajos incluso si sólo hay una estructura débil en los datos, porque en los conjuntos de datos permutados correspondientes no hay absolutamente ninguna estructura. Por lo tanto, esta prueba sólo es capaz de mostrar cuándo el modelo supera de forma fiable las conjeturas al azar."

#: ../modules/cross_validation.rst:924
msgid "Finally, :func:`~sklearn.model_selection.permutation_test_score` is computed using brute force and interally fits ``(n_permutations + 1) * n_cv`` models. It is therefore only tractable with small datasets for which fitting an individual model is very fast."
msgstr "Por último, :func:`~sklearn.model_selection.permutation_test_score` se calcula utilizando la fuerza bruta y se ajusta internamente a los modelos ``(n_permutations + 1) * n_cv``. Por lo tanto, sólo es viable con conjuntos de datos pequeños para los que el ajuste de un modelo individual es muy rápido."

#: ../modules/cross_validation.rst:931
msgid ":ref:`sphx_glr_auto_examples_feature_selection_plot_permutation_test_for_classification.py`"
msgstr ":ref:`sphx_glr_auto_examples_feature_selection_plot_permutation_test_for_classification.py`"

#: ../modules/cross_validation.rst:935
msgid "Ojala and Garriga. `Permutation Tests for Studying Classifier Performance <http://www.jmlr.org/papers/volume11/ojala10a/ojala10a.pdf>`_. J. Mach. Learn. Res. 2010."
msgstr "Ojala and Garriga. `Permutation Tests for Studying Classifier Performance <http://www.jmlr.org/papers/volume11/ojala10a/ojala10a.pdf>`_. J. Mach. Learn. Res. 2010."

