msgid ""
msgstr ""
"Project-Id-Version: scikit-learn\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-03-31 11:24-0400\n"
"PO-Revision-Date: 2021-04-28 19:57\n"
"Last-Translator: \n"
"Language-Team: Spanish\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Crowdin-Project: scikit-learn\n"
"X-Crowdin-Project-ID: 450526\n"
"X-Crowdin-Language: es-ES\n"
"X-Crowdin-File: /main/doc/en/modules/permutation_importance.po\n"
"X-Crowdin-File-ID: 4806\n"
"Language: es_ES\n"

#: ../modules/permutation_importance.rst:5
msgid "Permutation feature importance"
msgstr "Importancia de la característica de permutación"

#: ../modules/permutation_importance.rst:9
msgid "Permutation feature importance is a model inspection technique that can be used for any :term:`fitted` :term:`estimator` when the data is tabular. This is especially useful for non-linear or opaque :term:`estimators`. The permutation feature importance is defined to be the decrease in a model score when a single feature value is randomly shuffled [1]_. This procedure breaks the relationship between the feature and the target, thus the drop in the model score is indicative of how much the model depends on the feature. This technique benefits from being model agnostic and can be calculated many times with different permutations of the feature."
msgstr "La importancia de la característica de permutación es una técnica de inspección del modelo que puede ser usada para cualquier :term:`estimador` :term:`ajustado` cuando los datos son tabulares. Esto es especialmente útil para los :term:`estimadores` no lineales u opacos. La importancia de la característica de permutación se define como la disminución de la puntuación de un modelo cuando un único valor de la característica se baraja aleatoriamente [1]_. Este procedimiento rompe la relación entre la característica y el objetivo, por lo tanto, la caída en la puntuación del modelo es indicativa de cuánto depende el modelo de la característica. Esta técnica se beneficia de ser independiente del modelo y se puede calcular muchas veces con diferentes permutaciones de la característica."

#: ../modules/permutation_importance.rst:19
msgid "The :func:`permutation_importance` function calculates the feature importance of :term:`estimators` for a given dataset. The ``n_repeats`` parameter sets the number of times a feature is randomly shuffled and returns a sample of feature importances."
msgstr "La función :func:`permutation_importance` calcula la importancia de las características de :term:`estimadores` para un conjunto de datos determinado. El parámetro ``n_repeats`` establece el número de veces que una característica se baraja aleatoriamente y devuelve una muestra de las importancias de las características."

#: ../modules/permutation_importance.rst:24
msgid "Let's consider the following trained regression model::"
msgstr "Consideremos el siguiente modelo de regresión entrenado::"

#: ../modules/permutation_importance.rst:37
msgid "Its validation performance, measured via the :math:`R^2` score, is significantly larger than the chance level. This makes it possible to use the :func:`permutation_importance` function to probe which features are most predictive::"
msgstr "Su validación de rendimiento, medido a través de la puntuación :math:`R^2`, es significativamente mayor que el nivel de azar. Esto permite utilizar la función :func:`permutation_importance` para comprobar qué características son más predictivas::"

#: ../modules/permutation_importance.rst:58
msgid "Note that the importance values for the top features represent a large fraction of the reference score of 0.356."
msgstr "Ten en cuenta que los valores de importancia para las características superiores representan una fracción grande de la puntuación de referencia de 0,356."

#: ../modules/permutation_importance.rst:61
msgid "Permutation importances can be computed either on the training set or on a held-out testing or validation set. Using a held-out set makes it possible to highlight which features contribute the most to the generalization power of the inspected model. Features that are important on the training set but not on the held-out set might cause the model to overfit."
msgstr "Las importancias de las permutaciones pueden ser calculadas en el conjunto de entrenamiento o en un conjunto de prueba o validación apartado (held-out). El uso de un conjunto apartado permite destacar las características que contribuyen más a la potencia de generalización del modelo inspeccionado. Las características que son importantes en el conjunto de entrenamiento pero no en el conjunto apartado pueden hacer que el modelo se ajuste en exceso."

#: ../modules/permutation_importance.rst:69
msgid "Features that are deemed of **low importance for a bad model** (low cross-validation score) could be **very important for a good model**. Therefore it is always important to evaluate the predictive power of a model using a held-out set (or better with cross-validation) prior to computing importances. Permutation importance does not reflect to the intrinsic predictive value of a feature by itself but **how important this feature is for a particular model**."
msgstr "Las características que se consideran de **baja importancia para un mal modelo** (baja puntuación de validación cruzada) podrían ser **muy importantes para un buen modelo**. Por lo tanto, siempre es importante evaluar la potencia predictiva de un modelo utilizando un conjunto apartado (o mejor con validación cruzada) previo al cálculo de las importancias. La importancia de la permutación no refleja el valor predictivo intrínseco de una característica por sí misma, sino **cuán importante es esta característica para un modelo en particular**."

#: ../modules/permutation_importance.rst:78
msgid "Outline of the permutation importance algorithm"
msgstr "Esquema del algoritmo de importancia de la permutación"

#: ../modules/permutation_importance.rst:80
msgid "Inputs: fitted predictive model :math:`m`, tabular dataset (training or validation) :math:`D`."
msgstr "Entradas: modelo predictivo ajustado :math:`m`, conjunto de datos tabular (entrenamiento o validación) :math:`D`."

#: ../modules/permutation_importance.rst:82
msgid "Compute the reference score :math:`s` of the model :math:`m` on data :math:`D` (for instance the accuracy for a classifier or the :math:`R^2` for a regressor)."
msgstr "Calcula la puntuación de referencia :math:`s` del modelo :math:`m` en los datos :math:`D` (por ejemplo, la exactitud para un clasificador o el :math:`R^2` para un regresor)."

#: ../modules/permutation_importance.rst:85
msgid "For each feature :math:`j` (column of :math:`D`):"
msgstr "Para cada característica :math:`j` (columna de :math:`D`):"

#: ../modules/permutation_importance.rst:87
msgid "For each repetition :math:`k` in :math:`{1, ..., K}`:"
msgstr "Para cada repetición :math:`k` en :math:`{1, ..., K}`:"

#: ../modules/permutation_importance.rst:89
msgid "Randomly shuffle column :math:`j` of dataset :math:`D` to generate a corrupted version of the data named :math:`\\tilde{D}_{k,j}`."
msgstr "Baraja aleatoriamente la columna :math:`j` del conjunto de datos :math:`D` para generar una versión corrupta de los datos denominada :math:`\\tilde{D}_{k,j}`."

#: ../modules/permutation_importance.rst:91
msgid "Compute the score :math:`s_{k,j}` of model :math:`m` on corrupted data :math:`\\tilde{D}_{k,j}`."
msgstr "Calcula la puntuación :math:`s_{k,j}` del modelo :math:`m` en los datos corruptos :math:`\\tilde{D}_{k,j}`."

#: ../modules/permutation_importance.rst:94
msgid "Compute importance :math:`i_j` for feature :math:`f_j` defined as:"
msgstr "Calcula la importancia :math:`i_j` para la característica :math:`f_j` definida como:"

#: ../modules/permutation_importance.rst:96
msgid "i_j = s - \\frac{1}{K} \\sum_{k=1}^{K} s_{k,j}\n\n"
msgstr "i_j = s - \\frac{1}{K} \\sum_{k=1}^{K} s_{k,j}\n\n"

#: ../modules/permutation_importance.rst:99
msgid "Relation to impurity-based importance in trees"
msgstr "Relación con la importancia basada en la impureza en árboles"

#: ../modules/permutation_importance.rst:101
msgid "Tree-based models provide an alternative measure of :ref:`feature importances based on the mean decrease in impurity <random_forest_feature_importance>` (MDI). Impurity is quantified by the splitting criterion of the decision trees (Gini, Entropy or Mean Squared Error). However, this method can give high importance to features that may not be predictive on unseen data when the model is overfitting. Permutation-based feature importance, on the other hand, avoids this issue, since it can be computed on unseen data."
msgstr "Los modelos basados en árboles proporcionan una medida alternativa de la :ref:`importancia de las características basada en la disminución media de la impureza <random_forest_feature_importance>` (MDI). La impureza es cuantificada mediante el criterio de división de los árboles de decisión (Gini, Entropía o Error Medio Cuadrático). Sin embargo, este método puede dar mucha importancia a características que pueden no ser predictivas en datos no vistos cuando el modelo está sobreajustado. En cambio, la importancia de las características basada en la permutación evita este problema, ya que puede calcularse con datos no vistos."

#: ../modules/permutation_importance.rst:109
msgid "Furthermore, impurity-based feature importance for trees are **strongly biased** and **favor high cardinality features** (typically numerical features) over low cardinality features such as binary features or categorical variables with a small number of possible categories."
msgstr "Además, la importancia de características basadas en la impureza para los árboles es **fuertemente sesgada** y **favorecen las características de alta cardinalidad** (características normalmente numéricas) sobre características de baja cardinalidad, tales como características binarias o variables categóricas con un pequeño número de categorías posibles."

#: ../modules/permutation_importance.rst:114
msgid "Permutation-based feature importances do not exhibit such a bias. Additionally, the permutation feature importance may be computed performance metric on the model predictions predictions and can be used to analyze any model class (not just tree-based models)."
msgstr "Las importancias de las características basadas en la permutación no presentan ese sesgo. Adicionalmente, la importancia de la característica de permutación puede ser una métrica de rendimiento calculada sobre las predicciones del modelo y se puede utilizar para analizar cualquier clase de modelo (no sólo modelos basados en árboles)."

#: ../modules/permutation_importance.rst:119
msgid "The following example highlights the limitations of impurity-based feature importance in contrast to permutation-based feature importance: :ref:`sphx_glr_auto_examples_inspection_plot_permutation_importance.py`."
msgstr "El siguiente ejemplo resalta las limitaciones de la importancia de la característica basada en la impureza en contraste con la importancia de la característica basada en la permutación: :ref:`sphx_glr_auto_examples_inspection_plot_permutation_importance.py`."

#: ../modules/permutation_importance.rst:124
msgid "Misleading values on strongly correlated features"
msgstr "Valores engañosos en características fuertemente correlacionadas"

#: ../modules/permutation_importance.rst:126
msgid "When two features are correlated and one of the features is permuted, the model will still have access to the feature through its correlated feature. This will result in a lower importance value for both features, where they might *actually* be important."
msgstr "Cuando dos características están correlacionadas y una de las características se permuta, el modelo todavía tendrá acceso a la característica a través de su característica correlacionada. Esto dará lugar a un valor de menor importancia para ambas características, cuando podrían ser *realmente* importantes."

#: ../modules/permutation_importance.rst:131
msgid "One way to handle this is to cluster features that are correlated and only keep one feature from each cluster. This strategy is explored in the following example: :ref:`sphx_glr_auto_examples_inspection_plot_permutation_importance_multicollinear.py`."
msgstr "Una forma de manejar esto es agrupar las características que están correlacionadas y sólo mantener una característica de cada conglomerado. Esta estrategia se explora en el siguiente ejemplo: :ref:`sphx_glr_auto_examples_inspection_plot_permutation_importance_multicollinear.py`."

#: ../modules/permutation_importance.rst:138
msgid ":ref:`sphx_glr_auto_examples_inspection_plot_permutation_importance.py`"
msgstr ":ref:`sphx_glr_auto_examples_inspection_plot_permutation_importance.py`"

#: ../modules/permutation_importance.rst:139
msgid ":ref:`sphx_glr_auto_examples_inspection_plot_permutation_importance_multicollinear.py`"
msgstr ":ref:`sphx_glr_auto_examples_inspection_plot_permutation_importance_multicollinear.py`"

#: ../modules/permutation_importance.rst:143
msgid "L. Breiman, \"Random Forests\", Machine Learning, 45(1), 5-32, 2001. https://doi.org/10.1023/A:1010933404324"
msgstr "L. Breiman, \"Random Forests\", Machine Learning, 45(1), 5-32, 2001. https://doi.org/10.1023/A:1010933404324"

