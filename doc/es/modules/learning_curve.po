msgid ""
msgstr ""
"Project-Id-Version: scikit-learn\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-03-31 11:24-0400\n"
"PO-Revision-Date: 2021-05-06 01:41\n"
"Last-Translator: \n"
"Language-Team: Spanish\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Crowdin-Project: scikit-learn\n"
"X-Crowdin-Project-ID: 450526\n"
"X-Crowdin-Language: es-ES\n"
"X-Crowdin-File: /main/doc/en/modules/learning_curve.po\n"
"X-Crowdin-File-ID: 5936\n"
"Language: es_ES\n"

#: ../modules/learning_curve.rst:5
msgid "Validation curves: plotting scores to evaluate models"
msgstr "Curvas de validación: dibujar las puntuaciones para evaluar los modelos"

#: ../modules/learning_curve.rst:9
msgid "Every estimator has its advantages and drawbacks. Its generalization error can be decomposed in terms of bias, variance and noise. The **bias** of an estimator is its average error for different training sets. The **variance** of an estimator indicates how sensitive it is to varying training sets. Noise is a property of the data."
msgstr "Cada estimador tiene sus ventajas e inconvenientes. Su error de generalización puede descomponerse en términos de sesgo, varianza y ruido. El **sesgo** de un estimador es su error medio para diferentes conjuntos de entrenamiento. La **varianza** de un estimador indica su sensibilidad a la variación de los conjuntos de entrenamiento. El ruido es una propiedad de los datos."

#: ../modules/learning_curve.rst:15
msgid "In the following plot, we see a function :math:`f(x) = \\cos (\\frac{3}{2} \\pi x)` and some noisy samples from that function. We use three different estimators to fit the function: linear regression with polynomial features of degree 1, 4 and 15. We see that the first estimator can at best provide only a poor fit to the samples and the true function because it is too simple (high bias), the second estimator approximates it almost perfectly and the last estimator approximates the training data perfectly but does not fit the true function very well, i.e. it is very sensitive to varying training data (high variance)."
msgstr "En el siguiente gráfico, vemos una función :math:`f(x) = \\cos (\\frac{3}{2} \\pi x)` y algunas muestras ruidosas de esa función. Utilizamos tres estimadores diferentes para ajustar la función: regresión lineal con características polinómicas de grado 1, 4 y 15. Vemos que el primer estimador sólo puede proporcionar, en el mejor de los casos, un ajuste pobre a las muestras y a la función verdadera porque es demasiado simple (alto sesgo), el segundo estimador se aproxima casi perfectamente y el último estimador se aproxima perfectamente a los datos de entrenamiento pero no se ajusta muy bien a la función verdadera, es decir, es muy sensible a la variación de los datos de entrenamiento (alta varianza)."

#: ../modules/learning_curve.rst:29
msgid "Bias and variance are inherent properties of estimators and we usually have to select learning algorithms and hyperparameters so that both bias and variance are as low as possible (see `Bias-variance dilemma <https://en.wikipedia.org/wiki/Bias-variance_dilemma>`_). Another way to reduce the variance of a model is to use more training data. However, you should only collect more training data if the true function is too complex to be approximated by an estimator with a lower variance."
msgstr "El sesgo y la varianza son propiedades inherentes a los estimadores y, por lo general, tenemos que seleccionar los algoritmos de aprendizaje y los hiperparámetros para que tanto el sesgo como la varianza sean lo más bajos posible (véase el dilema `Bias-varianza <https://en.wikipedia.org/wiki/Bias-variance_dilemma>`_). Otra forma de reducir la varianza de un modelo es utilizar más datos de entrenamiento. Sin embargo, sólo debería recoger más datos de entrenamiento si la función verdadera es demasiado compleja para ser aproximada por un estimador con una varianza menor."

#: ../modules/learning_curve.rst:37
msgid "In the simple one-dimensional problem that we have seen in the example it is easy to see whether the estimator suffers from bias or variance. However, in high-dimensional spaces, models can become very difficult to visualize. For this reason, it is often helpful to use the tools described below."
msgstr "En el problema unidimensional sencillo que hemos visto en el ejemplo es fácil ver si el estimador sufre de sesgo o varianza. Sin embargo, en espacios de alta dimensión, los modelos pueden resultar muy difíciles de visualizar. Por este motivo, suele ser útil utilizar las herramientas que se describen a continuación."

#: ../modules/learning_curve.rst:44
msgid ":ref:`sphx_glr_auto_examples_model_selection_plot_underfitting_overfitting.py`"
msgstr ":ref:`sphx_glr_auto_examples_model_selection_plot_underfitting_overfitting.py`"

#: ../modules/learning_curve.rst:45
msgid ":ref:`sphx_glr_auto_examples_model_selection_plot_validation_curve.py`"
msgstr ":ref:`sphx_glr_auto_examples_model_selection_plot_validation_curve.py`"

#: ../modules/learning_curve.rst:46
msgid ":ref:`sphx_glr_auto_examples_model_selection_plot_learning_curve.py`"
msgstr ":ref:`sphx_glr_auto_examples_model_selection_plot_learning_curve.py`"

#: ../modules/learning_curve.rst:52
msgid "Validation curve"
msgstr "Curva de validación"

#: ../modules/learning_curve.rst:54
msgid "To validate a model we need a scoring function (see :ref:`model_evaluation`), for example accuracy for classifiers. The proper way of choosing multiple hyperparameters of an estimator are of course grid search or similar methods (see :ref:`grid_search`) that select the hyperparameter with the maximum score on a validation set or multiple validation sets. Note that if we optimized the hyperparameters based on a validation score the validation score is biased and not a good estimate of the generalization any longer. To get a proper estimate of the generalization we have to compute the score on another test set."
msgstr "Para validar un modelo necesitamos una función de puntuación (véase :ref:`model_evaluation`), por ejemplo la precisión de los clasificadores. La forma adecuada de elegir múltiples hiperparámetros de un estimador es, por supuesto, la búsqueda en cuadrícula o métodos similares (véase :ref:`grid_search`) que seleccionan el hiperparámetro con la máxima puntuación en un conjunto de validación o en múltiples conjuntos de validación. Tenga en cuenta que si optimizamos los hiperparámetros basándonos en una puntuación de validación, la puntuación de validación está sesgada y ya no es una buena estimación de la generalización. Para obtener una estimación adecuada de la generalización tenemos que calcular la puntuación en otro conjunto de pruebas."

#: ../modules/learning_curve.rst:64
msgid "However, it is sometimes helpful to plot the influence of a single hyperparameter on the training score and the validation score to find out whether the estimator is overfitting or underfitting for some hyperparameter values."
msgstr "Sin embargo, a veces es útil dibujar la influencia de un solo hiperparámetro en la puntuación de entrenamiento y en la puntuación de validación para averiguar si el estimador está sobreajustado o infraajustado para algunos valores del hiperparámetro."

#: ../modules/learning_curve.rst:69
msgid "The function :func:`validation_curve` can help in this case::"
msgstr "La función :func:`validation_curve` puede ayudar en este caso::"

#: ../modules/learning_curve.rst:94
msgid "If the training score and the validation score are both low, the estimator will be underfitting. If the training score is high and the validation score is low, the estimator is overfitting and otherwise it is working very well. A low training score and a high validation score is usually not possible. Underfitting, overfitting, and a working model are shown in the in the plot below where we vary the parameter :math:`\\gamma` of an SVM on the digits dataset."
msgstr "Si la puntuación de entrenamiento y la de validación son bajas, el estimador estará infra ajustado. Si la puntuación de entrenamiento es alta y la de validación es baja, el estimador está sobre ajustado y, por el contrario, funciona muy bien. Una puntuación de entrenamiento baja y una puntuación de validación alta no suelen ser posibles. La infra adaptación, la sobre adaptación y un modelo que funciona se muestran en el gráfico siguiente, en el que variamos el parámetro :math:`\\gamma` de una SVM en el conjunto de datos de dígitos."

#: ../modules/learning_curve.rst:110
msgid "Learning curve"
msgstr "Curva de aprendizaje"

#: ../modules/learning_curve.rst:112
msgid "A learning curve shows the validation and training score of an estimator for varying numbers of training samples. It is a tool to find out how much we benefit from adding more training data and whether the estimator suffers more from a variance error or a bias error. Consider the following example where we plot the learning curve of a naive Bayes classifier and an SVM."
msgstr "Una curva de aprendizaje muestra la puntuación de validación y entrenamiento de un estimador para un número variable de muestras de entrenamiento. Es una herramienta para averiguar cuánto nos beneficiamos al añadir más datos de entrenamiento y si el estimador sufre más un error de varianza o un error de sesgo. Consideremos el siguiente ejemplo, en el que trazamos la curva de aprendizaje de un clasificador bayesiano ingenuo y un SVM."

#: ../modules/learning_curve.rst:118
msgid "For the naive Bayes, both the validation score and the training score converge to a value that is quite low with increasing size of the training set. Thus, we will probably not benefit much from more training data."
msgstr "Para el bayesiano ingenuo, tanto la puntuación de validación como la de entrenamiento convergen a un valor que es bastante bajo con el aumento del tamaño del conjunto de entrenamiento. Por lo tanto, es probable que no nos beneficiemos mucho de más datos de entrenamiento."

#: ../modules/learning_curve.rst:122
msgid "In contrast, for small amounts of data, the training score of the SVM is much greater than the validation score. Adding more training samples will most likely increase generalization."
msgstr "En cambio, para pequeñas cantidades de datos, la puntuación de entrenamiento de la SVM es mucho mayor que la de validación. Si se añaden más muestras de entrenamiento, lo más probable es que aumente la generalización."

#: ../modules/learning_curve.rst:131
msgid "We can use the function :func:`learning_curve` to generate the values that are required to plot such a learning curve (number of samples that have been used, the average scores on the training sets and the average scores on the validation sets)::"
msgstr "Podemos utilizar la función :func:`learning_curve` para generar los valores necesarios para dibujar dicha curva de aprendizaje (número de muestras que se han utilizado, las puntuaciones medias en los conjuntos de entrenamiento y las puntuaciones medias en los conjuntos de validación)::"

