msgid ""
msgstr ""
"Project-Id-Version: scikit-learn\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-03-31 11:24-0400\n"
"PO-Revision-Date: 2021-07-11 01:22\n"
"Last-Translator: \n"
"Language-Team: Spanish\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Crowdin-Project: scikit-learn\n"
"X-Crowdin-Project-ID: 450526\n"
"X-Crowdin-Language: es-ES\n"
"X-Crowdin-File: /main/doc/en/tutorial/statistical_inference/unsupervised_learning.po\n"
"X-Crowdin-File-ID: 4064\n"
"Language: es_ES\n"

#: ../tutorial/statistical_inference/unsupervised_learning.rst:3
msgid "Unsupervised learning: seeking representations of the data"
msgstr "Aprendizaje no supervisado: búsqueda de representaciones de los datos"

#: ../tutorial/statistical_inference/unsupervised_learning.rst:6
msgid "Clustering: grouping observations together"
msgstr "Conglomerado: grupo de observaciones"

msgid "The problem solved in clustering"
msgstr "El problema resuelto en el conglomerado"

#: ../tutorial/statistical_inference/unsupervised_learning.rst:10
msgid "Given the iris dataset, if we knew that there were 3 types of iris, but did not have access to a taxonomist to label them: we could try a **clustering task**: split the observations into well-separated group called *clusters*."
msgstr "Dado el conjunto de datos del iris, si supiéramos que hay 3 tipos de iris, pero no tuviéramos acceso a un taxónomo para etiquetarlos: podríamos intentar una **tarea de conglomerado**: dividir las observaciones en grupos bien separados llamados *conglomerado*."

#: ../tutorial/statistical_inference/unsupervised_learning.rst:21
msgid "K-means clustering"
msgstr "Conglomerado de k-medias"

#: ../tutorial/statistical_inference/unsupervised_learning.rst:23
msgid "Note that there exist a lot of different clustering criteria and associated algorithms. The simplest clustering algorithm is :ref:`k_means`."
msgstr "Ten en cuenta que existen muchos criterios de conglomerado diferentes y algoritmos asociados. El algoritmo de conglomerado más sencillo es :ref:`k_means`."

#: ../tutorial/statistical_inference/unsupervised_learning.rst:46
msgid "There is absolutely no guarantee of recovering a ground truth. First, choosing the right number of clusters is hard. Second, the algorithm is sensitive to initialization, and can fall into local minima, although scikit-learn employs several tricks to mitigate this issue."
msgstr "No hay ninguna garantía de que se recupere la verdad fundamental. En primer lugar, elegir el número correcto de conglomerados es difícil. En segundo lugar, el algoritmo es sensible a la inicialización y puede caer en mínimos locales, aunque scikit-learn emplea varios trucos para mitigar este problema."

#: ../tutorial/statistical_inference/unsupervised_learning.rst:57
msgid "**Bad initialization**"
msgstr "**Mala inicialización**"

#: ../tutorial/statistical_inference/unsupervised_learning.rst:63
msgid "**8 clusters**"
msgstr "**8 conglomerados**"

#: ../tutorial/statistical_inference/unsupervised_learning.rst:69
msgid "**Ground truth**"
msgstr "**verdad fundamental**"

#: ../tutorial/statistical_inference/unsupervised_learning.rst:71
msgid "**Don't over-interpret clustering results**"
msgstr "**No hay que sobreinterpretar los resultados del conglomerado**"

#: ../tutorial/statistical_inference/unsupervised_learning.rst:75
msgid "Clustering in general and KMeans, in particular, can be seen as a way of choosing a small number of exemplars to compress the information. The problem is sometimes known as `vector quantization <https://en.wikipedia.org/wiki/Vector_quantization>`_. For instance, this can be used to posterize an image::"
msgstr "El análisis de conglomerados en general y KMeans, en particular, puede verse como una forma de elegir un número reducido de ejemplares para comprimir la información. El problema se conoce a veces como `cuantización vectorial <https://en.wikipedia.org/wiki/Vector_quantization>`_. Por ejemplo, esto se puede utilizar para posterizar una imagen::"

#: ../tutorial/statistical_inference/unsupervised_learning.rst:100
msgid "**Raw image**"
msgstr "**Imagen en bruto**"

#: ../tutorial/statistical_inference/unsupervised_learning.rst:105
msgid "**K-means quantization**"
msgstr "**Cuantificación k-medias**"

#: ../tutorial/statistical_inference/unsupervised_learning.rst:110
msgid "**Equal bins**"
msgstr "**Igualdad de intervalos**"

#: ../tutorial/statistical_inference/unsupervised_learning.rst:116
msgid "**Image histogram**"
msgstr "**Histograma de la imagen**"

#: ../tutorial/statistical_inference/unsupervised_learning.rst:119
msgid "Hierarchical agglomerative clustering: Ward"
msgstr "Conglomerado jerárquico aglomerado: Ward"

#: ../tutorial/statistical_inference/unsupervised_learning.rst:121
msgid "A :ref:`hierarchical_clustering` method is a type of cluster analysis that aims to build a hierarchy of clusters. In general, the various approaches of this technique are either:"
msgstr "Un método de :ref:`hierarchical_clustering` es un tipo de análisis de conglomerados que pretende construir una jerarquía de conglomerados. En general, los distintos enfoques de esta técnica son:"

#: ../tutorial/statistical_inference/unsupervised_learning.rst:125
msgid "**Agglomerative** - bottom-up approaches: each observation starts in its own cluster, and clusters are iteratively merged in such a way to minimize a *linkage* criterion. This approach is particularly interesting when the clusters of interest are made of only a few observations. When the number of clusters is large, it is much more computationally efficient than k-means."
msgstr "**Aglomerativo** - enfoques ascendentes: cada observación comienza en su propio conglomerado, y los conglomerados se fusionan iterativamente de manera que se minimice un criterio de *enlace*. Este enfoque es especialmente interesante cuando los conglomerados de interés están formados por pocas observaciones. Cuando el número de conglomerados es grande, es mucho más eficiente desde el punto de vista computacional que k-medias."

#: ../tutorial/statistical_inference/unsupervised_learning.rst:132
msgid "**Divisive** - top-down approaches: all observations start in one cluster, which is iteratively split as one moves down the hierarchy. For estimating large numbers of clusters, this approach is both slow (due to all observations starting as one cluster, which it splits recursively) and statistically ill-posed."
msgstr "**Divisivo** - enfoques descendentes: todas las observaciones comienzan en un conglomerado, que se divide iterativamente a medida que se desciende en la jerarquía. Para estimar un gran número de conglomerados, este enfoque es lento (debido a que todas las observaciones comienzan en un conglomerado, que se divide recursivamente) y estadísticamente mal planteado."

#: ../tutorial/statistical_inference/unsupervised_learning.rst:139
msgid "Connectivity-constrained clustering"
msgstr "Conglomerado de conectividad restringida"

#: ../tutorial/statistical_inference/unsupervised_learning.rst:141
msgid "With agglomerative clustering, it is possible to specify which samples can be clustered together by giving a connectivity graph. Graphs in scikit-learn are represented by their adjacency matrix. Often, a sparse matrix is used. This can be useful, for instance, to retrieve connected regions (sometimes also referred to as connected components) when clustering an image."
msgstr "Con el conglomerado aglomerativo, es posible especificar qué muestras pueden agruparse dando un gráfico de conectividad. Los grafos en scikit-learn se representan mediante su matriz de adyacencia. A menudo, se utiliza una matriz dispersa. Esto puede ser útil, por ejemplo, para recuperar regiones conectadas (a veces también denominadas componentes conectados) cuando se conglomera una imagen."

#: ../tutorial/statistical_inference/unsupervised_learning.rst:163
msgid "We need a vectorized version of the image. `'rescaled_coins'` is a down-scaled version of the coins image to speed up the process::"
msgstr "Necesitamos una versión vectorizada de la imagen. `'rescaled_coins'` es una versión reducida de la imagen de las monedas para acelerar el proceso::"

#: ../tutorial/statistical_inference/unsupervised_learning.rst:169
msgid "Define the graph structure of the data. Pixels connected to their neighbors::"
msgstr "Define la estructura gráfica de los datos. Píxeles conectados a sus vecinos::"

#: ../tutorial/statistical_inference/unsupervised_learning.rst:181
msgid "Feature agglomeration"
msgstr "Aglomeración de características"

#: ../tutorial/statistical_inference/unsupervised_learning.rst:183
msgid "We have seen that sparsity could be used to mitigate the curse of dimensionality, *i.e* an insufficient amount of observations compared to the number of features. Another approach is to merge together similar features: **feature agglomeration**. This approach can be implemented by clustering in the feature direction, in other words clustering the transposed data."
msgstr "Hemos visto que la dispersión podría utilizarse para mitigar la maldición de la dimensionalidad, es decir, una cantidad insuficiente de observaciones en comparación con el número de características. Otro enfoque consiste en fusionar características similares: **aglomeración de características**. Este enfoque puede aplicarse mediante el conglomerado en la dirección de las características, es decir, agrupando los datos transpuestos."

msgid "``transform`` and ``inverse_transform`` methods"
msgstr "métodos ``transform`` y ``inverse_transform``"

#: ../tutorial/statistical_inference/unsupervised_learning.rst:213
msgid "Some estimators expose a ``transform`` method, for instance to reduce the dimensionality of the dataset."
msgstr "Algunos estimadores exponen un método de ``transform``, por ejemplo para reducir la dimensionalidad del conjunto de datos."

#: ../tutorial/statistical_inference/unsupervised_learning.rst:217
msgid "Decompositions: from a signal to components and loadings"
msgstr "Descomposiciones: de nombres de etiquetas a componentes y cargas"

msgid "**Components and loadings**"
msgstr "**Componentes y cargas**"

#: ../tutorial/statistical_inference/unsupervised_learning.rst:221
msgid "If X is our multivariate data, then the problem that we are trying to solve is to rewrite it on a different observational basis: we want to learn loadings L and a set of components C such that *X = L C*. Different criteria exist to choose the components"
msgstr "Si X son nuestros datos multivariantes, el problema que intentamos resolver es reescribirlo sobre una base observacional diferente: queremos aprender las cargas L y un conjunto de componentes C tal que *X = L C*. Existen diferentes criterios para elegir los componentes"

#: ../tutorial/statistical_inference/unsupervised_learning.rst:227
msgid "Principal component analysis: PCA"
msgstr "Análisis de componentes principales: PCA"

#: ../tutorial/statistical_inference/unsupervised_learning.rst:229
msgid ":ref:`PCA` selects the successive components that explain the maximum variance in the signal."
msgstr ":ref:`PCA` selecciona los componentes sucesivos que explican la máxima varianza de la señal."

#: ../tutorial/statistical_inference/unsupervised_learning.rst:242
msgid "|pca_3d_axis| |pca_3d_aligned|"
msgstr "|pca_3d_axis| |pca_3d_aligned|"

#: ../tutorial/statistical_inference/unsupervised_learning.rst:244
msgid "The point cloud spanned by the observations above is very flat in one direction: one of the three univariate features can almost be exactly computed using the other two. PCA finds the directions in which the data is not *flat*"
msgstr "La nube de puntos abarcada por las observaciones anteriores es muy plana en una dirección: una de las tres características univariantes puede calcularse casi exactamente con las otras dos. PCA encuentra las direcciones en las que los datos no son *planos*"

#: ../tutorial/statistical_inference/unsupervised_learning.rst:249
msgid "When used to *transform* data, PCA can reduce the dimensionality of the data by projecting on a principal subspace."
msgstr "Cuando se utiliza para *transformar* los datos, el PCA puede reducir la dimensionalidad de los datos proyectándolos en un subespacio principal."

#: ../tutorial/statistical_inference/unsupervised_learning.rst:278
msgid "Independent Component Analysis: ICA"
msgstr "Análisis de componentes independientes: ICA"

#: ../tutorial/statistical_inference/unsupervised_learning.rst:280
msgid ":ref:`ICA` selects components so that the distribution of their loadings carries a maximum amount of independent information. It is able to recover **non-Gaussian** independent signals:"
msgstr ":ref:`ICA` selecciona los componentes de forma que la distribución de sus cargas contenga la máxima cantidad de información independiente. Es capaz de recuperar señales independientes **no gaussianas**:"

