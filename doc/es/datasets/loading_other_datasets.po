msgid ""
msgstr ""
"Project-Id-Version: scikit-learn\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-03-31 11:24-0400\n"
"PO-Revision-Date: 2021-04-15 00:11\n"
"Last-Translator: \n"
"Language-Team: Spanish\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Crowdin-Project: scikit-learn\n"
"X-Crowdin-Project-ID: 450526\n"
"X-Crowdin-Language: es-ES\n"
"X-Crowdin-File: /main/doc/en/datasets/loading_other_datasets.po\n"
"X-Crowdin-File-ID: 2772\n"
"Language: es_ES\n"

#: ../datasets/loading_other_datasets.rst:8
msgid "Loading other datasets"
msgstr ""

#: ../datasets/loading_other_datasets.rst:15
msgid "Sample images"
msgstr ""

#: ../datasets/loading_other_datasets.rst:17
msgid "Scikit-learn also embeds a couple of sample JPEG images published under Creative Commons license by their authors. Those images can be useful to test algorithms and pipelines on 2D data."
msgstr ""

#: ../datasets/loading_other_datasets.rst:25:<autosummary>:1
msgid ":obj:`load_sample_images <sklearn.datasets.load_sample_images>`\\ \\(\\)"
msgstr ""

#: ../datasets/loading_other_datasets.rst:25:<autosummary>:1
msgid "Load sample images for image manipulation."
msgstr ""

#: ../datasets/loading_other_datasets.rst:25:<autosummary>:1
msgid ":obj:`load_sample_image <sklearn.datasets.load_sample_image>`\\ \\(image\\_name\\)"
msgstr ""

#: ../datasets/loading_other_datasets.rst:25:<autosummary>:1
msgid "Load the numpy array of a single sample image"
msgstr ""

#: ../datasets/loading_other_datasets.rst:34
msgid "The default coding of images is based on the ``uint8`` dtype to spare memory. Often machine learning algorithms work best if the input is converted to a floating point representation first. Also, if you plan to use ``matplotlib.pyplpt.imshow``, don't forget to scale to the range 0 - 1 as done in the following example."
msgstr ""

#: ../datasets/loading_other_datasets.rst:42
msgid ":ref:`sphx_glr_auto_examples_cluster_plot_color_quantization.py`"
msgstr ""

#: ../datasets/loading_other_datasets.rst:47
msgid "Datasets in svmlight / libsvm format"
msgstr ""

#: ../datasets/loading_other_datasets.rst:49
msgid "scikit-learn includes utility functions for loading datasets in the svmlight / libsvm format. In this format, each line takes the form ``<label> <feature-id>:<feature-value> <feature-id>:<feature-value> ...``. This format is especially suitable for sparse datasets. In this module, scipy sparse CSR matrices are used for ``X`` and numpy arrays are used for ``y``."
msgstr ""

#: ../datasets/loading_other_datasets.rst:55
msgid "You may load a dataset like as follows::"
msgstr ""

#: ../datasets/loading_other_datasets.rst:61
msgid "You may also load two (or more) datasets at once::"
msgstr ""

#: ../datasets/loading_other_datasets.rst:67
msgid "In this case, ``X_train`` and ``X_test`` are guaranteed to have the same number of features. Another way to achieve the same result is to fix the number of features::"
msgstr ""

msgid "Related links:"
msgstr ""

#: ../datasets/loading_other_datasets.rst:77
msgid "_`Public datasets in svmlight / libsvm format`: https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets"
msgstr ""

#: ../datasets/loading_other_datasets.rst:79
msgid "_`Faster API-compatible implementation`: https://github.com/mblondel/svmlight-loader"
msgstr ""

#: ../datasets/loading_other_datasets.rst:90
msgid "Downloading datasets from the openml.org repository"
msgstr ""

#: ../datasets/loading_other_datasets.rst:92
msgid "`openml.org <https://openml.org>`_ is a public repository for machine learning data and experiments, that allows everybody to upload open datasets."
msgstr ""

#: ../datasets/loading_other_datasets.rst:95
msgid "The ``sklearn.datasets`` package is able to download datasets from the repository using the function :func:`sklearn.datasets.fetch_openml`."
msgstr ""

#: ../datasets/loading_other_datasets.rst:99
msgid "For example, to download a dataset of gene expressions in mice brains::"
msgstr ""

#: ../datasets/loading_other_datasets.rst:104
msgid "To fully specify a dataset, you need to provide a name and a version, though the version is optional, see :ref:`openml_versions` below. The dataset contains a total of 1080 examples belonging to 8 different classes::"
msgstr ""

#: ../datasets/loading_other_datasets.rst:116
msgid "You can get more information on the dataset by looking at the ``DESCR`` and ``details`` attributes::"
msgstr ""

#: ../datasets/loading_other_datasets.rst:138
msgid "The ``DESCR`` contains a free-text description of the data, while ``details`` contains a dictionary of meta-data stored by openml, like the dataset id. For more details, see the `OpenML documentation <https://docs.openml.org/#data>`_ The ``data_id`` of the mice protein dataset is 40966, and you can use this (or the name) to get more information on the dataset on the openml website::"
msgstr ""

#: ../datasets/loading_other_datasets.rst:148
msgid "The ``data_id`` also uniquely identifies a dataset from OpenML::"
msgstr ""

#: ../datasets/loading_other_datasets.rst:166
msgid "Dataset Versions"
msgstr ""

#: ../datasets/loading_other_datasets.rst:168
msgid "A dataset is uniquely specified by its ``data_id``, but not necessarily by its name. Several different \"versions\" of a dataset with the same name can exist which can contain entirely different datasets. If a particular version of a dataset has been found to contain significant issues, it might be deactivated. Using a name to specify a dataset will yield the earliest version of a dataset that is still active. That means that ``fetch_openml(name=\"miceprotein\")`` can yield different results at different times if earlier versions become inactive. You can see that the dataset with ``data_id`` 40966 that we fetched above is the first version of the \"miceprotein\" dataset::"
msgstr ""

#: ../datasets/loading_other_datasets.rst:182
msgid "In fact, this dataset only has one version. The iris dataset on the other hand has multiple versions::"
msgstr ""

#: ../datasets/loading_other_datasets.rst:203
msgid "Specifying the dataset by the name \"iris\" yields the lowest version, version 1, with the ``data_id`` 61. To make sure you always get this exact dataset, it is safest to specify it by the dataset ``data_id``. The other dataset, with ``data_id`` 969, is version 3 (version 2 has become inactive), and contains a binarized version of the data::"
msgstr ""

#: ../datasets/loading_other_datasets.rst:212
msgid "You can also specify both the name and the version, which also uniquely identifies the dataset::"
msgstr ""

#: ../datasets/loading_other_datasets.rst:224
msgid "Vanschoren, van Rijn, Bischl and Torgo `\"OpenML: networked science in machine learning\" <https://arxiv.org/pdf/1407.7722.pdf>`_, ACM SIGKDD Explorations Newsletter, 15(2), 49-60, 2014."
msgstr ""

#: ../datasets/loading_other_datasets.rst:232
msgid "Loading from external datasets"
msgstr ""

#: ../datasets/loading_other_datasets.rst:234
msgid "scikit-learn works on any numeric data stored as numpy arrays or scipy sparse matrices. Other types that are convertible to numeric arrays such as pandas DataFrame are also acceptable."
msgstr ""

#: ../datasets/loading_other_datasets.rst:238
msgid "Here are some recommended ways to load standard columnar data into a format usable by scikit-learn:"
msgstr ""

#: ../datasets/loading_other_datasets.rst:241
msgid "`pandas.io <https://pandas.pydata.org/pandas-docs/stable/io.html>`_ provides tools to read data from common formats including CSV, Excel, JSON and SQL. DataFrames may also be constructed from lists of tuples or dicts. Pandas handles heterogeneous data smoothly and provides tools for manipulation and conversion into a numeric array suitable for scikit-learn."
msgstr ""

#: ../datasets/loading_other_datasets.rst:246
msgid "`scipy.io <https://docs.scipy.org/doc/scipy/reference/io.html>`_ specializes in binary formats often used in scientific computing context such as .mat and .arff"
msgstr ""

#: ../datasets/loading_other_datasets.rst:249
msgid "`numpy/routines.io <https://docs.scipy.org/doc/numpy/reference/routines.io.html>`_ for standard loading of columnar data into numpy arrays"
msgstr ""

#: ../datasets/loading_other_datasets.rst:251
msgid "scikit-learn's :func:`datasets.load_svmlight_file` for the svmlight or libSVM sparse format"
msgstr ""

#: ../datasets/loading_other_datasets.rst:253
msgid "scikit-learn's :func:`datasets.load_files` for directories of text files where the name of each directory is the name of each category and each file inside of each directory corresponds to one sample from that category"
msgstr ""

#: ../datasets/loading_other_datasets.rst:257
msgid "For some miscellaneous data such as images, videos, and audio, you may wish to refer to:"
msgstr ""

#: ../datasets/loading_other_datasets.rst:260
msgid "`skimage.io <https://scikit-image.org/docs/dev/api/skimage.io.html>`_ or `Imageio <https://imageio.readthedocs.io/en/latest/userapi.html>`_ for loading images and videos into numpy arrays"
msgstr ""

#: ../datasets/loading_other_datasets.rst:263
msgid "`scipy.io.wavfile.read <https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.io.wavfile.read.html>`_ for reading WAV files into a numpy array"
msgstr ""

#: ../datasets/loading_other_datasets.rst:267
msgid "Categorical (or nominal) features stored as strings (common in pandas DataFrames) will need converting to numerical features using :class:`~sklearn.preprocessing.OneHotEncoder` or :class:`~sklearn.preprocessing.OrdinalEncoder` or similar. See :ref:`preprocessing`."
msgstr ""

#: ../datasets/loading_other_datasets.rst:272
msgid "Note: if you manage your own numerical data it is recommended to use an optimized file format such as HDF5 to reduce data load times. Various libraries such as H5Py, PyTables and pandas provides a Python interface for reading and writing data in that format."
msgstr ""

