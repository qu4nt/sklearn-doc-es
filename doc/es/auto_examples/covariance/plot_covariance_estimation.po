msgid ""
msgstr ""
"Project-Id-Version: scikit-learn\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-03-31 11:24-0400\n"
"PO-Revision-Date: 2021-04-15 06:00\n"
"Last-Translator: \n"
"Language-Team: Spanish\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Crowdin-Project: scikit-learn\n"
"X-Crowdin-Project-ID: 450526\n"
"X-Crowdin-Language: es-ES\n"
"X-Crowdin-File: /main/doc/en/auto_examples/covariance/plot_covariance_estimation.po\n"
"X-Crowdin-File-ID: 4412\n"
"Language: es_ES\n"

#: ../auto_examples/covariance/plot_covariance_estimation.rst:13
msgid "Click :ref:`here <sphx_glr_download_auto_examples_covariance_plot_covariance_estimation.py>` to download the full example code or to run this example in your browser via Binder"
msgstr ""

#: ../auto_examples/covariance/plot_covariance_estimation.rst:23
msgid "Shrinkage covariance estimation: LedoitWolf vs OAS and max-likelihood"
msgstr ""

#: ../auto_examples/covariance/plot_covariance_estimation.rst:25
msgid "When working with covariance estimation, the usual approach is to use a maximum likelihood estimator, such as the :class:`~sklearn.covariance.EmpiricalCovariance`. It is unbiased, i.e. it converges to the true (population) covariance when given many observations. However, it can also be beneficial to regularize it, in order to reduce its variance; this, in turn, introduces some bias. This example illustrates the simple regularization used in :ref:`shrunk_covariance` estimators. In particular, it focuses on how to set the amount of regularization, i.e. how to choose the bias-variance trade-off."
msgstr ""

#: ../auto_examples/covariance/plot_covariance_estimation.rst:36
msgid "Here we compare 3 approaches:"
msgstr ""

#: ../auto_examples/covariance/plot_covariance_estimation.rst:38
msgid "Setting the parameter by cross-validating the likelihood on three folds according to a grid of potential shrinkage parameters."
msgstr ""

#: ../auto_examples/covariance/plot_covariance_estimation.rst:41
msgid "A close formula proposed by Ledoit and Wolf to compute the asymptotically optimal regularization parameter (minimizing a MSE criterion), yielding the :class:`~sklearn.covariance.LedoitWolf` covariance estimate."
msgstr ""

#: ../auto_examples/covariance/plot_covariance_estimation.rst:46
msgid "An improvement of the Ledoit-Wolf shrinkage, the :class:`~sklearn.covariance.OAS`, proposed by Chen et al. Its convergence is significantly better under the assumption that the data are Gaussian, in particular for small samples."
msgstr ""

#: ../auto_examples/covariance/plot_covariance_estimation.rst:51
msgid "To quantify estimation error, we plot the likelihood of unseen data for different values of the shrinkage parameter. We also show the choices by cross-validation, or with the LedoitWolf and OAS estimates."
msgstr ""

#: ../auto_examples/covariance/plot_covariance_estimation.rst:55
msgid "Note that the maximum likelihood estimate corresponds to no shrinkage, and thus performs poorly. The Ledoit-Wolf estimate performs really well, as it is close to the optimal and is computational not costly. In this example, the OAS estimate is a bit further away. Interestingly, both approaches outperform cross-validation, which is significantly most computationally costly."
msgstr ""

#: ../auto_examples/covariance/plot_covariance_estimation.rst:168
msgid "**Total running time of the script:** ( 0 minutes  0.961 seconds)"
msgstr ""

#: ../auto_examples/covariance/plot_covariance_estimation.rst:190
msgid ":download:`Download Python source code: plot_covariance_estimation.py <plot_covariance_estimation.py>`"
msgstr ""

#: ../auto_examples/covariance/plot_covariance_estimation.rst:196
msgid ":download:`Download Jupyter notebook: plot_covariance_estimation.ipynb <plot_covariance_estimation.ipynb>`"
msgstr ""

#: ../auto_examples/covariance/plot_covariance_estimation.rst:203
msgid "`Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_"
msgstr ""

