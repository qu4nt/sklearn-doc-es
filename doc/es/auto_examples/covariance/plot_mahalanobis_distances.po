msgid ""
msgstr ""
"Project-Id-Version: scikit-learn\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-03-31 11:24-0400\n"
"PO-Revision-Date: 2021-06-22 21:25\n"
"Last-Translator: \n"
"Language-Team: Spanish\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Crowdin-Project: scikit-learn\n"
"X-Crowdin-Project-ID: 450526\n"
"X-Crowdin-Language: es-ES\n"
"X-Crowdin-File: /main/doc/en/auto_examples/covariance/plot_mahalanobis_distances.po\n"
"X-Crowdin-File-ID: 4416\n"
"Language: es_ES\n"

#: ../auto_examples/covariance/plot_mahalanobis_distances.rst:13
msgid "Click :ref:`here <sphx_glr_download_auto_examples_covariance_plot_mahalanobis_distances.py>` to download the full example code or to run this example in your browser via Binder"
msgstr "Haz clic en :ref:`aquí <sphx_glr_download_auto_examples_covariance_plot_mahalanobis_distances.py>` para descargar el código de ejemplo completo o para ejecutar este ejemplo en tu navegador a través de Binder"

#: ../auto_examples/covariance/plot_mahalanobis_distances.rst:23
msgid "Robust covariance estimation and Mahalanobis distances relevance"
msgstr "Estimación robusta de la covarianza y relevancia de las distancias de Mahalanobis"

#: ../auto_examples/covariance/plot_mahalanobis_distances.rst:25
msgid "This example shows covariance estimation with Mahalanobis distances on Gaussian distributed data."
msgstr "Este ejemplo muestra la estimación de la covarianza con distancias de Mahalanobis en datos con distribución gaussiana."

#: ../auto_examples/covariance/plot_mahalanobis_distances.rst:28
msgid "For Gaussian distributed data, the distance of an observation :math:`x_i` to the mode of the distribution can be computed using its Mahalanobis distance:"
msgstr "Para los datos con distribución gaussiana, la distancia de una observación :math:`x_i` a la moda de la distribución puede calcularse utilizando su distancia de Mahalanobis:"

#: ../auto_examples/covariance/plot_mahalanobis_distances.rst:32
msgid "d_{(\\mu,\\Sigma)}(x_i)^2 = (x_i - \\mu)^T\\Sigma^{-1}(x_i - \\mu)"
msgstr "d_{(\\mu,\\Sigma)}(x_i)^2 = (x_i - \\mu)^T\\Sigma^{-1}(x_i - \\mu)"

#: ../auto_examples/covariance/plot_mahalanobis_distances.rst:36
msgid "where :math:`\\mu` and :math:`\\Sigma` are the location and the covariance of the underlying Gaussian distributions."
msgstr "donde :math:`\\mu` y :math:`\\Sigma` son la localización y la covarianza de las distribuciones gaussianas subyacentes."

#: ../auto_examples/covariance/plot_mahalanobis_distances.rst:39
msgid "In practice, :math:`\\mu` and :math:`\\Sigma` are replaced by some estimates. The standard covariance maximum likelihood estimate (MLE) is very sensitive to the presence of outliers in the data set and therefore, the downstream Mahalanobis distances also are. It would be better to use a robust estimator of covariance to guarantee that the estimation is resistant to \"erroneous\" observations in the dataset and that the calculated Mahalanobis distances accurately reflect the true organization of the observations."
msgstr "En la práctica, :math:`\\mu` y :math:`\\Sigma` se sustituyen por algunas estimaciones. La estimación estándar de covarianza por máxima verosimilitud (MLE) es muy sensible a la presencia de valores atípicos en el conjunto de datos y, por tanto, las distancias de Mahalanobis descendentes también lo son. Sería mejor utilizar un estimador robusto de la covarianza para garantizar que la estimación es resistente a las observaciones \"erróneas\" en el conjunto de datos y que las distancias de Mahalanobis calculadas reflejan con precisión la verdadera organización de las observaciones."

#: ../auto_examples/covariance/plot_mahalanobis_distances.rst:48
msgid "The Minimum Covariance Determinant estimator (MCD) is a robust, high-breakdown point (i.e. it can be used to estimate the covariance matrix of highly contaminated datasets, up to :math:`\\frac{n_\\text{samples}-n_\\text{features}-1}{2}` outliers) estimator of covariance. The idea behind the MCD is to find :math:`\\frac{n_\\text{samples}+n_\\text{features}+1}{2}` observations whose empirical covariance has the smallest determinant, yielding a \"pure\" subset of observations from which to compute standards estimates of location and covariance. The MCD was introduced by P.J.Rousseuw in [1]_."
msgstr "El estimador del Determinante Mínimo de la Covarianza (MCD) es un estimador de la covarianza robusto y con un punto de ruptura alto (es decir, puede utilizarse para estimar la matriz de covarianza de conjuntos de datos altamente contaminados, hasta :math:`\\frac{n_\\text{samples}-n_\\text{features}-1}{2}` los valores atípicos). La idea detrás del MCD es encontrar observaciones :math:`\\frac{n_\\text{samples}+n_\\text{features}+1}{2}` cuya covarianza empírica tenga el menor determinante, produciendo un subconjunto \"puro\" de observaciones a partir del cual calcular las estimaciones estándar de ubicación y covarianza. El MCD fue introducido por P.J.Rousseuw en [1]_."

#: ../auto_examples/covariance/plot_mahalanobis_distances.rst:59
msgid "This example illustrates how the Mahalanobis distances are affected by outlying data. Observations drawn from a contaminating distribution are not distinguishable from the observations coming from the real, Gaussian distribution when using standard covariance MLE based Mahalanobis distances. Using MCD-based Mahalanobis distances, the two populations become distinguishable. Associated applications include outlier detection, observation ranking and clustering."
msgstr "Este ejemplo ilustra cómo las distancias de Mahalanobis se ven afectadas por los datos periféricos. Las observaciones extraídas de una distribución contaminante no se distinguen de las observaciones procedentes de la distribución gaussiana real cuando se utilizan las distancias de Mahalanobis basadas en la covarianza estándar MLE. Con las distancias de Mahalanobis basadas en la MCD, las dos poblaciones se distinguen. Las aplicaciones asociadas incluyen la detección de valores atípicos, la clasificación de observaciones y el conglomerado."

#: ../auto_examples/covariance/plot_mahalanobis_distances.rst:70
msgid "See also :ref:`sphx_glr_auto_examples_covariance_plot_robust_vs_empirical_covariance.py`"
msgstr "Ver también :ref:`sphx_glr_auto_examples_covariance_plot_robust_vs_empirical_covariance.py`"

#: ../auto_examples/covariance/plot_mahalanobis_distances.rst:74
msgid "P. J. Rousseeuw. `Least median of squares regression <http://web.ipac.caltech.edu/staff/fmasci/home/astro_refs/LeastMedianOfSquares.pdf>`_. J. Am Stat Ass, 79:871, 1984."
msgstr "P. J. Rousseeuw. `Least median of squares regression <http://web.ipac.caltech.edu/staff/fmasci/home/astro_refs/LeastMedianOfSquares.pdf>`_. J. Am Stat Ass, 79:871, 1984."

#: ../auto_examples/covariance/plot_mahalanobis_distances.rst:77
msgid "Wilson, E. B., & Hilferty, M. M. (1931). `The distribution of chi-square. <https://water.usgs.gov/osw/bulletin17b/Wilson_Hilferty_1931.pdf>`_ Proceedings of the National Academy of Sciences of the United States of America, 17, 684-688."
msgstr "Wilson, E. B., & Hilferty, M. M. (1931). `The distribution of chi-square. <https://water.usgs.gov/osw/bulletin17b/Wilson_Hilferty_1931.pdf>`_ Proceedings of the National Academy of Sciences of the United States of America, 17, 684-688."

#: ../auto_examples/covariance/plot_mahalanobis_distances.rst:85
msgid "Generate data"
msgstr "Generar datos"

#: ../auto_examples/covariance/plot_mahalanobis_distances.rst:87
msgid "First, we generate a dataset of 125 samples and 2 features. Both features are Gaussian distributed with mean of 0 but feature 1 has a standard deviation equal to 2 and feature 2 has a standard deviation equal to 1. Next, 25 samples are replaced with Gaussian outlier samples where feature 1 has a standard devation equal to 1 and feature 2 has a standard deviation equal to 7."
msgstr "En primer lugar, generamos un conjunto de datos de 125 muestras y 2 características. Ambas características tienen una distribución gaussiana con una media de 0, pero la característica 1 tiene una desviación estándar igual a 2 y la característica 2 tiene una desviación estándar igual a 1. A continuación, se sustituyen 25 muestras por muestras gaussianas de valor atípico en las que la característica 1 tiene una desviación estándar igual a 1 y la característica 2 tiene una desviación estándar igual a 7."

#: ../auto_examples/covariance/plot_mahalanobis_distances.rst:127
msgid "Comparison of results"
msgstr "Comparación de resultados"

#: ../auto_examples/covariance/plot_mahalanobis_distances.rst:129
msgid "Below, we fit MCD and MLE based covariance estimators to our data and print the estimated covariance matrices. Note that the estimated variance of feature 2 is much higher with the MLE based estimator (7.5) than that of the MCD robust estimator (1.2). This shows that the MCD based robust estimator is much more resistant to the outlier samples, which were designed to have a much larger variance in feature 2."
msgstr "A continuación, ajustamos los estimadores de covarianza basados en MCD y MLE a nuestros datos e imprimimos las matrices de covarianza estimadas. Obsérvese que la varianza estimada de la característica 2 es mucho mayor con el estimador basado en MLE (7,5) que con el estimador robusto MCD (1,2). Esto muestra que el estimador robusto basado en MCD es mucho más resistente a las muestras de valor atípico, que fueron diseñadas para tener una varianza mucho mayor en la característica 2."

#: ../auto_examples/covariance/plot_mahalanobis_distances.rst:158
msgid "Out:"
msgstr "Salida:"

#: ../auto_examples/covariance/plot_mahalanobis_distances.rst:175
msgid "To better visualize the difference, we plot contours of the Mahalanobis distances calculated by both methods. Notice that the robust MCD based Mahalanobis distances fit the inlier black points much better, whereas the MLE based distances are more influenced by the outlier red points."
msgstr "Para visualizar mejor la diferencia, graficamos los contornos de las distancias de Mahalanobis calculadas por ambos métodos. Obsérvese que las distancias de Mahalanobis basadas en el MCD robusto se ajustan mucho mejor a los puntos negros de los valores típicos, mientras que las distancias basadas en el MLE están más influenciadas por los puntos rojos de los valores atípicos."

#: ../auto_examples/covariance/plot_mahalanobis_distances.rst:231
msgid "Finally, we highlight the ability of MCD based Mahalanobis distances to distinguish outliers. We take the cubic root of the Mahalanobis distances, yielding approximately normal distributions (as suggested by Wilson and Hilferty [2]_), then plot the values of inlier and outlier samples with boxplots. The distribution of outlier samples is more separated from the distribution of inlier samples for robust MCD based Mahalanobis distances."
msgstr "Por último, destacamos la capacidad de las distancias de Mahalanobis basadas en MCD para distinguir los valores atípicos. Tomamos la raíz cúbica de las distancias de Mahalanobis, lo que da lugar a distribuciones aproximadamente normales (como sugieren Wilson y Hilferty [2]_), y luego trazamos los valores de las muestras de los valores típicos y los valor atípico con boxplots. La distribución de las muestras atípicas está más separada de la distribución de las muestras típicas para el MCD robusto basado en las distancias de Mahalanobis."

#: ../auto_examples/covariance/plot_mahalanobis_distances.rst:288
msgid "**Total running time of the script:** ( 0 minutes  0.365 seconds)"
msgstr "**Tiempo total de ejecución del script:** (0 minutos 0.365 segundos)"

#: ../auto_examples/covariance/plot_mahalanobis_distances.rst:310
msgid ":download:`Download Python source code: plot_mahalanobis_distances.py <plot_mahalanobis_distances.py>`"
msgstr ":download:`Descargar el código fuente de Python: plot_mahalanobis_distances.py <plot_mahalanobis_distances.py>`"

#: ../auto_examples/covariance/plot_mahalanobis_distances.rst:316
msgid ":download:`Download Jupyter notebook: plot_mahalanobis_distances.ipynb <plot_mahalanobis_distances.ipynb>`"
msgstr ":download:`Descargar el cuaderno Jupyter: plot_mahalanobis_distances.ipynb <plot_mahalanobis_distances.ipynb>`"

#: ../auto_examples/covariance/plot_mahalanobis_distances.rst:323
msgid "`Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_"
msgstr "`Galería generada por Sphinx-Gallery <https://sphinx-gallery.github.io>`_"

