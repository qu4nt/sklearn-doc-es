msgid ""
msgstr ""
"Project-Id-Version: scikit-learn\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-03-31 11:24-0400\n"
"PO-Revision-Date: 2021-07-15 13:56\n"
"Last-Translator: \n"
"Language-Team: Spanish\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Crowdin-Project: scikit-learn\n"
"X-Crowdin-Project-ID: 450526\n"
"X-Crowdin-Language: es-ES\n"
"X-Crowdin-File: /main/doc/en/auto_examples/linear_model/plot_lasso_model_selection.po\n"
"X-Crowdin-File-ID: 4712\n"
"Language: es_ES\n"

#: ../auto_examples/linear_model/plot_lasso_model_selection.rst:13
msgid "Click :ref:`here <sphx_glr_download_auto_examples_linear_model_plot_lasso_model_selection.py>` to download the full example code or to run this example in your browser via Binder"
msgstr "Haz clic en :ref:`aquí <sphx_glr_download_auto_examples_linear_model_plot_lasso_model_selection.py>` para descargar el código de ejemplo completo o para ejecutar este ejemplo en tu navegador a través de Binder"

#: ../auto_examples/linear_model/plot_lasso_model_selection.rst:23
msgid "Lasso model selection: Cross-Validation / AIC / BIC"
msgstr "Selección del modelo Lasso: Validación cruzada / AIC / BIC"

#: ../auto_examples/linear_model/plot_lasso_model_selection.rst:25
msgid "Use the Akaike information criterion (AIC), the Bayes Information criterion (BIC) and cross-validation to select an optimal value of the regularization parameter alpha of the :ref:`lasso` estimator."
msgstr "Utiliza el criterio de información de Akaike (AIC), el criterio de información de Bayes (BIC) y la validación cruzada para seleccionar un valor óptimo del parámetro de regularización alfa del estimador :ref:`lasso`."

#: ../auto_examples/linear_model/plot_lasso_model_selection.rst:29
msgid "Results obtained with LassoLarsIC are based on AIC/BIC criteria."
msgstr "Los resultados obtenidos con LassoLarsIC se basan en criterios AIC/BIC."

#: ../auto_examples/linear_model/plot_lasso_model_selection.rst:31
msgid "Information-criterion based model selection is very fast, but it relies on a proper estimation of degrees of freedom, are derived for large samples (asymptotic results) and assume the model is correct, i.e. that the data are actually generated by this model. They also tend to break when the problem is badly conditioned (more features than samples)."
msgstr "La selección de modelos basada en el criterio de información es muy rápida, pero depende de una estimación adecuada de los grados de libertad, se derivan para muestras grandes (resultados asintóticos) y suponen que el modelo es correcto, es decir, que los datos son realmente generados por este modelo. También tienden a romperse cuando el problema está mal condicionado (más características que muestras)."

#: ../auto_examples/linear_model/plot_lasso_model_selection.rst:38
msgid "For cross-validation, we use 20-fold with 2 algorithms to compute the Lasso path: coordinate descent, as implemented by the LassoCV class, and Lars (least angle regression) as implemented by the LassoLarsCV class. Both algorithms give roughly the same results. They differ with regards to their execution speed and sources of numerical errors."
msgstr "Para la validación cruzada, utilizamos 20 veces con 2 algoritmos para calcular la trayectoria del Lasso: el descenso de coordenadas, implementado por la clase LassoCV, y Lars (regresión de ángulo mínimo), implementado por la clase LassoLarsCV. Ambos algoritmos dan aproximadamente los mismos resultados. Difieren en cuanto a su velocidad de ejecución y a las fuentes de errores numéricos."

#: ../auto_examples/linear_model/plot_lasso_model_selection.rst:44
msgid "Lars computes a path solution only for each kink in the path. As a result, it is very efficient when there are only of few kinks, which is the case if there are few features or samples. Also, it is able to compute the full path without setting any meta parameter. On the opposite, coordinate descent compute the path points on a pre-specified grid (here we use the default). Thus it is more efficient if the number of grid points is smaller than the number of kinks in the path. Such a strategy can be interesting if the number of features is really large and there are enough samples to select a large amount. In terms of numerical errors, for heavily correlated variables, Lars will accumulate more errors, while the coordinate descent algorithm will only sample the path on a grid."
msgstr "Lars calcula una solución de trayectoria sólo para cada pliegue de la trayectoria. Como resultado, es muy eficiente cuando sólo hay unos pocos pliegues, que es el caso si hay pocas características o muestras. Además, es capaz de calcular la trayectoria completa sin necesidad de establecer ningún metaparámetro. Por el contrario, el descenso por coordenadas calcula los puntos de la trayectoria en una cuadrícula preestablecida (aquí utilizamos la predeterminada). Por lo tanto, es más eficiente si el número de puntos de la cuadrícula es menor que el número de pliegues de la trayectoria. Esta estrategia puede ser interesante si el número de características es realmente grande y hay suficientes muestras para seleccionar una gran cantidad. En cuanto a los errores numéricos, para las variables muy correlacionadas, Lars acumulará más errores, mientras que el algoritmo de descenso por coordenadas sólo muestreará la trayectoria en una cuadrícula."

#: ../auto_examples/linear_model/plot_lasso_model_selection.rst:57
msgid "Note how the optimal value of alpha varies for each fold. This illustrates why nested-cross validation is necessary when trying to evaluate the performance of a method for which a parameter is chosen by cross-validation: this choice of parameter may not be optimal for unseen data."
msgstr "Observe cómo el valor óptimo de alfa varía para cada pliegue. Esto ilustra por qué es necesaria la validación cruzada anidada cuando se trata de evaluar el rendimiento de un método para el que se elige un parámetro mediante validación cruzada: esta elección del parámetro puede no ser óptima para los datos no vistos."

#: ../auto_examples/linear_model/plot_lasso_model_selection.rst:91
msgid "Out:"
msgstr "Out:"

#: ../auto_examples/linear_model/plot_lasso_model_selection.rst:220
msgid "**Total running time of the script:** ( 0 minutes  2.779 seconds)"
msgstr "**Tiempo total de ejecución del script:** ( 0 minutos 2.779 segundos)"

#: ../auto_examples/linear_model/plot_lasso_model_selection.rst:242
msgid ":download:`Download Python source code: plot_lasso_model_selection.py <plot_lasso_model_selection.py>`"
msgstr ":download:`Descargar el código fuente de Python: plot_lasso_model_selection.py <plot_lasso_model_selection.py>`"

#: ../auto_examples/linear_model/plot_lasso_model_selection.rst:248
msgid ":download:`Download Jupyter notebook: plot_lasso_model_selection.ipynb <plot_lasso_model_selection.ipynb>`"
msgstr ":download:`Descarga el cuaderno de Jupyter: plot_lasso_model_selection.ipynb <plot_lasso_model_selection.ipynb>`"

#: ../auto_examples/linear_model/plot_lasso_model_selection.rst:255
msgid "`Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_"
msgstr "`Galería generada por Sphinx-Gallery <https://sphinx-gallery.github.io>`_"

