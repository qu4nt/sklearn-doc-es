msgid ""
msgstr ""
"Project-Id-Version: scikit-learn\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-03-31 11:24-0400\n"
"PO-Revision-Date: 2021-04-15 00:07\n"
"Last-Translator: \n"
"Language-Team: Spanish\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Crowdin-Project: scikit-learn\n"
"X-Crowdin-Project-ID: 450526\n"
"X-Crowdin-Language: es-ES\n"
"X-Crowdin-File: /main/doc/en/auto_examples/feature_selection/plot_select_from_model_diabetes.po\n"
"X-Crowdin-File-ID: 2418\n"
"Language: es_ES\n"

#: ../auto_examples/feature_selection/plot_select_from_model_diabetes.rst:13
msgid "Click :ref:`here <sphx_glr_download_auto_examples_feature_selection_plot_select_from_model_diabetes.py>` to download the full example code or to run this example in your browser via Binder"
msgstr ""

#: ../auto_examples/feature_selection/plot_select_from_model_diabetes.rst:23
msgid "Model-based and sequential feature selection"
msgstr ""

#: ../auto_examples/feature_selection/plot_select_from_model_diabetes.rst:25
msgid "This example illustrates and compares two approaches for feature selection: :class:`~sklearn.feature_selection.SelectFromModel` which is based on feature importance, and :class:`~sklearn.feature_selection.SequentialFeatureSelection` which relies on a greedy approach."
msgstr ""

#: ../auto_examples/feature_selection/plot_select_from_model_diabetes.rst:31
msgid "We use the Diabetes dataset, which consists of 10 features collected from 442 diabetes patients."
msgstr ""

#: ../auto_examples/feature_selection/plot_select_from_model_diabetes.rst:34
msgid "Authors: `Manoj Kumar <mks542@nyu.edu>`_, `Maria Telenczuk <https://github.com/maikia>`_, Nicolas Hug."
msgstr ""

#: ../auto_examples/feature_selection/plot_select_from_model_diabetes.rst:37
msgid "License: BSD 3 clause"
msgstr ""

#: ../auto_examples/feature_selection/plot_select_from_model_diabetes.rst:57
msgid "Loading the data"
msgstr ""

#: ../auto_examples/feature_selection/plot_select_from_model_diabetes.rst:59
msgid "We first load the diabetes dataset which is available from within scikit-learn, and print its description:"
msgstr ""

#: ../auto_examples/feature_selection/plot_select_from_model_diabetes.rst:78
#: ../auto_examples/feature_selection/plot_select_from_model_diabetes.rst:201
#: ../auto_examples/feature_selection/plot_select_from_model_diabetes.rst:258
msgid "Out:"
msgstr ""

#: ../auto_examples/feature_selection/plot_select_from_model_diabetes.rst:127
msgid "Feature importance from coefficients"
msgstr ""

#: ../auto_examples/feature_selection/plot_select_from_model_diabetes.rst:129
msgid "To get an idea of the importance of the features, we are going to use the :class:`~sklearn.linear_model.LassoCV` estimator. The features with the highest absolute `coef_` value are considered the most important. We can observe the coefficients directly without needing to scale them (or scale the data) because from the description above, we know that the features were already standardized. For a more complete example on the interpretations of the coefficients of linear models, you may refer to :ref:`sphx_glr_auto_examples_inspection_plot_linear_model_coefficient_interpretation.py`."
msgstr ""

#: ../auto_examples/feature_selection/plot_select_from_model_diabetes.rst:168
msgid "Selecting features based on importance"
msgstr ""

#: ../auto_examples/feature_selection/plot_select_from_model_diabetes.rst:170
msgid "Now we want to select the two features which are the most important according to the coefficients. The :class:`~sklearn.feature_selection.SelectFromModel` is meant just for that. :class:`~sklearn.feature_selection.SelectFromModel` accepts a `threshold` parameter and will select the features whose importance (defined by the coefficients) are above this threshold."
msgstr ""

#: ../auto_examples/feature_selection/plot_select_from_model_diabetes.rst:176
msgid "Since we want to select only 2 features, we will set this threshold slightly above the coefficient of third most important feature."
msgstr ""

#: ../auto_examples/feature_selection/plot_select_from_model_diabetes.rst:214
msgid "Selecting features with Sequential Feature Selection"
msgstr ""

#: ../auto_examples/feature_selection/plot_select_from_model_diabetes.rst:216
msgid "Another way of selecting features is to use :class:`~sklearn.feature_selection.SequentialFeatureSelector` (SFS). SFS is a greedy procedure where, at each iteration, we choose the best new feature to add to our selected features based a cross-validation score. That is, we start with 0 features and choose the best single feature with the highest score. The procedure is repeated until we reach the desired number of selected features."
msgstr ""

#: ../auto_examples/feature_selection/plot_select_from_model_diabetes.rst:224
msgid "We can also go in the reverse direction (backward SFS), *i.e.* start with all the features and greedily choose features to remove one by one. We illustrate both approaches here."
msgstr ""

#: ../auto_examples/feature_selection/plot_select_from_model_diabetes.rst:273
msgid "Discussion"
msgstr ""

#: ../auto_examples/feature_selection/plot_select_from_model_diabetes.rst:275
msgid "Interestingly, forward and backward selection have selected the same set of features. In general, this isn't the case and the two methods would lead to different results."
msgstr ""

#: ../auto_examples/feature_selection/plot_select_from_model_diabetes.rst:279
msgid "We also note that the features selected by SFS differ from those selected by feature importance: SFS selects `bmi` instead of `s1`. This does sound reasonable though, since `bmi` corresponds to the third most important feature according to the coefficients. It is quite remarkable considering that SFS makes no use of the coefficients at all."
msgstr ""

#: ../auto_examples/feature_selection/plot_select_from_model_diabetes.rst:285
msgid "To finish with, we should note that :class:`~sklearn.feature_selection.SelectFromModel` is significantly faster than SFS. Indeed, :class:`~sklearn.feature_selection.SelectFromModel` only needs to fit a model once, while SFS needs to cross-validate many different models for each of the iterations. SFS however works with any model, while :class:`~sklearn.feature_selection.SelectFromModel` requires the underlying estimator to expose a `coef_` attribute or a `feature_importances_` attribute. The forward SFS is faster than the backward SFS because it only needs to perform `n_features_to_select = 2` iterations, while the backward SFS needs to perform `n_features - n_features_to_select = 8` iterations."
msgstr ""

#: ../auto_examples/feature_selection/plot_select_from_model_diabetes.rst:299
msgid "**Total running time of the script:** ( 0 minutes  19.257 seconds)"
msgstr ""

#: ../auto_examples/feature_selection/plot_select_from_model_diabetes.rst:321
msgid ":download:`Download Python source code: plot_select_from_model_diabetes.py <plot_select_from_model_diabetes.py>`"
msgstr ""

#: ../auto_examples/feature_selection/plot_select_from_model_diabetes.rst:327
msgid ":download:`Download Jupyter notebook: plot_select_from_model_diabetes.ipynb <plot_select_from_model_diabetes.ipynb>`"
msgstr ""

#: ../auto_examples/feature_selection/plot_select_from_model_diabetes.rst:334
msgid "`Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_"
msgstr ""

