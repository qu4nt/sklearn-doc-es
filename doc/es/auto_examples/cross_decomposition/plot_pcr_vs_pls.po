msgid ""
msgstr ""
"Project-Id-Version: scikit-learn\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-03-31 11:24-0400\n"
"PO-Revision-Date: 2021-06-23 14:45\n"
"Last-Translator: \n"
"Language-Team: Spanish\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Crowdin-Project: scikit-learn\n"
"X-Crowdin-Project-ID: 450526\n"
"X-Crowdin-Language: es-ES\n"
"X-Crowdin-File: /main/doc/en/auto_examples/cross_decomposition/plot_pcr_vs_pls.po\n"
"X-Crowdin-File-ID: 4454\n"
"Language: es_ES\n"

#: ../auto_examples/cross_decomposition/plot_pcr_vs_pls.rst:13
msgid "Click :ref:`here <sphx_glr_download_auto_examples_cross_decomposition_plot_pcr_vs_pls.py>` to download the full example code or to run this example in your browser via Binder"
msgstr "Haz clic en :ref:`aquí <sphx_glr_download_auto_examples_cross_decomposition_plot_pcr_vs_pls.py>` para descargar el código de ejemplo completo o para ejecutar este ejemplo en tu navegador a través de Binder"

#: ../auto_examples/cross_decomposition/plot_pcr_vs_pls.rst:23
msgid "Principal Component Regression vs Partial Least Squares Regression"
msgstr "Regresión por componentes principales frente a la regresión por mínimos cuadrados parciales"

#: ../auto_examples/cross_decomposition/plot_pcr_vs_pls.rst:25
msgid "This example compares `Principal Component Regression <https://en.wikipedia.org/wiki/Principal_component_regression>`_ (PCR) and `Partial Least Squares Regression <https://en.wikipedia.org/wiki/Partial_least_squares_regression>`_ (PLS) on a toy dataset. Our goal is to illustrate how PLS can outperform PCR when the target is strongly correlated with some directions in the data that have a low variance."
msgstr "Este ejemplo compara la `Regresión por componentes principales <https://en.wikipedia.org/wiki/Principal_component_regression>`_ (PCR) y la `Regresión por mínimos cuadrados parciales <https://en.wikipedia.org/wiki/Partial_least_squares_regression>`_ (PLS) en un conjunto de datos de juguete. Nuestro objetivo es ilustrar cómo PLS puede superar a PCR cuando el objetivo está fuertemente correlacionado con algunas direcciones en los datos que tienen una baja varianza."

#: ../auto_examples/cross_decomposition/plot_pcr_vs_pls.rst:33
msgid "PCR is a regressor composed of two steps: first, :class:`~sklearn.decomposition.PCA` is applied to the training data, possibly performing dimensionality reduction; then, a regressor (e.g. a linear regressor) is trained on the transformed samples. In :class:`~sklearn.decomposition.PCA`, the transformation is purely unsupervised, meaning that no information about the targets is used. As a result, PCR may perform poorly in some datasets where the target is strongly correlated with *directions* that have low variance. Indeed, the dimensionality reduction of PCA projects the data into a lower dimensional space where the variance of the projected data is greedily maximized along each axis. Despite them having the most predictive power on the target, the directions with a lower variance will be dropped, and the final regressor will not be able to leverage them."
msgstr "PCR es un regresor compuesto por dos pasos: primero, se aplica :class:`~sklearn.decomposition.PCA` a los datos de entrenamiento, posiblemente realizando una reducción de la dimensionalidad; después, se entrena un regresor (por ejemplo, un regresor lineal) en las muestras transformadas. En :class:`~sklearn.decomposition.PCA`, la transformación es puramente no supervisada, lo que significa que no se utiliza información sobre los objetivos. Como resultado, la PCR puede tener un mal rendimiento en algunos conjuntos de datos en los que el objetivo está fuertemente correlacionado con *direcciones* que tienen baja varianza. De hecho, la reducción de la dimensionalidad de PCA proyecta los datos en un espacio de menor dimensión en el que la varianza de los datos proyectados se maximiza con avidez a lo largo de cada eje. A pesar de que tienen el mayor poder predictivo sobre el objetivo, las direcciones con una varianza más baja serán descartadas, y el regresor final no podrá aprovecharlas."

#: ../auto_examples/cross_decomposition/plot_pcr_vs_pls.rst:47
msgid "PLS is both a transformer and a regressor, and it is quite similar to PCR: it also applies a dimensionality reduction to the samples before applying a linear regressor to the transformed data. The main difference with PCR is that the PLS transformation is supervised. Therefore, as we will see in this example, it does not suffer from the issue we just mentioned."
msgstr "PLS es tanto un transformador como un regresor, y es bastante similar a la PCR: también aplica una reducción de la dimensionalidad a las muestras antes de aplicar un regresor lineal a los datos transformados. La principal diferencia con la PCR es que la transformación PLS es supervisada. Por lo tanto, como veremos en este ejemplo, no sufre el problema que acabamos de mencionar."

#: ../auto_examples/cross_decomposition/plot_pcr_vs_pls.rst:70
msgid "The data"
msgstr "Los datos"

#: ../auto_examples/cross_decomposition/plot_pcr_vs_pls.rst:72
msgid "We start by creating a simple dataset with two features. Before we even dive into PCR and PLS, we fit a PCA estimator to display the two principal components of this dataset, i.e. the two directions that explain the most variance in the data."
msgstr "Comenzamos creando un conjunto de datos sencillo con dos características. Antes de sumergirnos en la PCR y el PLS, ajustamos un estimador PCA para mostrar los dos componentes principales de este conjunto de datos, es decir, las dos direcciones que explican la mayor parte de la varianza en los datos."

#: ../auto_examples/cross_decomposition/plot_pcr_vs_pls.rst:117
msgid "For the purpose of this example, we now define the target `y` such that it is strongly correlated with a direction that has a small variance. To this end, we will project `X` onto the second component, and add some noise to it."
msgstr "Para el propósito de este ejemplo, ahora definimos el objetivo `y` de manera que esté fuertemente correlacionado con una dirección que tenga una varianza pequeña. Para ello, proyectaremos `X` sobre la segunda componente y le añadiremos algo de ruido."

#: ../auto_examples/cross_decomposition/plot_pcr_vs_pls.rst:151
msgid "Projection on one component and predictive power"
msgstr "Proyección sobre un componente y potencia de predicción"

#: ../auto_examples/cross_decomposition/plot_pcr_vs_pls.rst:153
msgid "We now create two regressors: PCR and PLS, and for our illustration purposes we set the number of components to 1. Before feeding the data to the PCA step of PCR, we first standardize it, as recommended by good practice. The PLS estimator has built-in scaling capabilities."
msgstr "Ahora creamos dos regresores: PCR y PLS, y para nuestra ilustración fijamos el número de componentes en 1. Antes de alimentar los datos al paso PCA de PCR, primero los estandarizamos, como recomiendan las buenas prácticas. El estimador PLS tiene capacidades de escala incorporadas."

#: ../auto_examples/cross_decomposition/plot_pcr_vs_pls.rst:158
msgid "For both models, we plot the projected data onto the first component against the target. In both cases, this projected data is what the regressors will use as training data."
msgstr "Para ambos modelos, trazamos los datos proyectados en el primer componente contra el objetivo. En ambos casos, estos datos proyectados son los que los regresores utilizarán como datos de entrenamiento."

#: ../auto_examples/cross_decomposition/plot_pcr_vs_pls.rst:211
msgid "As expected, the unsupervised PCA transformation of PCR has dropped the second component, i.e. the direction with the lowest variance, despite it being the most predictive direction. This is because PCA is a completely unsupervised transformation, and results in the projected data having a low predictive power on the target."
msgstr "Como era de esperar, la transformación PCA no supervisada de PCR ha dejado de lado el segundo componente, es decir, la dirección con menor varianza, a pesar de ser la dirección más predictiva. Esto se debe a que el PCA es una transformación completamente no supervisada, y da lugar a que los datos proyectados tengan una baja potencia predictivo sobre el objetivo."

#: ../auto_examples/cross_decomposition/plot_pcr_vs_pls.rst:217
msgid "On the other hand, the PLS regressor manages to capture the effect of the direction with the lowest variance, thanks to its use of target information during the transformation: it can recogize that this direction is actually the most predictive. We note that the first PLS component is negatively correlated with the target, which comes from the fact that the signs of eigenvectors are arbitrary."
msgstr "Por otra parte, el regresor PLS consigue captar el efecto de la dirección con menor varianza, gracias a que utiliza la información del objetivo durante la transformación: puede reconocer que esta dirección es realmente la más predictiva. Observamos que el primer componente del PLS está correlacionado negativamente con el objetivo, lo que se debe a que los signos de los autovectores son arbitrarios."

#: ../auto_examples/cross_decomposition/plot_pcr_vs_pls.rst:224
msgid "We also print the R-squared scores of both estimators, which further confirms that PLS is a better alternative than PCR in this case. A negative R-squared indicates that PCR performs worse than a regressor that would simply predict the mean of the target."
msgstr "También imprimimos las puntuaciones R-cuadrado de ambos estimadores, lo que confirma aún más que PLS es una alternativa mejor que PCR en este caso. Un R-cuadrado negativo indica que la PCR funciona peor que un regresor que simplemente predice la media del objetivo."

#: ../auto_examples/cross_decomposition/plot_pcr_vs_pls.rst:243
#: ../auto_examples/cross_decomposition/plot_pcr_vs_pls.rst:273
msgid "Out:"
msgstr "Salida:"

#: ../auto_examples/cross_decomposition/plot_pcr_vs_pls.rst:255
msgid "As a final remark, we note that PCR with 2 components performs as well as PLS: this is because in this case, PCR was able to leverage the second component which has the most preditive power on the target."
msgstr "Como observación final, observamos que la PCR con 2 componentes funciona tan bien como la PLS: esto se debe a que, en este caso, la PCR pudo aprovechar el segundo componente que tiene el mayor poder de predicción sobre el objetivo."

#: ../auto_examples/cross_decomposition/plot_pcr_vs_pls.rst:285
msgid "**Total running time of the script:** ( 0 minutes  0.965 seconds)"
msgstr "**Tiempo total de ejecución del script:** (0 minutos 0.965 segundos)"

#: ../auto_examples/cross_decomposition/plot_pcr_vs_pls.rst:307
msgid ":download:`Download Python source code: plot_pcr_vs_pls.py <plot_pcr_vs_pls.py>`"
msgstr ":download:`Descargar el código fuente de Python: plot_pcr_vs_pls.py <plot_pcr_vs_pls.py>`"

#: ../auto_examples/cross_decomposition/plot_pcr_vs_pls.rst:313
msgid ":download:`Download Jupyter notebook: plot_pcr_vs_pls.ipynb <plot_pcr_vs_pls.ipynb>`"
msgstr ":download:`Descarga el cuaderno Jupyter: plot_lw_vs_oas.ipynb <plot_pcr_vs_pls.ipynb>`"

#: ../auto_examples/cross_decomposition/plot_pcr_vs_pls.rst:320
msgid "`Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_"
msgstr "`Galería generada por Sphinx-Gallery <https://sphinx-gallery.github.io>`_"

