msgid ""
msgstr ""
"Project-Id-Version: scikit-learn\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-03-31 11:24-0400\n"
"PO-Revision-Date: 2021-04-15 00:13\n"
"Last-Translator: \n"
"Language-Team: Spanish\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Crowdin-Project: scikit-learn\n"
"X-Crowdin-Project-ID: 450526\n"
"X-Crowdin-Language: es-ES\n"
"X-Crowdin-File: /main/doc/en/auto_examples/preprocessing/plot_discretization_classification.po\n"
"X-Crowdin-File-ID: 2682\n"
"Language: es_ES\n"

#: ../auto_examples/preprocessing/plot_discretization_classification.rst:13
msgid "Click :ref:`here <sphx_glr_download_auto_examples_preprocessing_plot_discretization_classification.py>` to download the full example code or to run this example in your browser via Binder"
msgstr ""

#: ../auto_examples/preprocessing/plot_discretization_classification.rst:23
msgid "Feature discretization"
msgstr ""

#: ../auto_examples/preprocessing/plot_discretization_classification.rst:25
msgid "A demonstration of feature discretization on synthetic classification datasets. Feature discretization decomposes each feature into a set of bins, here equally distributed in width. The discrete values are then one-hot encoded, and given to a linear classifier. This preprocessing enables a non-linear behavior even though the classifier is linear."
msgstr ""

#: ../auto_examples/preprocessing/plot_discretization_classification.rst:31
msgid "On this example, the first two rows represent linearly non-separable datasets (moons and concentric circles) while the third is approximately linearly separable. On the two linearly non-separable datasets, feature discretization largely increases the performance of linear classifiers. On the linearly separable dataset, feature discretization decreases the performance of linear classifiers. Two non-linear classifiers are also shown for comparison."
msgstr ""

#: ../auto_examples/preprocessing/plot_discretization_classification.rst:38
msgid "This example should be taken with a grain of salt, as the intuition conveyed does not necessarily carry over to real datasets. Particularly in high-dimensional spaces, data can more easily be separated linearly. Moreover, using feature discretization and one-hot encoding increases the number of features, which easily lead to overfitting when the number of samples is small."
msgstr ""

#: ../auto_examples/preprocessing/plot_discretization_classification.rst:44
msgid "The plots show training points in solid colors and testing points semi-transparent. The lower right shows the classification accuracy on the test set."
msgstr ""

#: ../auto_examples/preprocessing/plot_discretization_classification.rst:59
msgid "Out:"
msgstr ""

#: ../auto_examples/preprocessing/plot_discretization_classification.rst:266
msgid "**Total running time of the script:** ( 0 minutes  25.578 seconds)"
msgstr ""

#: ../auto_examples/preprocessing/plot_discretization_classification.rst:288
msgid ":download:`Download Python source code: plot_discretization_classification.py <plot_discretization_classification.py>`"
msgstr ""

#: ../auto_examples/preprocessing/plot_discretization_classification.rst:294
msgid ":download:`Download Jupyter notebook: plot_discretization_classification.ipynb <plot_discretization_classification.ipynb>`"
msgstr ""

#: ../auto_examples/preprocessing/plot_discretization_classification.rst:301
msgid "`Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_"
msgstr ""

