msgid ""
msgstr ""
"Project-Id-Version: scikit-learn\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-03-31 11:24-0400\n"
"PO-Revision-Date: 2021-06-23 19:31\n"
"Last-Translator: \n"
"Language-Team: Spanish\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Crowdin-Project: scikit-learn\n"
"X-Crowdin-Project-ID: 450526\n"
"X-Crowdin-Language: es-ES\n"
"X-Crowdin-File: /main/doc/en/auto_examples/preprocessing/plot_all_scaling.po\n"
"X-Crowdin-File-ID: 4380\n"
"Language: es_ES\n"

#: ../auto_examples/preprocessing/plot_all_scaling.rst:13
msgid "Click :ref:`here <sphx_glr_download_auto_examples_preprocessing_plot_all_scaling.py>` to download the full example code or to run this example in your browser via Binder"
msgstr "Haz clic :ref:`aquí <sphx_glr_download_auto_examples_preprocessing_plot_all_scaling.py>` para descargar el código de ejemplo completo o para ejecutar este ejemplo en tu navegador a través de Binder"

#: ../auto_examples/preprocessing/plot_all_scaling.rst:23
msgid "Compare the effect of different scalers on data with outliers"
msgstr "Compara el efecto de los diferentes escaladores en los datos con los atípicos"

#: ../auto_examples/preprocessing/plot_all_scaling.rst:25
msgid "Feature 0 (median income in a block) and feature 5 (number of households) of the :ref:`california_housing_dataset` have very different scales and contain some very large outliers. These two characteristics lead to difficulties to visualize the data and, more importantly, they can degrade the predictive performance of many machine learning algorithms. Unscaled data can also slow down or even prevent the convergence of many gradient-based estimators."
msgstr "La característica 0 (ingresos medios en un bloque) y la característica 5 (número de hogares) del conjunto de datos :ref:`california_housing_dataset` tienen escalas muy diferentes y contienen algunos valores atípicos muy grandes. Estas dos características dificultan la visualización de los datos y, lo que es más importante, pueden degradar el rendimiento predictivo de muchos algoritmos de aprendizaje automático. Los datos no escalados también pueden ralentizar o incluso impedir la convergencia de muchos estimadores basados en el gradiente."

#: ../auto_examples/preprocessing/plot_all_scaling.rst:33
msgid "Indeed many estimators are designed with the assumption that each feature takes values close to zero or more importantly that all features vary on comparable scales. In particular, metric-based and gradient-based estimators often assume approximately standardized data (centered features with unit variances). A notable exception are decision tree-based estimators that are robust to arbitrary scaling of the data."
msgstr "De hecho, muchos estimadores están diseñados con la suposición de que cada característica tiene valores cercanos a cero o más importante que todas las características varían en escalas comparables. En particular, los estimadores basados en métricas y basados en degradados suelen asumir aproximadamente datos estandarizados (características centradas con variantes unitarias). Una excepción notable son los estimadores basados en árboles de decisiones que son robustos a la escala arbitraria de los datos."

#: ../auto_examples/preprocessing/plot_all_scaling.rst:40
msgid "This example uses different scalers, transformers, and normalizers to bring the data within a pre-defined range."
msgstr "Este ejemplo utiliza diferentes escaladores, transformadores y normalizadores para llevar los datos dentro de un rango predefinido."

#: ../auto_examples/preprocessing/plot_all_scaling.rst:43
msgid "Scalers are linear (or more precisely affine) transformers and differ from each other in the way they estimate the parameters used to shift and scale each feature."
msgstr "Los escaladores son transformadores lineales (o más precisamente) y difieren unos de otros en la forma en que estiman los parámetros utilizados para cambiar y escalar cada característica."

#: ../auto_examples/preprocessing/plot_all_scaling.rst:47
msgid ":class:`~sklearn.preprocessing.QuantileTransformer` provides non-linear transformations in which distances between marginal outliers and inliers are shrunk. :class:`~sklearn.preprocessing.PowerTransformer` provides non-linear transformations in which data is mapped to a normal distribution to stabilize variance and minimize skewness."
msgstr ":class:`~sklearn.preprocessing.QuantileTransformer` proporciona transformaciones no lineales en las que se reducen las distancias entre los valores marginales atípicos y los valores atípicos. :class:`~sklearn.preprocessing.PowerTransformer` proporciona transformaciones no lineales en las que los datos se asignan a una distribución normal para estabilizar la varianza y minimizar la asimetría."

#: ../auto_examples/preprocessing/plot_all_scaling.rst:54
msgid "Unlike the previous transformations, normalization refers to a per sample transformation instead of a per feature transformation."
msgstr "A diferencia de las transformaciones anteriores, la normalización se refiere a una transformación por muestra en lugar de una transformación por característica."

#: ../auto_examples/preprocessing/plot_all_scaling.rst:57
msgid "The following code is a bit verbose, feel free to jump directly to the analysis of the results_."
msgstr "El siguiente código es un poco verboso, siéntete libre de saltar directamente al análisis de los resultados_."

#: ../auto_examples/preprocessing/plot_all_scaling.rst:211
#, python-format
msgid "Two plots will be shown for each scaler/normalizer/transformer. The left figure will show a scatter plot of the full data set while the right figure will exclude the extreme values considering only 99 % of the data set, excluding marginal outliers. In addition, the marginal distributions for each feature will be shown on the sides of the scatter plot."
msgstr "Se mostrarán dos gráficos para cada escalador/normalizador/transformador. La figura de la izquierda mostrará un gráfico de dispersión del conjunto de datos completo, mientras que la figura de la derecha excluirá los valores extremos considerando sólo el 99% del conjunto de datos, excluyendo los valores atípicos marginales. Además, las distribuciones marginales de cada característica se mostrarán a los lados del gráfico de dispersión."

#: ../auto_examples/preprocessing/plot_all_scaling.rst:264
msgid "Original data"
msgstr "Datos originales"

#: ../auto_examples/preprocessing/plot_all_scaling.rst:266
msgid "Each transformation is plotted showing two transformed features, with the left plot showing the entire dataset, and the right zoomed-in to show the dataset without the marginal outliers. A large majority of the samples are compacted to a specific range, [0, 10] for the median income and [0, 6] for the number of households. Note that there are some marginal outliers (some blocks have more than 1200 households). Therefore, a specific pre-processing can be very beneficial depending of the application. In the following, we present some insights and behaviors of those pre-processing methods in the presence of marginal outliers."
msgstr "Cada transformación se traza mostrando dos características transformadas, con el gráfico de la izquierda mostrando el conjunto de datos, y el de la derecha ampliado para mostrar el conjunto de datos sin los valores marginales. La gran mayoría de las muestras están compactadas en un rango específico, [0, 10] para la mediana de ingresos y [0, 6] para el número de hogares. Observa que hay algunos valores atípicos marginales (algunos bloques tienen más de 1.200 hogares). Por lo tanto, un preprocesamiento específico puede ser muy beneficioso dependiendo de la aplicación. A continuación, presentamos algunas ideas y comportamientos de esos métodos de preprocesamiento en presencia de valores atípicos marginales."

#: ../auto_examples/preprocessing/plot_all_scaling.rst:297
msgid "StandardScaler"
msgstr "StandardScaler"

#: ../auto_examples/preprocessing/plot_all_scaling.rst:299
msgid ":class:`~sklearn.preprocessing.StandardScaler` removes the mean and scales the data to unit variance. The scaling shrinks the range of the feature values as shown in the left figure below. However, the outliers have an influence when computing the empirical mean and standard deviation. Note in particular that because the outliers on each feature have different magnitudes, the spread of the transformed data on each feature is very different: most of the data lie in the [-2, 4] range for the transformed median income feature while the same data is squeezed in the smaller [-0.2, 0.2] range for the transformed number of households."
msgstr ":class:`~sklearn.preprocessing.StandardScaler` elimina la media y escala los datos a la unidad de varianza. El escalado reduce el rango de los valores de las características como se muestra en la figura de la izquierda. Sin embargo, los valores atípicos influyen en el cálculo de la media empírica y la desviación estándar. Observa, en particular, que debido a que los valores atípicos de cada característica tienen diferentes magnitudes, la dispersión de los datos transformados de cada característica es muy diferente: la mayoría de los datos se encuentran en el intervalo [-2, 4] para la característica transformada de la mediana de los ingresos, mientras que los mismos datos están comprimidos en el intervalo más pequeño [-0,2, 0,2] para la transformación del número de hogares."

#: ../auto_examples/preprocessing/plot_all_scaling.rst:309
msgid ":class:`~sklearn.preprocessing.StandardScaler` therefore cannot guarantee balanced feature scales in the presence of outliers."
msgstr ":class:`~sklearn.preprocessing.StandardScaler` por lo tanto no puede garantizar escalas de características equilibradas en presencia de valores atípicos."

#: ../auto_examples/preprocessing/plot_all_scaling.rst:334
msgid "MinMaxScaler"
msgstr "MinMaxScaler"

#: ../auto_examples/preprocessing/plot_all_scaling.rst:336
msgid ":class:`~sklearn.preprocessing.MinMaxScaler` rescales the data set such that all feature values are in the range [0, 1] as shown in the right panel below. However, this scaling compresses all inliers into the narrow range [0, 0.005] for the transformed number of households."
msgstr ":class:`~sklearn.preprocessing.MinMaxScaler` reescala el conjunto de datos de forma que todos los valores de las características estén en el rango [0, 1], como se muestra en el panel derecho de abajo. Sin embargo, este escalado comprime todos los valores atípicos en el estrecho rango [0, 0,005] para el número transformado de hogares."

#: ../auto_examples/preprocessing/plot_all_scaling.rst:342
msgid "Both :class:`~sklearn.preprocessing.StandardScaler` and :class:`~sklearn.preprocessing.MinMaxScaler` are very sensitive to the presence of outliers."
msgstr ""

#: ../auto_examples/preprocessing/plot_all_scaling.rst:367
msgid "MaxAbsScaler"
msgstr ""

#: ../auto_examples/preprocessing/plot_all_scaling.rst:369
msgid ":class:`~sklearn.preprocessing.MaxAbsScaler` is similar to :class:`~sklearn.preprocessing.MinMaxScaler` except that the values are mapped in the range [0, 1]. On positive only data, both scalers behave similarly. :class:`~sklearn.preprocessing.MaxAbsScaler` therefore also suffers from the presence of large outliers."
msgstr ""

#: ../auto_examples/preprocessing/plot_all_scaling.rst:397
msgid "RobustScaler"
msgstr ""

#: ../auto_examples/preprocessing/plot_all_scaling.rst:399
msgid "Unlike the previous scalers, the centering and scaling statistics of :class:`~sklearn.preprocessing.RobustScaler` is based on percentiles and are therefore not influenced by a few number of very large marginal outliers. Consequently, the resulting range of the transformed feature values is larger than for the previous scalers and, more importantly, are approximately similar: for both features most of the transformed values lie in a [-2, 3] range as seen in the zoomed-in figure. Note that the outliers themselves are still present in the transformed data. If a separate outlier clipping is desirable, a non-linear transformation is required (see below)."
msgstr ""

#: ../auto_examples/preprocessing/plot_all_scaling.rst:431
msgid "PowerTransformer"
msgstr ""

#: ../auto_examples/preprocessing/plot_all_scaling.rst:433
msgid ":class:`~sklearn.preprocessing.PowerTransformer` applies a power transformation to each feature to make the data more Gaussian-like in order to stabilize variance and minimize skewness. Currently the Yeo-Johnson and Box-Cox transforms are supported and the optimal scaling factor is determined via maximum likelihood estimation in both methods. By default, :class:`~sklearn.preprocessing.PowerTransformer` applies zero-mean, unit variance normalization. Note that Box-Cox can only be applied to strictly positive data. Income and number of households happen to be strictly positive, but if negative values are present the Yeo-Johnson transformed is preferred."
msgstr ""

#: ../auto_examples/preprocessing/plot_all_scaling.rst:477
msgid "QuantileTransformer (uniform output)"
msgstr ""

#: ../auto_examples/preprocessing/plot_all_scaling.rst:479
msgid ":class:`~sklearn.preprocessing.QuantileTransformer` applies a non-linear transformation such that the probability density function of each feature will be mapped to a uniform or Gaussian distribution. In this case, all the data, including outliers, will be mapped to a uniform distribution with the range [0, 1], making outliers indistinguishable from inliers."
msgstr ""

#: ../auto_examples/preprocessing/plot_all_scaling.rst:486
msgid ":class:`~sklearn.preprocessing.RobustScaler` and :class:`~sklearn.preprocessing.QuantileTransformer` are robust to outliers in the sense that adding or removing outliers in the training set will yield approximately the same transformation. But contrary to :class:`~sklearn.preprocessing.RobustScaler`, :class:`~sklearn.preprocessing.QuantileTransformer` will also automatically collapse any outlier by setting them to the a priori defined range boundaries (0 and 1). This can result in saturation artifacts for extreme values."
msgstr ""

#: ../auto_examples/preprocessing/plot_all_scaling.rst:516
msgid "QuantileTransformer (Gaussian output)"
msgstr ""

#: ../auto_examples/preprocessing/plot_all_scaling.rst:518
msgid "To map to a Gaussian distribution, set the parameter ``output_distribution='normal'``."
msgstr ""

#: ../auto_examples/preprocessing/plot_all_scaling.rst:542
msgid "Normalizer"
msgstr ""

#: ../auto_examples/preprocessing/plot_all_scaling.rst:544
msgid "The :class:`~sklearn.preprocessing.Normalizer` rescales the vector for each sample to have unit norm, independently of the distribution of the samples. It can be seen on both figures below where all samples are mapped onto the unit circle. In our example the two selected features have only positive values; therefore the transformed data only lie in the positive quadrant. This would not be the case if some original features had a mix of positive and negative values."
msgstr ""

#: ../auto_examples/preprocessing/plot_all_scaling.rst:574
msgid "**Total running time of the script:** ( 0 minutes  10.126 seconds)"
msgstr ""

#: ../auto_examples/preprocessing/plot_all_scaling.rst:596
msgid ":download:`Download Python source code: plot_all_scaling.py <plot_all_scaling.py>`"
msgstr ""

#: ../auto_examples/preprocessing/plot_all_scaling.rst:602
msgid ":download:`Download Jupyter notebook: plot_all_scaling.ipynb <plot_all_scaling.ipynb>`"
msgstr ""

#: ../auto_examples/preprocessing/plot_all_scaling.rst:609
msgid "`Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_"
msgstr ""

