msgid ""
msgstr ""
"Project-Id-Version: scikit-learn\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-03-31 11:24-0400\n"
"PO-Revision-Date: 2021-08-17 15:54\n"
"Last-Translator: \n"
"Language-Team: Spanish\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Crowdin-Project: scikit-learn\n"
"X-Crowdin-Project-ID: 450526\n"
"X-Crowdin-Language: es-ES\n"
"X-Crowdin-File: /main/doc/en/auto_examples/gaussian_process/plot_compare_gpr_krr.po\n"
"X-Crowdin-File-ID: 4276\n"
"Language: es_ES\n"

#: ../auto_examples/gaussian_process/plot_compare_gpr_krr.rst:13
msgid "Click :ref:`here <sphx_glr_download_auto_examples_gaussian_process_plot_compare_gpr_krr.py>` to download the full example code or to run this example in your browser via Binder"
msgstr "Haz clic :ref:`aquí <sphx_glr_download_auto_examples_gaussian_process_plot_compare_gpr_krr.py>` para descargar el código de ejemplo completo o para ejecutar este ejemplo en tu navegador a través de Binder"

#: ../auto_examples/gaussian_process/plot_compare_gpr_krr.rst:23
msgid "Comparison of kernel ridge and Gaussian process regression"
msgstr "Comparación de la cresta del núcleo y la regresión del proceso gaussiano"

#: ../auto_examples/gaussian_process/plot_compare_gpr_krr.rst:25
msgid "Both kernel ridge regression (KRR) and Gaussian process regression (GPR) learn a target function by employing internally the \"kernel trick\". KRR learns a linear function in the space induced by the respective kernel which corresponds to a non-linear function in the original space. The linear function in the kernel space is chosen based on the mean-squared error loss with ridge regularization. GPR uses the kernel to define the covariance of a prior distribution over the target functions and uses the observed training data to define a likelihood function. Based on Bayes theorem, a (Gaussian) posterior distribution over target functions is defined, whose mean is used for prediction."
msgstr "Tanto la regresión de núcleo ridge (KRR) como la regresión por proceso gaussiano (GPR) aprenden una función objetivo empleando internamente el \"truco del núcleo\". La KRR aprende una función lineal en el espacio inducido por el núcleo respectivo que corresponde a una función no lineal en el espacio original. La función lineal en el espacio del núcleo se elige en función de la pérdida de error cuadrático medio con regularización de cresta. La GPR utiliza el núcleo para definir la covarianza de una distribución a priori sobre las funciones objetivo y utiliza los datos de entrenamiento observados para definir una función de verosimilitud. Basándose en el teorema de Bayes, se define una distribución posterior (gaussiana) sobre las funciones objetivo, cuya media se utiliza para la predicción."

#: ../auto_examples/gaussian_process/plot_compare_gpr_krr.rst:36
msgid "A major difference is that GPR can choose the kernel's hyperparameters based on gradient-ascent on the marginal likelihood function while KRR needs to perform a grid search on a cross-validated loss function (mean-squared error loss). A further difference is that GPR learns a generative, probabilistic model of the target function and can thus provide meaningful confidence intervals and posterior samples along with the predictions while KRR only provides predictions."
msgstr "Una de las principales diferencias es que GPR puede elegir los hiperparámetros del núcleo basándose en el gradiente de ascenso de la función de verosimilitud marginal, mientras que KRR tiene que realizar una búsqueda de cuadrícula en una función de pérdida validada de forma cruzada (pérdida de error cuadrático medio). Otra diferencia es que GPR aprende un modelo generativo y probabilístico de la función objetivo y, por tanto, puede proporcionar intervalos de confianza significativos y muestras posteriores junto con las predicciones, mientras que KRR sólo proporciona predicciones."

#: ../auto_examples/gaussian_process/plot_compare_gpr_krr.rst:44
msgid "This example illustrates both methods on an artificial dataset, which consists of a sinusoidal target function and strong noise. The figure compares the learned model of KRR and GPR based on a ExpSineSquared kernel, which is suited for learning periodic functions. The kernel's hyperparameters control the smoothness (l) and periodicity of the kernel (p). Moreover, the noise level of the data is learned explicitly by GPR by an additional WhiteKernel component in the kernel and by the regularization parameter alpha of KRR."
msgstr "Este ejemplo ilustra ambos métodos en un conjunto de datos artificial, que consiste en una función objetivo sinusoidal y un fuerte ruido. La figura compara el modelo aprendido de KRR y GPR basado en un núcleo ExpSineSquared, que es adecuado para el aprendizaje de funciones periódicas. Los hiperparámetros del núcleo controlan la suavidad (l) y la periodicidad del núcleo (p). Además, el nivel de ruido de los datos es aprendido explícitamente por GPR mediante un componente adicional WhiteKernel en el núcleo y por el parámetro de regularización alfa de KRR."

#: ../auto_examples/gaussian_process/plot_compare_gpr_krr.rst:52
msgid "The figure shows that both methods learn reasonable models of the target function. GPR correctly identifies the periodicity of the function to be roughly 2*pi (6.28), while KRR chooses the doubled periodicity 4*pi. Besides that, GPR provides reasonable confidence bounds on the prediction which are not available for KRR. A major difference between the two methods is the time required for fitting and predicting: while fitting KRR is fast in principle, the grid-search for hyperparameter optimization scales exponentially with the number of hyperparameters (\"curse of dimensionality\"). The gradient-based optimization of the parameters in GPR does not suffer from this exponential scaling and is thus considerable faster on this example with 3-dimensional hyperparameter space. The time for predicting is similar; however, generating the variance of the predictive distribution of GPR takes considerable longer than just predicting the mean."
msgstr "La figura muestra que ambos métodos aprenden modelos razonables de la función objetivo. GPR identifica correctamente que la periodicidad de la función es aproximadamente 2*pi (6,28), mientras que KRR elige la periodicidad duplicada 4*pi. Además, GPR proporciona límites de confianza razonables en la predicción que no están disponibles para KRR. Una diferencia importante entre los dos métodos es el tiempo necesario para el ajuste y la predicción: mientras que el ajuste de KRR es rápido en principio, la búsqueda en cuadrícula para la optimización de los hiperparámetros escala exponencialmente con el número de hiperparámetros (\"maldición de la dimensionalidad\"). La optimización de los parámetros basada en el gradiente en GPR no sufre este escalamiento exponencial y, por tanto, es considerablemente más rápida en este ejemplo con un espacio de hiperparámetros tridimensional. El tiempo de predicción es similar; sin embargo, generar la varianza de la distribución de predicción de GPR lleva bastante más tiempo que sólo predecir la media."

#: ../auto_examples/gaussian_process/plot_compare_gpr_krr.rst:77
msgid "Out:"
msgstr "Out:"

#: ../auto_examples/gaussian_process/plot_compare_gpr_krr.rst:176
msgid "**Total running time of the script:** ( 0 minutes  7.023 seconds)"
msgstr "**Tiempo total de ejecución del script:** (0 minutos 7.023 segundos)"

#: ../auto_examples/gaussian_process/plot_compare_gpr_krr.rst:198
msgid ":download:`Download Python source code: plot_compare_gpr_krr.py <plot_compare_gpr_krr.py>`"
msgstr ":download:`Descargar el código fuente de Python: plot_compare_gpr_krr.py <plot_compare_gpr_krr.py>`"

#: ../auto_examples/gaussian_process/plot_compare_gpr_krr.rst:204
msgid ":download:`Download Jupyter notebook: plot_compare_gpr_krr.ipynb <plot_compare_gpr_krr.ipynb>`"
msgstr ":download:`Descargar el cuaderno Jupyter: plot_compare_gpr_krr.ipynb <plot_compare_gpr_krr.ipynb>`"

#: ../auto_examples/gaussian_process/plot_compare_gpr_krr.rst:211
msgid "`Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_"
msgstr "`Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_"

