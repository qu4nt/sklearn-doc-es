msgid ""
msgstr ""
"Project-Id-Version: scikit-learn\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-03-31 11:24-0400\n"
"PO-Revision-Date: 2021-04-15 00:13\n"
"Last-Translator: \n"
"Language-Team: Spanish\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Crowdin-Project: scikit-learn\n"
"X-Crowdin-Project-ID: 450526\n"
"X-Crowdin-Language: es-ES\n"
"X-Crowdin-File: /main/doc/en/auto_examples/neighbors/plot_nca_dim_reduction.po\n"
"X-Crowdin-File-ID: 2656\n"
"Language: es_ES\n"

#: ../auto_examples/neighbors/plot_nca_dim_reduction.rst:13
msgid "Click :ref:`here <sphx_glr_download_auto_examples_neighbors_plot_nca_dim_reduction.py>` to download the full example code or to run this example in your browser via Binder"
msgstr ""

#: ../auto_examples/neighbors/plot_nca_dim_reduction.rst:23
msgid "Dimensionality Reduction with Neighborhood Components Analysis"
msgstr ""

#: ../auto_examples/neighbors/plot_nca_dim_reduction.rst:25
msgid "Sample usage of Neighborhood Components Analysis for dimensionality reduction."
msgstr ""

#: ../auto_examples/neighbors/plot_nca_dim_reduction.rst:27
msgid "This example compares different (linear) dimensionality reduction methods applied on the Digits data set. The data set contains images of digits from 0 to 9 with approximately 180 samples of each class. Each image is of dimension 8x8 = 64, and is reduced to a two-dimensional data point."
msgstr ""

#: ../auto_examples/neighbors/plot_nca_dim_reduction.rst:32
msgid "Principal Component Analysis (PCA) applied to this data identifies the combination of attributes (principal components, or directions in the feature space) that account for the most variance in the data. Here we plot the different samples on the 2 first principal components."
msgstr ""

#: ../auto_examples/neighbors/plot_nca_dim_reduction.rst:37
msgid "Linear Discriminant Analysis (LDA) tries to identify attributes that account for the most variance *between classes*. In particular, LDA, in contrast to PCA, is a supervised method, using known class labels."
msgstr ""

#: ../auto_examples/neighbors/plot_nca_dim_reduction.rst:41
msgid "Neighborhood Components Analysis (NCA) tries to find a feature space such that a stochastic nearest neighbor algorithm will give the best accuracy. Like LDA, it is a supervised method."
msgstr ""

#: ../auto_examples/neighbors/plot_nca_dim_reduction.rst:45
msgid "One can see that NCA enforces a clustering of the data that is visually meaningful despite the large reduction in dimension."
msgstr ""

#: ../auto_examples/neighbors/plot_nca_dim_reduction.rst:155
msgid "**Total running time of the script:** ( 0 minutes  3.374 seconds)"
msgstr ""

#: ../auto_examples/neighbors/plot_nca_dim_reduction.rst:177
msgid ":download:`Download Python source code: plot_nca_dim_reduction.py <plot_nca_dim_reduction.py>`"
msgstr ""

#: ../auto_examples/neighbors/plot_nca_dim_reduction.rst:183
msgid ":download:`Download Jupyter notebook: plot_nca_dim_reduction.ipynb <plot_nca_dim_reduction.ipynb>`"
msgstr ""

#: ../auto_examples/neighbors/plot_nca_dim_reduction.rst:190
msgid "`Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_"
msgstr ""

