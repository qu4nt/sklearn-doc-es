msgid ""
msgstr ""
"Project-Id-Version: scikit-learn\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-03-31 12:43-0400\n"
"PO-Revision-Date: 2021-06-19 19:31\n"
"Last-Translator: \n"
"Language-Team: Spanish\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Crowdin-Project: scikit-learn\n"
"X-Crowdin-Project-ID: 450526\n"
"X-Crowdin-Language: es-ES\n"
"X-Crowdin-File: /main/doc/en/auto_examples/inspection/plot_permutation_importance.po\n"
"X-Crowdin-File-ID: 4398\n"
"Language: es_ES\n"

#: ../auto_examples/inspection/plot_permutation_importance.rst:13
msgid "Click :ref:`here <sphx_glr_download_auto_examples_inspection_plot_permutation_importance.py>` to download the full example code or to run this example in your browser via Binder"
msgstr "Haz clic :ref:`aquí <sphx_glr_download_auto_examples_inspection_plot_permutation_importance.py>` para descargar el código completo del ejemplo o para ejecutar este ejemplo en tu navegador a través de Binder"

#: ../auto_examples/inspection/plot_permutation_importance.rst:23
msgid "Permutation Importance vs Random Forest Feature Importance (MDI)"
msgstr "Importancia de la Permutación vs la Importancia de las Características del Bosque Aleatorio (MDI)"

#: ../auto_examples/inspection/plot_permutation_importance.rst:25
msgid "In this example, we will compare the impurity-based feature importance of :class:`~sklearn.ensemble.RandomForestClassifier` with the permutation importance on the titanic dataset using :func:`~sklearn.inspection.permutation_importance`. We will show that the impurity-based feature importance can inflate the importance of numerical features."
msgstr "En este ejemplo, compararemos la importancia de las características basadas en las impurezas de :class:`~sklearn.ensemble.RandomForestClassifier` con la importancia de la permutación en el conjunto de datos titanic utilizando :func:`~sklearn.inspection.permutation_importance`. Mostraremos que la importancia de la característica basada en impurezas puede inflar la importancia de las características numéricas."

#: ../auto_examples/inspection/plot_permutation_importance.rst:32
msgid "Furthermore, the impurity-based feature importance of random forests suffers from being computed on statistics derived from the training dataset: the importances can be high even for features that are not predictive of the target variable, as long as the model has the capacity to use them to overfit."
msgstr "Además, la importancia de las características basadas en las impurezas de los bosques aleatorios se ve afectada por el hecho de que se calculan a partir de las estadísticas derivadas del conjunto de datos de entrenamiento: las importancias pueden ser altas incluso para las características que no son predictivas de la variable objetivo, siempre y cuando el modelo tenga la capacidad de utilizarlas para sobreajustar."

#: ../auto_examples/inspection/plot_permutation_importance.rst:37
msgid "This example shows how to use Permutation Importances as an alternative that can mitigate those limitations."
msgstr "Este ejemplo muestra cómo utilizar las Importancias de Permutación como una alternativa que puede mitigar esas limitaciones."

#: ../auto_examples/inspection/plot_permutation_importance.rst:42
msgid "[1] L. Breiman, \"Random Forests\", Machine Learning, 45(1), 5-32,"
msgstr "[1] L. Breiman, \"Random Forests\", Machine Learning, 45(1), 5-32,"

#: ../auto_examples/inspection/plot_permutation_importance.rst:43
msgid "https://doi.org/10.1023/A:1010933404324"
msgstr "https://doi.org/10.1023/A:1010933404324"

#: ../auto_examples/inspection/plot_permutation_importance.rst:73
msgid "Data Loading and Feature Engineering"
msgstr "Carga de Datos e Ingeniería de Características"

#: ../auto_examples/inspection/plot_permutation_importance.rst:74
msgid "Let's use pandas to load a copy of the titanic dataset. The following shows how to apply separate preprocessing on numerical and categorical features."
msgstr "Utilicemos pandas para cargar una copia del conjunto de datos del titanic. A continuación se muestra cómo aplicar el preprocesamiento por separado en características numéricas y categóricas."

#: ../auto_examples/inspection/plot_permutation_importance.rst:77
msgid "We further include two random variables that are not correlated in any way with the target variable (``survived``):"
msgstr "Además, incluimos dos variables aleatorias que no están correlacionadas de ninguna manera con la variable objetivo (``survived``):"

#: ../auto_examples/inspection/plot_permutation_importance.rst:80
msgid "``random_num`` is a high cardinality numerical variable (as many unique values as records)."
msgstr "``random_num`` es una variable numérica de alta cardinalidad (tantos valores únicos como registros)."

#: ../auto_examples/inspection/plot_permutation_importance.rst:82
msgid "``random_cat`` is a low cardinality categorical variable (3 possible values)."
msgstr "``random_cat`` es una variable categórica de baja cardinalidad (3 valores posibles)."

#: ../auto_examples/inspection/plot_permutation_importance.rst:123
#: ../auto_examples/inspection/plot_permutation_importance.rst:179
#: ../auto_examples/inspection/plot_permutation_importance.rst:239
msgid "Out:"
msgstr "Salida:"

#: ../auto_examples/inspection/plot_permutation_importance.rst:145
msgid "Accuracy of the Model"
msgstr "Precisión del modelo"

#: ../auto_examples/inspection/plot_permutation_importance.rst:146
msgid "Prior to inspecting the feature importances, it is important to check that the model predictive performance is high enough. Indeed there would be little interest of inspecting the important features of a non-predictive model."
msgstr ""

#: ../auto_examples/inspection/plot_permutation_importance.rst:150
msgid "Here one can observe that the train accuracy is very high (the forest model has enough capacity to completely memorize the training set) but it can still generalize well enough to the test set thanks to the built-in bagging of random forests."
msgstr ""

#: ../auto_examples/inspection/plot_permutation_importance.rst:155
msgid "It might be possible to trade some accuracy on the training set for a slightly better accuracy on the test set by limiting the capacity of the trees (for instance by setting ``min_samples_leaf=5`` or ``min_samples_leaf=10``) so as to limit overfitting while not introducing too much underfitting."
msgstr ""

#: ../auto_examples/inspection/plot_permutation_importance.rst:161
msgid "However let's keep our high capacity random forest model for now so as to illustrate some pitfalls with feature importance on variables with many unique values."
msgstr ""

#: ../auto_examples/inspection/plot_permutation_importance.rst:192
msgid "Tree's Feature Importance from Mean Decrease in Impurity (MDI)"
msgstr ""

#: ../auto_examples/inspection/plot_permutation_importance.rst:193
msgid "The impurity-based feature importance ranks the numerical features to be the most important features. As a result, the non-predictive ``random_num`` variable is ranked the most important!"
msgstr ""

#: ../auto_examples/inspection/plot_permutation_importance.rst:197
msgid "This problem stems from two limitations of impurity-based feature importances:"
msgstr ""

#: ../auto_examples/inspection/plot_permutation_importance.rst:200
msgid "impurity-based importances are biased towards high cardinality features;"
msgstr ""

#: ../auto_examples/inspection/plot_permutation_importance.rst:201
msgid "impurity-based importances are computed on training set statistics and therefore do not reflect the ability of feature to be useful to make predictions that generalize to the test set (when the model has enough capacity)."
msgstr ""

#: ../auto_examples/inspection/plot_permutation_importance.rst:251
msgid "As an alternative, the permutation importances of ``rf`` are computed on a held out test set. This shows that the low cardinality categorical feature, ``sex`` is the most important feature."
msgstr ""

#: ../auto_examples/inspection/plot_permutation_importance.rst:255
msgid "Also note that both random features have very low importances (close to 0) as expected."
msgstr ""

#: ../auto_examples/inspection/plot_permutation_importance.rst:286
msgid "It is also possible to compute the permutation importances on the training set. This reveals that ``random_num`` gets a significantly higher importance ranking than when computed on the test set. The difference between those two plots is a confirmation that the RF model has enough capacity to use that random numerical feature to overfit. You can further confirm this by re-running this example with constrained RF with min_samples_leaf=10."
msgstr ""

#: ../auto_examples/inspection/plot_permutation_importance.rst:321
msgid "**Total running time of the script:** ( 0 minutes  4.634 seconds)"
msgstr ""

#: ../auto_examples/inspection/plot_permutation_importance.rst:343
msgid ":download:`Download Python source code: plot_permutation_importance.py <plot_permutation_importance.py>`"
msgstr ""

#: ../auto_examples/inspection/plot_permutation_importance.rst:349
msgid ":download:`Download Jupyter notebook: plot_permutation_importance.ipynb <plot_permutation_importance.ipynb>`"
msgstr ""

#: ../auto_examples/inspection/plot_permutation_importance.rst:356
msgid "`Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_"
msgstr "`Galería generada por Sphinx-Gallery <https://sphinx-gallery.github.io>`_"

#~ msgid "**Total running time of the script:** ( 0 minutes  3.161 seconds)"
#~ msgstr ""

