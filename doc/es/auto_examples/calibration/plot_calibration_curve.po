msgid ""
msgstr ""
"Project-Id-Version: scikit-learn\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-03-31 11:24-0400\n"
"PO-Revision-Date: 2021-07-20 17:05\n"
"Last-Translator: \n"
"Language-Team: Spanish\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Crowdin-Project: scikit-learn\n"
"X-Crowdin-Project-ID: 450526\n"
"X-Crowdin-Language: es-ES\n"
"X-Crowdin-File: /main/doc/en/auto_examples/calibration/plot_calibration_curve.po\n"
"X-Crowdin-File-ID: 4264\n"
"Language: es_ES\n"

#: ../auto_examples/calibration/plot_calibration_curve.rst:13
msgid "Click :ref:`here <sphx_glr_download_auto_examples_calibration_plot_calibration_curve.py>` to download the full example code or to run this example in your browser via Binder"
msgstr "Haz clic en :ref:`aquí <sphx_glr_download_auto_examples_calibration_plot_calibration_curve.py>` para descargar el código completo del ejemplo o para ejecutar este ejemplo en tu navegador a través de Binder"

#: ../auto_examples/calibration/plot_calibration_curve.rst:23
msgid "Probability Calibration curves"
msgstr "Curvas de probabilidad de calibración"

#: ../auto_examples/calibration/plot_calibration_curve.rst:25
msgid "When performing classification one often wants to predict not only the class label, but also the associated probability. This probability gives some kind of confidence on the prediction. This example demonstrates how to display how well calibrated the predicted probabilities are and how to calibrate an uncalibrated classifier."
msgstr "Cuando se realiza una clasificación, a menudo se quiere predecir no sólo la etiqueta de la clase, sino también la probabilidad asociada. Esta probabilidad da algún tipo de confianza en la predicción. Este ejemplo demuestra cómo mostrar lo bien calibradas que están las probabilidades predichas y cómo calibrar un clasificador no calibrado."

#: ../auto_examples/calibration/plot_calibration_curve.rst:31
msgid "The experiment is performed on an artificial dataset for binary classification with 100,000 samples (1,000 of them are used for model fitting) with 20 features. Of the 20 features, only 2 are informative and 10 are redundant. The first figure shows the estimated probabilities obtained with logistic regression, Gaussian naive Bayes, and Gaussian naive Bayes with both isotonic calibration and sigmoid calibration. The calibration performance is evaluated with Brier score, reported in the legend (the smaller the better). One can observe here that logistic regression is well calibrated while raw Gaussian naive Bayes performs very badly. This is because of the redundant features which violate the assumption of feature-independence and result in an overly confident classifier, which is indicated by the typical transposed-sigmoid curve."
msgstr "El experimento se realiza en un conjunto de datos artificial para la clasificación binaria con 100.000 muestras (1.000 de ellas se utilizan para el ajuste del modelo) con 20 características. De las 20 características, sólo 2 son informativas y 10 son redundantes. La primera figura muestra las probabilidades estimadas obtenidas con regresión logística, Bayes ingenuo gaussiano y Bayes ingenuo gaussiano con calibración isotónica y calibración sigmoidea. El rendimiento de la calibración se evalúa con la puntuación de Brier, indicada en la leyenda (cuanto más pequeña, mejor). Se puede observar aquí que la regresión logística está bien calibrada mientras que el Bayes ingenuo gaussiano crudo tiene un rendimiento muy malo. Esto se debe a las características redundantes que violan la suposición de la independencia de las características y dan lugar a un clasificador demasiado confiado, lo que se indica con la típica curva transpuesta-sigmoide."

#: ../auto_examples/calibration/plot_calibration_curve.rst:44
msgid "Calibration of the probabilities of Gaussian naive Bayes with isotonic regression can fix this issue as can be seen from the nearly diagonal calibration curve. Sigmoid calibration also improves the brier score slightly, albeit not as strongly as the non-parametric isotonic regression. This can be attributed to the fact that we have plenty of calibration data such that the greater flexibility of the non-parametric model can be exploited."
msgstr "La calibración de las probabilidades del Bayes ingenuo gaussiano con una regresión isotónica puede solucionar este problema, como puede verse en la curva de calibración casi diagonal. La calibración sigmoidea también mejora ligeramente la puntuación de Brier, aunque no con tanta fuerza como la regresión isotónica no paramétrica. Esto puede atribuirse al hecho de que tenemos muchos datos de calibración, de modo que se puede aprovechar la mayor flexibilidad del modelo no paramétrico."

#: ../auto_examples/calibration/plot_calibration_curve.rst:51
msgid "The second figure shows the calibration curve of a linear support-vector classifier (LinearSVC). LinearSVC shows the opposite behavior as Gaussian naive Bayes: the calibration curve has a sigmoid curve, which is typical for an under-confident classifier. In the case of LinearSVC, this is caused by the margin property of the hinge loss, which lets the model focus on hard samples that are close to the decision boundary (the support vectors)."
msgstr "La segunda figura muestra la curva de calibración de un clasificador lineal de vectores de apoyo (LinearSVC). LinearSVC muestra el comportamiento opuesto al de los Bayes ingenuos gaussianos: la curva de calibración tiene una curva sigmoidea, lo que es típico de un clasificador poco fiable. En el caso de LinearSVC, esto se debe a la propiedad de margen de la pérdida de bisagra, que permite al modelo centrarse en las muestras duras que están cerca del límite de decisión (los vectores de soporte)."

#: ../auto_examples/calibration/plot_calibration_curve.rst:58
msgid "Both kinds of calibration can fix this issue and yield nearly identical results. This shows that sigmoid calibration can deal with situations where the calibration curve of the base classifier is sigmoid (e.g., for LinearSVC) but not where it is transposed-sigmoid (e.g., Gaussian naive Bayes)."
msgstr "Ambos tipos de calibración pueden solucionar este problema y producir resultados casi idénticos. Esto demuestra que la calibración sigmoidea puede resolver situaciones en las que la curva de calibración del clasificador base es sigmoidea (por ejemplo, para LinearSVC) pero no cuando es transpuesta-sigmoidea (por ejemplo, gaussiano naive Bayes)."

#: ../auto_examples/calibration/plot_calibration_curve.rst:85
msgid "Out:"
msgstr "Out:"

#: ../auto_examples/calibration/plot_calibration_curve.rst:243
msgid "**Total running time of the script:** ( 0 minutes  2.912 seconds)"
msgstr "**Tiempo total de ejecución del script:** (0 minutos 2.912 segundos)"

#: ../auto_examples/calibration/plot_calibration_curve.rst:265
msgid ":download:`Download Python source code: plot_calibration_curve.py <plot_calibration_curve.py>`"
msgstr ":download:`Download Python source code: plot_calibration_curve.py <plot_calibration_curve.py>`"

#: ../auto_examples/calibration/plot_calibration_curve.rst:271
msgid ":download:`Download Jupyter notebook: plot_calibration_curve.ipynb <plot_calibration_curve.ipynb>`"
msgstr ":download:`Descargar el cuaderno Jupyter: plot_calibration_curve.ipynb <plot_calibration_curve.ipynb>`"

#: ../auto_examples/calibration/plot_calibration_curve.rst:278
msgid "`Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_"
msgstr "`Galería generada por Sphinx-Gallery <https://sphinx-gallery.github.io>`_"

