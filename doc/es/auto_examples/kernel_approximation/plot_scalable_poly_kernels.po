msgid ""
msgstr ""
"Project-Id-Version: scikit-learn\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-03-31 11:24-0400\n"
"PO-Revision-Date: 2021-08-10 18:33\n"
"Last-Translator: \n"
"Language-Team: Spanish\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Crowdin-Project: scikit-learn\n"
"X-Crowdin-Project-ID: 450526\n"
"X-Crowdin-Language: es-ES\n"
"X-Crowdin-File: /main/doc/en/auto_examples/kernel_approximation/plot_scalable_poly_kernels.po\n"
"X-Crowdin-File-ID: 4450\n"
"Language: es_ES\n"

#: ../auto_examples/kernel_approximation/plot_scalable_poly_kernels.rst:13
msgid "Click :ref:`here <sphx_glr_download_auto_examples_kernel_approximation_plot_scalable_poly_kernels.py>` to download the full example code or to run this example in your browser via Binder"
msgstr "Haz clic :ref:`aquí <sphx_glr_download_auto_examples_kernel_approximation_plot_scalable_poly_kernels.py>` para descargar el código de ejemplo completo o para ejecutar este ejemplo en tu navegador a través de Binder"

#: ../auto_examples/kernel_approximation/plot_scalable_poly_kernels.rst:23
msgid "Scalable learning with polynomial kernel aproximation"
msgstr "Aprendizaje escalable con aproximación del núcleo polinomial"

#: ../auto_examples/kernel_approximation/plot_scalable_poly_kernels.rst:25
msgid "This example illustrates the use of :class:`PolynomialCountSketch` to efficiently generate polynomial kernel feature-space approximations. This is used to train linear classifiers that approximate the accuracy of kernelized ones."
msgstr "Este ejemplo ilustra el uso de :class:`PolynomialCountSketch` para generar eficientemente aproximaciones de espacio en el núcleo polinomial. Esto se utiliza para entrenar clasificadores lineales que aproximan la precisión de los kernelizados."

#: ../auto_examples/kernel_approximation/plot_scalable_poly_kernels.rst:32
msgid "We use the Covtype dataset [2], trying to reproduce the experiments on the original paper of Tensor Sketch [1], i.e. the algorithm implemented by :class:`PolynomialCountSketch`."
msgstr "Utilizamos el conjunto de datos Covtype [2], tratando de reproducir los experimentos del documento original de Tensor Sketch [1], es decir, el algoritmo implementado por :class:`PolynomialCountSketch`."

#: ../auto_examples/kernel_approximation/plot_scalable_poly_kernels.rst:36
msgid "First, we compute the accuracy of a linear classifier on the original features. Then, we train linear classifiers on different numbers of features (`n_components`) generated by :class:`PolynomialCountSketch`, approximating the accuracy of a kernelized classifier in a scalable manner."
msgstr "Primero, calculamos la precisión de un clasificador lineal en las características originales. Luego, entrenamos clasificadores lineales en diferentes números de características (`n_components`) generados por :class:`PolynomialCountSketch`, aproximar la precisión de un clasificador kernelizado de una manera escalable."

#: ../auto_examples/kernel_approximation/plot_scalable_poly_kernels.rst:67
msgid "Load the Covtype dataset, which contains 581,012 samples with 54 features each, distributed among 6 classes. The goal of this dataset is to predict forest cover type from cartographic variables only (no remotely sensed data). After loading, we transform it into a binary classification problem to match the version of the dataset in the LIBSVM webpage [2], which was the one used in [1]."
msgstr "Carga el conjunto de datos Covtype, que contiene 581.012 muestras con 54 características cada una, distribuidas entre 6 clases. El objetivo de este conjunto de datos es predecir el tipo de cubierta forestal únicamente a partir de variables cartográficas (sin datos de teledetección). Después de cargarlo, lo transformamos en un problema de clasificación binaria para que coincida con la versión del conjunto de datos en la página web de LIBSVM [2], que fue la que se utilizó en [1]."

#: ../auto_examples/kernel_approximation/plot_scalable_poly_kernels.rst:93
msgid "Here we select 5,000 samples for training and 10,000 for testing. To actually reproduce the results in the original Tensor Sketch paper, select 100,000 for training."
msgstr "Aquí seleccionamos 5.000 muestras para entrenamiento y 10.000 para pruebas. Para reproducir realmente los resultados en el papel original del dibujo del sensor, selecciona 100.000 para entrenamiento."

#: ../auto_examples/kernel_approximation/plot_scalable_poly_kernels.rst:115
msgid "Now scale features to the range [0, 1] to match the format of the dataset in the LIBSVM webpage, and then normalize to unit length as done in the original Tensor Sketch paper [1]."
msgstr "Ahora escalamos las características al rango [0, 1] para que coincidan con el formato del conjunto de datos en la página web de LIBSVM, y luego las normalizamos a longitudes unitarias como se hizo en el documento original de Tensor Sketch [1]."

#: ../auto_examples/kernel_approximation/plot_scalable_poly_kernels.rst:138
msgid "As a baseline, train a linear SVM on the original features and print the accuracy. We also measure and store accuracies and training times to plot them latter."
msgstr "Como línea de base, entrenar una SVM lineal sobre las características originales e imprimir la exactitud. También medimos y almacenamos exactitudes y tiempos de entrenamiento para tramitar estos últimos."

#: ../auto_examples/kernel_approximation/plot_scalable_poly_kernels.rst:164
#: ../auto_examples/kernel_approximation/plot_scalable_poly_kernels.rst:229
#: ../auto_examples/kernel_approximation/plot_scalable_poly_kernels.rst:271
msgid "Out:"
msgstr "Out:"

#: ../auto_examples/kernel_approximation/plot_scalable_poly_kernels.rst:175
msgid "Then we train linear SVMs on the features generated by :class:`PolynomialCountSketch` with different values for `n_components`, showing that these kernel feature approximations improve the accuracy of linear classification. In typical application scenarios, `n_components` should be larger than the number of features in the input representation in order to achieve an improvement with respect to linear classification. As a rule of thumb, the optimum of evaluation score / run time cost is typically achieved at around `n_components` = 10 * `n_features`, though this might depend on the specific dataset being handled. Note that, since the original samples have 54 features, the explicit feature map of the polynomial kernel of degree four would have approximately 8.5 million features (precisely, 54^4). Thanks to :class:`PolynomialCountSketch`, we can condense most of the discriminative information of that feature space into a much more compact representation. We repeat the experiment 5 times to compensate for the stochastic nature of :class:`PolynomialCountSketch`."
msgstr "A continuación, entrenamos SVMs lineales en las características generadas por :class:`PolynomialCountSketch` con diferentes valores para `n_components`, mostrando que estas aproximaciones de características del núcleo mejoran la precisión de la clasificación lineal. En los escenarios típicos de aplicación, `n_components` debe ser mayor que el número de características en la representación de entrada para lograr una mejora con respecto a la clasificación lineal. Como regla general, la puntuación óptima de la evaluación/coste del tiempo de ejecución suele alcanzarse en torno a `n_components` = 10 * `n_features`, aunque esto puede depender del conjunto de datos específico que se maneje. Ten en cuenta que, dado que las muestras originales tienen 54 características, el mapa de características explícito del núcleo polinómico de grado cuatro tendría aproximadamente 8,5 millones de características (exactamente, 54^4). Gracias a :class:`PolynomialCountSketch`, podemos condensar la mayor parte de la información discriminativa de ese espacio de características en una representación mucho más compacta. Repetimos el experimento 5 veces para compensar la naturaleza estocástica de :class:`PolynomialCountSketch`."

#: ../auto_examples/kernel_approximation/plot_scalable_poly_kernels.rst:243
msgid "Train a kernelized SVM to see how well :class:`PolynomialCountSketch` is approximating the performance of the kernel. This, of course, may take some time, as the SVC class has a relatively poor scalability. This is the reason why kernel approximators are so useful:"
msgstr "Entrena un SVM kernelizado para ver qué tan bien :class:`PolynomialCountSketch` se aproxima al rendimiento del núcleo. Esto, por supuesto, puede llevar algún tiempo, ya que la clase SVM tiene una escalabilidad relativamente pobre. Esta es la razón por la que los aproximadores del núcleo son tan útiles:"

#: ../auto_examples/kernel_approximation/plot_scalable_poly_kernels.rst:282
msgid "Finally, plot the resuts of the different methods against their training times. As we can see, the kernelized SVM achieves a higher accuracy, but its training time is much larger and, most importantly, will grow much faster if the number of training samples increases."
msgstr "Por último, traza los resultados de los diferentes métodos frente a sus tiempos de entrenamiento. Como podemos ver, la SVM kernelizada consigue una mayor precisión, pero su tiempo de entrenamiento es mucho mayor y, lo que es más importante, crecerá mucho más rápido si el número de muestras de entrenamiento aumenta."

#: ../auto_examples/kernel_approximation/plot_scalable_poly_kernels.rst:332
msgid "References"
msgstr "Referencias"

#: ../auto_examples/kernel_approximation/plot_scalable_poly_kernels.rst:334
msgid "[1] Pham, Ninh and Rasmus Pagh. \"Fast and scalable polynomial kernels via explicit feature maps.\" KDD '13 (2013). https://doi.org/10.1145/2487575.2487591"
msgstr "[1] Pham, Ninh and Rasmus Pagh. \"Fast and scalable polynomial kernels via explicit feature maps.\" KDD '13 (2013). https://doi.org/10.1145/2487575.2487591"

#: ../auto_examples/kernel_approximation/plot_scalable_poly_kernels.rst:338
msgid "[2] LIBSVM binary datasets repository https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html"
msgstr "[2] LIBSVM binary datasets repository https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/binary.html"

#: ../auto_examples/kernel_approximation/plot_scalable_poly_kernels.rst:344
msgid "**Total running time of the script:** ( 3 minutes  24.821 seconds)"
msgstr "**Tiempo total de ejecución del script:** (3 minutos 24.821 segundos)"

#: ../auto_examples/kernel_approximation/plot_scalable_poly_kernels.rst:366
msgid ":download:`Download Python source code: plot_scalable_poly_kernels.py <plot_scalable_poly_kernels.py>`"
msgstr ":download:`Descargar el código fuente de Python: plot_scalable_poly_kernels.py <plot_scalable_poly_kernels.py>`"

#: ../auto_examples/kernel_approximation/plot_scalable_poly_kernels.rst:372
msgid ":download:`Download Jupyter notebook: plot_scalable_poly_kernels.ipynb <plot_scalable_poly_kernels.ipynb>`"
msgstr ":download:`Descargar cuaderno de Jupyter: plot_scalable_poly_kernels.ipynb <plot_scalable_poly_kernels.ipynb>`"

#: ../auto_examples/kernel_approximation/plot_scalable_poly_kernels.rst:379
msgid "`Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_"
msgstr "`Galería generada por Sphinx-Gallery <https://sphinx-gallery.github.io>`_"

