msgid ""
msgstr ""
"Project-Id-Version: scikit-learn\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-03-31 11:24-0400\n"
"PO-Revision-Date: 2021-04-15 00:12\n"
"Last-Translator: \n"
"Language-Team: Spanish\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Crowdin-Project: scikit-learn\n"
"X-Crowdin-Project-ID: 450526\n"
"X-Crowdin-Language: es-ES\n"
"X-Crowdin-File: /main/doc/en/auto_examples/model_selection/plot_multi_metric_evaluation.po\n"
"X-Crowdin-File-ID: 2612\n"
"Language: es_ES\n"

#: ../auto_examples/model_selection/plot_multi_metric_evaluation.rst:13
msgid "Click :ref:`here <sphx_glr_download_auto_examples_model_selection_plot_multi_metric_evaluation.py>` to download the full example code or to run this example in your browser via Binder"
msgstr ""

#: ../auto_examples/model_selection/plot_multi_metric_evaluation.rst:23
msgid "Demonstration of multi-metric evaluation on cross_val_score and GridSearchCV"
msgstr ""

#: ../auto_examples/model_selection/plot_multi_metric_evaluation.rst:25
msgid "Multiple metric parameter search can be done by setting the ``scoring`` parameter to a list of metric scorer names or a dict mapping the scorer names to the scorer callables."
msgstr ""

#: ../auto_examples/model_selection/plot_multi_metric_evaluation.rst:29
msgid "The scores of all the scorers are available in the ``cv_results_`` dict at keys ending in ``'_<scorer_name>'`` (``'mean_test_precision'``, ``'rank_test_precision'``, etc...)"
msgstr ""

#: ../auto_examples/model_selection/plot_multi_metric_evaluation.rst:33
msgid "The ``best_estimator_``, ``best_index_``, ``best_score_`` and ``best_params_`` correspond to the scorer (key) that is set to the ``refit`` attribute."
msgstr ""

#: ../auto_examples/model_selection/plot_multi_metric_evaluation.rst:65
msgid "Running ``GridSearchCV`` using multiple evaluation metrics"
msgstr ""

#: ../auto_examples/model_selection/plot_multi_metric_evaluation.rst:100
msgid "Plotting the result"
msgstr ""

#: ../auto_examples/model_selection/plot_multi_metric_evaluation.rst:160
msgid "**Total running time of the script:** ( 0 minutes  29.546 seconds)"
msgstr ""

#: ../auto_examples/model_selection/plot_multi_metric_evaluation.rst:182
msgid ":download:`Download Python source code: plot_multi_metric_evaluation.py <plot_multi_metric_evaluation.py>`"
msgstr ""

#: ../auto_examples/model_selection/plot_multi_metric_evaluation.rst:188
msgid ":download:`Download Jupyter notebook: plot_multi_metric_evaluation.ipynb <plot_multi_metric_evaluation.ipynb>`"
msgstr ""

#: ../auto_examples/model_selection/plot_multi_metric_evaluation.rst:195
msgid "`Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_"
msgstr ""

