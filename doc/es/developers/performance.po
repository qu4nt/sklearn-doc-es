msgid ""
msgstr ""
"Project-Id-Version: scikit-learn\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-03-31 11:24-0400\n"
"PO-Revision-Date: 2021-07-15 05:47\n"
"Last-Translator: \n"
"Language-Team: Spanish\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"
"X-Crowdin-Project: scikit-learn\n"
"X-Crowdin-Project-ID: 450526\n"
"X-Crowdin-Language: es-ES\n"
"X-Crowdin-File: /main/doc/en/developers/performance.po\n"
"X-Crowdin-File-ID: 4022\n"
"Language: es_ES\n"

#: ../developers/performance.rst:5
msgid "How to optimize for speed"
msgstr ""

#: ../developers/performance.rst:7
msgid "The following gives some practical guidelines to help you write efficient code for the scikit-learn project."
msgstr "A continuación se ofrecen algunas directrices prácticas para ayudarte a escribir un código eficiente para el proyecto scikit-learn."

#: ../developers/performance.rst:12
msgid "While it is always useful to profile your code so as to **check performance assumptions**, it is also highly recommended to **review the literature** to ensure that the implemented algorithm is the state of the art for the task before investing into costly implementation optimization."
msgstr ""

#: ../developers/performance.rst:18
msgid "Times and times, hours of efforts invested in optimizing complicated implementation details have been rendered irrelevant by the subsequent discovery of simple **algorithmic tricks**, or by using another algorithm altogether that is better suited to the problem."
msgstr ""

#: ../developers/performance.rst:23
msgid "The section :ref:`warm-restarts` gives an example of such a trick."
msgstr ""

#: ../developers/performance.rst:27
msgid "Python, Cython or C/C++?"
msgstr "¿Python, Cython o C/C++?"

#: ../developers/performance.rst:31
msgid "In general, the scikit-learn project emphasizes the **readability** of the source code to make it easy for the project users to dive into the source code so as to understand how the algorithm behaves on their data but also for ease of maintainability (by the developers)."
msgstr ""

#: ../developers/performance.rst:36
msgid "When implementing a new algorithm is thus recommended to **start implementing it in Python using Numpy and Scipy** by taking care of avoiding looping code using the vectorized idioms of those libraries. In practice this means trying to **replace any nested for loops by calls to equivalent Numpy array methods**. The goal is to avoid the CPU wasting time in the Python interpreter rather than crunching numbers to fit your statistical model. It's generally a good idea to consider NumPy and SciPy performance tips: https://scipy.github.io/old-wiki/pages/PerformanceTips"
msgstr ""

#: ../developers/performance.rst:45
msgid "Sometimes however an algorithm cannot be expressed efficiently in simple vectorized Numpy code. In this case, the recommended strategy is the following:"
msgstr ""

#: ../developers/performance.rst:49
msgid "**Profile** the Python implementation to find the main bottleneck and isolate it in a **dedicated module level function**. This function will be reimplemented as a compiled extension module."
msgstr ""

#: ../developers/performance.rst:53
msgid "If there exists a well maintained BSD or MIT **C/C++** implementation of the same algorithm that is not too big, you can write a **Cython wrapper** for it and include a copy of the source code of the library in the scikit-learn source tree: this strategy is used for the classes :class:`svm.LinearSVC`, :class:`svm.SVC` and :class:`linear_model.LogisticRegression` (wrappers for liblinear and libsvm)."
msgstr ""

#: ../developers/performance.rst:61
msgid "Otherwise, write an optimized version of your Python function using **Cython** directly. This strategy is used for the :class:`linear_model.ElasticNet` and :class:`linear_model.SGDClassifier` classes for instance."
msgstr ""

#: ../developers/performance.rst:66
msgid "**Move the Python version of the function in the tests** and use it to check that the results of the compiled extension are consistent with the gold standard, easy to debug Python version."
msgstr ""

#: ../developers/performance.rst:70
msgid "Once the code is optimized (not simple bottleneck spottable by profiling), check whether it is possible to have **coarse grained parallelism** that is amenable to **multi-processing** by using the ``joblib.Parallel`` class."
msgstr ""

#: ../developers/performance.rst:75
msgid "When using Cython, use either"
msgstr ""

#: ../developers/performance.rst:82
msgid "to generate C files. You are responsible for adding .c/.cpp extensions along with build parameters in each submodule ``setup.py``."
msgstr ""

#: ../developers/performance.rst:85
msgid "C/C++ generated files are embedded in distributed stable packages. The goal is to make it possible to install scikit-learn stable version on any machine with Python, Numpy, Scipy and C/C++ compiler."
msgstr ""

#: ../developers/performance.rst:92
msgid "Profiling Python code"
msgstr ""

#: ../developers/performance.rst:94
msgid "In order to profile Python code we recommend to write a script that loads and prepare you data and then use the IPython integrated profiler for interactively exploring the relevant part for the code."
msgstr ""

#: ../developers/performance.rst:98
msgid "Suppose we want to profile the Non Negative Matrix Factorization module of scikit-learn. Let us setup a new IPython session and load the digits dataset and as in the :ref:`sphx_glr_auto_examples_classification_plot_digits_classification.py` example::"
msgstr ""

#: ../developers/performance.rst:108
msgid "Before starting the profiling session and engaging in tentative optimization iterations, it is important to measure the total execution time of the function we want to optimize without any kind of profiler overhead and save it somewhere for later reference::"
msgstr ""

#: ../developers/performance.rst:116
msgid "To have a look at the overall performance profile using the ``%prun`` magic command::"
msgstr ""

#: ../developers/performance.rst:136
msgid "The ``tottime`` column is the most interesting: it gives to total time spent executing the code of a given function ignoring the time spent in executing the sub-functions. The real total time (local code + sub-function calls) is given by the ``cumtime`` column."
msgstr ""

#: ../developers/performance.rst:141
msgid "Note the use of the ``-l nmf.py`` that restricts the output to lines that contains the \"nmf.py\" string. This is useful to have a quick look at the hotspot of the nmf Python module it-self ignoring anything else."
msgstr ""

#: ../developers/performance.rst:145
msgid "Here is the beginning of the output of the same command without the ``-l nmf.py`` filter::"
msgstr ""

#: ../developers/performance.rst:166
msgid "The above results show that the execution is largely dominated by dot products operations (delegated to blas). Hence there is probably no huge gain to expect by rewriting this code in Cython or C/C++: in this case out of the 1.7s total execution time, almost 0.7s are spent in compiled code we can consider optimal. By rewriting the rest of the Python code and assuming we could achieve a 1000% boost on this portion (which is highly unlikely given the shallowness of the Python loops), we would not gain more than a 2.4x speed-up globally."
msgstr ""

#: ../developers/performance.rst:175
msgid "Hence major improvements can only be achieved by **algorithmic improvements** in this particular example (e.g. trying to find operation that are both costly and useless to avoid computing then rather than trying to optimize their implementation)."
msgstr ""

#: ../developers/performance.rst:180
#, python-format
msgid "It is however still interesting to check what's happening inside the ``_nls_subproblem`` function which is the hotspot if we only consider Python code: it takes around 100% of the accumulated time of the module. In order to better understand the profile of this specific function, let us install ``line_profiler`` and wire it to IPython:"
msgstr ""

#: ../developers/performance.rst:190
msgid "**Under IPython 0.13+**, first create a configuration profile:"
msgstr ""

#: ../developers/performance.rst:196
msgid "Then register the line_profiler extension in ``~/.ipython/profile_default/ipython_config.py``::"
msgstr ""

#: ../developers/performance.rst:202
msgid "This will register the ``%lprun`` magic command in the IPython terminal application and the other frontends such as qtconsole and notebook."
msgstr ""

#: ../developers/performance.rst:204
msgid "Now restart IPython and let us use this new toy::"
msgstr ""

#: ../developers/performance.rst:251
msgid "By looking at the top values of the ``% Time`` column it is really easy to pin-point the most expensive expressions that would deserve additional care."
msgstr ""

#: ../developers/performance.rst:256
msgid "Memory usage profiling"
msgstr ""

#: ../developers/performance.rst:258
msgid "You can analyze in detail the memory usage of any Python code with the help of `memory_profiler <https://pypi.org/project/memory_profiler/>`_. First, install the latest version:"
msgstr ""

#: ../developers/performance.rst:266
msgid "Then, setup the magics in a manner similar to ``line_profiler``."
msgstr ""

#: ../developers/performance.rst:268
msgid "**Under IPython 0.11+**, first create a configuration profile:"
msgstr ""

#: ../developers/performance.rst:275
msgid "Then register the extension in ``~/.ipython/profile_default/ipython_config.py`` alongside the line profiler::"
msgstr ""

#: ../developers/performance.rst:282
msgid "This will register the ``%memit`` and ``%mprun`` magic commands in the IPython terminal application and the other frontends such as qtconsole and   notebook."
msgstr ""

#: ../developers/performance.rst:285
msgid "``%mprun`` is useful to examine, line-by-line, the memory usage of key functions in your program. It is very similar to ``%lprun``, discussed in the previous section. For example, from the ``memory_profiler`` ``examples`` directory::"
msgstr ""

#: ../developers/performance.rst:304
msgid "Another useful magic that ``memory_profiler`` defines is ``%memit``, which is analogous to ``%timeit``. It can be used as follows::"
msgstr ""

#: ../developers/performance.rst:312
msgid "For more details, see the docstrings of the magics, using ``%memit?`` and ``%mprun?``."
msgstr ""

#: ../developers/performance.rst:317
msgid "Performance tips for the Cython developer"
msgstr ""

#: ../developers/performance.rst:319
msgid "If profiling of the Python code reveals that the Python interpreter overhead is larger by one order of magnitude or more than the cost of the actual numerical computation (e.g. ``for`` loops over vector components, nested evaluation of conditional expression, scalar arithmetic...), it is probably adequate to extract the hotspot portion of the code as a standalone function in a ``.pyx`` file, add static type declarations and then use Cython to generate a C program suitable to be compiled as a Python extension module."
msgstr ""

#: ../developers/performance.rst:328
msgid "The official documentation available at http://docs.cython.org/ contains a tutorial and reference guide for developing such a module. In the following we will just highlight a couple of tricks that we found important in practice on the existing cython codebase in the scikit-learn project."
msgstr ""

#: ../developers/performance.rst:334
msgid "TODO: html report, type declarations, bound checks, division by zero checks, memory alignment, direct blas calls..."
msgstr ""

#: ../developers/performance.rst:337
msgid "https://www.youtube.com/watch?v=gMvkiQ-gOW8"
msgstr "https://www.youtube.com/watch?v=gMvkiQ-gOW8"

#: ../developers/performance.rst:338
msgid "http://conference.scipy.org/proceedings/SciPy2009/paper_1/"
msgstr "http://conference.scipy.org/proceedings/SciPy2009/paper_1/"

#: ../developers/performance.rst:339
msgid "http://conference.scipy.org/proceedings/SciPy2009/paper_2/"
msgstr "http://conference.scipy.org/proceedings/SciPy2009/paper_2/"

#: ../developers/performance.rst:342
msgid "Using OpenMP"
msgstr ""

#: ../developers/performance.rst:344
msgid "Since scikit-learn can be built without OpenMP, it's necessary to protect each direct call to OpenMP. This can be done using the following syntax::"
msgstr ""

#: ../developers/performance.rst:360
msgid "Protecting the parallel loop, ``prange``, is already done by cython."
msgstr ""

#: ../developers/performance.rst:366
msgid "Profiling compiled extensions"
msgstr ""

#: ../developers/performance.rst:368
msgid "When working with compiled extensions (written in C/C++ with a wrapper or directly as Cython extension), the default Python profiler is useless: we need a dedicated tool to introspect what's happening inside the compiled extension it-self."
msgstr ""

#: ../developers/performance.rst:374
msgid "Using yep and gperftools"
msgstr ""

#: ../developers/performance.rst:376
msgid "Easy profiling without special compilation options use yep:"
msgstr ""

#: ../developers/performance.rst:378
msgid "https://pypi.org/project/yep/"
msgstr "https://pypi.org/project/yep/"

#: ../developers/performance.rst:379
msgid "http://fa.bianp.net/blog/2011/a-profiler-for-python-extensions"
msgstr "http://fa.bianp.net/blog/2011/a-profiler-for-python-extensions"

#: ../developers/performance.rst:382
msgid "Using gprof"
msgstr ""

#: ../developers/performance.rst:384
msgid "In order to profile compiled Python extensions one could use ``gprof`` after having recompiled the project with ``gcc -pg`` and using the ``python-dbg`` variant of the interpreter on debian / ubuntu: however this approach requires to also have ``numpy`` and ``scipy`` recompiled with ``-pg`` which is rather complicated to get working."
msgstr ""

#: ../developers/performance.rst:390
msgid "Fortunately there exist two alternative profilers that don't require you to recompile everything."
msgstr ""

#: ../developers/performance.rst:394
msgid "Using valgrind / callgrind / kcachegrind"
msgstr ""

#: ../developers/performance.rst:397
msgid "kcachegrind"
msgstr ""

#: ../developers/performance.rst:399
msgid "``yep`` can be used to create a profiling report. ``kcachegrind`` provides a graphical environment to visualize this report:"
msgstr ""

#: ../developers/performance.rst:414
msgid "``yep`` can be executed with the argument ``--lines`` or ``-l`` to compile a profiling report 'line by line'."
msgstr ""

#: ../developers/performance.rst:418
msgid "Multi-core parallelism using ``joblib.Parallel``"
msgstr ""

#: ../developers/performance.rst:420
msgid "See `joblib documentation <https://joblib.readthedocs.io>`_"
msgstr "Ver `documentación joblib <https://joblib.readthedocs.io>`_"

#: ../developers/performance.rst:426
msgid "A simple algorithmic trick: warm restarts"
msgstr ""

#: ../developers/performance.rst:428
msgid "See the glossary entry for `warm_start <http://scikit-learn.org/dev/glossary.html#term-warm-start>`_"
msgstr ""

