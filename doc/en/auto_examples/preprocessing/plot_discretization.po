# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2007 - 2020, scikit-learn developers (BSD License)
# This file is distributed under the same license as the scikit-learn
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2021.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: scikit-learn 0.24\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-03-31 11:24-0400\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"

#: ../auto_examples/preprocessing/plot_discretization.rst:13
msgid ""
"Click :ref:`here "
"<sphx_glr_download_auto_examples_preprocessing_plot_discretization.py>` "
"to download the full example code or to run this example in your browser "
"via Binder"
msgstr ""

#: ../auto_examples/preprocessing/plot_discretization.rst:23
msgid "Using KBinsDiscretizer to discretize continuous features"
msgstr ""

#: ../auto_examples/preprocessing/plot_discretization.rst:25
msgid ""
"The example compares prediction result of linear regression (linear "
"model) and decision tree (tree based model) with and without "
"discretization of real-valued features."
msgstr ""

#: ../auto_examples/preprocessing/plot_discretization.rst:29
msgid ""
"As is shown in the result before discretization, linear model is fast to "
"build and relatively straightforward to interpret, but can only model "
"linear relationships, while decision tree can build a much more complex "
"model of the data. One way to make linear model more powerful on "
"continuous data is to use discretization (also known as binning). In the "
"example, we discretize the feature and one-hot encode the transformed "
"data. Note that if the bins are not reasonably wide, there would appear "
"to be a substantially increased risk of overfitting, so the discretizer "
"parameters should usually be tuned under cross validation."
msgstr ""

#: ../auto_examples/preprocessing/plot_discretization.rst:39
msgid ""
"After discretization, linear regression and decision tree make exactly "
"the same prediction. As features are constant within each bin, any model "
"must predict the same value for all points within a bin. Compared with "
"the result before discretization, linear model become much more flexible "
"while decision tree gets much less flexible. Note that binning features "
"generally has no beneficial effect for tree-based models, as these models"
" can learn to split up the data anywhere."
msgstr ""

#: ../auto_examples/preprocessing/plot_discretization.rst:121
msgid "**Total running time of the script:** ( 0 minutes  0.210 seconds)"
msgstr ""

#: ../auto_examples/preprocessing/plot_discretization.rst:143
msgid ""
":download:`Download Python source code: plot_discretization.py "
"<plot_discretization.py>`"
msgstr ""

#: ../auto_examples/preprocessing/plot_discretization.rst:149
msgid ""
":download:`Download Jupyter notebook: plot_discretization.ipynb "
"<plot_discretization.ipynb>`"
msgstr ""

#: ../auto_examples/preprocessing/plot_discretization.rst:156
msgid "`Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_"
msgstr ""

