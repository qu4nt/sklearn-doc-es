# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2007 - 2020, scikit-learn developers (BSD License)
# This file is distributed under the same license as the scikit-learn
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2021.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: scikit-learn 0.24\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-03-31 11:24-0400\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"

#: ../modules/generated/sklearn.preprocessing.scale.rst:2
msgid ":mod:`sklearn.preprocessing`.scale"
msgstr ""

#: of sklearn.preprocessing._data.scale:2
msgid "Standardize a dataset along any axis."
msgstr ""

#: of sklearn.preprocessing._data.scale:4
msgid "Center to the mean and component wise scale to unit variance."
msgstr ""

#: of sklearn.preprocessing._data.scale:6
msgid "Read more in the :ref:`User Guide <preprocessing_scaler>`."
msgstr ""

#: of sklearn.preprocessing._data.scale
msgid "Parameters"
msgstr ""

#: of sklearn.preprocessing._data.scale:11
msgid "**X**"
msgstr ""

#: of
msgid "{array-like, sparse matrix} of shape (n_samples, n_features)"
msgstr ""

#: of sklearn.preprocessing._data.scale:11
msgid "The data to center and scale."
msgstr ""

#: of sklearn.preprocessing._data.scale:16
msgid "**axis**"
msgstr ""

#: of
msgid "int, default=0"
msgstr ""

#: of sklearn.preprocessing._data.scale:14
msgid ""
"axis used to compute the means and standard deviations along. If 0, "
"independently standardize each feature, otherwise (if 1) standardize each"
" sample."
msgstr ""

#: of sklearn.preprocessing._data.scale:19
msgid "**with_mean**"
msgstr ""

#: of
msgid "bool, default=True"
msgstr ""

#: of sklearn.preprocessing._data.scale:19
msgid "If True, center the data before scaling."
msgstr ""

#: of sklearn.preprocessing._data.scale:23
msgid "**with_std**"
msgstr ""

#: of sklearn.preprocessing._data.scale:22
msgid ""
"If True, scale the data to unit variance (or equivalently, unit standard "
"deviation)."
msgstr ""

#: of sklearn.preprocessing._data.scale:28
msgid "**copy**"
msgstr ""

#: of sklearn.preprocessing._data.scale:26
msgid ""
"set to False to perform inplace row normalization and avoid a copy (if "
"the input is already a numpy array or a scipy.sparse CSC matrix and if "
"axis is 1)."
msgstr ""

#: of sklearn.preprocessing._data.scale
msgid "Returns"
msgstr ""

#: of sklearn.preprocessing._data.scale:39
msgid "**X_tr**"
msgstr ""

#: of
msgid "{ndarray, sparse matrix} of shape (n_samples, n_features)"
msgstr ""

#: of sklearn.preprocessing._data.scale:33
msgid "The transformed data."
msgstr ""

#: of sklearn.preprocessing._data.scale:44
msgid ":obj:`StandardScaler`"
msgstr ""

#: of sklearn.preprocessing._data.scale:45
msgid ""
"Performs scaling to unit variance using the Transformer API (e.g. as part"
" of a preprocessing :class:`~sklearn.pipeline.Pipeline`)."
msgstr ""

#: of sklearn.preprocessing._data.scale:49
msgid "Notes"
msgstr ""

#: of sklearn.preprocessing._data.scale:50
msgid ""
"This implementation will refuse to center scipy.sparse matrices since it "
"would make them non-sparse and would potentially crash the program with "
"memory exhaustion problems."
msgstr ""

#: of sklearn.preprocessing._data.scale:54
msgid ""
"Instead the caller is expected to either set explicitly `with_mean=False`"
" (in that case, only variance scaling will be performed on the features "
"of the CSC matrix) or to call `X.toarray()` if he/she expects the "
"materialized dense array to fit in memory."
msgstr ""

#: of sklearn.preprocessing._data.scale:59
msgid "To avoid memory copy the caller should pass a CSC matrix."
msgstr ""

#: of sklearn.preprocessing._data.scale:61
msgid ""
"NaNs are treated as missing values: disregarded to compute the "
"statistics, and maintained during the data transformation."
msgstr ""

#: of sklearn.preprocessing._data.scale:64
msgid ""
"We use a biased estimator for the standard deviation, equivalent to "
"`numpy.std(x, ddof=0)`. Note that the choice of `ddof` is unlikely to "
"affect model performance."
msgstr ""

#: of sklearn.preprocessing._data.scale:68
msgid ""
"For a comparison of the different scalers, transformers, and normalizers,"
" see :ref:`examples/preprocessing/plot_all_scaling.py "
"<sphx_glr_auto_examples_preprocessing_plot_all_scaling.py>`."
msgstr ""

#: of sklearn.preprocessing._data.scale:72
msgid "Risk of data leak"
msgstr ""

#: of sklearn.preprocessing._data.scale:74
msgid ""
"Do not use :func:`~sklearn.preprocessing.scale` unless you know what you "
"are doing. A common mistake is to apply it to the entire data *before* "
"splitting into training and test sets. This will bias the model "
"evaluation because information would have leaked from the test set to the"
" training set. In general, we recommend using "
":class:`~sklearn.preprocessing.StandardScaler` within a :ref:`Pipeline "
"<pipeline>` in order to prevent most risks of data leaking: `pipe = "
"make_pipeline(StandardScaler(), LogisticRegression())`."
msgstr ""

