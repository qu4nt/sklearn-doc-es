# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2007 - 2020, scikit-learn developers (BSD License)
# This file is distributed under the same license as the scikit-learn
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2021.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: scikit-learn 0.24\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-03-31 11:24-0400\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"

#: ../modules/generated/sklearn.neighbors.LocalOutlierFactor.rst:2
msgid ":mod:`sklearn.neighbors`.LocalOutlierFactor"
msgstr ""

#: of sklearn.neighbors._lof.LocalOutlierFactor:2
msgid "Unsupervised Outlier Detection using Local Outlier Factor (LOF)"
msgstr ""

#: of sklearn.neighbors._lof.LocalOutlierFactor:4
msgid ""
"The anomaly score of each sample is called Local Outlier Factor. It "
"measures the local deviation of density of a given sample with respect to"
" its neighbors. It is local in that the anomaly score depends on how "
"isolated the object is with respect to the surrounding neighborhood. More"
" precisely, locality is given by k-nearest neighbors, whose distance is "
"used to estimate the local density. By comparing the local density of a "
"sample to the local densities of its neighbors, one can identify samples "
"that have a substantially lower density than their neighbors. These are "
"considered outliers."
msgstr ""

#: of sklearn.base.BaseEstimator.get_params
#: sklearn.base.BaseEstimator.set_params
#: sklearn.neighbors.LocalOutlierFactor.decision_function
#: sklearn.neighbors.LocalOutlierFactor.fit_predict
#: sklearn.neighbors.LocalOutlierFactor.predict
#: sklearn.neighbors.LocalOutlierFactor.score_samples
#: sklearn.neighbors._base.KNeighborsMixin.kneighbors
#: sklearn.neighbors._base.KNeighborsMixin.kneighbors_graph
#: sklearn.neighbors._lof.LocalOutlierFactor
#: sklearn.neighbors._lof.LocalOutlierFactor.fit
msgid "Parameters"
msgstr ""

#: of sklearn.neighbors._base.KNeighborsMixin.kneighbors:15
#: sklearn.neighbors._base.KNeighborsMixin.kneighbors_graph:17
#: sklearn.neighbors._lof.LocalOutlierFactor:22
msgid "**n_neighbors**"
msgstr ""

#: of
msgid "int, default=20"
msgstr ""

#: of sklearn.neighbors._lof.LocalOutlierFactor:20
msgid ""
"Number of neighbors to use by default for :meth:`kneighbors` queries. If "
"n_neighbors is larger than the number of samples provided, all samples "
"will be used."
msgstr ""

#: of sklearn.neighbors._lof.LocalOutlierFactor:34
msgid "**algorithm**"
msgstr ""

#: of
msgid "{'auto', 'ball_tree', 'kd_tree', 'brute'}, default='auto'"
msgstr ""

#: of sklearn.neighbors._lof.LocalOutlierFactor:25
msgid "Algorithm used to compute the nearest neighbors:"
msgstr ""

#: of sklearn.neighbors._lof.LocalOutlierFactor:27
msgid "'ball_tree' will use :class:`BallTree`"
msgstr ""

#: of sklearn.neighbors._lof.LocalOutlierFactor:28
msgid "'kd_tree' will use :class:`KDTree`"
msgstr ""

#: of sklearn.neighbors._lof.LocalOutlierFactor:29
msgid "'brute' will use a brute-force search."
msgstr ""

#: of sklearn.neighbors._lof.LocalOutlierFactor:30
msgid ""
"'auto' will attempt to decide the most appropriate algorithm based on the"
" values passed to :meth:`fit` method."
msgstr ""

#: of sklearn.neighbors._lof.LocalOutlierFactor:33
msgid ""
"Note: fitting on sparse input will override the setting of this "
"parameter, using brute force."
msgstr ""

#: of sklearn.neighbors._lof.LocalOutlierFactor:40
msgid "**leaf_size**"
msgstr ""

#: of
msgid "int, default=30"
msgstr ""

#: of sklearn.neighbors._lof.LocalOutlierFactor:37
msgid ""
"Leaf size passed to :class:`BallTree` or :class:`KDTree`. This can affect"
" the speed of the construction and query, as well as the memory required "
"to store the tree. The optimal value depends on the nature of the "
"problem."
msgstr ""

#: of sklearn.neighbors._lof.LocalOutlierFactor:69
msgid "**metric**"
msgstr ""

#: of
msgid "str or callable, default='minkowski'"
msgstr ""

#: of sklearn.neighbors._lof.LocalOutlierFactor:43
msgid ""
"metric used for the distance computation. Any metric from scikit-learn or"
" scipy.spatial.distance can be used."
msgstr ""

#: of sklearn.neighbors._lof.LocalOutlierFactor:46
msgid ""
"If metric is \"precomputed\", X is assumed to be a distance matrix and "
"must be square. X may be a sparse matrix, in which case only \"nonzero\" "
"elements may be considered neighbors."
msgstr ""

#: of sklearn.neighbors._lof.LocalOutlierFactor:50
msgid ""
"If metric is a callable function, it is called on each pair of instances "
"(rows) and the resulting value recorded. The callable should take two "
"arrays as input and return one value indicating the distance between "
"them. This works for Scipy's metrics, but is less efficient than passing "
"the metric name as a string."
msgstr ""

#: of sklearn.neighbors._lof.LocalOutlierFactor:56
msgid "Valid values for metric are:"
msgstr ""

#: of sklearn.neighbors._lof.LocalOutlierFactor:58
msgid ""
"from scikit-learn: ['cityblock', 'cosine', 'euclidean', 'l1', 'l2', "
"'manhattan']"
msgstr ""

#: of sklearn.neighbors._lof.LocalOutlierFactor:61
msgid ""
"from scipy.spatial.distance: ['braycurtis', 'canberra', 'chebyshev', "
"'correlation', 'dice', 'hamming', 'jaccard', 'kulsinski', 'mahalanobis', "
"'minkowski', 'rogerstanimoto', 'russellrao', 'seuclidean', "
"'sokalmichener', 'sokalsneath', 'sqeuclidean', 'yule']"
msgstr ""

#: of sklearn.neighbors._lof.LocalOutlierFactor:67
msgid ""
"See the documentation for scipy.spatial.distance for details on these "
"metrics: https://docs.scipy.org/doc/scipy/reference/spatial.distance.html"
msgstr ""

#: of sklearn.neighbors._lof.LocalOutlierFactor:75
msgid "**p**"
msgstr ""

#: of
msgid "int, default=2"
msgstr ""

#: of sklearn.neighbors._lof.LocalOutlierFactor:72
msgid ""
"Parameter for the Minkowski metric from "
":func:`sklearn.metrics.pairwise.pairwise_distances`. When p = 1, this is "
"equivalent to using manhattan_distance (l1), and euclidean_distance (l2) "
"for p = 2. For arbitrary p, minkowski_distance (l_p) is used."
msgstr ""

#: of sklearn.neighbors._lof.LocalOutlierFactor:78
msgid "**metric_params**"
msgstr ""

#: of
msgid "dict, default=None"
msgstr ""

#: of sklearn.neighbors._lof.LocalOutlierFactor:78
msgid "Additional keyword arguments for the metric function."
msgstr ""

#: of sklearn.neighbors._lof.LocalOutlierFactor:91
msgid "**contamination**"
msgstr ""

#: of
msgid "'auto' or float, default='auto'"
msgstr ""

#: of sklearn.neighbors._lof.LocalOutlierFactor:81
msgid ""
"The amount of contamination of the data set, i.e. the proportion of "
"outliers in the data set. When fitting this is used to define the "
"threshold on the scores of the samples."
msgstr ""

#: of sklearn.neighbors._lof.LocalOutlierFactor:85
msgid "if 'auto', the threshold is determined as in the original paper,"
msgstr ""

#: of sklearn.neighbors._lof.LocalOutlierFactor:87
msgid "if a float, the contamination should be in the range [0, 0.5]."
msgstr ""

#: of sklearn.neighbors._lof.LocalOutlierFactor:89
msgid "The default value of ``contamination`` changed from 0.1 to ``'auto'``."
msgstr ""

#: of sklearn.neighbors._lof.LocalOutlierFactor:100
msgid "**novelty**"
msgstr ""

#: of
msgid "bool, default=False"
msgstr ""

#: of sklearn.neighbors._lof.LocalOutlierFactor:94
msgid ""
"By default, LocalOutlierFactor is only meant to be used for outlier "
"detection (novelty=False). Set novelty to True if you want to use "
"LocalOutlierFactor for novelty detection. In this case be aware that that"
" you should only use predict, decision_function and score_samples on new "
"unseen data and not on the training set."
msgstr ""

#: of sklearn.neighbors._lof.LocalOutlierFactor:109
msgid "**n_jobs**"
msgstr ""

#: of
msgid "int, default=None"
msgstr ""

#: of sklearn.neighbors._lof.LocalOutlierFactor:103
msgid ""
"The number of parallel jobs to run for neighbors search. ``None`` means 1"
" unless in a :obj:`joblib.parallel_backend` context. ``-1`` means using "
"all processors. See :term:`Glossary <n_jobs>` for more details."
msgstr ""

#: of sklearn.neighbors._lof.LocalOutlierFactor
msgid "Attributes"
msgstr ""

#: of sklearn.neighbors._lof.LocalOutlierFactor:122
msgid "**negative_outlier_factor_**"
msgstr ""

#: of
msgid "ndarray of shape (n_samples,)"
msgstr ""

#: of sklearn.neighbors._lof.LocalOutlierFactor:114
msgid ""
"The opposite LOF of the training samples. The higher, the more normal. "
"Inliers tend to have a LOF score close to 1 (``negative_outlier_factor_``"
" close to -1), while outliers tend to have a larger LOF score."
msgstr ""

#: of sklearn.neighbors._lof.LocalOutlierFactor:119
msgid ""
"The local outlier factor (LOF) of a sample captures its supposed 'degree "
"of abnormality'. It is the average of the ratio of the local reachability"
" density of a sample and those of its k-nearest neighbors."
msgstr ""

#: of sklearn.neighbors._lof.LocalOutlierFactor:125
msgid "**n_neighbors_**"
msgstr ""

#: of
msgid "int"
msgstr ""

#: of sklearn.neighbors._lof.LocalOutlierFactor:125
msgid "The actual number of neighbors used for :meth:`kneighbors` queries."
msgstr ""

#: of sklearn.neighbors._lof.LocalOutlierFactor:136
msgid "**offset_**"
msgstr ""

#: of
msgid "float"
msgstr ""

#: of sklearn.neighbors._lof.LocalOutlierFactor:128
msgid ""
"Offset used to obtain binary labels from the raw scores. Observations "
"having a negative_outlier_factor smaller than `offset_` are detected as "
"abnormal. The offset is set to -1.5 (inliers score around -1), except "
"when a contamination parameter different than \"auto\" is provided. In "
"that case, the offset is defined in such a way we obtain the expected "
"number of outliers in training."
msgstr ""

#: of sklearn.neighbors._lof.LocalOutlierFactor:139
msgid "**effective_metric_**"
msgstr ""

#: of
msgid "str"
msgstr ""

#: of sklearn.neighbors._lof.LocalOutlierFactor:139
msgid "The effective metric used for the distance computation."
msgstr ""

#: of sklearn.neighbors._lof.LocalOutlierFactor:142
msgid "**effective_metric_params_**"
msgstr ""

#: of
msgid "dict"
msgstr ""

#: of sklearn.neighbors._lof.LocalOutlierFactor:142
msgid "The effective additional keyword arguments for the metric function."
msgstr ""

#: of sklearn.neighbors._lof.LocalOutlierFactor:150
msgid "**n_samples_fit_**"
msgstr ""

#: of sklearn.neighbors._lof.LocalOutlierFactor:145
msgid "It is the number of samples in the fitted data."
msgstr ""

#: of sklearn.neighbors._lof.LocalOutlierFactor:153
msgid "References"
msgstr ""

#: of sklearn.neighbors._lof.LocalOutlierFactor:154
msgid ""
"Breunig, M. M., Kriegel, H. P., Ng, R. T., & Sander, J. (2000, May). LOF:"
" identifying density-based local outliers. In ACM sigmod record."
msgstr ""

#: of sklearn.neighbors._lof.LocalOutlierFactor:159
msgid "[Rca479bb49841-1]_"
msgstr ""

#: of sklearn.neighbors._base.KNeighborsMixin.kneighbors:39
#: sklearn.neighbors._base.KNeighborsMixin.kneighbors_graph:46
#: sklearn.neighbors._lof.LocalOutlierFactor:162
msgid "Examples"
msgstr ""

#: of sklearn.neighbors._lof.LocalOutlierFactor:173
msgid "Methods"
msgstr ""

#: of sklearn.neighbors._lof.LocalOutlierFactor:181:<autosummary>:1
msgid ":obj:`fit <sklearn.neighbors.LocalOutlierFactor.fit>`\\"
msgstr ""

#: of sklearn.neighbors._lof.LocalOutlierFactor.fit:2
#: sklearn.neighbors._lof.LocalOutlierFactor:181:<autosummary>:1
msgid "Fit the local outlier factor detector from the training dataset."
msgstr ""

#: of sklearn.neighbors._lof.LocalOutlierFactor:181:<autosummary>:1
msgid ":obj:`get_params <sklearn.neighbors.LocalOutlierFactor.get_params>`\\"
msgstr ""

#: of sklearn.base.BaseEstimator.get_params:2
#: sklearn.neighbors._lof.LocalOutlierFactor:181:<autosummary>:1
msgid "Get parameters for this estimator."
msgstr ""

#: of sklearn.neighbors._lof.LocalOutlierFactor:181:<autosummary>:1
msgid ":obj:`kneighbors <sklearn.neighbors.LocalOutlierFactor.kneighbors>`\\"
msgstr ""

#: of sklearn.neighbors._base.KNeighborsMixin.kneighbors:2
#: sklearn.neighbors._lof.LocalOutlierFactor:181:<autosummary>:1
msgid "Finds the K-neighbors of a point."
msgstr ""

#: of sklearn.neighbors._lof.LocalOutlierFactor:181:<autosummary>:1
msgid ""
":obj:`kneighbors_graph "
"<sklearn.neighbors.LocalOutlierFactor.kneighbors_graph>`\\"
msgstr ""

#: of sklearn.neighbors._base.KNeighborsMixin.kneighbors_graph:2
#: sklearn.neighbors._lof.LocalOutlierFactor:181:<autosummary>:1
msgid "Computes the (weighted) graph of k-Neighbors for points in X"
msgstr ""

#: of sklearn.neighbors._lof.LocalOutlierFactor:181:<autosummary>:1
msgid ":obj:`set_params <sklearn.neighbors.LocalOutlierFactor.set_params>`\\"
msgstr ""

#: of sklearn.base.BaseEstimator.set_params:2
#: sklearn.neighbors._lof.LocalOutlierFactor:181:<autosummary>:1
msgid "Set the parameters of this estimator."
msgstr ""

#: of sklearn.neighbors.LocalOutlierFactor.decision_function:2
msgid "Shifted opposite of the Local Outlier Factor of X."
msgstr ""

#: of sklearn.neighbors.LocalOutlierFactor.decision_function:4
msgid "Bigger is better, i.e. large values correspond to inliers."
msgstr ""

#: of sklearn.neighbors.LocalOutlierFactor.decision_function:6
msgid ""
"**Only available for novelty detection (when novelty is set to True).** "
"The shift offset allows a zero threshold for being an outlier. The "
"argument X is supposed to contain *new data*: if X contains a point from "
"training, it considers the later in its own neighborhood. Also, the "
"samples in X are not considered in the neighborhood of any point."
msgstr ""

#: of sklearn.neighbors.LocalOutlierFactor.decision_function:17
#: sklearn.neighbors.LocalOutlierFactor.fit_predict:12
#: sklearn.neighbors.LocalOutlierFactor.predict:12
#: sklearn.neighbors.LocalOutlierFactor.score_samples:19
#: sklearn.neighbors._base.KNeighborsMixin.kneighbors:11
#: sklearn.neighbors._base.KNeighborsMixin.kneighbors_graph:13
#: sklearn.neighbors._lof.LocalOutlierFactor.fit:8
msgid "**X**"
msgstr ""

#: of
msgid "array-like of shape (n_samples, n_features)"
msgstr ""

#: of sklearn.neighbors.LocalOutlierFactor.decision_function:16
#: sklearn.neighbors.LocalOutlierFactor.score_samples:18
msgid ""
"The query sample or samples to compute the Local Outlier Factor w.r.t. "
"the training samples."
msgstr ""

#: of sklearn.base.BaseEstimator.get_params
#: sklearn.base.BaseEstimator.set_params
#: sklearn.neighbors.LocalOutlierFactor.decision_function
#: sklearn.neighbors.LocalOutlierFactor.fit_predict
#: sklearn.neighbors.LocalOutlierFactor.predict
#: sklearn.neighbors.LocalOutlierFactor.score_samples
#: sklearn.neighbors._base.KNeighborsMixin.kneighbors
#: sklearn.neighbors._base.KNeighborsMixin.kneighbors_graph
#: sklearn.neighbors._lof.LocalOutlierFactor.fit
msgid "Returns"
msgstr ""

#: of sklearn.neighbors.LocalOutlierFactor.decision_function:35
msgid "**shifted_opposite_lof_scores**"
msgstr ""

#: of sklearn.neighbors.LocalOutlierFactor.decision_function:22
msgid ""
"The shifted opposite of the Local Outlier Factor of each input samples. "
"The lower, the more abnormal. Negative scores represent outliers, "
"positive scores represent inliers."
msgstr ""

#: of
msgid ""
"{array-like, sparse matrix} of shape (n_samples, n_features) or"
"                 (n_samples, n_samples) if metric='precomputed'"
msgstr ""

#: of sklearn.neighbors._lof.LocalOutlierFactor.fit:8
msgid "Training data."
msgstr ""

#: of sklearn.neighbors.LocalOutlierFactor.fit_predict:15
#: sklearn.neighbors._lof.LocalOutlierFactor.fit:11
msgid "**y**"
msgstr ""

#: of
msgid "Ignored"
msgstr ""

#: of sklearn.neighbors.LocalOutlierFactor.fit_predict:15
#: sklearn.neighbors._lof.LocalOutlierFactor.fit:11
msgid "Not used, present for API consistency by convention."
msgstr ""

#: of sklearn.base.BaseEstimator.set_params:28
#: sklearn.neighbors._lof.LocalOutlierFactor.fit:27
msgid "**self**"
msgstr ""

#: of
msgid "LocalOutlierFactor"
msgstr ""

#: of sklearn.neighbors._lof.LocalOutlierFactor.fit:16
msgid "The fitted local outlier factor detector."
msgstr ""

#: of sklearn.neighbors.LocalOutlierFactor.fit_predict:2
msgid "Fits the model to the training set X and returns the labels."
msgstr ""

#: of sklearn.neighbors.LocalOutlierFactor.fit_predict:4
msgid ""
"**Not available for novelty detection (when novelty is set to True).** "
"Label is 1 for an inlier and -1 for an outlier according to the LOF score"
" and the contamination parameter."
msgstr ""

#: of
msgid "array-like of shape (n_samples, n_features), default=None"
msgstr ""

#: of sklearn.neighbors.LocalOutlierFactor.fit_predict:11
#: sklearn.neighbors.LocalOutlierFactor.predict:11
msgid ""
"The query sample or samples to compute the Local Outlier Factor w.r.t. to"
" the training samples."
msgstr ""

#: of sklearn.neighbors.LocalOutlierFactor.fit_predict:31
#: sklearn.neighbors.LocalOutlierFactor.predict:28
msgid "**is_inlier**"
msgstr ""

#: of sklearn.neighbors.LocalOutlierFactor.fit_predict:20
msgid "Returns -1 for anomalies/outliers and 1 for inliers."
msgstr ""

#: of sklearn.base.BaseEstimator.get_params:9
msgid "**deep**"
msgstr ""

#: of
msgid "bool, default=True"
msgstr ""

#: of sklearn.base.BaseEstimator.get_params:8
msgid ""
"If True, will return the parameters for this estimator and contained "
"subobjects that are estimators."
msgstr ""

#: of sklearn.base.BaseEstimator.get_params:25
msgid "**params**"
msgstr ""

#: of sklearn.base.BaseEstimator.get_params:14
msgid "Parameter names mapped to their values."
msgstr ""

#: of sklearn.neighbors._base.KNeighborsMixin.kneighbors:4
msgid "Returns indices of and distances to the neighbors of each point."
msgstr ""

#: of
msgid ""
"array-like, shape (n_queries, n_features),             or (n_queries, "
"n_indexed) if metric == 'precomputed',                 default=None"
msgstr ""

#: of sklearn.neighbors._base.KNeighborsMixin.kneighbors:9
msgid ""
"The query point or points. If not provided, neighbors of each indexed "
"point are returned. In this case, the query point is not considered its "
"own neighbor."
msgstr ""

#: of sklearn.neighbors._base.KNeighborsMixin.kneighbors:14
msgid ""
"Number of neighbors required for each sample. The default is the value "
"passed to the constructor."
msgstr ""

#: of sklearn.neighbors._base.KNeighborsMixin.kneighbors:18
msgid "**return_distance**"
msgstr ""

#: of sklearn.neighbors._base.KNeighborsMixin.kneighbors:18
msgid "Whether or not to return the distances."
msgstr ""

#: of sklearn.neighbors._base.KNeighborsMixin.kneighbors:24
msgid "**neigh_dist**"
msgstr ""

#: of
msgid "ndarray of shape (n_queries, n_neighbors)"
msgstr ""

#: of sklearn.neighbors._base.KNeighborsMixin.kneighbors:23
msgid ""
"Array representing the lengths to points, only present if "
"return_distance=True"
msgstr ""

#: of sklearn.neighbors._base.KNeighborsMixin.kneighbors:36
msgid "**neigh_ind**"
msgstr ""

#: of sklearn.neighbors._base.KNeighborsMixin.kneighbors:27
msgid "Indices of the nearest points in the population matrix."
msgstr ""

#: of sklearn.neighbors._base.KNeighborsMixin.kneighbors:40
msgid ""
"In the following example, we construct a NearestNeighbors class from an "
"array representing our data set and ask who's the closest point to "
"[1,1,1]"
msgstr ""

#: of sklearn.neighbors._base.KNeighborsMixin.kneighbors:52
msgid ""
"As you can see, it returns [[0.5]], and [[2]], which means that the "
"element is at distance 0.5 and is the third element of samples (indexes "
"start at 0). You can also query for multiple points:"
msgstr ""

#: of
msgid ""
"array-like of shape (n_queries, n_features),                 or "
"(n_queries, n_indexed) if metric == 'precomputed',                 "
"default=None"
msgstr ""

#: of sklearn.neighbors._base.KNeighborsMixin.kneighbors_graph:8
msgid ""
"The query point or points. If not provided, neighbors of each indexed "
"point are returned. In this case, the query point is not considered its "
"own neighbor. For ``metric='precomputed'`` the shape should be "
"(n_queries, n_indexed). Otherwise the shape should be (n_queries, "
"n_features)."
msgstr ""

#: of sklearn.neighbors._base.KNeighborsMixin.kneighbors_graph:16
msgid ""
"Number of neighbors for each sample. The default is the value passed to "
"the constructor."
msgstr ""

#: of sklearn.neighbors._base.KNeighborsMixin.kneighbors_graph:22
msgid "**mode**"
msgstr ""

#: of
msgid "{'connectivity', 'distance'}, default='connectivity'"
msgstr ""

#: of sklearn.neighbors._base.KNeighborsMixin.kneighbors_graph:20
msgid ""
"Type of returned matrix: 'connectivity' will return the connectivity "
"matrix with ones and zeros, in 'distance' the edges are Euclidean "
"distance between points."
msgstr ""

#: of sklearn.neighbors._base.KNeighborsMixin.kneighbors_graph:35
msgid "**A**"
msgstr ""

#: of
msgid "sparse-matrix of shape (n_queries, n_samples_fit)"
msgstr ""

#: of sklearn.neighbors._base.KNeighborsMixin.kneighbors_graph:27
msgid ""
"`n_samples_fit` is the number of samples in the fitted data `A[i, j]` is "
"assigned the weight of edge that connects `i` to `j`. The matrix is of "
"CSR format."
msgstr ""

#: of sklearn.neighbors._base.KNeighborsMixin.kneighbors_graph:40
msgid ":obj:`NearestNeighbors.radius_neighbors_graph`"
msgstr ""

#: of sklearn.neighbors.LocalOutlierFactor.predict:2
msgid "Predict the labels (1 inlier, -1 outlier) of X according to LOF."
msgstr ""

#: of sklearn.neighbors.LocalOutlierFactor.predict:4
msgid ""
"**Only available for novelty detection (when novelty is set to True).** "
"This method allows to generalize prediction to *new observations* (not in"
" the training set)."
msgstr ""

#: of sklearn.neighbors.LocalOutlierFactor.predict:17
msgid "Returns -1 for anomalies/outliers and +1 for inliers."
msgstr ""

#: of sklearn.neighbors.LocalOutlierFactor.score_samples:2
msgid "Opposite of the Local Outlier Factor of X."
msgstr ""

#: of sklearn.neighbors.LocalOutlierFactor.score_samples:4
msgid ""
"It is the opposite as bigger is better, i.e. large values correspond to "
"inliers."
msgstr ""

#: of sklearn.neighbors.LocalOutlierFactor.score_samples:7
msgid ""
"**Only available for novelty detection (when novelty is set to True).** "
"The argument X is supposed to contain *new data*: if X contains a point "
"from training, it considers the later in its own neighborhood. Also, the "
"samples in X are not considered in the neighborhood of any point. The "
"score_samples on training data is available by considering the the "
"``negative_outlier_factor_`` attribute."
msgstr ""

#: of sklearn.neighbors.LocalOutlierFactor.score_samples:36
msgid "**opposite_lof_scores**"
msgstr ""

#: of sklearn.neighbors.LocalOutlierFactor.score_samples:24
msgid ""
"The opposite of the Local Outlier Factor of each input samples. The "
"lower, the more abnormal."
msgstr ""

#: of sklearn.base.BaseEstimator.set_params:4
msgid ""
"The method works on simple estimators as well as on nested objects (such "
"as :class:`~sklearn.pipeline.Pipeline`). The latter have parameters of "
"the form ``<component>__<parameter>`` so that it's possible to update "
"each component of a nested object."
msgstr ""

#: of sklearn.base.BaseEstimator.set_params:12
msgid "**\\*\\*params**"
msgstr ""

#: of sklearn.base.BaseEstimator.set_params:12
msgid "Estimator parameters."
msgstr ""

#: of
msgid "estimator instance"
msgstr ""

#: of sklearn.base.BaseEstimator.set_params:17
msgid "Estimator instance."
msgstr ""

#: ../modules/generated/sklearn.neighbors.LocalOutlierFactor.examples:4
msgid "Examples using ``sklearn.neighbors.LocalOutlierFactor``"
msgstr ""

#: ../modules/generated/sklearn.neighbors.LocalOutlierFactor.examples:15
#: ../modules/generated/sklearn.neighbors.LocalOutlierFactor.examples:23
msgid ":ref:`sphx_glr_auto_examples_miscellaneous_plot_anomaly_comparison.py`"
msgstr ""

#: ../modules/generated/sklearn.neighbors.LocalOutlierFactor.examples:34
#: ../modules/generated/sklearn.neighbors.LocalOutlierFactor.examples:42
msgid ":ref:`sphx_glr_auto_examples_neighbors_plot_lof_outlier_detection.py`"
msgstr ""

#: ../modules/generated/sklearn.neighbors.LocalOutlierFactor.examples:53
#: ../modules/generated/sklearn.neighbors.LocalOutlierFactor.examples:61
msgid ":ref:`sphx_glr_auto_examples_neighbors_plot_lof_novelty_detection.py`"
msgstr ""

