# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2007 - 2020, scikit-learn developers (BSD License)
# This file is distributed under the same license as the scikit-learn
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2021.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: scikit-learn 0.24\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-03-31 11:24-0400\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"

#: ../modules/generated/sklearn.gaussian_process.kernels.Matern.rst:2
msgid ":mod:`sklearn.gaussian_process.kernels`.Matern"
msgstr ""

#: of sklearn.gaussian_process.kernels.Matern:2
msgid "Matern kernel."
msgstr ""

#: of sklearn.gaussian_process.kernels.Matern:4
msgid ""
"The class of Matern kernels is a generalization of the :class:`RBF`. It "
"has an additional parameter :math:`\\nu` which controls the smoothness of"
" the resulting function. The smaller :math:`\\nu`, the less smooth the "
"approximated function is. As :math:`\\nu\\rightarrow\\infty`, the kernel "
"becomes equivalent to the :class:`RBF` kernel. When :math:`\\nu = 1/2`, "
"the Mat√©rn kernel becomes identical to the absolute exponential kernel. "
"Important intermediate values are :math:`\\nu=1.5` (once differentiable "
"functions) and :math:`\\nu=2.5` (twice differentiable functions)."
msgstr ""

#: of sklearn.gaussian_process.kernels.Matern:15
msgid "The kernel is given by:"
msgstr ""

#: of sklearn.gaussian_process.kernels.Matern:17
msgid ""
"k(x_i, x_j) =  \\frac{1}{\\Gamma(\\nu)2^{\\nu-1}}\\Bigg(\n"
"\\frac{\\sqrt{2\\nu}}{l} d(x_i , x_j )\n"
"\\Bigg)^\\nu K_\\nu\\Bigg(\n"
"\\frac{\\sqrt{2\\nu}}{l} d(x_i , x_j )\\Bigg)\n"
"\n"
msgstr ""

#: of sklearn.gaussian_process.kernels.Matern:23
msgid ""
"where :math:`d(\\cdot,\\cdot)` is the Euclidean distance, "
":math:`K_{\\nu}(\\cdot)` is a modified Bessel function and "
":math:`\\Gamma(\\cdot)` is the gamma function. See [Rc15b4675c755-1]_, "
"Chapter 4, Section 4.2, for details regarding the different variants of "
"the Matern kernel."
msgstr ""

#: of sklearn.gaussian_process.kernels.Matern:29
msgid "Read more in the :ref:`User Guide <gp_kernels>`."
msgstr ""

#: of sklearn.gaussian_process.kernels.Kernel.clone_with_theta
#: sklearn.gaussian_process.kernels.Kernel.get_params
#: sklearn.gaussian_process.kernels.Matern
#: sklearn.gaussian_process.kernels.Matern.__call__
#: sklearn.gaussian_process.kernels.NormalizedKernelMixin.diag
msgid "Parameters"
msgstr ""

#: of sklearn.gaussian_process.kernels.Matern:38
msgid "**length_scale**"
msgstr ""

#: of
msgid "float or ndarray of shape (n_features,), default=1.0"
msgstr ""

#: of sklearn.gaussian_process.kernels.Matern:36
msgid ""
"The length scale of the kernel. If a float, an isotropic kernel is used. "
"If an array, an anisotropic kernel is used where each dimension of l "
"defines the length-scale of the respective feature dimension."
msgstr ""

#: of sklearn.gaussian_process.kernels.Matern:43
msgid "**length_scale_bounds**"
msgstr ""

#: of
msgid "pair of floats >= 0 or \"fixed\", default=(1e-5, 1e5)"
msgstr ""

#: of sklearn.gaussian_process.kernels.Matern:41
msgid ""
"The lower and upper bound on 'length_scale'. If set to \"fixed\", "
"'length_scale' cannot be changed during hyperparameter tuning."
msgstr ""

#: of sklearn.gaussian_process.kernels.Matern:58
msgid "**nu**"
msgstr ""

#: of
msgid "float, default=1.5"
msgstr ""

#: of sklearn.gaussian_process.kernels.Matern:46
msgid ""
"The parameter nu controlling the smoothness of the learned function. The "
"smaller nu, the less smooth the approximated function is. For nu=inf, the"
" kernel becomes equivalent to the RBF kernel and for nu=0.5 to the "
"absolute exponential kernel. Important intermediate values are nu=1.5 "
"(once differentiable functions) and nu=2.5 (twice differentiable "
"functions). Note that values of nu not in [0.5, 1.5, 2.5, inf] incur a "
"considerably higher computational cost (appr. 10 times higher) since they"
" require to evaluate the modified Bessel function. Furthermore, in "
"contrast to l, nu is kept fixed to its initial value and not optimized."
msgstr ""

#: of sklearn.gaussian_process.kernels.Matern
msgid "Attributes"
msgstr ""

#: of sklearn.gaussian_process.kernels.Matern:63
msgid "**anisotropic**"
msgstr ""

#: of sklearn.gaussian_process.kernels.Matern:66
msgid ":obj:`bounds <bounds>`"
msgstr ""

#: of sklearn.gaussian_process.kernels.Matern:66
#: sklearn.gaussian_process.kernels.Matern.bounds:2
msgid "Returns the log-transformed bounds on the theta."
msgstr ""

#: of sklearn.gaussian_process.kernels.Matern:69
msgid "**hyperparameter_length_scale**"
msgstr ""

#: of sklearn.gaussian_process.kernels.Matern:72
msgid ":obj:`hyperparameters <hyperparameters>`"
msgstr ""

#: of sklearn.gaussian_process.kernels.Matern:72
#: sklearn.gaussian_process.kernels.Matern.hyperparameters:2
msgid "Returns a list of all hyperparameter specifications."
msgstr ""

#: of sklearn.gaussian_process.kernels.Matern:75
msgid ":obj:`n_dims <n_dims>`"
msgstr ""

#: of sklearn.gaussian_process.kernels.Matern:75
#: sklearn.gaussian_process.kernels.Matern.n_dims:2
msgid "Returns the number of non-fixed hyperparameters of the kernel."
msgstr ""

#: of sklearn.gaussian_process.kernels.Matern:78
msgid ":obj:`requires_vector_input <requires_vector_input>`"
msgstr ""

#: of sklearn.gaussian_process.kernels.Matern:78
msgid ""
"Returns whether the kernel is defined on fixed-length feature vectors or "
"generic objects."
msgstr ""

#: of sklearn.gaussian_process.kernels.Matern:86
msgid ":obj:`theta <theta>`"
msgstr ""

#: of sklearn.gaussian_process.kernels.Matern:81
#: sklearn.gaussian_process.kernels.Matern.theta:2
msgid "Returns the (flattened, log-transformed) non-fixed hyperparameters."
msgstr ""

#: of sklearn.gaussian_process.kernels.Matern:89
msgid "References"
msgstr ""

#: of sklearn.gaussian_process.kernels.Matern:90
msgid ""
"`Carl Edward Rasmussen, Christopher K. I. Williams (2006). \"Gaussian "
"Processes for Machine Learning\". The MIT Press. "
"<http://www.gaussianprocess.org/gpml/>`_"
msgstr ""

#: of sklearn.gaussian_process.kernels.Matern:96
msgid "[Rc15b4675c755-1]_"
msgstr ""

#: of sklearn.gaussian_process.kernels.Matern:99
msgid "Examples"
msgstr ""

#: of sklearn.gaussian_process.kernels.Matern:114
msgid "Methods"
msgstr ""

#: of sklearn.gaussian_process.kernels.Matern:123:<autosummary>:1
msgid ":obj:`__call__ <sklearn.gaussian_process.kernels.Matern.__call__>`\\"
msgstr ""

#: of sklearn.gaussian_process.kernels.Matern.__call__:2
#: sklearn.gaussian_process.kernels.Matern:123:<autosummary>:1
msgid "Return the kernel k(X, Y) and optionally its gradient."
msgstr ""

#: of sklearn.gaussian_process.kernels.Matern:123:<autosummary>:1
msgid ""
":obj:`clone_with_theta "
"<sklearn.gaussian_process.kernels.Matern.clone_with_theta>`\\"
msgstr ""

#: of sklearn.gaussian_process.kernels.Kernel.clone_with_theta:2
#: sklearn.gaussian_process.kernels.Matern:123:<autosummary>:1
msgid "Returns a clone of self with given hyperparameters theta."
msgstr ""

#: of sklearn.gaussian_process.kernels.Matern:123:<autosummary>:1
msgid ":obj:`diag <sklearn.gaussian_process.kernels.Matern.diag>`\\"
msgstr ""

#: of sklearn.gaussian_process.kernels.Matern:123:<autosummary>:1
#: sklearn.gaussian_process.kernels.NormalizedKernelMixin.diag:2
msgid "Returns the diagonal of the kernel k(X, X)."
msgstr ""

#: of sklearn.gaussian_process.kernels.Matern:123:<autosummary>:1
msgid ":obj:`get_params <sklearn.gaussian_process.kernels.Matern.get_params>`\\"
msgstr ""

#: of sklearn.gaussian_process.kernels.Kernel.get_params:2
#: sklearn.gaussian_process.kernels.Matern:123:<autosummary>:1
msgid "Get parameters of this kernel."
msgstr ""

#: of sklearn.gaussian_process.kernels.Matern:123:<autosummary>:1
msgid ""
":obj:`is_stationary "
"<sklearn.gaussian_process.kernels.Matern.is_stationary>`\\"
msgstr ""

#: of sklearn.gaussian_process.kernels.Matern:123:<autosummary>:1
#: sklearn.gaussian_process.kernels.StationaryKernelMixin.is_stationary:2
msgid "Returns whether the kernel is stationary."
msgstr ""

#: of sklearn.gaussian_process.kernels.Matern:123:<autosummary>:1
msgid ":obj:`set_params <sklearn.gaussian_process.kernels.Matern.set_params>`\\"
msgstr ""

#: of sklearn.gaussian_process.kernels.Kernel.set_params:2
#: sklearn.gaussian_process.kernels.Matern:123:<autosummary>:1
msgid "Set the parameters of this kernel."
msgstr ""

#: of sklearn.gaussian_process.kernels.Matern.__call__:8
#: sklearn.gaussian_process.kernels.NormalizedKernelMixin.diag:11
msgid "**X**"
msgstr ""

#: of
msgid "ndarray of shape (n_samples_X, n_features)"
msgstr ""

#: of sklearn.gaussian_process.kernels.Matern.__call__:8
#: sklearn.gaussian_process.kernels.NormalizedKernelMixin.diag:11
msgid "Left argument of the returned kernel k(X, Y)"
msgstr ""

#: of sklearn.gaussian_process.kernels.Matern.__call__:12
msgid "**Y**"
msgstr ""

#: of
msgid "ndarray of shape (n_samples_Y, n_features), default=None"
msgstr ""

#: of sklearn.gaussian_process.kernels.Matern.__call__:11
msgid ""
"Right argument of the returned kernel k(X, Y). If None, k(X, X) if "
"evaluated instead."
msgstr ""

#: of sklearn.gaussian_process.kernels.Matern.__call__:17
msgid "**eval_gradient**"
msgstr ""

#: of
msgid "bool, default=False"
msgstr ""

#: of sklearn.gaussian_process.kernels.Matern.__call__:15
msgid ""
"Determines whether the gradient with respect to the log of the kernel "
"hyperparameter is computed. Only supported when Y is None."
msgstr ""

#: of sklearn.gaussian_process.kernels.Kernel.get_params
#: sklearn.gaussian_process.kernels.Kernel.set_params
#: sklearn.gaussian_process.kernels.Matern.__call__
#: sklearn.gaussian_process.kernels.Matern.bounds
#: sklearn.gaussian_process.kernels.Matern.theta
#: sklearn.gaussian_process.kernels.NormalizedKernelMixin.diag
msgid "Returns"
msgstr ""

#: of sklearn.gaussian_process.kernels.Matern.__call__:22
msgid "**K**"
msgstr ""

#: of
msgid "ndarray of shape (n_samples_X, n_samples_Y)"
msgstr ""

#: of sklearn.gaussian_process.kernels.Matern.__call__:22
msgid "Kernel k(X, Y)"
msgstr ""

#: of sklearn.gaussian_process.kernels.Matern.__call__:38
msgid "**K_gradient**"
msgstr ""

#: of
msgid ""
"ndarray of shape (n_samples_X, n_samples_X, n_dims),                 "
"optional"
msgstr ""

#: of sklearn.gaussian_process.kernels.Matern.__call__:25
msgid ""
"The gradient of the kernel k(X, X) with respect to the log of the "
"hyperparameter of the kernel. Only returned when `eval_gradient` is True."
msgstr ""

#: of sklearn.gaussian_process.kernels.Matern.bounds:20
msgid "**bounds**"
msgstr ""

#: of
msgid "ndarray of shape (n_dims, 2)"
msgstr ""

#: of sklearn.gaussian_process.kernels.Matern.bounds:9
msgid "The log-transformed bounds on the kernel's hyperparameters theta"
msgstr ""

#: of sklearn.gaussian_process.kernels.Kernel.clone_with_theta:20
#: sklearn.gaussian_process.kernels.Matern.theta:24
msgid "**theta**"
msgstr ""

#: of
msgid "ndarray of shape (n_dims,)"
msgstr ""

#: of sklearn.gaussian_process.kernels.Kernel.clone_with_theta:8
msgid "The hyperparameters"
msgstr ""

#: of sklearn.gaussian_process.kernels.NormalizedKernelMixin.diag:4
msgid ""
"The result of this method is identical to np.diag(self(X)); however, it "
"can be evaluated more efficiently since only the diagonal is evaluated."
msgstr ""

#: of sklearn.gaussian_process.kernels.NormalizedKernelMixin.diag:27
msgid "**K_diag**"
msgstr ""

#: of
msgid "ndarray of shape (n_samples_X,)"
msgstr ""

#: of sklearn.gaussian_process.kernels.NormalizedKernelMixin.diag:16
msgid "Diagonal of kernel k(X, X)"
msgstr ""

#: of sklearn.gaussian_process.kernels.Kernel.get_params:9
msgid "**deep**"
msgstr ""

#: of
msgid "bool, default=True"
msgstr ""

#: of sklearn.gaussian_process.kernels.Kernel.get_params:8
msgid ""
"If True, will return the parameters for this estimator and contained "
"subobjects that are estimators."
msgstr ""

#: of sklearn.gaussian_process.kernels.Kernel.get_params:25
msgid "**params**"
msgstr ""

#: of
msgid "dict"
msgstr ""

#: of sklearn.gaussian_process.kernels.Kernel.get_params:14
msgid "Parameter names mapped to their values."
msgstr ""

#: of sklearn.gaussian_process.kernels.Matern.requires_vector_input:2
msgid ""
"Returns whether the kernel is defined on fixed-length feature vectors or "
"generic objects. Defaults to True for backward compatibility."
msgstr ""

#: of sklearn.gaussian_process.kernels.Kernel.set_params:4
msgid ""
"The method works on simple kernels as well as on nested kernels. The "
"latter have parameters of the form ``<component>__<parameter>`` so that "
"it's possible to update each component of a nested object."
msgstr ""

#: of sklearn.gaussian_process.kernels.Kernel.set_params:23
msgid "self"
msgstr ""

#: of sklearn.gaussian_process.kernels.Matern.theta:4
msgid ""
"Note that theta are typically the log-transformed values of the kernel's "
"hyperparameters as this representation of the search space is more "
"amenable for hyperparameter search, as hyperparameters like length-scales"
" naturally live on a log-scale."
msgstr ""

#: of sklearn.gaussian_process.kernels.Matern.theta:13
msgid "The non-fixed, log-transformed hyperparameters of the kernel"
msgstr ""

#: ../modules/generated/sklearn.gaussian_process.kernels.Matern.examples:4
msgid "Examples using ``sklearn.gaussian_process.kernels.Matern``"
msgstr ""

#: ../modules/generated/sklearn.gaussian_process.kernels.Matern.examples:15
#: ../modules/generated/sklearn.gaussian_process.kernels.Matern.examples:23
msgid ":ref:`sphx_glr_auto_examples_gaussian_process_plot_gpr_prior_posterior.py`"
msgstr ""

