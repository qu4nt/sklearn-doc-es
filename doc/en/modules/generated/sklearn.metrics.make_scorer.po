# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2007 - 2020, scikit-learn developers (BSD License)
# This file is distributed under the same license as the scikit-learn
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2021.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: scikit-learn 0.24\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-03-31 11:24-0400\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"

#: ../modules/generated/sklearn.metrics.make_scorer.rst:2
msgid ":mod:`sklearn.metrics`.make_scorer"
msgstr ""

#: of sklearn.metrics._scorer.make_scorer:2
msgid "Make a scorer from a performance metric or loss function."
msgstr ""

#: of sklearn.metrics._scorer.make_scorer:4
msgid ""
"This factory function wraps scoring functions for use in "
":class:`~sklearn.model_selection.GridSearchCV` and "
":func:`~sklearn.model_selection.cross_val_score`. It takes a score "
"function, such as :func:`~sklearn.metrics.accuracy_score`, "
":func:`~sklearn.metrics.mean_squared_error`, "
":func:`~sklearn.metrics.adjusted_rand_index` or "
":func:`~sklearn.metrics.average_precision` and returns a callable that "
"scores an estimator's output. The signature of the call is `(estimator, "
"X, y)` where `estimator` is the model to be evaluated, `X` is the data "
"and `y` is the ground truth labeling (or `None` in the case of "
"unsupervised models)."
msgstr ""

#: of sklearn.metrics._scorer.make_scorer:16
msgid "Read more in the :ref:`User Guide <scoring>`."
msgstr ""

#: of sklearn.metrics._scorer.make_scorer
msgid "Parameters"
msgstr ""

#: of sklearn.metrics._scorer.make_scorer:22
msgid "**score_func**"
msgstr ""

#: of
msgid "callable"
msgstr ""

#: of sklearn.metrics._scorer.make_scorer:21
msgid ""
"Score function (or loss function) with signature ``score_func(y, y_pred, "
"**kwargs)``."
msgstr ""

#: of sklearn.metrics._scorer.make_scorer:27
msgid "**greater_is_better**"
msgstr ""

#: of
msgid "bool, default=True"
msgstr ""

#: of sklearn.metrics._scorer.make_scorer:25
msgid ""
"Whether score_func is a score function (default), meaning high is good, "
"or a loss function, meaning low is good. In the latter case, the scorer "
"object will sign-flip the outcome of the score_func."
msgstr ""

#: of sklearn.metrics._scorer.make_scorer:35
msgid "**needs_proba**"
msgstr ""

#: of
msgid "bool, default=False"
msgstr ""

#: of sklearn.metrics._scorer.make_scorer:30
msgid ""
"Whether score_func requires predict_proba to get probability estimates "
"out of a classifier."
msgstr ""

#: of sklearn.metrics._scorer.make_scorer:33
msgid ""
"If True, for binary `y_true`, the score function is supposed to accept a "
"1D `y_pred` (i.e., probability of the positive class, shape "
"`(n_samples,)`)."
msgstr ""

#: of sklearn.metrics._scorer.make_scorer:47
msgid "**needs_threshold**"
msgstr ""

#: of sklearn.metrics._scorer.make_scorer:38
msgid ""
"Whether score_func takes a continuous decision certainty. This only works"
" for binary classification using estimators that have either a "
"decision_function or predict_proba method."
msgstr ""

#: of sklearn.metrics._scorer.make_scorer:42
msgid ""
"If True, for binary `y_true`, the score function is supposed to accept a "
"1D `y_pred` (i.e., probability of the positive class or the decision "
"function, shape `(n_samples,)`)."
msgstr ""

#: of sklearn.metrics._scorer.make_scorer:46
msgid ""
"For example ``average_precision`` or the area under the roc curve can not"
" be computed using discrete predictions alone."
msgstr ""

#: of sklearn.metrics._scorer.make_scorer:50
msgid "**\\*\\*kwargs**"
msgstr ""

#: of
msgid "additional arguments"
msgstr ""

#: of sklearn.metrics._scorer.make_scorer:50
msgid "Additional parameters to be passed to score_func."
msgstr ""

#: of sklearn.metrics._scorer.make_scorer
msgid "Returns"
msgstr ""

#: of sklearn.metrics._scorer.make_scorer:62
msgid "**scorer**"
msgstr ""

#: of sklearn.metrics._scorer.make_scorer:55
msgid "Callable object that returns a scalar score; greater is better."
msgstr ""

#: of sklearn.metrics._scorer.make_scorer:65
msgid "Notes"
msgstr ""

#: of sklearn.metrics._scorer.make_scorer:66
msgid ""
"If `needs_proba=False` and `needs_threshold=False`, the score function is"
" supposed to accept the output of :term:`predict`. If `needs_proba=True`,"
" the score function is supposed to accept the output of "
":term:`predict_proba` (For binary `y_true`, the score function is "
"supposed to accept probability of the positive class). If "
"`needs_threshold=True`, the score function is supposed to accept the "
"output of :term:`decision_function`."
msgstr ""

#: of sklearn.metrics._scorer.make_scorer:76
msgid "Examples"
msgstr ""

#: ../modules/generated/sklearn.metrics.make_scorer.examples:4
msgid "Examples using ``sklearn.metrics.make_scorer``"
msgstr ""

#: ../modules/generated/sklearn.metrics.make_scorer.examples:15
#: ../modules/generated/sklearn.metrics.make_scorer.examples:23
msgid ":ref:`sphx_glr_auto_examples_model_selection_plot_multi_metric_evaluation.py`"
msgstr ""

