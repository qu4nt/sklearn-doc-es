# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2007 - 2020, scikit-learn developers (BSD License)
# This file is distributed under the same license as the scikit-learn
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2021.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: scikit-learn 0.24\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-03-31 11:24-0400\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"

#: ../modules/unsupervised_reduction.rst:6
msgid "Unsupervised dimensionality reduction"
msgstr ""

#: ../modules/unsupervised_reduction.rst:8
msgid ""
"If your number of features is high, it may be useful to reduce it with an"
" unsupervised step prior to supervised steps. Many of the :ref"
":`unsupervised-learning` methods implement a ``transform`` method that "
"can be used to reduce the dimensionality. Below we discuss two specific "
"example of this pattern that are heavily used."
msgstr ""

msgid "**Pipelining**"
msgstr ""

#: ../modules/unsupervised_reduction.rst:16
msgid ""
"The unsupervised data reduction and the supervised estimator can be "
"chained in one step. See :ref:`pipeline`."
msgstr ""

#: ../modules/unsupervised_reduction.rst:22
msgid "PCA: principal component analysis"
msgstr ""

#: ../modules/unsupervised_reduction.rst:24
msgid ""
":class:`decomposition.PCA` looks for a combination of features that "
"capture well the variance of the original features. See "
":ref:`decompositions`."
msgstr ""

#: ../modules/unsupervised_reduction.rst:29
msgid ":ref:`sphx_glr_auto_examples_applications_plot_face_recognition.py`"
msgstr ""

#: ../modules/unsupervised_reduction.rst:32
msgid "Random projections"
msgstr ""

#: ../modules/unsupervised_reduction.rst:34
msgid ""
"The module: :mod:`random_projection` provides several tools for data "
"reduction by random projections. See the relevant section of the "
"documentation: :ref:`random_projection`."
msgstr ""

#: ../modules/unsupervised_reduction.rst:40
msgid ":ref:`sphx_glr_auto_examples_miscellaneous_plot_johnson_lindenstrauss_bound.py`"
msgstr ""

#: ../modules/unsupervised_reduction.rst:43
msgid "Feature agglomeration"
msgstr ""

#: ../modules/unsupervised_reduction.rst:45
msgid ""
":class:`cluster.FeatureAgglomeration` applies "
":ref:`hierarchical_clustering` to group together features that behave "
"similarly."
msgstr ""

#: ../modules/unsupervised_reduction.rst:51
msgid ":ref:`sphx_glr_auto_examples_cluster_plot_feature_agglomeration_vs_univariate_selection.py`"
msgstr ""

#: ../modules/unsupervised_reduction.rst:52
msgid ":ref:`sphx_glr_auto_examples_cluster_plot_digits_agglomeration.py`"
msgstr ""

msgid "**Feature scaling**"
msgstr ""

#: ../modules/unsupervised_reduction.rst:56
msgid ""
"Note that if features have very different scaling or statistical "
"properties, :class:`cluster.FeatureAgglomeration` may not be able to "
"capture the links between related features. Using a "
":class:`preprocessing.StandardScaler` can be useful in these settings."
msgstr ""

