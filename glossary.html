

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  
  <title>Glosario de Términos Comunes y Elementos de la API &mdash; documentación de scikit-learn - 0.24.2</title>
  
  <link rel="canonical" href="http://scikit-learn.org/stable/glossary.html" />

  
  <link rel="shortcut icon" href="_static/favicon.ico"/>
  

  <link rel="stylesheet" href="_static/css/vendor/bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/gallery.css" type="text/css" />
  <link rel="stylesheet" href="_static/gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="_static/gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="_static/gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
<script id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
<script src="_static/jquery.js"></script> 
</head>
<body>
<nav id="navbar" class="sk-docs-navbar navbar navbar-expand-md navbar-light bg-light py-0">
  <div class="container-fluid sk-docs-container px-0">
      <a class="navbar-brand py-0" href="index.html">
        <img
          class="sk-brand-img"
          src="_static/scikit-learn-logo-small.png"
          alt="logo"/>
      </a>
    <button
      id="sk-navbar-toggler"
      class="navbar-toggler"
      type="button"
      data-toggle="collapse"
      data-target="#navbarSupportedContent"
      aria-controls="navbarSupportedContent"
      aria-expanded="false"
      aria-label="Toggle navigation"
    >
      <span class="navbar-toggler-icon"></span>
    </button>

    <div class="sk-navbar-collapse collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav mr-auto">
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="install.html">Instalación</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="user_guide.html">Manual de Usuario</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="modules/classes.html">API</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="auto_examples/index.html">Ejemplos</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="getting_started.html">¿Cómo empezar?</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="tutorial/index.html">Tutorial</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="whats_new/v0.24.html">Novedades</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="#">Glosario</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="developers/index.html">Desarrollo</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="faq.html">FAQ</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="support.html">Soporte</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="related_projects.html">Paquetes relacionados</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="roadmap.html">Hoja de ruta</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="about.html">Sobre nosotros</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="https://github.com/scikit-learn/scikit-learn">GitHub</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="https://scikit-learn.org/dev/versions.html">Otras versiones y descargas</a>
        </li>
        <li class="nav-item dropdown nav-more-item-dropdown">
          <a class="sk-nav-link nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Más</a>
          <div class="dropdown-menu" aria-labelledby="navbarDropdown">
              <a class="sk-nav-dropdown-item dropdown-item" href="getting_started.html">¿Cómo empezar?</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="tutorial/index.html">Tutorial</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="whats_new/v0.24.html">Novedades</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="#">Glosario</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="developers/index.html">Desarrollo</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="faq.html">FAQ</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="support.html">Soporte</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="related_projects.html">Paquetes relacionados</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="roadmap.html">Hoja de ruta</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="about.html">Sobre nosotros</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="https://github.com/scikit-learn/scikit-learn">GitHub</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="https://scikit-learn.org/dev/versions.html">Otras versiones y descargas</a>
          </div>
        </li>
      </ul>
      <div id="searchbox" role="search">
          <div class="searchformwrapper">
          <form class="search" action="search.html" method="get">
            <input class="sk-search-text-input" type="text" name="q" aria-labelledby="searchlabel" />
            <input class="sk-search-text-btn" type="submit" value="Ir a" />
          </form>
          </div>
      </div>
    </div>
  </div>
</nav>
<div class="d-flex" id="sk-doc-wrapper">
    <input type="checkbox" name="sk-toggle-checkbox" id="sk-toggle-checkbox">
    <label id="sk-sidemenu-toggle" class="sk-btn-toggle-toc btn sk-btn-primary" for="sk-toggle-checkbox">Alternar menú</label>
    <div id="sk-sidebar-wrapper" class="border-right">
      <div class="sk-sidebar-toc-wrapper">
        <div class="sk-sidebar-toc-logo">
          <a href="index.html">
            <img
              class="sk-brand-img"
              src="_static/scikit-learn-logo-small.png"
              alt="logo"/>
          </a>
        </div>
        <div class="btn-group w-100 mb-2" role="group" aria-label="rellinks">
            <a href="common_pitfalls.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="10. Fallas comunes y prácticas recomendadas">Prev</a>
            <a href="#" role="button" class="btn sk-btn-rellink disabled py-1">Arriba</a>
            <a href="auto_examples/index.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="Ejemplos">Sig.</a>
        </div>
        <div class="alert alert-danger p-1 mb-2" role="alert">
          <p class="text-center mb-0">
          <strong>scikit-learn 0.24.2</strong><br/>
          <a href="http://scikit-learn.org/dev/versions.html">Otras versiones</a>
          </p>
        </div>
        <div class="alert alert-warning p-1 mb-2" role="alert">
          <p class="text-center mb-0">
            Por favor <a class="font-weight-bold" href="about.html#citing-scikit-learn"><string>cítanos</string></a> si usas el software.
          </p>
        </div>
            <div class="sk-sidebar-toc">
              <ul>
<li><a class="reference internal" href="#">Glosario de Términos Comunes y Elementos de la API</a><ul>
<li><a class="reference internal" href="#general-concepts">Conceptos Generales</a></li>
<li><a class="reference internal" href="#class-apis-and-estimator-types">APIs de Clase y Tipos de Estimadores</a></li>
<li><a class="reference internal" href="#target-types">Tipos de Objetivos</a></li>
<li><a class="reference internal" href="#methods">Métodos</a></li>
<li><a class="reference internal" href="#parameters">Parámetros</a></li>
<li><a class="reference internal" href="#attributes">Atributos</a></li>
<li><a class="reference internal" href="#data-and-sample-properties">Datos y propiedades de la muestra</a></li>
</ul>
</li>
</ul>

            </div>
      </div>
    </div>
    <div id="sk-page-content-wrapper">
      <div class="sk-page-content container-fluid body px-md-3" role="main">
        
  <section id="glossary-of-common-terms-and-api-elements">
<span id="glossary"></span><h1>Glosario de Términos Comunes y Elementos de la API<a class="headerlink" href="#glossary-of-common-terms-and-api-elements" title="Enlazar permanentemente con este título">¶</a></h1>
<p>Este glosario espera representar definitivamente las convenciones tácitas y explícitas aplicadas en scikit-learn y su API, proporcionando al mismo tiempo una referencia para los usuarios y colaboradores. Su objetivo es describir los conceptos y detallar su correspondiente API o bien enlazar con otras partes relevantes de la documentación que lo hagan. Al enlazar con las entradas de glosario de la Referencia de la API y la Guía de Usuario, podemos minimizar la redundancia y la inconsistencia.</p>
<p>Empezamos por listar los conceptos generales (y cualquiera que no encajaba en otra parte), pero conjuntos más específicos de términos relacionados se listan a continuación: <a class="reference internal" href="#glossary-estimator-types"><span class="std std-ref">APIs de Clase y Tipos de Estimadores</span></a>, <a class="reference internal" href="#glossary-target-types"><span class="std std-ref">Tipos de Objetivos</span></a>, <a class="reference internal" href="#glossary-methods"><span class="std std-ref">Métodos</span></a>, <a class="reference internal" href="#glossary-parameters"><span class="std std-ref">Parámetros</span></a>, <a class="reference internal" href="#glossary-attributes"><span class="std std-ref">Atributos</span></a>, <a class="reference internal" href="#glossary-sample-props"><span class="std std-ref">Datos y propiedades de la muestra</span></a>.</p>
<section id="general-concepts">
<h2>Conceptos Generales<a class="headerlink" href="#general-concepts" title="Enlazar permanentemente con este título">¶</a></h2>
<dl class="glossary">
<dt id="term-1d">1D<a class="headerlink" href="#term-1d" title="Permalink to this term">¶</a></dt><dt id="term-1d-array">Arreglo 1D<a class="headerlink" href="#term-1d-array" title="Permalink to this term">¶</a></dt><dd><p>Un arreglo unidimensional. Un arreglo NumPy cuyo <code class="docutils literal notranslate"><span class="pre">.shape</span></code> tiene longitud 1. Un vector.</p>
</dd>
<dt id="term-2d">2D<a class="headerlink" href="#term-2d" title="Permalink to this term">¶</a></dt><dt id="term-2d-array">Arreglo 2D<a class="headerlink" href="#term-2d-array" title="Permalink to this term">¶</a></dt><dd><p>Un arreglo bidimensional. Un arreglo NumPy cuyo <code class="docutils literal notranslate"><span class="pre">.shape</span></code> tiene longitud 2. A menudo representa una matriz.</p>
</dd>
<dt id="term-API">API<a class="headerlink" href="#term-API" title="Permalink to this term">¶</a></dt><dd><p>Se refiere tanto a las interfaces <em>específicas</em> para los estimadores implementados en scikit-learn como a las convenciones <em>generalizadas</em> entre los tipos de estimadores, tal como se describe en este glosario y <a class="reference internal" href="developers/develop.html#api-overview"><span class="std std-ref">se resume en la documentación de los colaboradores</span></a>.</p>
<p>Las interfaces específicas que constituyen la API pública de scikit-learn están ampliamente documentadas en <a class="reference internal" href="modules/classes.html#api-ref"><span class="std std-ref">Referencia de la API</span></a>. Sin embargo, consideramos menos formalmente cualquier cosa como API pública si ninguno de los identificadores requeridos para acceder a ella comienza con <code class="docutils literal notranslate"><span class="pre">_</span></code>.  En general, tratamos de mantener <a class="reference internal" href="#term-backwards-compatibility"><span class="xref std std-term">compatibilidad con versiones anteriores</span></a> para todos los objetos en la API pública.</p>
<p>La API privada, incluyendo funciones, módulos y métodos que empiezan por <code class="docutils literal notranslate"><span class="pre">_</span></code> no tienen garantizada su estabilidad.</p>
</dd>
<dt id="term-array-like">array-like<a class="headerlink" href="#term-array-like" title="Permalink to this term">¶</a></dt><dd><p>El formato de datos más común de <em>entrada</em> a los estimadores y funciones de Scikit-learn, array-like es cualquier tipo objeto para el que <a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.asarray.html#numpy.asarray" title="(en NumPy versión 1.21)"><code class="xref py py-func docutils literal notranslate"><span class="pre">numpy.asarray</span></code></a> producirá un arreglo de forma apropiada (normalmente de 1 o 2 dimensiones) de dtype apropiado (normalmente numérico).</p>
<p>Esto incluye:</p>
<ul class="simple">
<li><p>un arreglo numpy</p></li>
<li><p>una lista de números</p></li>
<li><p>una lista de listas de números de longitud-k para alguna longitud fija k</p></li>
<li><p>una <a class="reference external" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas.DataFrame" title="(en pandas versión 1.3.2)"><code class="xref py py-class docutils literal notranslate"><span class="pre">pandas.DataFrame</span></code></a> con todas las columnas numéricas</p></li>
<li><p>una <a class="reference external" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html#pandas.Series" title="(en pandas versión 1.3.2)"><code class="xref py py-class docutils literal notranslate"><span class="pre">pandas.Series</span></code></a> numérica</p></li>
</ul>
<p>Excluye:</p>
<ul class="simple">
<li><p>una <a class="reference internal" href="#term-sparse-matrix"><span class="xref std std-term">matriz dispersa</span></a></p></li>
<li><p>un iterador</p></li>
<li><p>un generador</p></li>
</ul>
<p>Ten en cuenta que las <em>salidas</em> de los estimadores y funciones de scikit-learn (por ejemplo, las predicciones) deben ser generalmente arreglos o matrices dispersas, o listas de las mismas (como en <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code> de <a class="reference internal" href="modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier" title="sklearn.tree.DecisionTreeClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">tree.DecisionTreeClassifier</span></code></a> de salida múltiple). Un estimador en el que <code class="docutils literal notranslate"><span class="pre">predict()</span></code> devuelve una lista o una <code class="docutils literal notranslate"><span class="pre">pandas.Series</span></code> no es válido.</p>
</dd>
<dt id="term-attribute">atributo<a class="headerlink" href="#term-attribute" title="Permalink to this term">¶</a></dt><dt id="term-attributes">atributos<a class="headerlink" href="#term-attributes" title="Permalink to this term">¶</a></dt><dd><p>La mayoría de las veces utilizamos atributo para referirnos a cómo se almacena la información del modelo en un estimador durante el ajuste.  Cualquier atributo público almacenado en una instancia del estimador debe empezar con un carácter alfabético y terminar con un solo guión bajo si se establece en <a class="reference internal" href="#term-fit"><span class="xref std std-term">fit</span></a> o <a class="reference internal" href="#term-partial_fit"><span class="xref std std-term">partial_fit</span></a>.  Esto es lo que se encuentra en la documentación <em>Atributos</em> de un estimador.  La información almacenada en los atributos suele ser: estadísticos suficientes utilizados para la predicción o la transformación; salidas <a class="reference internal" href="#term-transductive"><span class="xref std std-term">transductivas</span></a> como <a class="reference internal" href="#term-labels_"><span class="xref std std-term">labels_</span></a> o <a class="reference internal" href="#term-embedding_"><span class="xref std std-term">embedding_</span></a>; o datos de diagnóstico, como <a class="reference internal" href="#term-feature_importances_"><span class="xref std std-term">feature_importances_</span></a>. Los atributos comunes se listan <a class="reference internal" href="#glossary-attributes"><span class="std std-ref">a continuación</span></a>.</p>
<p>Un atributo público puede tener el mismo nombre que un <a class="reference internal" href="#term-parameter"><span class="xref std std-term">parámetro</span></a> del constructor, con un <code class="docutils literal notranslate"><span class="pre">_</span></code> añadido. Se utiliza para almacenar una versión validada o estimada de la entrada del usuario. Por ejemplo, <a class="reference internal" href="modules/generated/sklearn.decomposition.PCA.html#sklearn.decomposition.PCA" title="sklearn.decomposition.PCA"><code class="xref py py-class docutils literal notranslate"><span class="pre">decomposition.PCA</span></code></a> se construye con un parámetro <code class="docutils literal notranslate"><span class="pre">n_components</span></code>. A partir de esto, junto con otros parámetros y los datos, PCA estima el atributo <code class="docutils literal notranslate"><span class="pre">n_components_</span></code>.</p>
<p>También pueden establecerse otros atributos privados utilizados en la predicción/transformación/etc. durante el ajuste.  Estos empiezan con un solo guión bajo y no se asegura que sean estables para el acceso público.</p>
<p>Un atributo público en una instancia del estimador que no termine en un guión bajo debe ser el valor almacenado y no modificado de un <a class="reference internal" href="#term-parameter"><span class="xref std std-term">parámetro</span></a> <code class="docutils literal notranslate"><span class="pre">__init__</span></code>  del mismo nombre.  Debido a esta equivalencia, se agregan en la documentación de <em>Parámetros</em> de un estimador.</p>
</dd>
<dt id="term-backwards-compatibility">compatibilidad con versiones anteriores<a class="headerlink" href="#term-backwards-compatibility" title="Permalink to this term">¶</a></dt><dd><p>Por lo general, intentamos mantener la compatibilidad con versiones anteriores (es decir, las interfaces y los comportamientos pueden ampliarse, pero no modificarse ni eliminarse) de una versión a otra, pero esto tiene algunas excepciones:</p>
<dl class="simple">
<dt>Solamente API pública</dt><dd><p>El comportamiento de los objetos a los que se accede a través de identificadores privados (los que empiezan por <code class="docutils literal notranslate"><span class="pre">_</span></code>) puede cambiar arbitrariamente entre versiones.</p>
</dd>
<dt>Como está documentado</dt><dd><p>Por lo general, asumiremos que los usuarios se han ceñido a los tipos y rangos de parámetros documentados. Si la documentación pide una lista y el usuario proporciona una tupla, no garantizamos un comportamiento consistente de una versión a otra.</p>
</dd>
<dt>Obsolescencia</dt><dd><p>Los comportamientos pueden cambiar tras un periodo de <a class="reference internal" href="#term-deprecation"><span class="xref std std-term">obsolescencia</span></a> (normalmente de dos versiones). Las advertencias se emiten utilizando el módulo <a class="reference external" href="https://docs.python.org/3/library/warnings.html#module-warnings" title="(en Python versión 3.9)"><code class="xref py py-mod docutils literal notranslate"><span class="pre">warnings</span></code></a> de Python.</p>
</dd>
<dt>Argumentos de palabras clave</dt><dd><p>A veces podemos suponer que todos los parámetros opcionales (que no sean X e y para <a class="reference internal" href="#term-fit"><span class="xref std std-term">fit</span></a> y métodos similares) se pasan sólo como argumentos de palabra clave y pueden ser reordenados posicionalmente.</p>
</dd>
<dt>Corrección de errores y mejoras</dt><dd><p>Las correcciones de errores y -menos a menudo- las mejoras pueden cambiar el comportamiento de los estimadores, incluyendo las predicciones de un estimador entrenado con los mismos datos y <a class="reference internal" href="#term-random_state"><span class="xref std std-term">random_state</span></a>.  Cuando esto ocurre, intentamos indicarlo claramente en el registro de cambios.</p>
</dd>
<dt>Serialización</dt><dd><p>No aseguramos que el pickling de un estimador en una versión permita que sea unpickled a un modelo equivalente en la versión siguiente.  (En el caso de los estimadores del paquete sklearn, emitimos una advertencia cuando se intenta realizar este unpickling, incluso si es posible que funcione). Ver <a class="reference internal" href="modules/model_persistence.html#persistence-limitations"><span class="std std-ref">Limitaciones de seguridad y mantenimiento</span></a>.</p>
</dd>
<dt><a class="reference internal" href="modules/generated/sklearn.utils.estimator_checks.check_estimator.html#sklearn.utils.estimator_checks.check_estimator" title="sklearn.utils.estimator_checks.check_estimator"><code class="xref py py-func docutils literal notranslate"><span class="pre">utils.estimator_checks.check_estimator</span></code></a></dt><dd><p>Proporcionamos garantías limitadas de compatibilidad con versiones anteriores para las comprobaciones de los estimadores: podemos añadir requisitos adicionales a los estimadores probados con esta función, normalmente cuando éstos se asumían de manera informal pero no se probaban formalmente.</p>
</dd>
</dl>
<p>A pesar de este contrato informal con nuestros usuarios, el software se proporciona tal cual, tal como se indica en la licencia.  Cuando una versión introduce inadvertidamente cambios que no son compatibles con las versiones anteriores, estos se conocen como regresiones de software.</p>
</dd>
<dt id="term-callable">invocable<a class="headerlink" href="#term-callable" title="Permalink to this term">¶</a></dt><dd><p>Una función, una clase o un objeto que implementa el método <code class="docutils literal notranslate"><span class="pre">__call__</span></code>; cualquier cosa que devuelva True cuando sea el argumento de <a class="reference external" href="https://docs.python.org/3/library/functions.html#callable">callable()</a>.</p>
</dd>
<dt id="term-categorical-feature">característica categórica<a class="headerlink" href="#term-categorical-feature" title="Permalink to this term">¶</a></dt><dd><p>Una <a class="reference internal" href="#term-feature"><span class="xref std std-term">característica</span></a> categórica o nominal es aquella que tiene un conjunto finito de valores discretos en la población de datos. Normalmente se representan como columnas de enteros o cadenas. Las cadenas serán rechazadas por la mayoría de los estimadores de scikit-learn, y los enteros serán tratados como ordinales o valores de conteo. Para el uso con la mayoría de los estimadores, las variables categóricas deben ser codificadas one-hot. Algunas excepciones notables son los modelos basados en árboles, como los modelos de bosques aleatorios y de potenciación del gradiente, que suelen funcionar mejor y más rápido con variables categóricas codificadas con números enteros. <a class="reference internal" href="modules/generated/sklearn.preprocessing.OrdinalEncoder.html#sklearn.preprocessing.OrdinalEncoder" title="sklearn.preprocessing.OrdinalEncoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">OrdinalEncoder</span></code></a> ayuda a codificar las características categóricas con valores de cadena como enteros ordinales, y <a class="reference internal" href="modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder" title="sklearn.preprocessing.OneHotEncoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">OneHotEncoder</span></code></a> puede utilizarse para codificar one-hot las características categóricas. Véase también <a class="reference internal" href="modules/preprocessing.html#preprocessing-categorical-features"><span class="std std-ref">Codificación de características categóricas</span></a> y el paquete <a class="reference external" href="https://contrib.scikit-learn.org/categorical-encoding">categorical-encoding</a> para las herramientas relacionadas con la codificación de características categóricas.</p>
</dd>
<dt id="term-clone">clonar<a class="headerlink" href="#term-clone" title="Permalink to this term">¶</a></dt><dt id="term-cloned">clonado<a class="headerlink" href="#term-cloned" title="Permalink to this term">¶</a></dt><dd><p>Para copiar una <a class="reference internal" href="#term-estimator-instance"><span class="xref std std-term">instancia del estimador</span></a> y crear una nueva con <a class="reference internal" href="#term-parameters"><span class="xref std std-term">parámetros</span></a> idénticos, pero sin <a class="reference internal" href="#term-attributes"><span class="xref std std-term">atributos</span></a> ajustados, utilizando <a class="reference internal" href="modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone"><code class="xref py py-func docutils literal notranslate"><span class="pre">clone</span></code></a>.</p>
<p>Cuando se llama a <code class="docutils literal notranslate"><span class="pre">fit</span></code>, un <a class="reference internal" href="#term-meta-estimator"><span class="xref std std-term">meta-estimator</span></a> normalmente clona una instancia de estimador wrapped antes de ajustar la instancia clonada. (Las excepciones, por razones de legado, incluyen <a class="reference internal" href="modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline" title="sklearn.pipeline.Pipeline"><code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code></a> y <a class="reference internal" href="modules/generated/sklearn.pipeline.FeatureUnion.html#sklearn.pipeline.FeatureUnion" title="sklearn.pipeline.FeatureUnion"><code class="xref py py-class docutils literal notranslate"><span class="pre">FeatureUnion</span></code></a>.)</p>
<p>Si el parámetro <code class="docutils literal notranslate"><span class="pre">random_state</span></code> del estimador es un entero (o si el estimador no tiene un parámetro <code class="docutils literal notranslate"><span class="pre">random_state</span></code>), se devuelve un <em>clon exacto</em>: el clon y el estimador original darán exactamente los mismos resultados. En caso contrario, se devuelve un <em>clon estadístico</em>: el clon puede dar resultados diferentes a los del estimador original. Puedes encontrar más detalles en <a class="reference internal" href="common_pitfalls.html#randomness"><span class="std std-ref">Control de aleatoriedad</span></a>.</p>
</dd>
<dt id="term-common-tests">tests comunes<a class="headerlink" href="#term-common-tests" title="Permalink to this term">¶</a></dt><dd><p>Esto se refiere a las pruebas que se ejecutan en casi todas las clases de estimadores en scikit-learn para comprobar que cumplen con las convenciones básicas de la API.  Están disponibles para uso externo a través de <a class="reference internal" href="modules/generated/sklearn.utils.estimator_checks.check_estimator.html#sklearn.utils.estimator_checks.check_estimator" title="sklearn.utils.estimator_checks.check_estimator"><code class="xref py py-func docutils literal notranslate"><span class="pre">utils.estimator_checks.check_estimator</span></code></a>, con la mayor parte de la implementación en <code class="docutils literal notranslate"><span class="pre">sklearn/utils/estimator_checks.py</span></code>.</p>
<p>Nota: Algunas excepciones al régimen común de pruebas son actualmente de codificación fija en la biblioteca, pero esperamos reemplazar esto marcando comportamientos excepcionales en el estimador usando <a class="reference internal" href="#term-estimator-tags"><span class="xref std std-term">etiquetas del estimador</span></a> (semánticas).</p>
</dd>
<dt id="term-deprecation">obsolescencia<a class="headerlink" href="#term-deprecation" title="Permalink to this term">¶</a></dt><dd><p>Usamos la obsolescencia para violar lentamente nuestras garantías de <a class="reference internal" href="#term-backwards-compatibility"><span class="xref std std-term">compatibilidad con versiones anteriores</span></a>, generalmente para:</p>
<ul class="simple">
<li><p>cambiar el valor por defecto de un parámetro; o</p></li>
<li><p>eliminar un parámetro, atributo, método, clase, etc.</p></li>
</ul>
<p>Normalmente emitiremos una advertencia cuando se utilice un elemento obsoleto aunque puede haber limitaciones en este sentido.  Por ejemplo, emitiremos una advertencia cuando alguien establezca un parámetro que haya sido obsoleto, pero puede que no lo hagamos cuando accedan al atributo de ese parámetro en la instancia del estimador.</p>
<p>Ver la <a class="reference internal" href="developers/contributing.html#contributing-deprecation"><span class="std std-ref">Guía de Colaboradores</span></a>.</p>
</dd>
<dt id="term-dimensionality">dimensionalidad<a class="headerlink" href="#term-dimensionality" title="Permalink to this term">¶</a></dt><dd><p>Puede usarse para referirse al número de <a class="reference internal" href="#term-features"><span class="xref std std-term">características</span></a> (es decir, <a class="reference internal" href="#term-n_features"><span class="xref std std-term">n_features</span></a>), o de columnas en una matriz de características 2D. Sin embargo, las dimensiones también se utilizan para referirse a la longitud de la forma de un arreglo NumPy, distinguiendo un arreglo 1D de una matriz 2D.</p>
</dd>
<dt id="term-docstring">cadena de documentación<a class="headerlink" href="#term-docstring" title="Permalink to this term">¶</a></dt><dd><p>La documentación incrustada para un módulo, clase, función, etc., normalmente en el código como una cadena al principio de la definición del objeto, y accesible como el atributo <code class="docutils literal notranslate"><span class="pre">__doc__</span></code> del objeto.</p>
<p>Intentamos adherirnos a la <a class="reference external" href="https://www.python.org/dev/peps/pep-0257/">PEP257</a>, y seguir <a class="reference external" href="https://numpydoc.readthedocs.io/en/latest/format.html">las convenciones de NumpyDoc</a>.</p>
</dd>
<dt id="term-double-underscore">doble guión bajo<a class="headerlink" href="#term-double-underscore" title="Permalink to this term">¶</a></dt><dt id="term-double-underscore-notation">notación de doble guión bajo<a class="headerlink" href="#term-double-underscore-notation" title="Permalink to this term">¶</a></dt><dd><p>Cuando se especifican los nombres de los parámetros para los estimadores anidados, se puede utilizar <code class="docutils literal notranslate"><span class="pre">__</span></code> para separar entre padre e hijo en algunos contextos. El uso más común es cuando se establecen parámetros a través de un metaestimador con <a class="reference internal" href="#term-set_params"><span class="xref std std-term">set_params</span></a> y por lo tanto en la especificación de una cuadrícula de búsqueda en <a class="reference internal" href="modules/grid_search.html#grid-search"><span class="std std-ref">la búsqueda de parámetros</span></a>. Ver <a class="reference internal" href="#term-parameter"><span class="xref std std-term">parámetro</span></a>. También se utiliza en <a class="reference internal" href="modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline.fit" title="sklearn.pipeline.Pipeline.fit"><code class="xref py py-meth docutils literal notranslate"><span class="pre">pipeline.Pipeline.fit</span></code></a> para pasar <a class="reference internal" href="#term-sample-properties"><span class="xref std std-term">propiedades muestrales</span></a> a los métodos <code class="docutils literal notranslate"><span class="pre">fit</span></code> de los estimadores en el pipeline.</p>
</dd>
<dt id="term-dtype">dtype<a class="headerlink" href="#term-dtype" title="Permalink to this term">¶</a></dt><dt id="term-data-type">tipo de dato<a class="headerlink" href="#term-data-type" title="Permalink to this term">¶</a></dt><dd><p>Los arreglos de NumPy asumen un tipo de datos homogéneo en todo momento, disponible en el atributo <code class="docutils literal notranslate"><span class="pre">.dtype</span></code> de un arreglo (o matriz dispersa). Generalmente asumimos tipos de datos simples para los datos de scikit-learn: de punto flotante (float) o entero. Podemos admitir tipos de datos de objeto o de cadena para los arreglos antes de codificarlos o vectorizarlos.  Nuestros estimadores no funcionan con arreglos struct, por ejemplo.</p>
<p>Nuestra documentación puede dar a veces información sobre la precisión del dtype, por ejemplo <code class="docutils literal notranslate"><span class="pre">np.int32</span></code>, <code class="docutils literal notranslate"><span class="pre">np.int64</span></code>, etc. Cuando se proporciona la precisión, se refiere al dtype de NumPy. Si se utiliza una precisión arbitraria, la documentación se referirá al dtype <code class="docutils literal notranslate"><span class="pre">integer</span></code> o <code class="docutils literal notranslate"><span class="pre">floating</span></code>. Ten en cuenta que en este caso, la precisión puede ser dependiente de la plataforma. El dtype <code class="docutils literal notranslate"><span class="pre">numeric</span></code> se refiere a aceptar tanto <code class="docutils literal notranslate"><span class="pre">integer</span></code> como <code class="docutils literal notranslate"><span class="pre">floating</span></code>.</p>
<p>TODO: Mencionar incidencias de eficiencia y precisión; política de reparto.</p>
</dd>
<dt id="term-duck-typing">duck typing<a class="headerlink" href="#term-duck-typing" title="Permalink to this term">¶</a></dt><dd><p>Intentamos aplicar <a class="reference external" href="https://en.wikipedia.org/wiki/Duck_typing">duck typing</a> para determinar cómo manejar algunos valores de entrada (por ejemplo, comprobar si un estimador dado es un clasificador).  Es decir, evitamos utilizar <code class="docutils literal notranslate"><span class="pre">isinstance</span></code> siempre que sea posible, y nos basamos en la presencia o ausencia de atributos para determinar el comportamiento de un objeto.  Es necesario hacer algunas matizaciones cuando se sigue este enfoque:</p>
<ul>
<li><p>Para algunos estimadores, un atributo sólo puede estar disponible una vez que es <a class="reference internal" href="#term-fitted"><span class="xref std std-term">ajustado</span></a>.  Por ejemplo, no podemos determinar a priori si <a class="reference internal" href="#term-predict_proba"><span class="xref std std-term">predict_proba</span></a> está disponible en una búsqueda en cuadrícula en la que la cuadrícula incluye la alternancia entre un predictor probabilístico y uno no probabilístico en el último paso del pipeline.  A continuación, sólo podemos determinar si <code class="docutils literal notranslate"><span class="pre">clf</span></code> es probabilístico después de ajustarlo a algunos datos:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">SGDClassifier</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">SGDClassifier</span><span class="p">(),</span>
<span class="gp">... </span>                   <span class="n">param_grid</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;loss&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;log&#39;</span><span class="p">,</span> <span class="s1">&#39;hinge&#39;</span><span class="p">]})</span>
</pre></div>
</div>
<p>Esto significa que sólo podemos comprobar los atributos duck-typed después del ajuste, y que debemos tener cuidado para que los <a class="reference internal" href="#term-meta-estimators"><span class="xref std std-term">meta estimadores</span></a> sólo presenten atributos según el estado del estimador subyacente después del ajuste.</p>
</li>
<li><p>Comprobar si un atributo está presente (usando <code class="docutils literal notranslate"><span class="pre">hasattr</span></code>) es en general tan costoso como obtener el atributo (<code class="docutils literal notranslate"><span class="pre">getattr</span></code> o notación de puntos).  En algunos casos, obtener el atributo puede ser realmente costoso (por ejemplo, para algunas implementaciones de <a class="reference internal" href="#term-feature_importances_"><span class="xref std std-term">feature_importances_</span></a>, lo que puede sugerir que se trata de un defecto de diseño de la API).  Así que el código que ejecuta <code class="docutils literal notranslate"><span class="pre">hasattr</span></code> seguido de <code class="docutils literal notranslate"><span class="pre">getattr</span></code> debe ser evitado; <code class="docutils literal notranslate"><span class="pre">getattr</span></code> dentro de un bloque try-except es preferible.</p></li>
<li><p>Para determinar algunos aspectos de las expectativas de un estimador o el soporte para alguna característica, utilizamos <a class="reference internal" href="#term-estimator-tags"><span class="xref std std-term">etiquetas del estimador</span></a> en lugar de duck typing.</p></li>
</ul>
</dd>
<dt id="term-early-stopping">parada anticipada<a class="headerlink" href="#term-early-stopping" title="Permalink to this term">¶</a></dt><dd><p>Consiste en detener un método de optimización iterativo antes de la convergencia de la pérdida asociada al entrenamiento, para evitar el sobreajuste. Por lo general, esto se hace controlando la puntuación de generalización en un conjunto de validación. Cuando está disponible, se activa a través del parámetro <code class="docutils literal notranslate"><span class="pre">early_stopping</span></code> o estableciendo un <a class="reference internal" href="#term-n_iter_no_change"><span class="xref std std-term">n_iter_no_change</span></a> positivo.</p>
</dd>
<dt id="term-estimator-instance">instancia del estimador<a class="headerlink" href="#term-estimator-instance" title="Permalink to this term">¶</a></dt><dd><p>A veces utilizamos esta terminología para distinguir una clase <a class="reference internal" href="#term-estimator"><span class="xref std std-term">estimador</span></a> de una instancia construida. Por ejemplo, en lo siguiente, <code class="docutils literal notranslate"><span class="pre">cls</span></code> es una clase estimador, mientras que <code class="docutils literal notranslate"><span class="pre">est1</span></code> y <code class="docutils literal notranslate"><span class="pre">est2</span></code> son instancias:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="bp">cls</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span>
<span class="n">est1</span> <span class="o">=</span> <span class="bp">cls</span><span class="p">()</span>
<span class="n">est2</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">()</span>
</pre></div>
</div>
</dd>
<dt id="term-examples">ejemplos<a class="headerlink" href="#term-examples" title="Permalink to this term">¶</a></dt><dd><p>Intentamos dar ejemplos de uso básico para la mayoría de las funciones y clases de la API:</p>
<ul class="simple">
<li><p>como doctests en sus cadenas de documentación (es decir, dentro del propio código de la biblioteca <code class="docutils literal notranslate"><span class="pre">sklearn/</span></code>).</p></li>
<li><p>como ejemplos en la <a class="reference internal" href="auto_examples/index.html#general-examples"><span class="std std-ref">galería de ejemplos</span></a> renderizada (usando <a class="reference external" href="https://sphinx-gallery.readthedocs.io/">sphinx-gallery</a>) a partir de scripts en el directorio <code class="docutils literal notranslate"><span class="pre">examples/</span></code>, ejemplificando características o parámetros clave del estimador/función.  Estos también deben ser referenciados desde el Manual de Usuario.</p></li>
<li><p>a veces en el <a class="reference internal" href="user_guide.html#user-guide"><span class="std std-ref">Manual de Usuario</span></a> (construido a partir de <code class="docutils literal notranslate"><span class="pre">doc/</span></code>) junto a una descripción técnica del estimador.</p></li>
</ul>
</dd>
<dt id="term-experimental">experimental<a class="headerlink" href="#term-experimental" title="Permalink to this term">¶</a></dt><dd><p>Una herramienta experimental ya es utilizable, pero su API pública, como los valores de los parámetros por defecto o los atributos ajustados, sigue estando sujeta a cambios en futuras versiones sin la habitual política de advertencias de <a class="reference internal" href="#term-deprecation"><span class="xref std std-term">obsolescencia</span></a>.</p>
</dd>
<dt id="term-evaluation-metric">métrica de evaluación<a class="headerlink" href="#term-evaluation-metric" title="Permalink to this term">¶</a></dt><dt id="term-evaluation-metrics">métricas de evaluación<a class="headerlink" href="#term-evaluation-metrics" title="Permalink to this term">¶</a></dt><dd><p>Las métricas de evaluación dan una medida del rendimiento de un modelo.  Podemos utilizar este término específicamente para referirnos a las funciones de <code class="xref py py-mod docutils literal notranslate"><span class="pre">metrics</span></code> (sin tener en cuenta <code class="xref py py-mod docutils literal notranslate"><span class="pre">metrics.pairwise</span></code>), a diferencia del método <a class="reference internal" href="#term-score"><span class="xref std std-term">score</span></a> y la API <a class="reference internal" href="#term-scoring"><span class="xref std std-term">scoring</span></a> utilizada en la validación-cruzada. Véase <a class="reference internal" href="modules/model_evaluation.html#model-evaluation"><span class="std std-ref">Métricas y puntuación: cuantificar la calidad de las predicciones</span></a>.</p>
<p>Estas funciones suelen aceptar una verdad fundamental (o los datos crudos en los que la métrica evalúa el agrupamiento sin una verdad fundamental) y una predicción, ya sea la salida de <a class="reference internal" href="#term-predict"><span class="xref std std-term">predict</span></a> (<code class="docutils literal notranslate"><span class="pre">y_pred</span></code>), de <a class="reference internal" href="#term-predict_proba"><span class="xref std std-term">predict_proba</span></a> (<code class="docutils literal notranslate"><span class="pre">y_proba</span></code>), o de una función de puntuación arbitraria incluyendo <a class="reference internal" href="#term-decision_function"><span class="xref std std-term">decision_function</span></a> (<code class="docutils literal notranslate"><span class="pre">y_score</span></code>). Las funciones suelen tener un nombre que termina con <code class="docutils literal notranslate"><span class="pre">_score</span></code> si una puntuación mayor indica un modelo mejor, y <code class="docutils literal notranslate"><span class="pre">_loss</span></code> si una puntuación menor indica un modelo mejor.  Esta diversidad de interfaz motiva la API de puntuación.</p>
<p>Tenga en cuenta que algunos estimadores pueden calcular métricas que no están incluidas en <code class="xref py py-mod docutils literal notranslate"><span class="pre">metrics</span></code> y que son específicas del estimador, especialmente las verosimilitudes del modelo.</p>
</dd>
<dt id="term-estimator-tags">etiquetas del estimador<a class="headerlink" href="#term-estimator-tags" title="Permalink to this term">¶</a></dt><dd><p>Una característica propuesta (por ejemplo, <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/issues/8022">#8022</a>) por la cual las capacidades de un estimador se describen a través de un conjunto de etiquetas semánticas. Esto permitiría algunos comportamientos en tiempo de ejecución basados en la inspección del estimador, pero también permite que cada estimador se someta a las pruebas de invarianza apropiadas mientras se exceptúa de otros <a class="reference internal" href="#term-common-tests"><span class="xref std std-term">tests comunes</span></a>.</p>
<p>Algunos aspectos de las etiquetas del estimador se determinan actualmente a través del <a class="reference internal" href="#term-duck-typing"><span class="xref std std-term">duck typing</span></a> de métodos como <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code> y a través de algunos atributos especiales en los objetos de los estimadores:</p>
<dl class="glossary">
<dt id="term-_estimator_type"><code class="docutils literal notranslate"><span class="pre">_estimator_type</span></code><a class="headerlink" href="#term-_estimator_type" title="Permalink to this term">¶</a></dt><dd><p>Este atributo con valor de cadena identifica un estimador como clasificador, regresor, etc. Se establece mediante mixins como <a class="reference internal" href="modules/generated/sklearn.base.ClassifierMixin.html#sklearn.base.ClassifierMixin" title="sklearn.base.ClassifierMixin"><code class="xref py py-class docutils literal notranslate"><span class="pre">base.ClassifierMixin</span></code></a>, pero debe adoptarse más explícitamente en un <a class="reference internal" href="#term-meta-estimator"><span class="xref std std-term">meta-estimator</span></a>. Su valor debe comprobarse normalmente mediante un helper como <a class="reference internal" href="modules/generated/sklearn.base.is_classifier.html#sklearn.base.is_classifier" title="sklearn.base.is_classifier"><code class="xref py py-func docutils literal notranslate"><span class="pre">base.is_classifier</span></code></a>.</p>
</dd>
<dt id="term-_pairwise"><code class="docutils literal notranslate"><span class="pre">_pairwise</span></code><a class="headerlink" href="#term-_pairwise" title="Permalink to this term">¶</a></dt><dd><p>Este atributo booleano indica si los datos (<code class="docutils literal notranslate"><span class="pre">X</span></code>) pasados a <code class="xref py py-func docutils literal notranslate"><span class="pre">fit</span></code> y métodos similares consisten en medidas de pares sobre muestras en lugar de una representación de características para cada muestra.  Suele ser <code class="docutils literal notranslate"><span class="pre">True</span></code> cuando un estimador tiene un parámetro <code class="docutils literal notranslate"><span class="pre">metric</span></code> o <code class="docutils literal notranslate"><span class="pre">affinity</span></code> o <code class="docutils literal notranslate"><span class="pre">kernel</span></code> con valor <code class="docutils literal notranslate"><span class="pre">precomputed</span></code>. Su propósito principal es que cuando un <a class="reference internal" href="#term-meta-estimator"><span class="xref std std-term">meta-estimator</span></a> extrae una submuestra de datos destinada a un estimador por pares, los datos necesitan ser indexados en ambos ejes, mientras que otros datos son indexados sólo en el primer eje.</p>
<div class="deprecated">
<p><span class="versionmodified deprecated">Obsoleto desde la versión 0.24: </span>El atributo _pairwise queda obsoleto en 0.24. A partir de la versión 1.1 (cambio de nombre de la versión 0.26), se utilizará la etiqueta del estimador <code class="docutils literal notranslate"><span class="pre">pairwise</span></code>.</p>
</div>
</dd>
</dl>
<p>Para obtener información más detallada, ver <a class="reference internal" href="developers/develop.html#estimator-tags"><span class="std std-ref">Etiquetas de Estimador</span></a>.</p>
</dd>
<dt id="term-feature">característica<a class="headerlink" href="#term-feature" title="Permalink to this term">¶</a></dt><dt id="term-features">características<a class="headerlink" href="#term-features" title="Permalink to this term">¶</a></dt><dt id="term-feature-vector">vector de características<a class="headerlink" href="#term-feature-vector" title="Permalink to this term">¶</a></dt><dd><p>En el resumen, una característica es una función (en su sentido matemático) que asigna un objeto muestreado a una cantidad numérica o categórica. El término «característica» también se utiliza comúnmente para referirse a estas cantidades, siendo los elementos individuales de un vector que representa una muestra. En una matriz de datos, las características se representan como columnas: cada columna contiene el resultado de aplicar una función de característica a un conjunto de muestras.</p>
<p>En otras partes, las características se conocen como atributos, predictores, regresores o variables independientes.</p>
<p>Casi todos los estimadores de scikit-learn asumen que las características son numéricas, finitas y no faltan, incluso cuando tienen dominios y distribuciones semánticamente distintas (categóricas, ordinales, de valores de conteo, de valores reales, de intervalo). Ver también <a class="reference internal" href="#term-categorical-feature"><span class="xref std std-term">característica categórica</span></a> y <a class="reference internal" href="#term-missing-values"><span class="xref std std-term">valores faltantes</span></a>.</p>
<p><code class="docutils literal notranslate"><span class="pre">n_features</span></code> indica el número de características de un conjunto de datos.</p>
</dd>
<dt id="term-fitting">ajuste<a class="headerlink" href="#term-fitting" title="Permalink to this term">¶</a></dt><dd><p>Llamar a <a class="reference internal" href="#term-fit"><span class="xref std std-term">fit</span></a> (o <a class="reference internal" href="#term-fit_transform"><span class="xref std std-term">fit_transform</span></a>, <a class="reference internal" href="#term-fit_predict"><span class="xref std std-term">fit_predict</span></a>, etc.) en un estimador.</p>
</dd>
<dt id="term-fitted">ajustado<a class="headerlink" href="#term-fitted" title="Permalink to this term">¶</a></dt><dd><p>El estado de un estimador después del <a class="reference internal" href="#term-fitting"><span class="xref std std-term">ajuste</span></a>.</p>
<p>No existe un procedimiento convencional para comprobar si un estimador está ajustado.  Sin embargo, un estimador que no está ajustado:</p>
<ul class="simple">
<li><p>debería emitir <a class="reference internal" href="modules/generated/sklearn.exceptions.NotFittedError.html#sklearn.exceptions.NotFittedError" title="sklearn.exceptions.NotFittedError"><code class="xref py py-class docutils literal notranslate"><span class="pre">exceptions.NotFittedError</span></code></a> cuando se llama a un método de predicción (<a class="reference internal" href="#term-predict"><span class="xref std std-term">predict</span></a>, <a class="reference internal" href="#term-transform"><span class="xref std std-term">transform</span></a>, etc.). (<a class="reference internal" href="modules/generated/sklearn.utils.validation.check_is_fitted.html#sklearn.utils.validation.check_is_fitted" title="sklearn.utils.validation.check_is_fitted"><code class="xref py py-func docutils literal notranslate"><span class="pre">utils.validation.check_is_fitted</span></code></a> se utiliza internamente para este propósito).</p></li>
<li><p>no debe tener <a class="reference internal" href="#term-attributes"><span class="xref std std-term">atributos</span></a> que comiencen con un carácter alfabético y termine con un guión bajo. (Ten en cuenta que un descriptor para el atributo todavía puede estar presente en la clase, pero hasattr debe devolver False).</p></li>
</ul>
</dd>
<dt id="term-function">función<a class="headerlink" href="#term-function" title="Permalink to this term">¶</a></dt><dd><p>Proporcionamos interfaces de funciones ad hoc para muchos algoritmos, mientras que las clases de <a class="reference internal" href="#term-estimator"><span class="xref std std-term">estimator</span></a> proporcionan una interfaz más consistente.</p>
<p>En particular, scikit-learn puede proporcionar una interfaz de función que ajusta un modelo a algunos datos y devuelve los parámetros del modelo entrenado, como en <a class="reference internal" href="modules/generated/sklearn.linear_model.enet_path.html#sklearn.linear_model.enet_path" title="sklearn.linear_model.enet_path"><code class="xref py py-func docutils literal notranslate"><span class="pre">linear_model.enet_path</span></code></a>.  Para los modelos transductivos, también devuelve las etiquetas de embedding o de conglomerado, como en <a class="reference internal" href="modules/generated/sklearn.manifold.spectral_embedding.html#sklearn.manifold.spectral_embedding" title="sklearn.manifold.spectral_embedding"><code class="xref py py-func docutils literal notranslate"><span class="pre">manifold.spectral_embedding</span></code></a> o <a class="reference internal" href="modules/generated/dbscan-function.html#sklearn.cluster.dbscan" title="sklearn.cluster.dbscan"><code class="xref py py-func docutils literal notranslate"><span class="pre">cluster.dbscan</span></code></a>.  Muchos transformadores de preprocesamiento también proporcionan una interfaz de función, similar a la llamada a <a class="reference internal" href="#term-fit_transform"><span class="xref std std-term">fit_transform</span></a>, como en <a class="reference internal" href="modules/generated/sklearn.preprocessing.maxabs_scale.html#sklearn.preprocessing.maxabs_scale" title="sklearn.preprocessing.maxabs_scale"><code class="xref py py-func docutils literal notranslate"><span class="pre">preprocessing.maxabs_scale</span></code></a>.  Los usuarios deben tener cuidado de evitar <a class="reference internal" href="#term-data-leakage"><span class="xref std std-term">fuga de datos</span></a> cuando hagan uso de estas funciones equivalentes a <code class="docutils literal notranslate"><span class="pre">fit_transform</span></code>.</p>
<p>No tenemos una política estricta sobre cuándo proporcionar o no formas de función de los estimadores, pero los encargados del mantenimiento considerar la coherencia con las interfaces existentes, y si proporcionar una función podría apartar a los usuarios de las mejores prácticas (en lo que respecta a la fuga de datos, etc.).</p>
</dd>
<dt id="term-gallery">galería<a class="headerlink" href="#term-gallery" title="Permalink to this term">¶</a></dt><dd><p>Ver <a class="reference internal" href="#term-examples"><span class="xref std std-term">ejemplos</span></a>.</p>
</dd>
<dt id="term-hyperparameter">hiperparámetro<a class="headerlink" href="#term-hyperparameter" title="Permalink to this term">¶</a></dt><dt id="term-hyper-parameter">hiper-parámetro<a class="headerlink" href="#term-hyper-parameter" title="Permalink to this term">¶</a></dt><dd><p>Ver <a class="reference internal" href="#term-parameter"><span class="xref std std-term">parámetro</span></a>.</p>
</dd>
<dt id="term-impute">imputar<a class="headerlink" href="#term-impute" title="Permalink to this term">¶</a></dt><dt id="term-imputation">imputación<a class="headerlink" href="#term-imputation" title="Permalink to this term">¶</a></dt><dd><p>La mayoría de los algoritmos de aprendizaje automático requieren que sus entradas no tengan <a class="reference internal" href="#term-missing-values"><span class="xref std std-term">valores faltantes</span></a>, y no funcionarán si se viola este requisito. Los algoritmos que intentan rellenar (o imputar) los valores faltantes se denominan algoritmos de imputación.</p>
</dd>
<dt id="term-indexable">indexable<a class="headerlink" href="#term-indexable" title="Permalink to this term">¶</a></dt><dd><p>Un <a class="reference internal" href="#term-array-like"><span class="xref std std-term">array-like</span></a>, <a class="reference internal" href="#term-sparse-matrix"><span class="xref std std-term">matriz dispersa</span></a>, DataFrame de pandas o secuencia (generalmente una lista).</p>
</dd>
<dt id="term-induction">inducción<a class="headerlink" href="#term-induction" title="Permalink to this term">¶</a></dt><dt id="term-inductive">inductivo<a class="headerlink" href="#term-inductive" title="Permalink to this term">¶</a></dt><dd><p>El aprendizaje automático inductivo (en contraste con <a class="reference internal" href="#term-transductive"><span class="xref std std-term">transductivo</span></a>) construye un modelo de algunos datos que luego puede aplicarse a nuevas instancias. La mayoría de los estimadores en scikit-learn son inductivos, con métodos <a class="reference internal" href="#term-predict"><span class="xref std std-term">predict</span></a> y/o <a class="reference internal" href="#term-transform"><span class="xref std std-term">transform</span></a>.</p>
</dd>
<dt id="term-joblib">joblib<a class="headerlink" href="#term-joblib" title="Permalink to this term">¶</a></dt><dd><p>Una biblioteca de Python (<a class="reference external" href="https://joblib.readthedocs.io">https://joblib.readthedocs.io</a>) utilizada en scikit-learn para facilitar el paralelismo simple y el almacenamiento en caché.  Joblib está orientada a trabajar eficientemente con arreglos de numpy, por ejemplo mediante el uso de <a class="reference internal" href="#term-memory-mapping"><span class="xref std std-term">mapeo de memoria</span></a>. Ver <a class="reference internal" href="computing/parallelism.html#parallelism"><span class="std std-ref">Paralelismo</span></a> para más información.</p>
</dd>
<dt id="term-label-indicator-matrix">matriz indicadora de etiqueta<a class="headerlink" href="#term-label-indicator-matrix" title="Permalink to this term">¶</a></dt><dt id="term-multilabel-indicator-matrix">matriz indicatriz multietiqueta<a class="headerlink" href="#term-multilabel-indicator-matrix" title="Permalink to this term">¶</a></dt><dt id="term-multilabel-indicator-matrices">matrices indicatrices multietiqueta<a class="headerlink" href="#term-multilabel-indicator-matrices" title="Permalink to this term">¶</a></dt><dd><p>El formato utilizado para representar datos multietiqueta, en el que cada fila de un arreglo 2D o matriz dispersa corresponde a una muestra, cada columna corresponde a una clase, y cada elemento es 1 si la muestra está etiquetada con la clase y 0 si no es así.</p>
</dd>
<dt id="term-leakage">fuga<a class="headerlink" href="#term-leakage" title="Permalink to this term">¶</a></dt><dt id="term-data-leakage">fuga de datos<a class="headerlink" href="#term-data-leakage" title="Permalink to this term">¶</a></dt><dd><p>Un problema en la validación cruzada en el que el rendimiento de la generalización puede sobreestimarse ya que el conocimiento de los datos de prueba se incluyó inadvertidamente en el entrenamiento de un modelo.  Este es un riesgo, por ejemplo, cuando se aplica un <a class="reference internal" href="#term-transformer"><span class="xref std std-term">transformador</span></a> a la totalidad de un conjunto de datos en lugar de a cada porción de entrenamiento en una división de validación-cruzada.</p>
<p>Nuestro objetivo es proporcionar interfaces (como <code class="xref py py-mod docutils literal notranslate"><span class="pre">pipeline</span></code> y <code class="xref py py-mod docutils literal notranslate"><span class="pre">model_selection</span></code>) que protejan al usuario de la fuga de datos.</p>
</dd>
<dt id="term-memmapping">mapeo de mem<a class="headerlink" href="#term-memmapping" title="Permalink to this term">¶</a></dt><dt id="term-memory-map">mapa de memoria<a class="headerlink" href="#term-memory-map" title="Permalink to this term">¶</a></dt><dt id="term-memory-mapping">mapeo de memoria<a class="headerlink" href="#term-memory-mapping" title="Permalink to this term">¶</a></dt><dd><p>Una estrategia de eficiencia de memoria que mantiene los datos en el disco en lugar de copiarlos en la memoria principal.  Los mapas de memoria pueden ser creados para arreglos que pueden ser leídos, escritos, o ambos, usando <a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.memmap.html#numpy.memmap" title="(en NumPy versión 1.21)"><code class="xref py py-obj docutils literal notranslate"><span class="pre">numpy.memmap</span></code></a>. Cuando se utiliza <a class="reference internal" href="#term-joblib"><span class="xref std std-term">joblib</span></a> para paralelizar las operaciones en scikit-learn, se pueden crear automáticamente mapas de memoria para arreglos grandes para reducir la sobrecarga de duplicación de memoria en el multiprocesamiento.</p>
</dd>
<dt id="term-missing-values">valores faltantes<a class="headerlink" href="#term-missing-values" title="Permalink to this term">¶</a></dt><dd><p>La mayoría de los estimadores de scikit-learn no trabajan con valores faltantes. Cuando lo hacen (por ejemplo, en <a class="reference internal" href="modules/generated/sklearn.impute.SimpleImputer.html#sklearn.impute.SimpleImputer" title="sklearn.impute.SimpleImputer"><code class="xref py py-class docutils literal notranslate"><span class="pre">impute.SimpleImputer</span></code></a>), NaN es la representación preferida de los valores faltantes en los arreglos de punto flotante (float).  Si el arreglo tiene un dtype entero, NaN no se puede representar. Por esta razón, apoyamos la especificación de otro valor <code class="docutils literal notranslate"><span class="pre">missing_values</span></code> cuando la <a class="reference internal" href="#term-imputation"><span class="xref std std-term">imputación</span></a> o el aprendizaje se puede realizar en el espacio de enteros. Los <a class="reference internal" href="#term-unlabeled-data"><span class="xref std std-term">datos no etiquetados</span></a> son un caso especial de valores faltantes en el <a class="reference internal" href="#term-target"><span class="xref std std-term">objetivo</span></a>.</p>
</dd>
<dt id="term-n_features"><code class="docutils literal notranslate"><span class="pre">n_features</span></code><a class="headerlink" href="#term-n_features" title="Permalink to this term">¶</a></dt><dd><p>El número de <a class="reference internal" href="#term-features"><span class="xref std std-term">características</span></a>.</p>
</dd>
<dt id="term-n_outputs"><code class="docutils literal notranslate"><span class="pre">n_outputs</span></code><a class="headerlink" href="#term-n_outputs" title="Permalink to this term">¶</a></dt><dd><p>El número de <a class="reference internal" href="#term-outputs"><span class="xref std std-term">salidas</span></a> en el <a class="reference internal" href="#term-target"><span class="xref std std-term">objetivo</span></a>.</p>
</dd>
<dt id="term-n_samples"><code class="docutils literal notranslate"><span class="pre">n_samples</span></code><a class="headerlink" href="#term-n_samples" title="Permalink to this term">¶</a></dt><dd><p>El número de <a class="reference internal" href="#term-samples"><span class="xref std std-term">muestras</span></a>.</p>
</dd>
<dt id="term-n_targets"><code class="docutils literal notranslate"><span class="pre">n_targets</span></code><a class="headerlink" href="#term-n_targets" title="Permalink to this term">¶</a></dt><dd><p>Sinónimo de <a class="reference internal" href="#term-n_outputs"><span class="xref std std-term">n_outputs</span></a>.</p>
</dd>
<dt id="term-narrative-docs">documentos narrativos<a class="headerlink" href="#term-narrative-docs" title="Permalink to this term">¶</a></dt><dt id="term-narrative-documentation">documentación narrativa<a class="headerlink" href="#term-narrative-documentation" title="Permalink to this term">¶</a></dt><dd><p>Un alias para <a class="reference internal" href="user_guide.html#user-guide"><span class="std std-ref">Manual de Usuario</span></a>, es decir, la documentación escrita en <code class="docutils literal notranslate"><span class="pre">doc/modules/</span></code>. A diferencia de la <a class="reference internal" href="modules/classes.html#api-ref"><span class="std std-ref">Referencia API</span></a> proporcionada a través de cadenas de documentación, el Manual de Usuario tiene como objetivo:</p>
<ul class="simple">
<li><p>agrupa las herramientas proporcionadas por scikit-learn de forma temática o en términos de uso;</p></li>
<li><p>dar motivos de por qué alguien utilizaría cada herramienta en particular, a menudo mediante la comparación;</p></li>
<li><p>proporciona descripciones tanto intuitivas como técnicas de las herramientas;</p></li>
<li><p>proporciona o enlaza con <a class="reference internal" href="#term-examples"><span class="xref std std-term">ejemplos</span></a> de uso de las características clave de una herramienta.</p></li>
</ul>
</dd>
<dt id="term-np">np<a class="headerlink" href="#term-np" title="Permalink to this term">¶</a></dt><dd><p>Una abreviatura de Numpy debido a la declaración de importación convencional:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</pre></div>
</div>
</dd>
<dt id="term-online-learning">aprendizaje en línea<a class="headerlink" href="#term-online-learning" title="Permalink to this term">¶</a></dt><dd><p>Donde un modelo se actualiza de forma iterativa recibiendo cada lote de <a class="reference internal" href="#term-targets"><span class="xref std std-term">objetivos</span></a> de verdad fundamental poco después de hacer predicciones sobre el lote de datos correspondiente. Intrínsecamente, el modelo debe ser utilizable para la predicción después de cada lote. Ver <a class="reference internal" href="#term-partial_fit"><span class="xref std std-term">partial_fit</span></a>.</p>
</dd>
<dt id="term-out-of-core">fuera del núcleo<a class="headerlink" href="#term-out-of-core" title="Permalink to this term">¶</a></dt><dd><p>Una estrategia de eficiencia en la que no se almacenan todos los datos en la memoria principal a la vez, normalmente realizando el aprendizaje en lotes de datos. Ver <a class="reference internal" href="#term-partial_fit"><span class="xref std std-term">partial_fit</span></a>.</p>
</dd>
<dt id="term-outputs">salidas<a class="headerlink" href="#term-outputs" title="Permalink to this term">¶</a></dt><dd><p>Variables escalares/categóricas individuales por muestra en el <a class="reference internal" href="#term-target"><span class="xref std std-term">objetivo</span></a>.  Por ejemplo, en la clasificación multietiqueta cada etiqueta posible corresponde a una salida binaria. También se denominan <em>respuestas</em>, <em>tareas</em> u <em>objetivos</em>. Ver <a class="reference internal" href="#term-multioutput-multiclass"><span class="xref std std-term">multiclase multisalida</span></a> y <a class="reference internal" href="#term-continuous-multioutput"><span class="xref std std-term">salida múltiple continua</span></a>.</p>
</dd>
<dt id="term-pair">par<a class="headerlink" href="#term-pair" title="Permalink to this term">¶</a></dt><dd><p>Una tupla de longitud dos.</p>
</dd>
<dt id="term-parameter">parámetro<a class="headerlink" href="#term-parameter" title="Permalink to this term">¶</a></dt><dt id="term-parameters">parámetros<a class="headerlink" href="#term-parameters" title="Permalink to this term">¶</a></dt><dt id="term-param">param<a class="headerlink" href="#term-param" title="Permalink to this term">¶</a></dt><dt id="term-params">params<a class="headerlink" href="#term-params" title="Permalink to this term">¶</a></dt><dd><p>La mayoría de las veces utilizamos <em>parámetro</em> para referirnos a los aspectos de un estimador que pueden especificarse en su construcción. Por ejemplo, <code class="docutils literal notranslate"><span class="pre">max_depth</span></code> y <code class="docutils literal notranslate"><span class="pre">random_state</span></code> son parámetros de <code class="xref py py-class docutils literal notranslate"><span class="pre">RandomForestClassifier</span></code>. Los parámetros del constructor de un estimador se almacenan sin modificar como atributos en la instancia del estimador, y convencionalmente empiezan con un carácter alfabético y terminan con un carácter alfanumérico.  Los parámetros del constructor de cada estimador se describen en la cadena de documentación del estimador.</p>
<p>No utilizamos parámetros en el sentido estadístico, en el que los parámetros son valores que especifican un modelo y pueden estimarse a partir de los datos. Lo que llamamos parámetros podría ser lo que los estadísticos llaman hiperparámetros del modelo: aspectos para configurar la estructura del modelo que a menudo no se aprenden directamente de los datos. Sin embargo, nuestros parámetros también se utilizan para prescribir operaciones de modelado que no afectan al modelo entrenado, como <a class="reference internal" href="#term-n_jobs"><span class="xref std std-term">n_jobs</span></a> para controlar el paralelismo.</p>
<p>Cuando se habla de los parámetros de un <a class="reference internal" href="#term-meta-estimator"><span class="xref std std-term">meta-estimador</span></a>, también se pueden incluir los parámetros de los estimadores incluidos (wrapped) en el meta-estimador. Normalmente, estos parámetros anidados se denotan utilizando un <a class="reference internal" href="#term-double-underscore"><span class="xref std std-term">doble guión bajo</span></a> (<code class="docutils literal notranslate"><span class="pre">__</span></code>) para separar entre el estimador-como-parámetro y su parámetro. Así, <code class="docutils literal notranslate"><span class="pre">clf</span> <span class="pre">=</span> <span class="pre">BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth=3))</span></code> tiene un parámetro de profundidad <code class="docutils literal notranslate"><span class="pre">base_estimator__max_depth</span></code> con valor <code class="docutils literal notranslate"><span class="pre">3</span></code>, al que se puede acceder con <code class="docutils literal notranslate"><span class="pre">clf.base_estimator.max_depth</span></code> o <code class="docutils literal notranslate"><span class="pre">clf.get_params()['base_estimator__max_depth']</span></code>.</p>
<p>La lista de parámetros y sus valores actuales pueden recuperarse de una <a class="reference internal" href="#term-estimator-instance"><span class="xref std std-term">instancia del estimador</span></a> utilizando su método <a class="reference internal" href="#term-get_params"><span class="xref std std-term">get_params</span></a>.</p>
<p>Entre la construcción y el ajuste, los parámetros pueden modificarse utilizando <a class="reference internal" href="#term-set_params"><span class="xref std std-term">set_params</span></a>.  Para permitir esto, los parámetros no se validan o modifican normalmente cuando se construye el estimador, o cuando se establece cada parámetro. La validación de los parámetros se realiza cuando se llama a <a class="reference internal" href="#term-fit"><span class="xref std std-term">fit</span></a>.</p>
<p>Los parámetros comunes están listados <a class="reference internal" href="#glossary-parameters"><span class="std std-ref">abajo</span></a>.</p>
</dd>
<dt id="term-pairwise-metric">métrica por pares<a class="headerlink" href="#term-pairwise-metric" title="Permalink to this term">¶</a></dt><dt id="term-pairwise-metrics">métricas por pares<a class="headerlink" href="#term-pairwise-metrics" title="Permalink to this term">¶</a></dt><dd><p>En su sentido más amplio, una métrica por pares define una función para medir la similitud o disimilitud entre dos muestras (cada una de las cuales se representa normalmente como un <a class="reference internal" href="#term-feature-vector"><span class="xref std std-term">vector de características</span></a>).  En particular, proporcionamos implementaciones de métricas de distancia (así como métricas impropias como la Distancia Coseno) a través de <a class="reference internal" href="modules/generated/sklearn.metrics.pairwise_distances.html#sklearn.metrics.pairwise_distances" title="sklearn.metrics.pairwise_distances"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.pairwise_distances</span></code></a>, y de funciones núcleo (una clase restringida de funciones de similitud) en <code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.pairwise_kernels</span></code>.  Éstas pueden calcular matrices de distancia por pares que son simétricas y, por tanto, almacenan datos de forma redundante.</p>
<p>Ver también <a class="reference internal" href="#term-precomputed"><span class="xref std std-term">precalculado</span></a> y <a class="reference internal" href="#term-metric"><span class="xref std std-term">metric</span></a>.</p>
<p>Ten en cuenta que para la mayoría de las métricas de distancia, dependemos de las implementaciones de <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/reference/spatial.distance.html#module-scipy.spatial.distance" title="(en SciPy versión 1.7.1)"><code class="xref py py-mod docutils literal notranslate"><span class="pre">scipy.spatial.distance</span></code></a>, pero podemos reimplementarlas por eficiencia en nuestro contexto.  El módulo <code class="xref py py-mod docutils literal notranslate"><span class="pre">neighbors</span></code> también duplica algunas implementaciones de métricas para su integración con estructuras de datos de búsqueda de árboles binarios eficientes.</p>
</dd>
<dt id="term-pd">pd<a class="headerlink" href="#term-pd" title="Permalink to this term">¶</a></dt><dd><p>Una abreviatura de <a class="reference external" href="https://pandas.pydata.org">Pandas</a> debido a la declaración de importación convencional:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
</pre></div>
</div>
</dd>
<dt id="term-precomputed">precalculado<a class="headerlink" href="#term-precomputed" title="Permalink to this term">¶</a></dt><dd><p>Donde los algoritmos dependen de <a class="reference internal" href="#term-pairwise-metrics"><span class="xref std std-term">métricas por pares</span></a>, y pueden calcularse sólo a partir de las métricas por pares, a menudo permitimos al usuario especificar que el <a class="reference internal" href="#term-X"><span class="xref std std-term">X</span></a> proporcionado ya está en el espacio de (des)similitud por pares, en lugar de en un espacio de características. Es decir, cuando se pasa a <a class="reference internal" href="#term-fit"><span class="xref std std-term">fit</span></a>, es una matriz cuadrada y simétrica, en la que cada arreglo indica la (des)similitud con cada muestra, y cuando se pasa a los métodos de predicción/transformación, cada fila corresponde a una muestra de prueba y cada columna a una muestra de entrenamiento.</p>
<p>El uso de X precalculado suele indicarse estableciendo un parámetro <code class="docutils literal notranslate"><span class="pre">metric</span></code>, <code class="docutils literal notranslate"><span class="pre">affinity</span></code> o <code class="docutils literal notranslate"><span class="pre">kernel</span></code> con la cadena “precomputed”. Si este es el caso, el estimador debe establecer la etiqueta del estimador <code class="docutils literal notranslate"><span class="pre">pairwise</span></code> como True.</p>
</dd>
<dt id="term-rectangular">rectangular<a class="headerlink" href="#term-rectangular" title="Permalink to this term">¶</a></dt><dd><p>Los datos que pueden representarse como una matriz con <a class="reference internal" href="#term-samples"><span class="xref std std-term">muestras</span></a> en el primer eje y un conjunto fijo y finito de <a class="reference internal" href="#term-features"><span class="xref std std-term">características</span></a> en el segundo se denominan rectangulares.</p>
<p>Este término excluye las muestras con estructuras no vectoriales, como un texto, una imagen de tamaño arbitrario, una serie de tiempo de longitud arbitraria, un conjunto de vectores, etc. El propósito de un <a class="reference internal" href="#term-vectorizer"><span class="xref std std-term">vectorizador</span></a> es producir formas rectangulares de tales datos.</p>
</dd>
<dt id="term-sample">muestra<a class="headerlink" href="#term-sample" title="Permalink to this term">¶</a></dt><dt id="term-samples">muestras<a class="headerlink" href="#term-samples" title="Permalink to this term">¶</a></dt><dd><p>Solemos utilizar este término como sustantivo para indicar un único vector de características. En otras partes, una muestra se denomina instancia, punto de datos u observación. <code class="docutils literal notranslate"><span class="pre">n_samples</span></code> indica el número de muestras de un conjunto de datos, siendo el número de filas de un arreglo de datos <a class="reference internal" href="#term-X"><span class="xref std std-term">X</span></a>.</p>
</dd>
<dt id="term-sample-property">propiedad de la muestra<a class="headerlink" href="#term-sample-property" title="Permalink to this term">¶</a></dt><dt id="term-sample-properties">propiedades muestrales<a class="headerlink" href="#term-sample-properties" title="Permalink to this term">¶</a></dt><dd><p>Una propiedad de la muestra se refiere a los datos de cada muestra (por ejemplo, un arreglo de longitud n_samples) que se pasa a un método de estimación o a una función similar, junto con, pero distinto de, <a class="reference internal" href="#term-features"><span class="xref std std-term">características</span></a> (<code class="docutils literal notranslate"><span class="pre">X</span></code>) y <a class="reference internal" href="#term-target"><span class="xref std std-term">objetivo</span></a> (<code class="docutils literal notranslate"><span class="pre">y</span></code>). El ejemplo más destacado es <a class="reference internal" href="#term-sample_weight"><span class="xref std std-term">sample_weight</span></a>; ver otros en <a class="reference internal" href="#glossary-sample-props"><span class="std std-ref">Datos y propiedades de la muestra</span></a>.</p>
<p>A partir de la versión 0.19 no tenemos un enfoque consistente para manejar las propiedades muestrales y su enrutamiento en <a class="reference internal" href="#term-meta-estimators"><span class="xref std std-term">meta estimadores</span></a>, aunque a menudo se utiliza un parámetro <code class="docutils literal notranslate"><span class="pre">fit_params</span></code>.</p>
</dd>
<dt id="term-scikit-learn-contrib">scikit-learn-contrib<a class="headerlink" href="#term-scikit-learn-contrib" title="Permalink to this term">¶</a></dt><dd><p>Un lugar para publicar bibliotecas compatibles con scikit-learn que están ampliamente autorizadas por los desarrolladores principales y la comunidad de colaboradores, pero que no son mantenidas por el equipo de desarrolladores principales. Ver <a class="reference external" href="https://scikit-learn-contrib.github.io">https://scikit-learn-contrib.github.io</a>.</p>
</dd>
<dt id="term-scikit-learn-enhancement-proposals">propuestas de mejora de scikit-learn<a class="headerlink" href="#term-scikit-learn-enhancement-proposals" title="Permalink to this term">¶</a></dt><dt id="term-SLEP">SLEP<a class="headerlink" href="#term-SLEP" title="Permalink to this term">¶</a></dt><dt id="term-SLEPs">SLEPs<a class="headerlink" href="#term-SLEPs" title="Permalink to this term">¶</a></dt><dd><p>Los cambios en los principios de la API y los cambios en las dependencias o en las versiones soportadas se producen a través de una <a class="reference internal" href="governance.html#slep"><span class="std std-ref">SLEP</span></a> y siguen el proceso de toma de decisiones descrito en <a class="reference internal" href="governance.html#governance"><span class="std std-ref">La gestión y toma de decisiones en el ámbito de la ciencia</span></a>. Para todas las votaciones, una propuesta debe haberse hecho pública y debatido antes de la votación. Dicha propuesta debe ser un documento consolidado, en forma de «Propuesta de Mejora de Scikit-Learn» (Scikit-Learn Enhancement Proposal, SLEP), en lugar de una larga discusión sobre un tema. Una SLEP debe enviarse como un pull-request a <a class="reference external" href="https://scikit-learn-enhancement-proposals.readthedocs.io">propuestas de mejora</a> utilizando la <a class="reference external" href="https://scikit-learn-enhancement-proposals.readthedocs.io/en/latest/slep_template.html">plantilla SLEP</a>.</p>
</dd>
<dt id="term-semi-supervised">semi-supervisado<a class="headerlink" href="#term-semi-supervised" title="Permalink to this term">¶</a></dt><dt id="term-semi-supervised-learning">aprendizaje semi-supervisado<a class="headerlink" href="#term-semi-supervised-learning" title="Permalink to this term">¶</a></dt><dt id="term-semisupervised">semi supervisado<a class="headerlink" href="#term-semisupervised" title="Permalink to this term">¶</a></dt><dd><p>Aprendizaje en el que la predicción esperada (etiqueta o verdad fundamental) sólo está disponible para algunas muestras proporcionadas como datos de entrenamiento al hacer el <a class="reference internal" href="#term-fitting"><span class="xref std std-term">ajuste</span></a> del modelo. Convencionalmente aplicamos la etiqueta <code class="docutils literal notranslate"><span class="pre">-1</span></code> a las muestras <a class="reference internal" href="#term-unlabeled"><span class="xref std std-term">sin etiquetar</span></a> en la clasificación semi supervisada.</p>
</dd>
<dt id="term-sparse-matrix">matriz dispersa<a class="headerlink" href="#term-sparse-matrix" title="Permalink to this term">¶</a></dt><dt id="term-sparse-graph">grafo disperso<a class="headerlink" href="#term-sparse-graph" title="Permalink to this term">¶</a></dt><dd><p>Una representación de datos numéricos bidimensionales que es más eficiente en cuanto a la memoria que el correspondiente arreglo de numpy denso donde casi todos los elementos son cero. Utilizamos el framework <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/reference/sparse.html#module-scipy.sparse" title="(en SciPy versión 1.7.1)"><code class="xref py py-mod docutils literal notranslate"><span class="pre">scipy.sparse</span></code></a>, que proporciona varias representaciones de datos dispersos subyacentes, o <em>formatos</em>. Algunos formatos son más eficientes que otros para tareas particulares, y cuando un formato particular proporciona un beneficio especial, tratamos de documentar este hecho en las descripciones de los parámetros de scikit-learn.</p>
<p>Algunos formatos de matrices dispersas (especialmente CSR, CSC, COO y LIL) distinguen entre ceros <em>implícitos</em> y <em>explícitos</em>. Los ceros explícitos se almacenan (es decir, consumen memoria en un arreglo de <code class="docutils literal notranslate"><span class="pre">datos</span></code>) en la estructura de datos, mientras que los ceros implícitos corresponden a todos los elementos no definidos en el almacenamiento explícito.</p>
<p>En scikit-learn se utilizan dos semánticas para las matrices dispersas:</p>
<dl class="simple">
<dt>semánticas de matriz</dt><dd><p>La matriz dispersa se interpreta como un arreglo en la que los ceros implícitos y explícitos se interpretan como el número 0. Esta es la interpretación que se adopta con más frecuencia, por ejemplo, cuando se utilizan matrices dispersas para matrices de características o <a class="reference internal" href="#term-multilabel-indicator-matrices"><span class="xref std std-term">matrices indicatrices multietiqueta</span></a>.</p>
</dd>
<dt>semánticas de gráfico</dt><dd><p>Al igual que con <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/reference/sparse.csgraph.html#module-scipy.sparse.csgraph" title="(en SciPy versión 1.7.1)"><code class="xref py py-mod docutils literal notranslate"><span class="pre">scipy.sparse.csgraph</span></code></a>, los ceros explícitos se interpretan como el número 0, pero los ceros implícitos indican un valor enmascarado o ausente, como la ausencia de una arista entre dos vértices de un grafo, donde un valor explícito indica el peso de una arista. Esta interpretación se adopta para representar la conectividad en el agrupamiento, en las representaciones de vecindarios más cercanos (por ejemplo, <a class="reference internal" href="modules/generated/sklearn.neighbors.kneighbors_graph.html#sklearn.neighbors.kneighbors_graph" title="sklearn.neighbors.kneighbors_graph"><code class="xref py py-func docutils literal notranslate"><span class="pre">neighbors.kneighbors_graph</span></code></a>), y para la representación de distancias precalculadas donde sólo se requieren las distancias en el vecindario de cada punto.</p>
</dd>
</dl>
<p>Cuando se trabaja con matrices dispersas, asumimos que son dispersas por una buena razón, y evitamos escribir código que densifique una matriz dispersa proporcionada por el usuario, manteniendo en su lugar la dispersidad o generando un error si no es posible (es decir, si un estimador no soporta / no puede soportar matrices dispersas).</p>
</dd>
<dt id="term-supervised">supervisado<a class="headerlink" href="#term-supervised" title="Permalink to this term">¶</a></dt><dt id="term-supervised-learning">aprendizaje supervisado<a class="headerlink" href="#term-supervised-learning" title="Permalink to this term">¶</a></dt><dd><p>Aprendizaje en el que la predicción esperada (etiqueta o verdad fundamental) está disponible para cada muestra cuando se hace el <a class="reference internal" href="#term-fitting"><span class="xref std std-term">ajuste</span></a> del modelo, proporcionado como <a class="reference internal" href="#term-y"><span class="xref std std-term">y</span></a>.  Este es el enfoque adoptado en un <a class="reference internal" href="#term-classifier"><span class="xref std std-term">clasificador</span></a> o <a class="reference internal" href="#term-regressor"><span class="xref std std-term">regresor</span></a> entre otros estimadores.</p>
</dd>
<dt id="term-target">objetivo<a class="headerlink" href="#term-target" title="Permalink to this term">¶</a></dt><dt id="term-targets">objetivos<a class="headerlink" href="#term-targets" title="Permalink to this term">¶</a></dt><dd><p>La <em>variable dependiente</em> en el aprendizaje <a class="reference internal" href="#term-supervised"><span class="xref std std-term">supervisado</span></a> (y <a class="reference internal" href="#term-semisupervised"><span class="xref std std-term">semisupervisado</span></a>), pasada como <a class="reference internal" href="#term-y"><span class="xref std std-term">y</span></a> al método <a class="reference internal" href="#term-fit"><span class="xref std std-term">fit</span></a> de un estimador.  También se conoce como <em>variable dependiente</em>, <em>variable de resultado</em>, <em>variable de respuesta</em>, <em>verdad fundamental</em> o <em>etiqueta</em>. Scikit-learn trabaja con objetivos que tienen una estructura mínima: una clase de un conjunto finito, un número finito de valor real, múltiples clases o múltiples números. Ver <a class="reference internal" href="#glossary-target-types"><span class="std std-ref">Tipos de Objetivos</span></a>.</p>
</dd>
<dt id="term-transduction">transducción<a class="headerlink" href="#term-transduction" title="Permalink to this term">¶</a></dt><dt id="term-transductive">transductivo<a class="headerlink" href="#term-transductive" title="Permalink to this term">¶</a></dt><dd><p>Un método de aprendizaje automático transductivo (en contraste con <a class="reference internal" href="#term-inductive"><span class="xref std std-term">inductivo</span></a>) está diseñado para modelar un conjunto de datos específico, pero no para aplicar ese modelo a datos no vistos. Algunos ejemplos son <a class="reference internal" href="modules/generated/sklearn.manifold.TSNE.html#sklearn.manifold.TSNE" title="sklearn.manifold.TSNE"><code class="xref py py-class docutils literal notranslate"><span class="pre">manifold.TSNE</span></code></a>, <a class="reference internal" href="modules/generated/sklearn.cluster.AgglomerativeClustering.html#sklearn.cluster.AgglomerativeClustering" title="sklearn.cluster.AgglomerativeClustering"><code class="xref py py-class docutils literal notranslate"><span class="pre">cluster.AgglomerativeClustering</span></code></a> y <a class="reference internal" href="modules/generated/sklearn.neighbors.LocalOutlierFactor.html#sklearn.neighbors.LocalOutlierFactor" title="sklearn.neighbors.LocalOutlierFactor"><code class="xref py py-class docutils literal notranslate"><span class="pre">neighbors.LocalOutlierFactor</span></code></a>.</p>
</dd>
<dt id="term-unlabeled">sin etiquetar<a class="headerlink" href="#term-unlabeled" title="Permalink to this term">¶</a></dt><dt id="term-unlabeled-data">datos no etiquetados<a class="headerlink" href="#term-unlabeled-data" title="Permalink to this term">¶</a></dt><dd><p>Muestras con una verdad fundamental desconocida cuando se ajustan; equivalentemente, <a class="reference internal" href="#term-missing-values"><span class="xref std std-term">valores faltantes</span></a> en el <a class="reference internal" href="#term-target"><span class="xref std std-term">objetivo</span></a>. Ver también el aprendizaje <a class="reference internal" href="#term-semisupervised"><span class="xref std std-term">semi supervisado</span></a> y <a class="reference internal" href="#term-unsupervised"><span class="xref std std-term">no supervisado</span></a>.</p>
</dd>
<dt id="term-unsupervised">no supervisado<a class="headerlink" href="#term-unsupervised" title="Permalink to this term">¶</a></dt><dt id="term-unsupervised-learning">aprendizaje no supervisado<a class="headerlink" href="#term-unsupervised-learning" title="Permalink to this term">¶</a></dt><dd><p>Aprendizaje en el que la predicción esperada (etiqueta o verdad fundamental) no está disponible para cada muestra cuando se hace el <a class="reference internal" href="#term-fitting"><span class="xref std std-term">ajuste</span></a> del modelo, como en <a class="reference internal" href="#term-clusterers"><span class="xref std std-term">agrupadores</span></a> y <a class="reference internal" href="#term-outlier-detectors"><span class="xref std std-term">detectores de valores atípicos</span></a>.  Los estimadores no supervisados ignoran cualquier <a class="reference internal" href="#term-y"><span class="xref std std-term">y</span></a> pasado a <a class="reference internal" href="#term-fit"><span class="xref std std-term">fit</span></a>.</p>
</dd>
</dl>
</section>
<section id="class-apis-and-estimator-types">
<span id="glossary-estimator-types"></span><h2>APIs de Clase y Tipos de Estimadores<a class="headerlink" href="#class-apis-and-estimator-types" title="Enlazar permanentemente con este título">¶</a></h2>
<dl class="glossary">
<dt id="term-classifier">clasificador<a class="headerlink" href="#term-classifier" title="Permalink to this term">¶</a></dt><dt id="term-classifiers">clasificadores<a class="headerlink" href="#term-classifiers" title="Permalink to this term">¶</a></dt><dd><p>Un <a class="reference internal" href="#term-predictor"><span class="xref std std-term">predictor</span></a> <a class="reference internal" href="#term-supervised"><span class="xref std std-term">supervisado</span></a> (o <a class="reference internal" href="#term-semisupervised"><span class="xref std std-term">semi supervisado</span></a>) con un conjunto finito de posibles valores de salida discretos.</p>
<p>Un clasificador soporta el modelado de algunos de los objetivos <a class="reference internal" href="#term-binary"><span class="xref std std-term">binario</span></a>, <a class="reference internal" href="#term-multiclass"><span class="xref std std-term">multiclase</span></a>, <a class="reference internal" href="#term-multilabel"><span class="xref std std-term">multietiqueta</span></a>, o <a class="reference internal" href="#term-multioutput-multiclass"><span class="xref std std-term">multiclase multisalida</span></a>.  Dentro de scikit-learn, todos los clasificadores soportan la clasificación multiclase, utilizando por defecto una estrategia de uno contra el resto sobre el problema de clasificación binaria.</p>
<p>Los clasificadores deben almacenar un atributo <a class="reference internal" href="#term-classes_"><span class="xref std std-term">classes_</span></a> después del ajuste, y normalmente heredan de <a class="reference internal" href="modules/generated/sklearn.base.ClassifierMixin.html#sklearn.base.ClassifierMixin" title="sklearn.base.ClassifierMixin"><code class="xref py py-class docutils literal notranslate"><span class="pre">base.ClassifierMixin</span></code></a>, que establece su atributo <a class="reference internal" href="#term-_estimator_type"><span class="xref std std-term">_estimator_type</span></a>.</p>
<p>Un clasificador puede distinguirse de otros estimadores con <a class="reference internal" href="modules/generated/sklearn.base.is_classifier.html#sklearn.base.is_classifier" title="sklearn.base.is_classifier"><code class="xref py py-func docutils literal notranslate"><span class="pre">is_classifier</span></code></a>.</p>
<p>Un clasificador debe implementar:</p>
<ul class="simple">
<li><p><a class="reference internal" href="#term-fit"><span class="xref std std-term">fit</span></a></p></li>
<li><p><a class="reference internal" href="#term-predict"><span class="xref std std-term">predict</span></a></p></li>
<li><p><a class="reference internal" href="#term-score"><span class="xref std std-term">score</span></a></p></li>
</ul>
<p>También puede ser apropiado implementar <a class="reference internal" href="#term-decision_function"><span class="xref std std-term">decision_function</span></a>, <a class="reference internal" href="#term-predict_proba"><span class="xref std std-term">predict_proba</span></a> y <a class="reference internal" href="#term-predict_log_proba"><span class="xref std std-term">predict_log_proba</span></a>.</p>
</dd>
<dt id="term-clusterer">agrupador<a class="headerlink" href="#term-clusterer" title="Permalink to this term">¶</a></dt><dt id="term-clusterers">agrupadores<a class="headerlink" href="#term-clusterers" title="Permalink to this term">¶</a></dt><dd><p>Un <a class="reference internal" href="#term-predictor"><span class="xref std std-term">predictor</span></a> <a class="reference internal" href="#term-unsupervised"><span class="xref std std-term">no supervisado</span></a> con un conjunto finito de valores de salida discretos.</p>
<p>Un agrupador suele almacenar <a class="reference internal" href="#term-labels_"><span class="xref std std-term">labels_</span></a> después del ajuste, y debe hacerlo si es <a class="reference internal" href="#term-transductive"><span class="xref std std-term">transductivo</span></a>.</p>
<p>Un agrupador debe implementar:</p>
<ul class="simple">
<li><p><a class="reference internal" href="#term-fit"><span class="xref std std-term">fit</span></a></p></li>
<li><p><a class="reference internal" href="#term-fit_predict"><span class="xref std std-term">fit_predict</span></a> si es <a class="reference internal" href="#term-transductive"><span class="xref std std-term">transductivo</span></a></p></li>
<li><p><a class="reference internal" href="#term-predict"><span class="xref std std-term">predict</span></a> si es <a class="reference internal" href="#term-inductive"><span class="xref std std-term">inductivo</span></a></p></li>
</ul>
</dd>
<dt id="term-density-estimator">estimador de la densidad<a class="headerlink" href="#term-density-estimator" title="Permalink to this term">¶</a></dt><dd><p>TODO</p>
</dd>
<dt id="term-estimator">estimador<a class="headerlink" href="#term-estimator" title="Permalink to this term">¶</a></dt><dt id="term-estimators">estimadores<a class="headerlink" href="#term-estimators" title="Permalink to this term">¶</a></dt><dd><p>Un objeto que gestiona la estimación y decodificación de un modelo. El modelo se estima como una función determinista de:</p>
<ul class="simple">
<li><p><a class="reference internal" href="#term-parameters"><span class="xref std std-term">parámetros</span></a> proporcionados en la construcción del objeto o con <a class="reference internal" href="#term-set_params"><span class="xref std std-term">set_params</span></a>;</p></li>
<li><p>el estado aleatorio global <a class="reference external" href="https://numpy.org/doc/stable/reference/random/index.html#module-numpy.random" title="(en NumPy versión 1.21)"><code class="xref py py-mod docutils literal notranslate"><span class="pre">numpy.random</span></code></a> si el parámetro <a class="reference internal" href="#term-random_state"><span class="xref std std-term">random_state</span></a> del estimador se establece como None; y</p></li>
<li><p>cualquier dato o <a class="reference internal" href="#term-sample-properties"><span class="xref std std-term">propiedades muestrales</span></a> pasados a la llamada más reciente a <a class="reference internal" href="#term-fit"><span class="xref std std-term">fit</span></a>, <a class="reference internal" href="#term-fit_transform"><span class="xref std std-term">fit_transform</span></a> o <a class="reference internal" href="#term-fit_predict"><span class="xref std std-term">fit_predict</span></a>, o datos pasados de forma similar en una secuencia de llamadas a <a class="reference internal" href="#term-partial_fit"><span class="xref std std-term">partial_fit</span></a>.</p></li>
</ul>
<p>El modelo estimado se almacena en los <a class="reference internal" href="#term-attributes"><span class="xref std std-term">atributos</span></a> públicos y privados de la instancia del estimador, lo que facilita la decodificación mediante métodos de predicción y transformación.</p>
<p>Los estimadores tienen que proporcionar un método <a class="reference internal" href="#term-fit"><span class="xref std std-term">fit</span></a>, y deberían proporcionar <a class="reference internal" href="#term-set_params"><span class="xref std std-term">set_params</span></a> y <a class="reference internal" href="#term-get_params"><span class="xref std std-term">get_params</span></a>, aunque normalmente se proporcionan por herencia de <a class="reference internal" href="modules/generated/sklearn.base.BaseEstimator.html#sklearn.base.BaseEstimator" title="sklearn.base.BaseEstimator"><code class="xref py py-class docutils literal notranslate"><span class="pre">base.BaseEstimator</span></code></a>.</p>
<p>La funcionalidad principal de algunos estimadores también puede estar disponible como una <a class="reference internal" href="#term-function"><span class="xref std std-term">función</span></a>.</p>
</dd>
<dt id="term-feature-extractor">extractor de características<a class="headerlink" href="#term-feature-extractor" title="Permalink to this term">¶</a></dt><dt id="term-feature-extractors">extractores de características<a class="headerlink" href="#term-feature-extractors" title="Permalink to this term">¶</a></dt><dd><p>Un <a class="reference internal" href="#term-transformer"><span class="xref std std-term">transformador</span></a> que toma una entrada en la que cada muestra no está representada como un objeto <a class="reference internal" href="#term-array-like"><span class="xref std std-term">array-like</span></a> de longitud fija, y produce un objeto <a class="reference internal" href="#term-array-like"><span class="xref std std-term">array-like</span></a> de <a class="reference internal" href="#term-features"><span class="xref std std-term">características</span></a> para cada muestra (y, por tanto, un array-like bidimensional para un conjunto de muestras). En otras palabras, mapea (con pérdida) una representación de datos no rectangulares en datos <a class="reference internal" href="#term-rectangular"><span class="xref std std-term">rectangulares</span></a>.</p>
<p>Los extractores de características deben implementar al menos:</p>
<ul class="simple">
<li><p><a class="reference internal" href="#term-fit"><span class="xref std std-term">fit</span></a></p></li>
<li><p><a class="reference internal" href="#term-transform"><span class="xref std std-term">transform</span></a></p></li>
<li><p><a class="reference internal" href="#term-get_feature_names"><span class="xref std std-term">get_feature_names</span></a></p></li>
</ul>
</dd>
<dt id="term-meta-estimator">meta-estimador<a class="headerlink" href="#term-meta-estimator" title="Permalink to this term">¶</a></dt><dt id="term-meta-estimators">meta estimadores<a class="headerlink" href="#term-meta-estimators" title="Permalink to this term">¶</a></dt><dt id="term-metaestimator">metaestimador<a class="headerlink" href="#term-metaestimator" title="Permalink to this term">¶</a></dt><dt id="term-metaestimators">metaestimadores<a class="headerlink" href="#term-metaestimators" title="Permalink to this term">¶</a></dt><dd><p>Un <a class="reference internal" href="#term-estimator"><span class="xref std std-term">estimador</span></a> que toma otro estimador como parámetro. Algunos ejemplos son <a class="reference internal" href="modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline" title="sklearn.pipeline.Pipeline"><code class="xref py py-class docutils literal notranslate"><span class="pre">pipeline.Pipeline</span></code></a>, <a class="reference internal" href="modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV" title="sklearn.model_selection.GridSearchCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">model_selection.GridSearchCV</span></code></a>, <a class="reference internal" href="modules/generated/sklearn.feature_selection.SelectFromModel.html#sklearn.feature_selection.SelectFromModel" title="sklearn.feature_selection.SelectFromModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">feature_selection.SelectFromModel</span></code></a> y <a class="reference internal" href="modules/generated/sklearn.ensemble.BaggingClassifier.html#sklearn.ensemble.BaggingClassifier" title="sklearn.ensemble.BaggingClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">ensemble.BaggingClassifier</span></code></a>.</p>
<p>En el método <a class="reference internal" href="#term-fit"><span class="xref std std-term">fit</span></a> de un metaestimador, cualquier estimador contenido debe ser <a class="reference internal" href="#term-cloned"><span class="xref std std-term">clonado</span></a> antes de ser ajustado (aunque FIXME: Pipeline y FeatureUnion no hacen esto actualmente). Una excepción a esto es que un estimador puede documentar explícitamente que acepta un estimador preajustado (por ejemplo, usando <code class="docutils literal notranslate"><span class="pre">prefit=True</span></code> en <a class="reference internal" href="modules/generated/sklearn.feature_selection.SelectFromModel.html#sklearn.feature_selection.SelectFromModel" title="sklearn.feature_selection.SelectFromModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">feature_selection.SelectFromModel</span></code></a>). Un problema conocido con esto es que el estimador preajustado perderá su modelo si el metaestimador es clonado. Un metaestimador debe haber invocado a <code class="docutils literal notranslate"><span class="pre">fit</span></code> antes de la predicción, incluso si todos los estimadores contenidos son preajustados.</p>
<p>En los casos en los que los comportamientos principales de un meta-estimador (por ejemplo, la implementación de <a class="reference internal" href="#term-predict"><span class="xref std std-term">predict</span></a> o <a class="reference internal" href="#term-transform"><span class="xref std std-term">transform</span></a>) son funciones de los métodos de predicción/transformación del <em>estimador base</em> proporcionado (o de múltiples estimadores base), un meta-estimador debe proporcionar al menos los métodos estándar proporcionados por el estimador base.  Puede que no sea posible identificar qué métodos proporciona el estimador subyacente hasta que el meta-estimador haya sido <a class="reference internal" href="#term-fitted"><span class="xref std std-term">ajustado</span></a> (ver también <a class="reference internal" href="#term-duck-typing"><span class="xref std std-term">duck typing</span></a>), para lo cual <a class="reference internal" href="modules/generated/sklearn.utils.metaestimators.if_delegate_has_method.html#sklearn.utils.metaestimators.if_delegate_has_method" title="sklearn.utils.metaestimators.if_delegate_has_method"><code class="xref py py-func docutils literal notranslate"><span class="pre">utils.metaestimators.if_delegate_has_method</span></code></a> puede ayudar.  También debería proporcionar (o modificar) las <a class="reference internal" href="#term-estimator-tags"><span class="xref std std-term">etiquetas del estimador</span></a> y el atributo <a class="reference internal" href="#term-classes_"><span class="xref std std-term">classes_</span></a> proporcionados por el estimador base.</p>
<p>Los metaestimadores deben tener cuidado de validar los datos lo menos posible antes de pasarlos a un estimador subyacente. Esto ahorra tiempo de cálculo y puede, por ejemplo, permitir que el estimador subyacente trabaje fácilmente con datos que no son <a class="reference internal" href="#term-rectangular"><span class="xref std std-term">rectangulares</span></a>.</p>
</dd>
<dt id="term-outlier-detector">detector de valores atípicos<a class="headerlink" href="#term-outlier-detector" title="Permalink to this term">¶</a></dt><dt id="term-outlier-detectors">detectores de valores atípicos<a class="headerlink" href="#term-outlier-detectors" title="Permalink to this term">¶</a></dt><dd><p>Un <a class="reference internal" href="#term-predictor"><span class="xref std std-term">predictor</span></a> binario <a class="reference internal" href="#term-unsupervised"><span class="xref std std-term">no supervisado</span></a> que modela la distinción entre muestras centrales y periféricas.</p>
<p>Los detectores de valores atípicos deben implementar:</p>
<ul class="simple">
<li><p><a class="reference internal" href="#term-fit"><span class="xref std std-term">fit</span></a></p></li>
<li><p><a class="reference internal" href="#term-fit_predict"><span class="xref std std-term">fit_predict</span></a> si es <a class="reference internal" href="#term-transductive"><span class="xref std std-term">transductivo</span></a></p></li>
<li><p><a class="reference internal" href="#term-predict"><span class="xref std std-term">predict</span></a> si es <a class="reference internal" href="#term-inductive"><span class="xref std std-term">inductivo</span></a></p></li>
</ul>
<p>Los detectores inductivos de valores atípicos también pueden implementar <a class="reference internal" href="#term-decision_function"><span class="xref std std-term">decision_function</span></a> para dar una puntuación normalizada de los valores atípicos cuando éstos tengan una puntuación inferior a 0. <a class="reference internal" href="#term-score_samples"><span class="xref std std-term">score_samples</span></a> puede proporcionar una puntuación no normalizada por muestra.</p>
</dd>
<dt id="term-predictor">predictor<a class="headerlink" href="#term-predictor" title="Permalink to this term">¶</a></dt><dt id="term-predictors">predictores<a class="headerlink" href="#term-predictors" title="Permalink to this term">¶</a></dt><dd><p>Un <a class="reference internal" href="#term-estimator"><span class="xref std std-term">estimador</span></a> que soporta <a class="reference internal" href="#term-predict"><span class="xref std std-term">predict</span></a> y/o <a class="reference internal" href="#term-fit_predict"><span class="xref std std-term">fit_predict</span></a>. Esto incluye <a class="reference internal" href="#term-classifier"><span class="xref std std-term">clasificador</span></a>, <a class="reference internal" href="#term-regressor"><span class="xref std std-term">regresor</span></a>, <a class="reference internal" href="#term-outlier-detector"><span class="xref std std-term">detector de valores atípicos</span></a> y <a class="reference internal" href="#term-clusterer"><span class="xref std std-term">agrupador</span></a>.</p>
<p>En estadística, «predictores» se refiere a <a class="reference internal" href="#term-features"><span class="xref std std-term">características</span></a>.</p>
</dd>
<dt id="term-regressor">regresor<a class="headerlink" href="#term-regressor" title="Permalink to this term">¶</a></dt><dt id="term-regressors">regresores<a class="headerlink" href="#term-regressors" title="Permalink to this term">¶</a></dt><dd><p>Un <a class="reference internal" href="#term-predictor"><span class="xref std std-term">predictor</span></a> <a class="reference internal" href="#term-supervised"><span class="xref std std-term">supervisado</span></a> (o <a class="reference internal" href="#term-semi-supervised"><span class="xref std std-term">semi-supervisado</span></a>) con valores de salida <a class="reference internal" href="#term-continuous"><span class="xref std std-term">continuos</span></a>.</p>
<p>Los regresores suelen heredar de <a class="reference internal" href="modules/generated/sklearn.base.RegressorMixin.html#sklearn.base.RegressorMixin" title="sklearn.base.RegressorMixin"><code class="xref py py-class docutils literal notranslate"><span class="pre">base.RegressorMixin</span></code></a>, que establece su atributo <a class="reference internal" href="#term-_estimator_type"><span class="xref std std-term">_estimator_type</span></a>.</p>
<p>Un regresor puede distinguirse de otros estimadores con <a class="reference internal" href="modules/generated/sklearn.base.is_regressor.html#sklearn.base.is_regressor" title="sklearn.base.is_regressor"><code class="xref py py-func docutils literal notranslate"><span class="pre">is_regressor</span></code></a>.</p>
<p>Un regresor debe implementar:</p>
<ul class="simple">
<li><p><a class="reference internal" href="#term-fit"><span class="xref std std-term">fit</span></a></p></li>
<li><p><a class="reference internal" href="#term-predict"><span class="xref std std-term">predict</span></a></p></li>
<li><p><a class="reference internal" href="#term-score"><span class="xref std std-term">score</span></a></p></li>
</ul>
</dd>
<dt id="term-transformer">transformador<a class="headerlink" href="#term-transformer" title="Permalink to this term">¶</a></dt><dt id="term-transformers">transformadores<a class="headerlink" href="#term-transformers" title="Permalink to this term">¶</a></dt><dd><p>Un estimador que soporta <a class="reference internal" href="#term-transform"><span class="xref std std-term">transform</span></a> y/o <a class="reference internal" href="#term-fit_transform"><span class="xref std std-term">fit_transform</span></a>. Un transformador puramente <a class="reference internal" href="#term-transductive"><span class="xref std std-term">transductivo</span></a>, como <a class="reference internal" href="modules/generated/sklearn.manifold.TSNE.html#sklearn.manifold.TSNE" title="sklearn.manifold.TSNE"><code class="xref py py-class docutils literal notranslate"><span class="pre">manifold.TSNE</span></code></a>, puede no implementar <code class="docutils literal notranslate"><span class="pre">transform</span></code>.</p>
</dd>
<dt id="term-vectorizer">vectorizador<a class="headerlink" href="#term-vectorizer" title="Permalink to this term">¶</a></dt><dt id="term-vectorizers">vectorizadores<a class="headerlink" href="#term-vectorizers" title="Permalink to this term">¶</a></dt><dd><p>Ver <a class="reference internal" href="#term-feature-extractor"><span class="xref std std-term">extractor de características</span></a>.</p>
</dd>
</dl>
<p>Existen otras APIs relacionadas específicamente con una pequeña familia de estimadores, como:</p>
<dl class="glossary simple">
<dt id="term-cross-validation-splitter">separador de validación-cruzada<a class="headerlink" href="#term-cross-validation-splitter" title="Permalink to this term">¶</a></dt><dt id="term-CV-splitter">separador de CV<a class="headerlink" href="#term-CV-splitter" title="Permalink to this term">¶</a></dt><dt id="term-cross-validation-generator">generador de validación-cruzada<a class="headerlink" href="#term-cross-validation-generator" title="Permalink to this term">¶</a></dt><dd><p>Una familia de clases que no son estimadores y que se utilizan para dividir un conjunto de datos en una secuencia de partes de entrenamiento y de prueba (ver <a class="reference internal" href="modules/cross_validation.html#cross-validation"><span class="std std-ref">Validación cruzada: evaluación del rendimiento del estimador</span></a>), proporcionando métodos <a class="reference internal" href="#term-split"><span class="xref std std-term">split</span></a> y <a class="reference internal" href="#term-get_n_splits"><span class="xref std std-term">get_n_splits</span></a>. Ten en cuenta que, a diferencia de los estimadores, éstas no tienen métodos <a class="reference internal" href="#term-fit"><span class="xref std std-term">fit</span></a> y no proporcionan <a class="reference internal" href="#term-set_params"><span class="xref std std-term">set_params</span></a> o <a class="reference internal" href="#term-get_params"><span class="xref std std-term">get_params</span></a>. La validación de parámetros puede realizarse en <code class="docutils literal notranslate"><span class="pre">__init__</span></code>.</p>
</dd>
<dt id="term-cross-validation-estimator">estimador de validación-cruzada<a class="headerlink" href="#term-cross-validation-estimator" title="Permalink to this term">¶</a></dt><dd><p>Un estimador que tiene incorporada la capacidad de validación cruzada para seleccionar automáticamente los mejores hiperparámetros (ver el <a class="reference internal" href="modules/grid_search.html#grid-search"><span class="std std-ref">Manual de Usuario</span></a>). Algunos ejemplos de estimadores de validación cruzada son <a class="reference internal" href="modules/generated/sklearn.linear_model.ElasticNetCV.html#sklearn.linear_model.ElasticNetCV" title="sklearn.linear_model.ElasticNetCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">ElasticNetCV</span></code></a> y <a class="reference internal" href="modules/generated/sklearn.linear_model.LogisticRegressionCV.html#sklearn.linear_model.LogisticRegressionCV" title="sklearn.linear_model.LogisticRegressionCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">LogisticRegressionCV</span></code></a>. Los estimadores de validación cruzada se denominan <code class="docutils literal notranslate"><span class="pre">EstimatorCV</span></code> y suelen ser aproximadamente equivalentes a <code class="docutils literal notranslate"><span class="pre">GridSearchCV(Estimator(),</span> <span class="pre">...)</span></code>. La ventaja de utilizar un estimador de validación cruzada sobre la clase canónica <a class="reference internal" href="#term-estimator"><span class="xref std std-term">estimador</span></a> junto con la <a class="reference internal" href="modules/grid_search.html#grid-search"><span class="std std-ref">búsqueda en cuadrícula</span></a> es que pueden aprovechar el warm-starting reutilizando los resultados precalculados en los pasos anteriores del proceso de validación cruzada. Por lo general, esto supone una mejora de la velocidad. Una excepción es la clase <a class="reference internal" href="modules/generated/sklearn.linear_model.RidgeCV.html#sklearn.linear_model.RidgeCV" title="sklearn.linear_model.RidgeCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">RidgeCV</span></code></a>, que en cambio puede realizar un eficiente Leave-One-Out CV.</p>
</dd>
<dt id="term-scorer">puntuador<a class="headerlink" href="#term-scorer" title="Permalink to this term">¶</a></dt><dd><p>Un objeto invocable no estimador que evalúa un estimador en datos de prueba dados, devolviendo un número. A diferencia de las <a class="reference internal" href="#term-evaluation-metrics"><span class="xref std std-term">métricas de evaluación</span></a>, un número mayor devuelto debe corresponder con una <em>mejor</em> puntuación. Ver <a class="reference internal" href="modules/model_evaluation.html#scoring-parameter"><span class="std std-ref">El parámetro scoring: definir las reglas de evaluación del modelo</span></a>.</p>
</dd>
</dl>
<p>Otros ejemplos:</p>
<ul class="simple">
<li><p><a class="reference internal" href="modules/generated/sklearn.neighbors.DistanceMetric.html#sklearn.neighbors.DistanceMetric" title="sklearn.neighbors.DistanceMetric"><code class="xref py py-class docutils literal notranslate"><span class="pre">neighbors.DistanceMetric</span></code></a></p></li>
<li><p><a class="reference internal" href="modules/generated/sklearn.gaussian_process.kernels.Kernel.html#sklearn.gaussian_process.kernels.Kernel" title="sklearn.gaussian_process.kernels.Kernel"><code class="xref py py-class docutils literal notranslate"><span class="pre">gaussian_process.kernels.Kernel</span></code></a></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">tree.Criterion</span></code></p></li>
</ul>
</section>
<section id="target-types">
<span id="glossary-target-types"></span><h2>Tipos de Objetivos<a class="headerlink" href="#target-types" title="Enlazar permanentemente con este título">¶</a></h2>
<dl class="glossary">
<dt id="term-binary">binario<a class="headerlink" href="#term-binary" title="Permalink to this term">¶</a></dt><dd><p>Un problema de clasificación que consta de dos clases.  Un objetivo binario puede representarse como para un problema <a class="reference internal" href="#term-multiclass"><span class="xref std std-term">multiclase</span></a> pero con sólo dos etiquetas.  Una función de decisión binaria se representa como un arreglo 1D.</p>
<p>Semánticamente, una clase suele considerarse la clase «positiva». A menos que se especifique lo contrario (por ejemplo, utilizando <a class="reference internal" href="#term-pos_label"><span class="xref std std-term">pos_label</span></a> en <a class="reference internal" href="#term-evaluation-metrics"><span class="xref std std-term">métricas de evaluación</span></a>), consideramos la etiqueta de clase con el mayor valor (numérico o lexicográfico) como la clase positiva: de las etiquetas [0, 1], 1 es la clase positiva; de [1, 2], 2 es la clase positiva; de [“no”, “yes”], “yes” es la clase positiva; de [“no”, “YES”], “no” es la clase positiva.  Esto afecta a la salida de <a class="reference internal" href="#term-decision_function"><span class="xref std std-term">decision_function</span></a>, por ejemplo.</p>
<p>Ten en cuenta que un conjunto de datos muestreado de un <code class="docutils literal notranslate"><span class="pre">y</span></code> multiclase o un <code class="docutils literal notranslate"><span class="pre">y</span></code> continuo puede parecer binario.</p>
<p><a class="reference internal" href="modules/generated/sklearn.utils.multiclass.type_of_target.html#sklearn.utils.multiclass.type_of_target" title="sklearn.utils.multiclass.type_of_target"><code class="xref py py-func docutils literal notranslate"><span class="pre">type_of_target</span></code></a> devolverá “binary” para la entrada binaria, o un arreglo similar con una sola clase presente.</p>
</dd>
<dt id="term-continuous">continuo<a class="headerlink" href="#term-continuous" title="Permalink to this term">¶</a></dt><dd><p>Un problema de regresión en el que el objetivo de cada muestra es un número de punto flotante finito representado como un arreglo unidimensional de números de punto flotante (floats) (o a veces ints).</p>
<p><a class="reference internal" href="modules/generated/sklearn.utils.multiclass.type_of_target.html#sklearn.utils.multiclass.type_of_target" title="sklearn.utils.multiclass.type_of_target"><code class="xref py py-func docutils literal notranslate"><span class="pre">type_of_target</span></code></a> devolverá “continuous” para la entrada continua, pero si los datos son todos enteros, se identificará como “multiclass”.</p>
</dd>
<dt id="term-continuous-multioutput">salida múltiple continua<a class="headerlink" href="#term-continuous-multioutput" title="Permalink to this term">¶</a></dt><dt id="term-continuous-multi-output">salida-múltiple continua<a class="headerlink" href="#term-continuous-multi-output" title="Permalink to this term">¶</a></dt><dt id="term-multioutput-continuous">multisalida continua<a class="headerlink" href="#term-multioutput-continuous" title="Permalink to this term">¶</a></dt><dt id="term-multi-output-continuous">multi-salida continua<a class="headerlink" href="#term-multi-output-continuous" title="Permalink to this term">¶</a></dt><dd><p>Un problema de regresión en el que el objetivo de cada muestra consiste en <code class="docutils literal notranslate"><span class="pre">n_outputs</span></code> <a class="reference internal" href="#term-outputs"><span class="xref std std-term">salidas</span></a>, cada una de ellas un número de punto flotante finito, para un int fijo <code class="docutils literal notranslate"><span class="pre">n_outputs</span> <span class="pre">&gt;</span> <span class="pre">1</span></code> en un conjunto de datos particular.</p>
<p>Los objetivos de salida múltiple continua se representan como múltiples objetivos <a class="reference internal" href="#term-continuous"><span class="xref std std-term">continuos</span></a>, apilados horizontalmente en un arreglo de forma <code class="docutils literal notranslate"><span class="pre">(n_samples,</span> <span class="pre">n_outputs)</span></code>.</p>
<p><a class="reference internal" href="modules/generated/sklearn.utils.multiclass.type_of_target.html#sklearn.utils.multiclass.type_of_target" title="sklearn.utils.multiclass.type_of_target"><code class="xref py py-func docutils literal notranslate"><span class="pre">type_of_target</span></code></a> devolverá “continuous-multioutput” para una entrada multisalida continua, pero si los datos son todos enteros, se identificará como “multiclass-multioutput”.</p>
</dd>
<dt id="term-multiclass">multiclase<a class="headerlink" href="#term-multiclass" title="Permalink to this term">¶</a></dt><dt id="term-multi-class">multi-clase<a class="headerlink" href="#term-multi-class" title="Permalink to this term">¶</a></dt><dd><p>Un problema de clasificación que consta de más de dos clases. Un objetivo multiclase puede representarse como un arreglo unidimensional de cadenas o enteros. También se acepta un vector columna 2D de enteros (es decir, una única salida en términos <a class="reference internal" href="#term-multioutput"><span class="xref std std-term">multioutput</span></a>).</p>
<p>No soportamos oficialmente otros objetos ordenables y hashables como etiquetas de clase, aunque los estimadores puedan funcionar cuando se dan objetivos de clasificación de ese tipo.</p>
<p>Para la clasificación semi supervisada, las muestras <a class="reference internal" href="#term-unlabeled"><span class="xref std std-term">sin etiquetar</span></a> deben tener la etiqueta especial -1 en <code class="docutils literal notranslate"><span class="pre">y</span></code>.</p>
<p>Dentro de sckit-learn, todos los estimadores que soportan la clasificación binaria también soportan la clasificación multiclase, utilizando One-vs-Rest por defecto.</p>
<p>Un <a class="reference internal" href="modules/generated/sklearn.preprocessing.LabelEncoder.html#sklearn.preprocessing.LabelEncoder" title="sklearn.preprocessing.LabelEncoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">preprocessing.LabelEncoder</span></code></a> ayuda a canonizar los objetivos multiclase como enteros.</p>
<p><a class="reference internal" href="modules/generated/sklearn.utils.multiclass.type_of_target.html#sklearn.utils.multiclass.type_of_target" title="sklearn.utils.multiclass.type_of_target"><code class="xref py py-func docutils literal notranslate"><span class="pre">type_of_target</span></code></a> devolverá “multiclass” para la entrada multiclase. El usuario también puede querer manejar la entrada “binary” de forma idéntica a “multiclass”.</p>
</dd>
<dt id="term-multiclass-multioutput">multisalida multiclase<a class="headerlink" href="#term-multiclass-multioutput" title="Permalink to this term">¶</a></dt><dt id="term-multi-class-multi-output">multi-salida multi-clase<a class="headerlink" href="#term-multi-class-multi-output" title="Permalink to this term">¶</a></dt><dt id="term-multioutput-multiclass">multiclase multisalida<a class="headerlink" href="#term-multioutput-multiclass" title="Permalink to this term">¶</a></dt><dt id="term-multi-output-multi-class">multi-clase multi-salida<a class="headerlink" href="#term-multi-output-multi-class" title="Permalink to this term">¶</a></dt><dd><p>Un problema de clasificación en el que el objetivo de cada muestra consiste en <code class="docutils literal notranslate"><span class="pre">n_outputs</span></code> <a class="reference internal" href="#term-outputs"><span class="xref std std-term">salidas</span></a>, cada una una etiqueta de clase, para un int fijo <code class="docutils literal notranslate"><span class="pre">n_outputs</span> <span class="pre">&gt;</span> <span class="pre">1</span></code> en un conjunto de datos particular. Cada salida tiene un conjunto fijo de clases disponibles, y cada muestra está etiquetada con una clase para cada salida. Una salida puede ser binaria o multiclase, y en el caso de que todas las salidas sean binarias, el objetivo es <a class="reference internal" href="#term-multilabel"><span class="xref std std-term">multietiqueta</span></a>.</p>
<p>Los objetivos multisalida se representan como múltiples objetivos <a class="reference internal" href="#term-multiclass"><span class="xref std std-term">multiclase</span></a>, apilados horizontalmente en un arreglo de forma <code class="docutils literal notranslate"><span class="pre">(n_samples,</span> <span class="pre">n_outputs)</span></code>.</p>
<p>XXX: Por razones de simplicidad, no siempre podemos admitir etiquetas de clase de cadena para multiclase multisalida, y se deben utilizar etiquetas de clase de enteros.</p>
<p><code class="xref py py-mod docutils literal notranslate"><span class="pre">multioutput</span></code> proporciona estimadores que estiman problemas de salidas múltiples utilizando múltiples estimadores de una sola salida. Es posible que esto no tenga en cuenta las dependencias entre las diferentes salidas, algo que los métodos que manejan de forma nativa el caso de las salidas múltiples (por ejemplo, árboles de decisión, vecinos más cercanos, redes neuronales) pueden hacer mejor.</p>
<p><a class="reference internal" href="modules/generated/sklearn.utils.multiclass.type_of_target.html#sklearn.utils.multiclass.type_of_target" title="sklearn.utils.multiclass.type_of_target"><code class="xref py py-func docutils literal notranslate"><span class="pre">type_of_target</span></code></a> devolverá “multiclass-multioutput” para una entrada multiclase multisalida.</p>
</dd>
<dt id="term-multilabel">multietiqueta<a class="headerlink" href="#term-multilabel" title="Permalink to this term">¶</a></dt><dt id="term-multi-label">multi-etiqueta<a class="headerlink" href="#term-multi-label" title="Permalink to this term">¶</a></dt><dd><p>Un objetivo <a class="reference internal" href="#term-multiclass-multioutput"><span class="xref std std-term">multiclase multisalida</span></a> donde cada salida es <a class="reference internal" href="#term-binary"><span class="xref std std-term">binaria</span></a>.  Puede representarse como un arreglo 2D (denso) o una matriz dispersa de enteros, de manera que cada columna es un objetivo binario independiente, donde las etiquetas positivas se indican con 1 y las negativas suelen ser -1 o 0. Los objetivos multietiqueta dispersos no se admiten en todos los casos en que los objetivos multietiqueta densos son admitidos.</p>
<p>Semánticamente, un objetivo multietiqueta puede considerarse como un conjunto de etiquetas para cada muestra. Aunque no se utiliza internamente, <a class="reference internal" href="modules/generated/sklearn.preprocessing.MultiLabelBinarizer.html#sklearn.preprocessing.MultiLabelBinarizer" title="sklearn.preprocessing.MultiLabelBinarizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">preprocessing.MultiLabelBinarizer</span></code></a> se proporciona como una herramienta para convertir de una representación de lista de conjuntos a un arreglo 2D o matriz dispersa. La codificación one-hot de un objetivo multiclase con <a class="reference internal" href="modules/generated/sklearn.preprocessing.LabelBinarizer.html#sklearn.preprocessing.LabelBinarizer" title="sklearn.preprocessing.LabelBinarizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">preprocessing.LabelBinarizer</span></code></a> lo convierte en un problema multietiqueta.</p>
<p><a class="reference internal" href="modules/generated/sklearn.utils.multiclass.type_of_target.html#sklearn.utils.multiclass.type_of_target" title="sklearn.utils.multiclass.type_of_target"><code class="xref py py-func docutils literal notranslate"><span class="pre">type_of_target</span></code></a> devolverá “multilabel-indicator” para la entrada multietiqueta, ya sea dispersa o densa.</p>
</dd>
<dt id="term-multioutput">salida múltiple<a class="headerlink" href="#term-multioutput" title="Permalink to this term">¶</a></dt><dt id="term-multi-output">multi-salida<a class="headerlink" href="#term-multi-output" title="Permalink to this term">¶</a></dt><dd><p>Un objetivo en el que cada muestra tiene múltiples etiquetas de clasificación/regresión. Ver <a class="reference internal" href="#term-multioutput-multiclass"><span class="xref std std-term">multiclase multisalida</span></a> y <a class="reference internal" href="#term-continuous-multioutput"><span class="xref std std-term">salida múltiple continua</span></a>. Actualmente no admitimos el modelado de objetivos mixtos de clasificación y regresión.</p>
</dd>
</dl>
</section>
<section id="methods">
<span id="glossary-methods"></span><h2>Métodos<a class="headerlink" href="#methods" title="Enlazar permanentemente con este título">¶</a></h2>
<dl class="glossary">
<dt id="term-decision_function"><code class="docutils literal notranslate"><span class="pre">decision_function</span></code><a class="headerlink" href="#term-decision_function" title="Permalink to this term">¶</a></dt><dd><p>En un <a class="reference internal" href="#term-classifier"><span class="xref std std-term">clasificador</span></a> ajustado o <a class="reference internal" href="#term-outlier-detector"><span class="xref std std-term">detector de valores atípicos</span></a>, predice una puntuación «blanda» para cada muestra en relación con cada clase, en lugar de la predicción categórica «dura» producida por <a class="reference internal" href="#term-predict"><span class="xref std std-term">predict</span></a>. Su entrada suele ser sólo algunos datos observados, <a class="reference internal" href="#term-X"><span class="xref std std-term">X</span></a>.</p>
<p>Si el estimador no estaba ya <a class="reference internal" href="#term-fitted"><span class="xref std std-term">ajustado</span></a>, la llamada a este método debería lanzar un <a class="reference internal" href="modules/generated/sklearn.exceptions.NotFittedError.html#sklearn.exceptions.NotFittedError" title="sklearn.exceptions.NotFittedError"><code class="xref py py-class docutils literal notranslate"><span class="pre">exceptions.NotFittedError</span></code></a>.</p>
<p>Convenciones de salida:</p>
<dl>
<dt>clasificación binaria</dt><dd><p>Un arreglo unidimensional, donde los valores estrictamente mayores que cero indican la clase positiva (es decir, la última clase en <a class="reference internal" href="#term-classes_"><span class="xref std std-term">classes_</span></a>).</p>
</dd>
<dt>clasificación multiclase</dt><dd><p>Un arreglo bidimensional, en el que el arg-máximo por fila es la clase predicha. Las columnas se ordenan según <a class="reference internal" href="#term-classes_"><span class="xref std std-term">classes_</span></a>.</p>
</dd>
<dt>clasificación multietiqueta</dt><dd><p>Scikit-learn es inconsistente en su representación de las funciones de decisión multietiqueta. Algunos estimadores la representan como una multiclase multisalida, es decir, una lista de arreglos 2D, cada uno con dos columnas. Otros la representan con un único arreglo 2D, cuyas columnas corresponden a las decisiones individuales de clasificación binaria. Esta última representación es ambiguamente idéntica al formato de clasificación multiclase, aunque su semántica difiere: debe interpretarse, como en el caso binario, fijando el umbral en 0.</p>
<p>TODO: <a class="reference external" href="https://gist.github.com/jnothman/4807b1b0266613c20ba4d1f88d0f8cf5">Este gist</a> destaca el uso de los diferentes formatos para la multietiqueta.</p>
</dd>
<dt>clasificación multisalida</dt><dd><p>Una lista de arreglos 2D, que corresponde a cada función de decisión multiclase.</p>
</dd>
<dt>detección de valores atípicos</dt><dd><p>Un arreglo unidimensional, en el que un valor mayor o igual a cero indica un valor típico.</p>
</dd>
</dl>
</dd>
<dt id="term-fit"><code class="docutils literal notranslate"><span class="pre">fit</span></code><a class="headerlink" href="#term-fit" title="Permalink to this term">¶</a></dt><dd><p>El método <code class="docutils literal notranslate"><span class="pre">fit</span></code> se proporciona en cada estimador. Normalmente toma algunas <a class="reference internal" href="#term-samples"><span class="xref std std-term">muestras</span></a> <code class="docutils literal notranslate"><span class="pre">X</span></code>, <a class="reference internal" href="#term-targets"><span class="xref std std-term">objetivos</span></a> <code class="docutils literal notranslate"><span class="pre">y</span></code> si el modelo es supervisado, y potencialmente otras <a class="reference internal" href="#term-sample-properties"><span class="xref std std-term">propiedades muestrales</span></a> como <a class="reference internal" href="#term-sample_weight"><span class="xref std std-term">sample_weight</span></a>. Debería:</p>
<ul class="simple">
<li><p>borra cualquiera de los <a class="reference internal" href="#term-attributes"><span class="xref std std-term">atributos</span></a> previos almacenados en el estimador, a menos que se utilice <a class="reference internal" href="#term-warm_start"><span class="xref std std-term">warm_start</span></a>;</p></li>
<li><p>valida e interpreta cualquiera de los <a class="reference internal" href="#term-parameters"><span class="xref std std-term">parámetros</span></a>, idealmente lanzando un error si no es válido;</p></li>
<li><p>valida los datos de entrada;</p></li>
<li><p>estima y almacena los atributos del modelo a partir de los parámetros estimados y los datos proporcionados; y</p></li>
<li><p>devuelve el estimador ahora <a class="reference internal" href="#term-fitted"><span class="xref std std-term">ajustado</span></a> para facilitar el encadenamiento de métodos.</p></li>
</ul>
<p><a class="reference internal" href="#glossary-target-types"><span class="std std-ref">Tipos de Objetivos</span></a> describe posibles formatos para <code class="docutils literal notranslate"><span class="pre">y</span></code>.</p>
</dd>
<dt id="term-fit_predict"><code class="docutils literal notranslate"><span class="pre">fit_predict</span></code><a class="headerlink" href="#term-fit_predict" title="Permalink to this term">¶</a></dt><dd><p>Utilizado especialmente para los estimadores <a class="reference internal" href="#term-unsupervised"><span class="xref std std-term">no supervisados</span></a>, <a class="reference internal" href="#term-transductive"><span class="xref std std-term">transductivos</span></a>, ajusta el modelo y devuelve las predicciones (similar a <a class="reference internal" href="#term-predict"><span class="xref std std-term">predict</span></a>) sobre los datos de entrenamiento. En los agrupadores, estas predicciones también se almacenan en el atributo <a class="reference internal" href="#term-labels_"><span class="xref std std-term">labels_</span></a>, y la salida de <code class="docutils literal notranslate"><span class="pre">.fit_predict(X)</span></code> suele ser equivalente a <code class="docutils literal notranslate"><span class="pre">.fit(X).predict(X)</span></code>. Los parámetros de <code class="docutils literal notranslate"><span class="pre">fit_predict</span></code> son los mismos que los de <code class="docutils literal notranslate"><span class="pre">fit</span></code>.</p>
</dd>
<dt id="term-fit_transform"><code class="docutils literal notranslate"><span class="pre">fit_transform</span></code><a class="headerlink" href="#term-fit_transform" title="Permalink to this term">¶</a></dt><dd><p>Un método en <a class="reference internal" href="#term-transformers"><span class="xref std std-term">transformadores</span></a> que ajusta el estimador y devuelve los datos de entrenamiento transformados. Toma parámetros como en <a class="reference internal" href="#term-fit"><span class="xref std std-term">fit</span></a> y su salida debería tener la misma forma que llamando a <code class="docutils literal notranslate"><span class="pre">.fit(X,</span> <span class="pre">...).transform(X)</span></code>. No obstante, hay casos raros en los que <code class="docutils literal notranslate"><span class="pre">.fit_transform(X,</span> <span class="pre">...)</span></code> y <code class="docutils literal notranslate"><span class="pre">.fit(X,</span> <span class="pre">...).transform(X)</span></code> no devuelven el mismo valor, donde los datos de entrenamiento deben tratarse de forma diferente (debido a la mezcla de modelos en ensembles apilados, por ejemplo; estos casos deben estar claramente documentados). Los transformadores <a class="reference internal" href="#term-transductive"><span class="xref std std-term">transductivos</span></a> también pueden proporcionar <code class="docutils literal notranslate"><span class="pre">fit_transform</span></code> pero no <a class="reference internal" href="#term-transform"><span class="xref std std-term">transform</span></a>.</p>
<p>Una de las razones para implementar <code class="docutils literal notranslate"><span class="pre">fit_transform</span></code> es que realizar <code class="docutils literal notranslate"><span class="pre">fit</span></code> y <code class="docutils literal notranslate"><span class="pre">transform</span></code> por separado sería menos eficiente que hacerlo conjuntamente. <a class="reference internal" href="modules/generated/sklearn.base.TransformerMixin.html#sklearn.base.TransformerMixin" title="sklearn.base.TransformerMixin"><code class="xref py py-class docutils literal notranslate"><span class="pre">base.TransformerMixin</span></code></a> proporciona una implementación por defecto, proporcionando una interfaz consistente a través de los transformadores en los que <code class="docutils literal notranslate"><span class="pre">fit_transform</span></code> está o no especializado.</p>
<p>En el aprendizaje <a class="reference internal" href="#term-inductive"><span class="xref std std-term">inductivo</span></a> – donde el objetivo es aprender un modelo generalizado que pueda aplicarse a nuevos datos – los usuarios deben tener cuidado de no aplicar <code class="docutils literal notranslate"><span class="pre">fit_transform</span></code> a la totalidad de un conjunto de datos (es decir, los datos de entrenamiento y de prueba juntos) antes de seguir modelando, ya que esto resulta en <a class="reference internal" href="#term-data-leakage"><span class="xref std std-term">fuga de datos</span></a>.</p>
</dd>
<dt id="term-get_feature_names"><code class="docutils literal notranslate"><span class="pre">get_feature_names</span></code><a class="headerlink" href="#term-get_feature_names" title="Permalink to this term">¶</a></dt><dd><p>Principalmente para <a class="reference internal" href="#term-feature-extractors"><span class="xref std std-term">extractores de características</span></a>, pero también se utiliza para que otros transformadores proporcionen nombres de cadenas para cada columna en la salida del método <a class="reference internal" href="#term-transform"><span class="xref std std-term">transform</span></a> del estimador. Tiene como salida una lista de cadenas y puede tomar una lista de cadenas como entrada, correspondiente a los nombres de las columnas de entrada a partir de las cuales se pueden generar los nombres de las columnas de salida.  Por defecto, las características de entrada se denominan x0, x1, ….</p>
</dd>
<dt id="term-get_n_splits"><code class="docutils literal notranslate"><span class="pre">get_n_splits</span></code><a class="headerlink" href="#term-get_n_splits" title="Permalink to this term">¶</a></dt><dd><p>En un <a class="reference internal" href="#term-CV-splitter"><span class="xref std std-term">separador de CV</span></a> (no un estimador), devuelve el número de elementos que se obtendría si se iterara a través del valor de retorno de <a class="reference internal" href="#term-split"><span class="xref std std-term">split</span></a> dados los mismos parámetros. Toma los mismos parámetros que split.</p>
</dd>
<dt id="term-get_params"><code class="docutils literal notranslate"><span class="pre">get_params</span></code><a class="headerlink" href="#term-get_params" title="Permalink to this term">¶</a></dt><dd><p>Obtiene todos los <a class="reference internal" href="#term-parameters"><span class="xref std std-term">parámetros</span></a>, y sus valores, que pueden establecerse utilizando <a class="reference internal" href="#term-set_params"><span class="xref std std-term">set_params</span></a>. Se puede utilizar un parámetro <code class="docutils literal notranslate"><span class="pre">deep</span></code>, cuando se establece en False para devolver sólo aquellos parámetros que no incluyan <code class="docutils literal notranslate"><span class="pre">__</span></code>, es decir, que no se deban a la indirección a través de estimadores contenidos.</p>
<p>La mayoría de los estimadores adoptan la definición de <a class="reference internal" href="modules/generated/sklearn.base.BaseEstimator.html#sklearn.base.BaseEstimator" title="sklearn.base.BaseEstimator"><code class="xref py py-class docutils literal notranslate"><span class="pre">base.BaseEstimator</span></code></a>, que simplemente adopta los parámetros definidos para <code class="docutils literal notranslate"><span class="pre">__init__</span></code>. <a class="reference internal" href="modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline" title="sklearn.pipeline.Pipeline"><code class="xref py py-class docutils literal notranslate"><span class="pre">pipeline.Pipeline</span></code></a>, entre otros, reimplementa <code class="docutils literal notranslate"><span class="pre">get_params</span></code> para declarar los estimadores nombrados en sus parámetros <code class="docutils literal notranslate"><span class="pre">steps</span></code> como parámetros en sí mismos.</p>
</dd>
<dt id="term-partial_fit"><code class="docutils literal notranslate"><span class="pre">partial_fit</span></code><a class="headerlink" href="#term-partial_fit" title="Permalink to this term">¶</a></dt><dd><p>Facilita el ajuste de un estimador en línea. A diferencia de <code class="docutils literal notranslate"><span class="pre">fit</span></code>, llamar repetidamente a <code class="docutils literal notranslate"><span class="pre">partial_fit</span></code> no borra el modelo, sino que lo actualiza con los datos proporcionados. La porción de datos proporcionada a <code class="docutils literal notranslate"><span class="pre">partial_fit</span></code> puede llamarse mini lotes. Cada mini lote debe tener una forma consistente, etc. En los estimadores iterativos, <code class="docutils literal notranslate"><span class="pre">partial_fit</span></code> suele realizar una sola iteración.</p>
<p><code class="docutils literal notranslate"><span class="pre">partial_fit</span></code> también se puede utilizar para el aprendizaje <a class="reference internal" href="#term-out-of-core"><span class="xref std std-term">fuera del núcleo</span></a>, aunque normalmente se limita al caso en que el aprendizaje se puede realizar en línea, es decir, el modelo es utilizable después de cada <code class="docutils literal notranslate"><span class="pre">partial_fit</span></code> y no hay ningún procesamiento separado necesario para finalizar el modelo. <a class="reference internal" href="modules/generated/sklearn.cluster.Birch.html#sklearn.cluster.Birch" title="sklearn.cluster.Birch"><code class="xref py py-class docutils literal notranslate"><span class="pre">cluster.Birch</span></code></a> introduce la convención de que llamar a <code class="docutils literal notranslate"><span class="pre">partial_fit(X)</span></code> producirá un modelo que no está finalizado, pero el modelo puede ser finalizado llamando a <code class="docutils literal notranslate"><span class="pre">partial_fit()</span></code>, es decir, sin pasar un mini lote adicional.</p>
<p>Generalmente, los parámetros del estimador no deben ser modificados entre llamadas a <code class="docutils literal notranslate"><span class="pre">partial_fit</span></code>, aunque <code class="docutils literal notranslate"><span class="pre">partial_fit</span></code> debe validarlos así como el nuevo mini lote de datos. En cambio, <code class="docutils literal notranslate"><span class="pre">warm_start</span></code> se utiliza para ajustar repetidamente el mismo estimador con los mismos datos pero variando los parámetros.</p>
<p>Como <code class="docutils literal notranslate"><span class="pre">fit</span></code>, <code class="docutils literal notranslate"><span class="pre">partial_fit</span></code> debe devolver el objeto estimador.</p>
<p>Para borrar el modelo, debe construirse un nuevo estimador, por ejemplo con <a class="reference internal" href="modules/generated/sklearn.base.clone.html#sklearn.base.clone" title="sklearn.base.clone"><code class="xref py py-func docutils literal notranslate"><span class="pre">base.clone</span></code></a>.</p>
<p>NOTA: El uso de <code class="docutils literal notranslate"><span class="pre">partial_fit</span></code> después de <code class="docutils literal notranslate"><span class="pre">fit</span></code> resulta en un comportamiento indefinido.</p>
</dd>
<dt id="term-predict"><code class="docutils literal notranslate"><span class="pre">predict</span></code><a class="headerlink" href="#term-predict" title="Permalink to this term">¶</a></dt><dd><p>Hace una predicción para cada muestra, normalmente sólo tomando <a class="reference internal" href="#term-X"><span class="xref std std-term">X</span></a> como entrada (pero consulta las convenciones de salida del regresor más abajo). En un <a class="reference internal" href="#term-classifier"><span class="xref std std-term">clasificador</span></a> o <a class="reference internal" href="#term-regressor"><span class="xref std std-term">regresor</span></a>, esta predicción está en el mismo espacio objetivo utilizado en el ajuste (por ejemplo, uno de {“red”, “amber”, “green”} si el <code class="docutils literal notranslate"><span class="pre">y</span></code> en el ajuste consistió en estas cadenas).  A pesar de esto, incluso cuando <code class="docutils literal notranslate"><span class="pre">y</span></code> pasado a <a class="reference internal" href="#term-fit"><span class="xref std std-term">fit</span></a> es una lista u otro array-like, la salida de <code class="docutils literal notranslate"><span class="pre">predict</span></code> debe ser siempre un arreglo o matriz dispersa. En un <a class="reference internal" href="#term-clusterer"><span class="xref std std-term">agrupador</span></a> o <a class="reference internal" href="#term-outlier-detector"><span class="xref std std-term">detector de valores atípicos</span></a> la predicción es un entero.</p>
<p>Si el estimador no estaba ya <a class="reference internal" href="#term-fitted"><span class="xref std std-term">ajustado</span></a>, la llamada a este método debería lanzar un <a class="reference internal" href="modules/generated/sklearn.exceptions.NotFittedError.html#sklearn.exceptions.NotFittedError" title="sklearn.exceptions.NotFittedError"><code class="xref py py-class docutils literal notranslate"><span class="pre">exceptions.NotFittedError</span></code></a>.</p>
<p>Convenciones de salida:</p>
<dl class="simple">
<dt>clasificador</dt><dd><p>Un arreglo de forma <code class="docutils literal notranslate"><span class="pre">(n_samples,)</span></code> <code class="docutils literal notranslate"><span class="pre">(n_samples,</span> <span class="pre">n_outputs)</span></code>. Los datos <a class="reference internal" href="#term-multilabel"><span class="xref std std-term">multietiqueta</span></a> pueden representarse como una matriz dispersa si se ha utilizado una matriz dispersa en el ajuste. Cada elemento debe ser uno de los valores del atributo <a class="reference internal" href="#term-classes_"><span class="xref std std-term">classes_</span></a> del clasificador.</p>
</dd>
<dt>agrupador</dt><dd><p>Un arreglo de forma <code class="docutils literal notranslate"><span class="pre">(n_samples,)</span></code> donde cada valor es de 0 a <code class="docutils literal notranslate"><span class="pre">n_clusters</span> <span class="pre">-</span> <span class="pre">1</span></code> si la muestra correspondiente está agrupada, y -1 si la muestra no está agrupada, como en <a class="reference internal" href="modules/generated/dbscan-function.html#sklearn.cluster.dbscan" title="sklearn.cluster.dbscan"><code class="xref py py-func docutils literal notranslate"><span class="pre">cluster.dbscan</span></code></a>.</p>
</dd>
<dt>detector de valores atípicos</dt><dd><p>Un arreglo de forma <code class="docutils literal notranslate"><span class="pre">(n_samples,)</span></code> donde cada valor es -1 para un valor atípico y 1 en caso contrario.</p>
</dd>
<dt>regresor</dt><dd><p>Un arreglo numérico de forma <code class="docutils literal notranslate"><span class="pre">(n_samples,)</span></code>, normalmente float64. Algunos regresores tienen opciones adicionales en su método <code class="docutils literal notranslate"><span class="pre">predict</span></code>, lo que les permite devolver la desviación estándar (<code class="docutils literal notranslate"><span class="pre">return_std=True</span></code>) o la covarianza (<code class="docutils literal notranslate"><span class="pre">return_cov=True</span></code>) relativa al valor predicho.  En este caso, el valor devuelto es una tupla de arreglos correspondientes a (media de la predicción, std, cov) según se requiera.</p>
</dd>
</dl>
</dd>
<dt id="term-predict_log_proba"><code class="docutils literal notranslate"><span class="pre">predict_log_proba</span></code><a class="headerlink" href="#term-predict_log_proba" title="Permalink to this term">¶</a></dt><dd><p>El logaritmo natural de la salida de <a class="reference internal" href="#term-predict_proba"><span class="xref std std-term">predict_proba</span></a>, proporcionado para facilitar la estabilidad numérica.</p>
</dd>
<dt id="term-predict_proba"><code class="docutils literal notranslate"><span class="pre">predict_proba</span></code><a class="headerlink" href="#term-predict_proba" title="Permalink to this term">¶</a></dt><dd><p>Un método en <a class="reference internal" href="#term-classifiers"><span class="xref std std-term">clasificadores</span></a> y <a class="reference internal" href="#term-clusterers"><span class="xref std std-term">agrupadores</span></a> que puede devolver estimaciones de probabilidad para cada clase/conglomerado.  Su entrada suele ser sólo algunos datos observados, <a class="reference internal" href="#term-X"><span class="xref std std-term">X</span></a>.</p>
<p>Si el estimador no estaba ya <a class="reference internal" href="#term-fitted"><span class="xref std std-term">ajustado</span></a>, la llamada a este método debería lanzar un <a class="reference internal" href="modules/generated/sklearn.exceptions.NotFittedError.html#sklearn.exceptions.NotFittedError" title="sklearn.exceptions.NotFittedError"><code class="xref py py-class docutils literal notranslate"><span class="pre">exceptions.NotFittedError</span></code></a>.</p>
<p>Las convenciones de salida son como las de <a class="reference internal" href="#term-decision_function"><span class="xref std std-term">decision_function</span></a>, excepto en el caso de la clasificación <a class="reference internal" href="#term-binary"><span class="xref std std-term">binaria</span></a>, donde una columna es la salida para cada clase (mientras que <code class="docutils literal notranslate"><span class="pre">decision_function</span></code> tiene como salida un arreglo 1D). Para las predicciones binarias y multiclase, cada fila debe sumar 1.</p>
<p>Al igual que otros métodos, <code class="docutils literal notranslate"><span class="pre">predict_proba</span></code> sólo debe estar presente cuando el estimador puede realizar predicciones probabilísticas (ver <a class="reference internal" href="#term-duck-typing"><span class="xref std std-term">duck typing</span></a>). Esto significa que la presencia del método puede depender de los parámetros del estimador (por ejemplo, en <a class="reference internal" href="modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier" title="sklearn.linear_model.SGDClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">linear_model.SGDClassifier</span></code></a>) o de los datos de entrenamiento (por ejemplo, en <a class="reference internal" href="modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV" title="sklearn.model_selection.GridSearchCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">model_selection.GridSearchCV</span></code></a>) y puede aparecer sólo después del ajuste.</p>
</dd>
<dt id="term-score"><code class="docutils literal notranslate"><span class="pre">score</span></code><a class="headerlink" href="#term-score" title="Permalink to this term">¶</a></dt><dd><p>Un método en un estimador, normalmente un <a class="reference internal" href="#term-predictor"><span class="xref std std-term">predictor</span></a>, que evalúa sus predicciones en un conjunto de datos dado, y devuelve una única puntuación numérica.  Un valor de retorno mayor debería indicar mejores predicciones; la precisión se utiliza para los clasificadores y R^2 para los regresores por defecto.</p>
<p>Si el estimador no estaba ya <a class="reference internal" href="#term-fitted"><span class="xref std std-term">ajustado</span></a>, la llamada a este método debería lanzar un <a class="reference internal" href="modules/generated/sklearn.exceptions.NotFittedError.html#sklearn.exceptions.NotFittedError" title="sklearn.exceptions.NotFittedError"><code class="xref py py-class docutils literal notranslate"><span class="pre">exceptions.NotFittedError</span></code></a>.</p>
<p>Algunos estimadores implementan una función de puntuación personalizada y específica del estimador, a menudo la verosimilitud de los datos bajo el modelo.</p>
</dd>
<dt id="term-score_samples"><code class="docutils literal notranslate"><span class="pre">score_samples</span></code><a class="headerlink" href="#term-score_samples" title="Permalink to this term">¶</a></dt><dd><p>TODO</p>
<p>Si el estimador no estaba ya <a class="reference internal" href="#term-fitted"><span class="xref std std-term">ajustado</span></a>, la llamada a este método debería lanzar un <a class="reference internal" href="modules/generated/sklearn.exceptions.NotFittedError.html#sklearn.exceptions.NotFittedError" title="sklearn.exceptions.NotFittedError"><code class="xref py py-class docutils literal notranslate"><span class="pre">exceptions.NotFittedError</span></code></a>.</p>
</dd>
<dt id="term-set_params"><code class="docutils literal notranslate"><span class="pre">set_params</span></code><a class="headerlink" href="#term-set_params" title="Permalink to this term">¶</a></dt><dd><p>Disponible en cualquier estimador, toma argumentos de palabras clave correspondientes a las claves de <a class="reference internal" href="#term-get_params"><span class="xref std std-term">get_params</span></a>. A cada uno se le proporciona un nuevo valor para asignar, de forma que al llamar a <code class="docutils literal notranslate"><span class="pre">get_params</span></code> después de <code class="docutils literal notranslate"><span class="pre">set_params</span></code> reflejará los <a class="reference internal" href="#term-parameters"><span class="xref std std-term">parámetros</span></a> modificados. La mayoría de los estimadores utilizan la implementación en <a class="reference internal" href="modules/generated/sklearn.base.BaseEstimator.html#sklearn.base.BaseEstimator" title="sklearn.base.BaseEstimator"><code class="xref py py-class docutils literal notranslate"><span class="pre">base.BaseEstimator</span></code></a>, que maneja los parámetros anidados y, en caso contrario, establece el parámetro como un atributo en el estimador. El método es sobreescrito en <a class="reference internal" href="modules/generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline" title="sklearn.pipeline.Pipeline"><code class="xref py py-class docutils literal notranslate"><span class="pre">pipeline.Pipeline</span></code></a> y estimadores relacionados.</p>
</dd>
<dt id="term-split"><code class="docutils literal notranslate"><span class="pre">split</span></code><a class="headerlink" href="#term-split" title="Permalink to this term">¶</a></dt><dd><p>En un <a class="reference internal" href="#term-CV-splitter"><span class="xref std std-term">separador de CV</span></a> (no un estimador), este método acepta parámetros (<a class="reference internal" href="#term-X"><span class="xref std std-term">X</span></a>, <a class="reference internal" href="#term-y"><span class="xref std std-term">y</span></a>, <a class="reference internal" href="#term-groups"><span class="xref std std-term">groups</span></a>), donde todos pueden ser opcionales, y devuelve un iterador sobre pares <code class="docutils literal notranslate"><span class="pre">(train_idx,</span> <span class="pre">test_idx)</span></code>.  Cada uno de {train,test}_idx es un arreglo 1D de enteros, con valores desde 0 hasta <code class="docutils literal notranslate"><span class="pre">X.shape[0]</span> <span class="pre">-</span> <span class="pre">1</span></code> de cualquier longitud, de forma que no aparezcan valores tanto en algún <code class="docutils literal notranslate"><span class="pre">train_idx</span></code> como en su correspondiente <code class="docutils literal notranslate"><span class="pre">test_idx</span></code>.</p>
</dd>
<dt id="term-transform"><code class="docutils literal notranslate"><span class="pre">transform</span></code><a class="headerlink" href="#term-transform" title="Permalink to this term">¶</a></dt><dd><p>En un <a class="reference internal" href="#term-transformer"><span class="xref std std-term">transformador</span></a>, transforma la entrada, normalmente sólo <a class="reference internal" href="#term-X"><span class="xref std std-term">X</span></a>, en algún espacio transformado (convencionalmente anotado como <a class="reference internal" href="#term-Xt"><span class="xref std std-term">Xt</span></a>). La salida es un arreglo o matriz dispersa de longitud <a class="reference internal" href="#term-n_samples"><span class="xref std std-term">n_samples</span></a> y con el número de columnas fijado después del <a class="reference internal" href="#term-fitting"><span class="xref std std-term">ajuste</span></a>.</p>
<p>Si el estimador no estaba ya <a class="reference internal" href="#term-fitted"><span class="xref std std-term">ajustado</span></a>, la llamada a este método debería lanzar un <a class="reference internal" href="modules/generated/sklearn.exceptions.NotFittedError.html#sklearn.exceptions.NotFittedError" title="sklearn.exceptions.NotFittedError"><code class="xref py py-class docutils literal notranslate"><span class="pre">exceptions.NotFittedError</span></code></a>.</p>
</dd>
</dl>
</section>
<section id="parameters">
<span id="glossary-parameters"></span><h2>Parámetros<a class="headerlink" href="#parameters" title="Enlazar permanentemente con este título">¶</a></h2>
<p>Estos nombres de parámetros comunes, utilizados específicamente en la construcción de estimadores (ver el concepto <a class="reference internal" href="#term-parameter"><span class="xref std std-term">parámetro</span></a>), a veces también aparecen como parámetros de funciones o constructores no estimadores.</p>
<dl class="glossary">
<dt id="term-class_weight"><code class="docutils literal notranslate"><span class="pre">class_weight</span></code><a class="headerlink" href="#term-class_weight" title="Permalink to this term">¶</a></dt><dd><p>Se utiliza para especificar las ponderaciones de las muestras cuando se ajustan los clasificadores en función de la clase <a class="reference internal" href="#term-target"><span class="xref std std-term">target</span></a>. Donde <a class="reference internal" href="#term-sample_weight"><span class="xref std std-term">sample_weight</span></a> también se admite y se da, se multiplica por la contribución de <code class="docutils literal notranslate"><span class="pre">class_weight</span></code>. Del mismo modo, cuando se utiliza <code class="docutils literal notranslate"><span class="pre">class_weight</span></code> en tareas de <a class="reference internal" href="#term-multioutput"><span class="xref std std-term">salida múltiple</span></a> (incluyendo <a class="reference internal" href="#term-multilabel"><span class="xref std std-term">multietiqueta</span></a>), las ponderaciones se multiplican por las salidas (es decir, las columnas de <code class="docutils literal notranslate"><span class="pre">y</span></code>).</p>
<p>Por defecto, todas las muestras tienen la misma ponderación, de manera que las clases se ponderan efectivamente por su prevalencia en los datos de entrenamiento. Esto podría lograrse explícitamente con <code class="docutils literal notranslate"><span class="pre">class_weight={label1:</span> <span class="pre">1,</span> <span class="pre">label2:</span> <span class="pre">1,</span> <span class="pre">...}</span></code> para todas las etiquetas de clase.</p>
<p>De forma más general, <code class="docutils literal notranslate"><span class="pre">class_weight</span></code> se especifica como un diccionario que mapea etiquetas de clase a ponderaciones (<code class="docutils literal notranslate"><span class="pre">{class_label:</span> <span class="pre">weight}</span></code>), de forma que cada muestra de la clase nombrada recibe esa ponderación.</p>
<p>Se puede utilizar <code class="docutils literal notranslate"><span class="pre">class_weight='balanced'</span></code> para dar a todas las clases la misma ponderación dando a cada muestra una ponderación inversamente relacionada con la prevalencia de su clase en los datos de entrenamiento: <code class="docutils literal notranslate"><span class="pre">n_samples</span> <span class="pre">/</span> <span class="pre">(n_classes</span> <span class="pre">*</span> <span class="pre">np.bincount(y))</span></code>. Las ponderaciones de las clases se utilizarán de forma diferente según el algoritmo: para los modelos lineales (como las Máquinas de Vectores de Soporte [Support Vector Machines, SVM] lineales o la regresión logística), las ponderaciones de las clases alterarán la función de pérdida ponderando la pérdida de cada muestra por su ponderación de la clase. Para los algoritmos basados en árboles, las ponderaciones de la clase se utilizarán para reponderar el criterio de separación. <strong>Nota</strong>, sin embargo, que este reequilibrio no tiene en cuenta la ponderación de las muestras en cada clase.</p>
<p>Para la clasificación multisalida, se utiliza una lista de diccionarios para especificar las ponderaciones de cada salida. Por ejemplo, para la clasificación multietiqueta de cuatro clases las ponderaciones deben ser <code class="docutils literal notranslate"><span class="pre">[{0:</span> <span class="pre">1,</span> <span class="pre">1:</span> <span class="pre">1},</span> <span class="pre">{0:</span> <span class="pre">1,</span> <span class="pre">1:</span> <span class="pre">5},</span> <span class="pre">{0:</span> <span class="pre">1,</span> <span class="pre">1:</span> <span class="pre">1},</span> <span class="pre">{0:</span> <span class="pre">1,</span> <span class="pre">1:</span> <span class="pre">1}]</span></code> en lugar de <code class="docutils literal notranslate"><span class="pre">[{1:1},</span> <span class="pre">{2:5},</span> <span class="pre">{3:1},</span> <span class="pre">{4:1}]</span></code>.</p>
<p>El parámetro <code class="docutils literal notranslate"><span class="pre">class_weight</span></code> se valida e interpreta con <code class="xref py py-func docutils literal notranslate"><span class="pre">utils.compute_class_weight</span></code>.</p>
</dd>
<dt id="term-cv"><code class="docutils literal notranslate"><span class="pre">cv</span></code><a class="headerlink" href="#term-cv" title="Permalink to this term">¶</a></dt><dd><p>Determina una estrategia de separación de validación-cruzada, como la utilizada en las rutinas basadas en la validación cruzada. <code class="docutils literal notranslate"><span class="pre">cv</span></code> también está disponible en estimadores como <a class="reference internal" href="modules/generated/sklearn.multioutput.ClassifierChain.html#sklearn.multioutput.ClassifierChain" title="sklearn.multioutput.ClassifierChain"><code class="xref py py-class docutils literal notranslate"><span class="pre">multioutput.ClassifierChain</span></code></a> o <a class="reference internal" href="modules/generated/sklearn.calibration.CalibratedClassifierCV.html#sklearn.calibration.CalibratedClassifierCV" title="sklearn.calibration.CalibratedClassifierCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">calibration.CalibratedClassifierCV</span></code></a> que utilizan las predicciones de un estimador como datos de entrenamiento para otro, para no sobreajustar la supervisión de entrenamiento.</p>
<p>Las entradas posibles para <code class="docutils literal notranslate"><span class="pre">cv</span></code> son usualmente:</p>
<ul class="simple">
<li><p>Un número entero que especifica el número de pliegues en la validación cruzada K-fold. K-fold se estratificará sobre las clases si el estimador es un clasificador (determinado por <a class="reference internal" href="modules/generated/sklearn.base.is_classifier.html#sklearn.base.is_classifier" title="sklearn.base.is_classifier"><code class="xref py py-func docutils literal notranslate"><span class="pre">base.is_classifier</span></code></a>) y los <a class="reference internal" href="#term-targets"><span class="xref std std-term">objetivos</span></a> pueden representar un problema de clasificación binario o multiclase (pero no de salida múltiple) (determinado por <a class="reference internal" href="modules/generated/sklearn.utils.multiclass.type_of_target.html#sklearn.utils.multiclass.type_of_target" title="sklearn.utils.multiclass.type_of_target"><code class="xref py py-func docutils literal notranslate"><span class="pre">utils.multiclass.type_of_target</span></code></a>).</p></li>
<li><p>Una instancia de <a class="reference internal" href="#term-cross-validation-splitter"><span class="xref std std-term">separador de validación-cruzada</span></a>. Consulta el <a class="reference internal" href="modules/cross_validation.html#cross-validation"><span class="std std-ref">Manual de Usuario</span></a> para conocer los separadores disponibles en scikit-learn.</p></li>
<li><p>Un iterable que produce separaciones de entrenamiento/prueba.</p></li>
</ul>
<p>Salvo algunas excepciones (especialmente cuando es una opción prescindir de la validación-cruzada), el valor por defecto es de 5 pliegues.</p>
<p>Los valores de <code class="docutils literal notranslate"><span class="pre">cv</span></code> se validan e interpretan con <code class="xref py py-func docutils literal notranslate"><span class="pre">utils.check_cv</span></code>.</p>
</dd>
<dt id="term-kernel"><code class="docutils literal notranslate"><span class="pre">kernel</span></code><a class="headerlink" href="#term-kernel" title="Permalink to this term">¶</a></dt><dd><p>TODO</p>
</dd>
<dt id="term-max_iter"><code class="docutils literal notranslate"><span class="pre">max_iter</span></code><a class="headerlink" href="#term-max_iter" title="Permalink to this term">¶</a></dt><dd><p>Para los estimadores que implican una optimización iterativa, esto determina el número máximo de iteraciones a realizar en <a class="reference internal" href="#term-fit"><span class="xref std std-term">fit</span></a>. Si las iteraciones <code class="docutils literal notranslate"><span class="pre">max_iter</span></code> se ejecutan sin convergencia, se debe levantar un <a class="reference internal" href="modules/generated/sklearn.exceptions.ConvergenceWarning.html#sklearn.exceptions.ConvergenceWarning" title="sklearn.exceptions.ConvergenceWarning"><code class="xref py py-class docutils literal notranslate"><span class="pre">exceptions.ConvergenceWarning</span></code></a>. Ten en cuenta que la interpretación de «una sola iteración» es inconsistente entre los estimadores: algunos, pero no todos, lo utilizan para referirse a una sola época (es decir, una pasada por cada muestra en los datos).</p>
<p>FIXME tal vez deberíamos tener algunos tests comunes sobre la relación entre ConvergenceWarning y max_iter.</p>
</dd>
<dt id="term-memory"><code class="docutils literal notranslate"><span class="pre">memory</span></code><a class="headerlink" href="#term-memory" title="Permalink to this term">¶</a></dt><dd><p>Algunos estimadores hacen uso de <a class="reference external" href="https://joblib.readthedocs.io/en/latest/generated/joblib.Memory.html#joblib.Memory" title="(en joblib versión 1.1.0.dev0)"><code class="xref py py-class docutils literal notranslate"><span class="pre">joblib.Memory</span></code></a> para almacenar soluciones parciales durante el ajuste. Así, cuando se llama de nuevo a <code class="docutils literal notranslate"><span class="pre">fit</span></code>, esas soluciones parciales han sido memorizadas y pueden ser reutilizadas.</p>
<p>Un parámetro <code class="docutils literal notranslate"><span class="pre">memory</span></code> puede especificarse como una cadena con una ruta a un directorio, o puede utilizarse una instancia de <a class="reference external" href="https://joblib.readthedocs.io/en/latest/generated/joblib.Memory.html#joblib.Memory" title="(en joblib versión 1.1.0.dev0)"><code class="xref py py-class docutils literal notranslate"><span class="pre">joblib.Memory</span></code></a> (o un objeto con una interfaz similar, es decir, un método <code class="docutils literal notranslate"><span class="pre">cache</span></code>).</p>
<p>Los valores de <code class="docutils literal notranslate"><span class="pre">memory</span></code> se validan e interpretan con <a class="reference internal" href="modules/generated/sklearn.utils.validation.check_memory.html#sklearn.utils.validation.check_memory" title="sklearn.utils.validation.check_memory"><code class="xref py py-func docutils literal notranslate"><span class="pre">utils.validation.check_memory</span></code></a>.</p>
</dd>
<dt id="term-metric"><code class="docutils literal notranslate"><span class="pre">metric</span></code><a class="headerlink" href="#term-metric" title="Permalink to this term">¶</a></dt><dd><p>Como parámetro, es el esquema para determinar la distancia entre dos puntos de datos.  Ver <a class="reference internal" href="modules/generated/sklearn.metrics.pairwise_distances.html#sklearn.metrics.pairwise_distances" title="sklearn.metrics.pairwise_distances"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.pairwise_distances</span></code></a>. En la práctica, para algunos algoritmos, se puede utilizar una métrica de distancia inadecuada (una que no obedece a la desigualdad del triángulo, como la Distancia del Coseno).</p>
<p>XXX: el análisis de conglomerados jerárquico utiliza <code class="docutils literal notranslate"><span class="pre">affinity</span></code> con este significado.</p>
<p>También utilizamos <em>metric</em> para referirnos a <a class="reference internal" href="#term-evaluation-metrics"><span class="xref std std-term">métricas de evaluación</span></a>, pero evitamos utilizar este sentido como nombre de parámetro.</p>
</dd>
<dt id="term-n_components"><code class="docutils literal notranslate"><span class="pre">n_components</span></code><a class="headerlink" href="#term-n_components" title="Permalink to this term">¶</a></dt><dd><p>El número de características en las que un <a class="reference internal" href="#term-transformer"><span class="xref std std-term">transformador</span></a> debe transformar la entrada. Ver <a class="reference internal" href="#term-components_"><span class="xref std std-term">components_</span></a> para el caso especial de la proyección afín.</p>
</dd>
<dt id="term-n_iter_no_change"><code class="docutils literal notranslate"><span class="pre">n_iter_no_change</span></code><a class="headerlink" href="#term-n_iter_no_change" title="Permalink to this term">¶</a></dt><dd><p>Número de iteraciones sin mejora a esperar antes de detener el procedimiento iterativo. También se conoce como parámetro de <em>paciencia</em>. Se suele utilizar con <a class="reference internal" href="#term-early-stopping"><span class="xref std std-term">parada anticipada</span></a> para evitar que se detenga demasiado pronto.</p>
</dd>
<dt id="term-n_jobs"><code class="docutils literal notranslate"><span class="pre">n_jobs</span></code><a class="headerlink" href="#term-n_jobs" title="Permalink to this term">¶</a></dt><dd><p>Este parámetro se utiliza para especificar cuántos procesos o hilos concurrentes deben utilizarse para las rutinas que se paralelizan con <a class="reference internal" href="#term-joblib"><span class="xref std std-term">joblib</span></a>.</p>
<p><code class="docutils literal notranslate"><span class="pre">n_jobs</span></code> es un número entero, que especifica el número máximo de trabajadores que se ejecutan simultáneamente. Si se da 1, no se utiliza el paralelismo joblib en absoluto, lo que es útil para la depuración. Si se establece en -1, se utilizan todas las CPUs. Para <code class="docutils literal notranslate"><span class="pre">n_jobs</span></code> por debajo de -1, se utilizan (n_cpus + 1 + n_jobs). Por ejemplo, con <code class="docutils literal notranslate"><span class="pre">n_jobs=-2</span></code>, se utilizan todas las CPUs excepto una.</p>
<p><code class="docutils literal notranslate"><span class="pre">n_jobs</span></code> es <code class="docutils literal notranslate"><span class="pre">None</span></code> por defecto, lo que significa <em>no establecido</em>; generalmente se interpretará como <code class="docutils literal notranslate"><span class="pre">n_jobs=1</span></code>, a menos que el contexto actual del backend <a class="reference external" href="https://joblib.readthedocs.io/en/latest/generated/joblib.Parallel.html#joblib.Parallel" title="(en joblib versión 1.1.0.dev0)"><code class="xref py py-class docutils literal notranslate"><span class="pre">joblib.Parallel</span></code></a> especifique lo contrario.</p>
<p>Para más detalles sobre el uso de <code class="docutils literal notranslate"><span class="pre">joblib</span></code> y sus interacciones con scikit-learn, consulta nuestras <a class="reference internal" href="computing/parallelism.html#parallelism"><span class="std std-ref">notas de paralelismo</span></a>.</p>
</dd>
<dt id="term-pos_label"><code class="docutils literal notranslate"><span class="pre">pos_label</span></code><a class="headerlink" href="#term-pos_label" title="Permalink to this term">¶</a></dt><dd><p>Valor con el que deben codificarse las etiquetas positivas en los problemas de clasificación binaria en los que no se asume la clase positiva. Este valor suele ser necesario para calcular métricas de evaluación asimétricas como la precisión y la exhaustividad.</p>
</dd>
<dt id="term-random_state"><code class="docutils literal notranslate"><span class="pre">random_state</span></code><a class="headerlink" href="#term-random_state" title="Permalink to this term">¶</a></dt><dd><p>Cuando la aleatorización es parte de un algoritmo de scikit-learn, se puede proporcionar un parámetro <code class="docutils literal notranslate"><span class="pre">random_state</span></code> para controlar el generador de números aleatorios utilizado. Ten en cuenta que la mera presencia de <code class="docutils literal notranslate"><span class="pre">random_state</span></code> no significa que la aleatorización se utilice siempre, ya que puede depender de que se establezca otro parámetro, por ejemplo, <code class="docutils literal notranslate"><span class="pre">shuffle</span></code>.</p>
<p>El valor pasado tendrá un efecto en la reproducibilidad de los resultados devueltos por la función (<a class="reference internal" href="#term-fit"><span class="xref std std-term">fit</span></a>, <a class="reference internal" href="#term-split"><span class="xref std std-term">split</span></a>, o cualquier otra función como <a class="reference internal" href="modules/generated/sklearn.cluster.k_means.html#sklearn.cluster.k_means" title="sklearn.cluster.k_means"><code class="xref py py-func docutils literal notranslate"><span class="pre">k_means</span></code></a>). El valor de <code class="docutils literal notranslate"><span class="pre">random_state</span></code> puede ser:</p>
<dl class="simple">
<dt>None (predeterminado)</dt><dd><p>Utiliza la instancia global de estado aleatorio de <a class="reference external" href="https://numpy.org/doc/stable/reference/random/index.html#module-numpy.random" title="(en NumPy versión 1.21)"><code class="xref py py-mod docutils literal notranslate"><span class="pre">numpy.random</span></code></a>. Si se llama a la función varias veces, se reutilizará la misma instancia y se producirán resultados diferentes.</p>
</dd>
<dt>Un número entero</dt><dd><p>Utiliza un nuevo generador de números aleatorios cuya semilla es el número entero dado. El uso de un int producirá los mismos resultados en diferentes llamadas. Sin embargo, puede valer la pena comprobar que sus resultados son estables a través de una serie de diferentes semillas aleatorias. Las semillas aleatorias enteras más populares son 0 y <a class="reference external" href="https://en.wikipedia.org/wiki/Answer_to_the_Ultimate_Question_of_Life%2C_the_Universe%2C_and_Everything">42</a>.</p>
</dd>
<dt>Una instancia de <a class="reference external" href="https://numpy.org/doc/stable/reference/random/legacy.html#numpy.random.RandomState" title="(en NumPy versión 1.21)"><code class="xref py py-class docutils literal notranslate"><span class="pre">numpy.random.RandomState</span></code></a></dt><dd><p>Utiliza el estado aleatorio proporcionado, afectando únicamente a otros usuarios de esa misma instancia de estado aleatorio. Llamar a la función varias veces reutilizará la misma instancia, y producirá resultados diferentes.</p>
</dd>
</dl>
<p><a class="reference internal" href="modules/generated/sklearn.utils.check_random_state.html#sklearn.utils.check_random_state" title="sklearn.utils.check_random_state"><code class="xref py py-func docutils literal notranslate"><span class="pre">utils.check_random_state</span></code></a> se utiliza internamente para validar la entrada <code class="docutils literal notranslate"><span class="pre">random_state</span></code> y devolver una instancia de <a class="reference external" href="https://numpy.org/doc/stable/reference/random/legacy.html#numpy.random.RandomState" title="(en NumPy versión 1.21)"><code class="xref py py-class docutils literal notranslate"><span class="pre">RandomState</span></code></a>.</p>
<p>Para más detalles sobre cómo controlar la aleatoriedad de los objetos de scikit-learn y evitar errores comunes, puedes consultar <a class="reference internal" href="common_pitfalls.html#randomness"><span class="std std-ref">Control de aleatoriedad</span></a>.</p>
</dd>
<dt id="term-scoring"><code class="docutils literal notranslate"><span class="pre">scoring</span></code><a class="headerlink" href="#term-scoring" title="Permalink to this term">¶</a></dt><dd><p>Especifica la función de puntuación que se va a maximizar (normalmente mediante <a class="reference internal" href="modules/cross_validation.html#cross-validation"><span class="std std-ref">validación-cruzada</span></a>), o – en algunos casos – múltiples funciones de puntuación a ser reportadas. La función de puntuación puede ser una cadena aceptada por <a class="reference internal" href="modules/generated/sklearn.metrics.get_scorer.html#sklearn.metrics.get_scorer" title="sklearn.metrics.get_scorer"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.get_scorer</span></code></a> o un <a class="reference internal" href="#term-scorer"><span class="xref std std-term">scorer</span></a> invocable, que no debe confundirse con una <a class="reference internal" href="#term-evaluation-metric"><span class="xref std std-term">métrica de evaluación</span></a>, ya que esta última tiene una API más diversa. <code class="docutils literal notranslate"><span class="pre">scoring</span></code> también se puede establecer como None, en cuyo caso se utiliza el método <a class="reference internal" href="#term-score"><span class="xref std std-term">score</span></a> del estimador. Ver <a class="reference internal" href="modules/model_evaluation.html#scoring-parameter"><span class="std std-ref">El parámetro scoring: definir las reglas de evaluación del modelo</span></a> en el Manual de Usuario.</p>
<p>Donde múltiples métricas pueden ser evaluadas, <code class="docutils literal notranslate"><span class="pre">scoring</span></code> puede ser dado como una lista de cadenas únicas, un diccionario con nombres como claves e invocables como valores o un invocable que devuelve un diccionario. Ten en cuenta que esto <em>no</em> especifica qué función de puntuación debe ser maximizada, y otro parámetro como <code class="docutils literal notranslate"><span class="pre">refit</span></code> puede ser utilizado para este propósito.</p>
<p>El parámetro <code class="docutils literal notranslate"><span class="pre">scoring</span></code> se valida e interpreta mediante <a class="reference internal" href="modules/generated/sklearn.metrics.check_scoring.html#sklearn.metrics.check_scoring" title="sklearn.metrics.check_scoring"><code class="xref py py-func docutils literal notranslate"><span class="pre">metrics.check_scoring</span></code></a>.</p>
</dd>
<dt id="term-verbose"><code class="docutils literal notranslate"><span class="pre">verbose</span></code><a class="headerlink" href="#term-verbose" title="Permalink to this term">¶</a></dt><dd><p>El registro (logging) no se maneja de manera muy consistente en scikit-learn en la actualidad, pero cuando se proporciona como una opción, el parámetro <code class="docutils literal notranslate"><span class="pre">verbose</span></code> suele estar disponible para elegir no registrar (establecido en False). Cualquier valor True debería permitir algún tipo de registro, pero los enteros más grandes (por ejemplo, por encima de 10) pueden ser necesarios para la verbosidad completa. Los registros verbosos se imprimen normalmente en la Salida Estándar. Los estimadores no deberían producir ninguna salida en la Salida Estándar con la configuración predeterminada <code class="docutils literal notranslate"><span class="pre">verbose</span></code>.</p>
</dd>
<dt id="term-warm_start"><code class="docutils literal notranslate"><span class="pre">warm_start</span></code><a class="headerlink" href="#term-warm_start" title="Permalink to this term">¶</a></dt><dd><p>Cuando se ajusta un estimador repetidamente en el mismo conjunto de datos, pero para múltiples valores de parámetros (como para encontrar el valor que maximiza el rendimiento como en <a class="reference internal" href="modules/grid_search.html#grid-search"><span class="std std-ref">búsqueda en cuadrícula</span></a>), puede ser posible reutilizar aspectos del modelo aprendidos del valor de parámetro anterior, ahorrando tiempo. Cuando <code class="docutils literal notranslate"><span class="pre">warm_start</span></code> es verdadero, los <a class="reference internal" href="#term-attributes"><span class="xref std std-term">atributos</span></a> del modelo <a class="reference internal" href="#term-fitted"><span class="xref std std-term">ajustado</span></a> existente se utilizan para inicializar el nuevo modelo en una llamada posterior a <a class="reference internal" href="#term-fit"><span class="xref std std-term">fit</span></a>.</p>
<p>Ten en cuenta que esto sólo es aplicable para algunos modelos y algunos parámetros, e incluso algunos órdenes de valores de parámetros. Por ejemplo, <code class="docutils literal notranslate"><span class="pre">warm_start</span></code> puede utilizarse al construir bosques aleatorios para añadir más árboles al bosque (incrementando <code class="docutils literal notranslate"><span class="pre">n_estimators</span></code>) pero no para reducir su número.</p>
<p><a class="reference internal" href="#term-partial_fit"><span class="xref std std-term">partial_fit</span></a> también conserva el modelo entre llamadas, pero difiere: con <code class="docutils literal notranslate"><span class="pre">warm_start</span></code> los parámetros cambian y los datos son (más o menos) constantes a través de las llamadas a <code class="docutils literal notranslate"><span class="pre">fit</span></code>; con <code class="docutils literal notranslate"><span class="pre">partial_fit</span></code>, el mini lote de datos cambia y los parámetros del modelo permanecen fijos.</p>
<p>Hay casos en los que se desea utilizar <code class="docutils literal notranslate"><span class="pre">warm_start</span></code> para ajustar en datos diferentes, pero estrechamente relacionados. Por ejemplo, uno puede ajustar inicialmente a un subconjunto de los datos, y luego afinar la búsqueda de parámetros en el conjunto de datos completo. Para la clasificación, todos los datos en una secuencia de llamadas <code class="docutils literal notranslate"><span class="pre">warm_start</span></code> a <code class="docutils literal notranslate"><span class="pre">fit</span></code> deben incluir muestras de cada clase.</p>
</dd>
</dl>
</section>
<section id="attributes">
<span id="glossary-attributes"></span><h2>Atributos<a class="headerlink" href="#attributes" title="Enlazar permanentemente con este título">¶</a></h2>
<p>Ver el concepto <a class="reference internal" href="#term-attribute"><span class="xref std std-term">atributo</span></a>.</p>
<dl class="glossary">
<dt id="term-classes_"><code class="docutils literal notranslate"><span class="pre">classes_</span></code><a class="headerlink" href="#term-classes_" title="Permalink to this term">¶</a></dt><dd><p>Una lista de etiquetas de clase conocidas por el <a class="reference internal" href="#term-classifier"><span class="xref std std-term">clasificador</span></a>, mapeando cada etiqueta a un índice numérico utilizado en la representación del modelo de nuestra salida. Por ejemplo, el arreglo de salida de <a class="reference internal" href="#term-predict_proba"><span class="xref std std-term">predict_proba</span></a> tiene columnas alineadas con <code class="docutils literal notranslate"><span class="pre">classes_</span></code>. Para los clasificadores de <a class="reference internal" href="#term-multioutput"><span class="xref std std-term">salida múltiple</span></a>, <code class="docutils literal notranslate"><span class="pre">classes_</span></code> debe ser una lista de listas, con una lista de clases para cada salida. Para cada salida, las clases deben estar ordenadas (numéricamente, o lexicográficamente para cadenas).</p>
<p><code class="docutils literal notranslate"><span class="pre">classes_</span></code> y el mapeo a los índices se suele gestionar con <a class="reference internal" href="modules/generated/sklearn.preprocessing.LabelEncoder.html#sklearn.preprocessing.LabelEncoder" title="sklearn.preprocessing.LabelEncoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">preprocessing.LabelEncoder</span></code></a>.</p>
</dd>
<dt id="term-components_"><code class="docutils literal notranslate"><span class="pre">components_</span></code><a class="headerlink" href="#term-components_" title="Permalink to this term">¶</a></dt><dd><p>Una matriz de transformación afín de forma <code class="docutils literal notranslate"><span class="pre">(n_components,</span> <span class="pre">n_features)</span></code> utilizada en muchos <a class="reference internal" href="#term-transformers"><span class="xref std std-term">transformadores</span></a> lineales donde <a class="reference internal" href="#term-n_components"><span class="xref std std-term">n_components</span></a> es el número de características de salida y <a class="reference internal" href="#term-n_features"><span class="xref std std-term">n_features</span></a> es el número de características de entrada.</p>
<p>Ver también <a class="reference internal" href="#term-components_"><span class="xref std std-term">components_</span></a> que es un atributo similar para los predictores lineales.</p>
</dd>
<dt id="term-coef_"><code class="docutils literal notranslate"><span class="pre">coef_</span></code><a class="headerlink" href="#term-coef_" title="Permalink to this term">¶</a></dt><dd><p>La matriz de ponderaciones/coeficientes de un <a class="reference internal" href="#term-predictor"><span class="xref std std-term">predictor</span></a> de modelo lineal generalizado, de forma <code class="docutils literal notranslate"><span class="pre">(n_features,)</span></code> para la clasificación binaria y la regresión de salida única, <code class="docutils literal notranslate"><span class="pre">(n_clases,</span> <span class="pre">n_features)</span></code> para la clasificación multiclase y <code class="docutils literal notranslate"><span class="pre">(n_targets,</span> <span class="pre">n_features)</span></code> para la regresión de salida múltiple. Ten en cuenta que esto no incluye el término de intercepto (o sesgo), que se almacena en <code class="docutils literal notranslate"><span class="pre">intercept_</span></code>.</p>
<p>Cuando está disponible, <code class="docutils literal notranslate"><span class="pre">feature_importances_</span></code> no suele proporcionarse también, pero puede calcularse como la norma de la entrada de cada característica en <code class="docutils literal notranslate"><span class="pre">coef_</span></code>.</p>
<p>Ver también <a class="reference internal" href="#term-components_"><span class="xref std std-term">components_</span></a> que es un atributo similar para los transformadores lineales.</p>
</dd>
<dt id="term-embedding_"><code class="docutils literal notranslate"><span class="pre">embedding_</span></code><a class="headerlink" href="#term-embedding_" title="Permalink to this term">¶</a></dt><dd><p>Un embedding de los datos de entrenamiento en estimadores <a class="reference internal" href="modules/manifold.html#manifold"><span class="std std-ref">aprendizaje múltiple</span></a>, con forma <code class="docutils literal notranslate"><span class="pre">(n_samples,</span> <span class="pre">n_components)</span></code>, idéntico a la salida de <a class="reference internal" href="#term-fit_transform"><span class="xref std std-term">fit_transform</span></a>. Ver también <a class="reference internal" href="#term-labels_"><span class="xref std std-term">labels_</span></a>.</p>
</dd>
<dt id="term-n_iter_"><code class="docutils literal notranslate"><span class="pre">n_iter_</span></code><a class="headerlink" href="#term-n_iter_" title="Permalink to this term">¶</a></dt><dd><p>El número de iteraciones realmente realizadas cuando se ajusta un estimador iterativo que puede detenerse en la convergencia. Ver también <a class="reference internal" href="#term-max_iter"><span class="xref std std-term">max_iter</span></a>.</p>
</dd>
<dt id="term-feature_importances_"><code class="docutils literal notranslate"><span class="pre">feature_importances_</span></code><a class="headerlink" href="#term-feature_importances_" title="Permalink to this term">¶</a></dt><dd><p>Un arreglo de forma <code class="docutils literal notranslate"><span class="pre">(n_features,)</span></code> disponible en algunos <a class="reference internal" href="#term-predictors"><span class="xref std std-term">predictores</span></a> para proporcionar una medida relativa de la importancia de cada característica en las predicciones del modelo.</p>
</dd>
<dt id="term-labels_"><code class="docutils literal notranslate"><span class="pre">labels_</span></code><a class="headerlink" href="#term-labels_" title="Permalink to this term">¶</a></dt><dd><p>Un arreglo que contiene una etiqueta de conglomerado para cada muestra de los datos de entrenamiento en <a class="reference internal" href="#term-clusterers"><span class="xref std std-term">agrupadores</span></a>, idéntica a la salida de <a class="reference internal" href="#term-fit_predict"><span class="xref std std-term">fit_predict</span></a>. Ver también <a class="reference internal" href="#term-embedding_"><span class="xref std std-term">embedding_</span></a>.</p>
</dd>
</dl>
</section>
<section id="data-and-sample-properties">
<span id="glossary-sample-props"></span><h2>Datos y propiedades de la muestra<a class="headerlink" href="#data-and-sample-properties" title="Enlazar permanentemente con este título">¶</a></h2>
<p>Ver el concepto <a class="reference internal" href="#term-sample-property"><span class="xref std std-term">sample property</span></a>.</p>
<dl class="glossary">
<dt id="term-groups"><code class="docutils literal notranslate"><span class="pre">groups</span></code><a class="headerlink" href="#term-groups" title="Permalink to this term">¶</a></dt><dd><p>Se utiliza en las rutinas de validación-cruzada para identificar las muestras que están correlacionadas. Cada valor es un identificador tal que, en un <a class="reference internal" href="#term-CV-splitter"><span class="xref std std-term">separador de CV</span></a> de apoyo, las muestras de algún valor de <code class="docutils literal notranslate"><span class="pre">groups</span></code> pueden no aparecer tanto en un conjunto de entrenamiento como en su correspondiente conjunto de prueba. Ver <a class="reference internal" href="modules/cross_validation.html#group-cv"><span class="std std-ref">Iteradores de validación cruzada para datos agrupados.</span></a>.</p>
</dd>
<dt id="term-sample_weight"><code class="docutils literal notranslate"><span class="pre">sample_weight</span></code><a class="headerlink" href="#term-sample_weight" title="Permalink to this term">¶</a></dt><dd><p>Una ponderación relativa para cada muestra. Intuitivamente, si todos las ponderaciones son números enteros, un modelo o puntuación ponderada debería ser equivalente a la calculada al repetir la muestra el número de veces especificado en la ponderación. Las ponderaciones pueden especificarse como números de punto flotante (floats), de modo que las ponderaciones de las muestras suelen ser equivalentes hasta un factor de escalamiento positivo constante.</p>
<p>FIXME ¿Es esta interpretación siempre el caso en la práctica? No tenemos tests comunes.</p>
<p>Algunos estimadores, como los árboles de decisión, admiten ponderaciones negativas. FIXME: Esta característica o su ausencia puede no estar probada o documentada en muchos estimadores.</p>
<p>Este no es del todo el caso en que otros parámetros del modelo consideran el número de muestras en una región, como ocurre con <code class="docutils literal notranslate"><span class="pre">min_samples</span></code> en <a class="reference internal" href="modules/generated/sklearn.cluster.DBSCAN.html#sklearn.cluster.DBSCAN" title="sklearn.cluster.DBSCAN"><code class="xref py py-class docutils literal notranslate"><span class="pre">cluster.DBSCAN</span></code></a>. En este caso, un conteo de muestras se convierte en una suma de sus ponderaciones.</p>
<p>En la clasificación, las ponderaciones de las muestras también pueden especificarse como una función de la clase con el <a class="reference internal" href="#term-parameter"><span class="xref std std-term">parámetro</span></a> estimador <a class="reference internal" href="#term-class_weight"><span class="xref std std-term">class_weight</span></a>.</p>
</dd>
<dt id="term-X"><code class="docutils literal notranslate"><span class="pre">X</span></code><a class="headerlink" href="#term-X" title="Permalink to this term">¶</a></dt><dd><p>Denota los datos que se observan en el momento del entrenamiento y de la predicción, utilizados como variables independientes en el aprendizaje. La notación es mayúscula para indicar que se trata normalmente de una matriz (ver <a class="reference internal" href="#term-rectangular"><span class="xref std std-term">rectangular</span></a>). Cuando se trata de una matriz, cada muestra puede estar representada por un vector de <a class="reference internal" href="#term-feature"><span class="xref std std-term">características</span></a>, o un vector de (des)similitudes <a class="reference internal" href="#term-precomputed"><span class="xref std std-term">precalculado</span></a> con cada muestra de entrenamiento. <code class="docutils literal notranslate"><span class="pre">X</span></code> también puede no ser una matriz, y puede requerir un <a class="reference internal" href="#term-feature-extractor"><span class="xref std std-term">extractor de características</span></a> o una <a class="reference internal" href="#term-pairwise-metric"><span class="xref std std-term">métrica por pares</span></a> para convertirla en una antes del aprendizaje de un modelo.</p>
</dd>
<dt id="term-Xt"><code class="docutils literal notranslate"><span class="pre">Xt</span></code><a class="headerlink" href="#term-Xt" title="Permalink to this term">¶</a></dt><dd><p>Abreviatura de «<a class="reference internal" href="#term-X"><span class="xref std std-term">X</span></a> transformada».</p>
</dd>
<dt id="term-y"><code class="docutils literal notranslate"><span class="pre">y</span></code><a class="headerlink" href="#term-y" title="Permalink to this term">¶</a></dt><dt id="term-Y"><code class="docutils literal notranslate"><span class="pre">Y</span></code><a class="headerlink" href="#term-Y" title="Permalink to this term">¶</a></dt><dd><p>Denota datos que pueden observarse en el momento del entrenamiento como variable dependiente en el aprendizaje, pero que no están disponibles en el momento de la predicción, y suele ser el <a class="reference internal" href="#term-target"><span class="xref std std-term">objetivo</span></a> de la predicción. La notación puede ser mayúscula para indicar que se trata de una matriz, que representa objetivos de <a class="reference internal" href="#term-multioutput"><span class="xref std std-term">salida múltiple</span></a>, por ejemplo; pero normalmente utilizamos <code class="docutils literal notranslate"><span class="pre">y</span></code> y a veces lo hacemos incluso cuando se asumen múltiples salidas.</p>
</dd>
</dl>
</section>
</section>


      </div>
    <div class="container">
      <footer class="sk-content-footer">
            &copy; 2007 - 2020, scikit-learn developers (BSD License).
          <a href="_sources/glossary.rst.txt" rel="nofollow">Mostrar la fuente de esta página</a>
      </footer>
    </div>
  </div>
</div>
<script src="_static/js/vendor/bootstrap.min.js"></script>

<script>
    window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
    ga('create', 'UA-22606712-2', 'auto');
    ga('set', 'anonymizeIp', true);
    ga('send', 'pageview');
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>


<script>
$(document).ready(function() {
    /* Add a [>>>] button on the top-right corner of code samples to hide
     * the >>> and ... prompts and the output and thus make the code
     * copyable. */
    var div = $('.highlight-python .highlight,' +
                '.highlight-python3 .highlight,' +
                '.highlight-pycon .highlight,' +
		'.highlight-default .highlight')
    var pre = div.find('pre');

    // get the styles from the current theme
    pre.parent().parent().css('position', 'relative');
    var hide_text = 'Hide prompts and outputs';
    var show_text = 'Show prompts and outputs';

    // create and add the button to all the code blocks that contain >>>
    div.each(function(index) {
        var jthis = $(this);
        if (jthis.find('.gp').length > 0) {
            var button = $('<span class="copybutton">&gt;&gt;&gt;</span>');
            button.attr('title', hide_text);
            button.data('hidden', 'false');
            jthis.prepend(button);
        }
        // tracebacks (.gt) contain bare text elements that need to be
        // wrapped in a span to work with .nextUntil() (see later)
        jthis.find('pre:has(.gt)').contents().filter(function() {
            return ((this.nodeType == 3) && (this.data.trim().length > 0));
        }).wrap('<span>');
    });

    // define the behavior of the button when it's clicked
    $('.copybutton').click(function(e){
        e.preventDefault();
        var button = $(this);
        if (button.data('hidden') === 'false') {
            // hide the code output
            button.parent().find('.go, .gp, .gt').hide();
            button.next('pre').find('.gt').nextUntil('.gp, .go').css('visibility', 'hidden');
            button.css('text-decoration', 'line-through');
            button.attr('title', show_text);
            button.data('hidden', 'true');
        } else {
            // show the code output
            button.parent().find('.go, .gp, .gt').show();
            button.next('pre').find('.gt').nextUntil('.gp, .go').css('visibility', 'visible');
            button.css('text-decoration', 'none');
            button.attr('title', hide_text);
            button.data('hidden', 'false');
        }
    });

	/*** Add permalink buttons next to glossary terms ***/
	$('dl.glossary > dt[id]').append(function() {
		return ('<a class="headerlink" href="#' +
			    this.getAttribute('id') +
			    '" title="Permalink to this term">¶</a>');
	});
  /*** Hide navbar when scrolling down ***/
  // Returns true when headerlink target matches hash in url
  (function() {
    hashTargetOnTop = function() {
        var hash = window.location.hash;
        if ( hash.length < 2 ) { return false; }

        var target = document.getElementById( hash.slice(1) );
        if ( target === null ) { return false; }

        var top = target.getBoundingClientRect().top;
        return (top < 2) && (top > -2);
    };

    // Hide navbar on load if hash target is on top
    var navBar = document.getElementById("navbar");
    var navBarToggler = document.getElementById("sk-navbar-toggler");
    var navBarHeightHidden = "-" + navBar.getBoundingClientRect().height + "px";
    var $window = $(window);

    hideNavBar = function() {
        navBar.style.top = navBarHeightHidden;
    };

    showNavBar = function() {
        navBar.style.top = "0";
    }

    if (hashTargetOnTop()) {
        hideNavBar()
    }

    var prevScrollpos = window.pageYOffset;
    hideOnScroll = function(lastScrollTop) {
        if (($window.width() < 768) && (navBarToggler.getAttribute("aria-expanded") === 'true')) {
            return;
        }
        if (lastScrollTop > 2 && (prevScrollpos <= lastScrollTop) || hashTargetOnTop()){
            hideNavBar()
        } else {
            showNavBar()
        }
        prevScrollpos = lastScrollTop;
    };

    /*** high performance scroll event listener***/
    var raf = window.requestAnimationFrame ||
        window.webkitRequestAnimationFrame ||
        window.mozRequestAnimationFrame ||
        window.msRequestAnimationFrame ||
        window.oRequestAnimationFrame;
    var lastScrollTop = $window.scrollTop();

    if (raf) {
        loop();
    }

    function loop() {
        var scrollTop = $window.scrollTop();
        if (lastScrollTop === scrollTop) {
            raf(loop);
            return;
        } else {
            lastScrollTop = scrollTop;
            hideOnScroll(lastScrollTop);
            raf(loop);
        }
    }
  })();
});

</script>
    
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
    
</body>
</html>