

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  
  <title>6.3. Preprocesamiento de los datos &mdash; documentación de scikit-learn - 0.24.2</title>
  
  <link rel="canonical" href="http://scikit-learn.org/stable/modules/preprocessing.html" />

  
  <link rel="shortcut icon" href="../_static/favicon.ico"/>
  

  <link rel="stylesheet" href="../_static/css/vendor/bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/gallery.css" type="text/css" />
  <link rel="stylesheet" href="../_static/gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../_static/gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../_static/gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
<script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
<script src="../_static/jquery.js"></script> 
</head>
<body>
<nav id="navbar" class="sk-docs-navbar navbar navbar-expand-md navbar-light bg-light py-0">
  <div class="container-fluid sk-docs-container px-0">
      <a class="navbar-brand py-0" href="../index.html">
        <img
          class="sk-brand-img"
          src="../_static/scikit-learn-logo-small.png"
          alt="logo"/>
      </a>
    <button
      id="sk-navbar-toggler"
      class="navbar-toggler"
      type="button"
      data-toggle="collapse"
      data-target="#navbarSupportedContent"
      aria-controls="navbarSupportedContent"
      aria-expanded="false"
      aria-label="Toggle navigation"
    >
      <span class="navbar-toggler-icon"></span>
    </button>

    <div class="sk-navbar-collapse collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav mr-auto">
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../install.html">Instalación</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../user_guide.html">Manual de Usuario</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="classes.html">API</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../auto_examples/index.html">Ejemplos</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../getting_started.html">¿Cómo empezar?</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../tutorial/index.html">Tutorial</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../whats_new/v0.24.html">Novedades</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../glossary.html">Glosario</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../developers/index.html">Desarrollo</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../faq.html">FAQ</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../support.html">Soporte</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../related_projects.html">Paquetes relacionados</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../roadmap.html">Hoja de ruta</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../about.html">Sobre nosotros</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="https://github.com/scikit-learn/scikit-learn">GitHub</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="https://scikit-learn.org/dev/versions.html">Otras versiones y descargas</a>
        </li>
        <li class="nav-item dropdown nav-more-item-dropdown">
          <a class="sk-nav-link nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Más</a>
          <div class="dropdown-menu" aria-labelledby="navbarDropdown">
              <a class="sk-nav-dropdown-item dropdown-item" href="../getting_started.html">¿Cómo empezar?</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../tutorial/index.html">Tutorial</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../whats_new/v0.24.html">Novedades</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../glossary.html">Glosario</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../developers/index.html">Desarrollo</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../faq.html">FAQ</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../support.html">Soporte</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../related_projects.html">Paquetes relacionados</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../roadmap.html">Hoja de ruta</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../about.html">Sobre nosotros</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="https://github.com/scikit-learn/scikit-learn">GitHub</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="https://scikit-learn.org/dev/versions.html">Otras versiones y descargas</a>
          </div>
        </li>
      </ul>
      <div id="searchbox" role="search">
          <div class="searchformwrapper">
          <form class="search" action="../search.html" method="get">
            <input class="sk-search-text-input" type="text" name="q" aria-labelledby="searchlabel" />
            <input class="sk-search-text-btn" type="submit" value="Ir a" />
          </form>
          </div>
      </div>
    </div>
  </div>
</nav>
<div class="d-flex" id="sk-doc-wrapper">
    <input type="checkbox" name="sk-toggle-checkbox" id="sk-toggle-checkbox">
    <label id="sk-sidemenu-toggle" class="sk-btn-toggle-toc btn sk-btn-primary" for="sk-toggle-checkbox">Alternar menú</label>
    <div id="sk-sidebar-wrapper" class="border-right">
      <div class="sk-sidebar-toc-wrapper">
        <div class="sk-sidebar-toc-logo">
          <a href="../index.html">
            <img
              class="sk-brand-img"
              src="../_static/scikit-learn-logo-small.png"
              alt="logo"/>
          </a>
        </div>
        <div class="btn-group w-100 mb-2" role="group" aria-label="rellinks">
            <a href="feature_extraction.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="6.2. Extracción de características">Prev</a><a href="../data_transforms.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="6. Transformaciones de conjuntos de datos">Arriba</a>
            <a href="impute.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="6.4. Imputación de valores faltantes">Sig.</a>
        </div>
        <div class="alert alert-danger p-1 mb-2" role="alert">
          <p class="text-center mb-0">
          <strong>scikit-learn 0.24.2</strong><br/>
          <a href="http://scikit-learn.org/dev/versions.html">Otras versiones</a>
          </p>
        </div>
        <div class="alert alert-warning p-1 mb-2" role="alert">
          <p class="text-center mb-0">
            Por favor <a class="font-weight-bold" href="../about.html#citing-scikit-learn"><string>cítanos</string></a> si usas el software.
          </p>
        </div>
            <div class="sk-sidebar-toc">
              <ul>
<li><a class="reference internal" href="#">6.3. Preprocesamiento de los datos</a><ul>
<li><a class="reference internal" href="#standardization-or-mean-removal-and-variance-scaling">6.3.1. Estandarización, o eliminación media y escala de varianza</a><ul>
<li><a class="reference internal" href="#scaling-features-to-a-range">6.3.1.1. Escalamiento de las características a un rango</a></li>
<li><a class="reference internal" href="#scaling-sparse-data">6.3.1.2. Escalamiento de datos dispersos</a></li>
<li><a class="reference internal" href="#scaling-data-with-outliers">6.3.1.3. Escalamiento de datos con valores atípicos</a></li>
<li><a class="reference internal" href="#centering-kernel-matrices">6.3.1.4. Centrado de matrices del núcleo</a></li>
</ul>
</li>
<li><a class="reference internal" href="#non-linear-transformation">6.3.2. Transformación no lineal</a><ul>
<li><a class="reference internal" href="#mapping-to-a-uniform-distribution">6.3.2.1. Mapeo a una Distribución Uniforme</a></li>
<li><a class="reference internal" href="#mapping-to-a-gaussian-distribution">6.3.2.2. Mapeo a una Distribución Gaussiana</a></li>
</ul>
</li>
<li><a class="reference internal" href="#normalization">6.3.3. Normalización</a></li>
<li><a class="reference internal" href="#encoding-categorical-features">6.3.4. Codificación de características categóricas</a></li>
<li><a class="reference internal" href="#discretization">6.3.5. Discretización</a><ul>
<li><a class="reference internal" href="#k-bins-discretization">6.3.5.1. Discretización K-clases o intervalos de clase</a></li>
<li><a class="reference internal" href="#feature-binarization">6.3.5.2. Binarización de característica</a></li>
</ul>
</li>
<li><a class="reference internal" href="#imputation-of-missing-values">6.3.6. Imputación de valores faltantes</a></li>
<li><a class="reference internal" href="#generating-polynomial-features">6.3.7. Generación de características polinomiales</a></li>
<li><a class="reference internal" href="#custom-transformers">6.3.8. Transformadores personalizados</a></li>
</ul>
</li>
</ul>

            </div>
      </div>
    </div>
    <div id="sk-page-content-wrapper">
      <div class="sk-page-content container-fluid body px-md-3" role="main">
        
  <section id="preprocessing-data">
<span id="preprocessing"></span><h1><span class="section-number">6.3. </span>Preprocesamiento de los datos<a class="headerlink" href="#preprocessing-data" title="Enlazar permanentemente con este título">¶</a></h1>
<p>El paquete <code class="docutils literal notranslate"><span class="pre">sklearn.preprocessing</span></code> proporciona varias funciones de utilidad comunes y clases transformadoras para cambiar los vectores de características en bruto a una representación que sea más adecuada para los estimadores posteriores.</p>
<p>En general, los algoritmos de aprendizaje se benefician de la estandarización del conjunto de datos. Si hay algunos valores atípicos presentes en el conjunto, los escaladores robustos o transformadores son más apropiados. Los comportamientos de los diferentes escaladores, transformadores y normalizadores en un conjunto de datos que contiene valores atípicos marginales se resaltan en <a class="reference internal" href="../auto_examples/preprocessing/plot_all_scaling.html#sphx-glr-auto-examples-preprocessing-plot-all-scaling-py"><span class="std std-ref">Compara el efecto de los diferentes escaladores en los datos con los atípicos</span></a>.</p>
<section id="standardization-or-mean-removal-and-variance-scaling">
<span id="preprocessing-scaler"></span><h2><span class="section-number">6.3.1. </span>Estandarización, o eliminación media y escala de varianza<a class="headerlink" href="#standardization-or-mean-removal-and-variance-scaling" title="Enlazar permanentemente con este título">¶</a></h2>
<p>La <strong>Estandarización</strong> de conjuntos de datos es un <strong>requisito común para muchos estimadores de aprendizaje automático</strong> implementados en scikit-learn; podrían comportarse mal si las características individuales no se ven más o menos como datos distribuidos normalmente estándar: Gaussiana con <strong>media cero y varianza unitaria</strong>.</p>
<p>En la práctica a menudo ignoramos la forma de la distribución y simplemente transformamos los datos para centrarlos eliminando el valor medio de cada característica, luego los escalamos dividiendo características no constantes por su desviación estándar.</p>
<p>Por ejemplo, muchos elementos utilizados en la función objetivo de un algoritmo de aprendizaje (como el kernel RBF de Máquinas de Vectores de Soporte o los regularizadores l1 y l2 de modelos lineales) asumen que todas las características están centradas en cero y tienen varianza del mismo orden. Si una característica tiene varianza de un orden de magnitud mayor que otras, podría dominar la función objetivo y hacer que el estimador no pueda aprender de otras características correctamente como se esperaba.</p>
<p>El módulo <a class="reference internal" href="classes.html#module-sklearn.preprocessing" title="sklearn.preprocessing"><code class="xref py py-mod docutils literal notranslate"><span class="pre">preprocessing</span></code></a> proporciona la clase de utilidad <a class="reference internal" href="generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler" title="sklearn.preprocessing.StandardScaler"><code class="xref py py-class docutils literal notranslate"><span class="pre">StandardScaler</span></code></a>, que es una forma rápida y sencilla de realizar la siguiente operación en un conjunto de datos array-like:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">preprocessing</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span> <span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">],</span>
<span class="gp">... </span>                    <span class="p">[</span> <span class="mf">2.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">],</span>
<span class="gp">... </span>                    <span class="p">[</span> <span class="mf">0.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scaler</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">StandardScaler</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scaler</span>
<span class="go">StandardScaler()</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">scaler</span><span class="o">.</span><span class="n">mean_</span>
<span class="go">array([1. ..., 0. ..., 0.33...])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">scaler</span><span class="o">.</span><span class="n">scale_</span>
<span class="go">array([0.81..., 0.81..., 1.24...])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">X_scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_scaled</span>
<span class="go">array([[ 0.  ..., -1.22...,  1.33...],</span>
<span class="go">       [ 1.22...,  0.  ..., -0.26...],</span>
<span class="go">       [-1.22...,  1.22..., -1.06...]])</span>
</pre></div>
</div>
<p>Los datos escalados tienen una media cero y varianza unitaria:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">X_scaled</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="go">array([0., 0., 0.])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">X_scaled</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="go">array([1., 1., 1.])</span>
</pre></div>
</div>
<p>Esta clase implementa la API <code class="docutils literal notranslate"><span class="pre">Transformer</span></code> para calcular la media y la desviación estándar en un conjunto de entrenamiento para poder volver a aplicar posteriormente la misma transformación en el conjunto de prueba. Esta clase es, por lo tanto, adecuada para su uso en los primeros pasos de un <a class="reference internal" href="generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline" title="sklearn.pipeline.Pipeline"><code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code></a>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_classification</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_classification</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pipe</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">LogisticRegression</span><span class="p">())</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pipe</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>  <span class="c1"># apply scaling on training data</span>
<span class="go">Pipeline(steps=[(&#39;standardscaler&#39;, StandardScaler()),</span>
<span class="go">                (&#39;logisticregression&#39;, LogisticRegression())])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">pipe</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>  <span class="c1"># apply scaling on testing data, without leaking training data.</span>
<span class="go">0.96</span>
</pre></div>
</div>
<p>Es posible desactivar el centrado o el escalado pasando <code class="docutils literal notranslate"><span class="pre">with_mean=False</span></code> o <code class="docutils literal notranslate"><span class="pre">with_std=False</span></code> al constructor de <a class="reference internal" href="generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler" title="sklearn.preprocessing.StandardScaler"><code class="xref py py-class docutils literal notranslate"><span class="pre">StandardScaler</span></code></a>.</p>
<section id="scaling-features-to-a-range">
<h3><span class="section-number">6.3.1.1. </span>Escalamiento de las características a un rango<a class="headerlink" href="#scaling-features-to-a-range" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Una estandarización alternativa es el escalamiento de características para que se sitúen entre un valor mínimo y máximo determinado, a menudo entre cero y uno, o para que el valor absoluto máximo de cada característica se escalado al tamaño unitario. Esto puede lograrse utilizando <a class="reference internal" href="generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler" title="sklearn.preprocessing.MinMaxScaler"><code class="xref py py-class docutils literal notranslate"><span class="pre">MinMaxScaler</span></code></a> o <a class="reference internal" href="generated/sklearn.preprocessing.MaxAbsScaler.html#sklearn.preprocessing.MaxAbsScaler" title="sklearn.preprocessing.MaxAbsScaler"><code class="xref py py-class docutils literal notranslate"><span class="pre">MaxAbsScaler</span></code></a>, respectivamente.</p>
<p>La motivación para utilizar esta escala incluye robustez ante desviaciones estándar muy pequeñas de las características y preservando las entradas cero en los datos dispersos.</p>
<p>Aquí hay un ejemplo para escalar una matriz de datos de juguete al rango <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">1]</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">X_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span> <span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">],</span>
<span class="gp">... </span>                    <span class="p">[</span> <span class="mf">2.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">],</span>
<span class="gp">... </span>                    <span class="p">[</span> <span class="mf">0.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">]])</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">min_max_scaler</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">MinMaxScaler</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_train_minmax</span> <span class="o">=</span> <span class="n">min_max_scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_train_minmax</span>
<span class="go">array([[0.5       , 0.        , 1.        ],</span>
<span class="go">       [1.        , 0.5       , 0.33333333],</span>
<span class="go">       [0.        , 1.        , 0.        ]])</span>
</pre></div>
</div>
<p>La misma instancia del transformador puede aplicarse a unos nuevos datos de prueba no vistos durante el llamado de ajuste: se aplicarán las mismas operaciones de escalamiento y desplazamiento para ser coherentes con la transformación realizada en los datos de entrenamiento:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">X_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="o">-</span><span class="mf">3.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span>  <span class="mf">4.</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_test_minmax</span> <span class="o">=</span> <span class="n">min_max_scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_test_minmax</span>
<span class="go">array([[-1.5       ,  0.        ,  1.66666667]])</span>
</pre></div>
</div>
<p>Es posible inspeccionar los atributos del escalador para encontrar la naturaleza exacta de la transformación aprendida en los datos de entrenamiento:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">min_max_scaler</span><span class="o">.</span><span class="n">scale_</span>
<span class="go">array([0.5       , 0.5       , 0.33...])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">min_max_scaler</span><span class="o">.</span><span class="n">min_</span>
<span class="go">array([0.        , 0.5       , 0.33...])</span>
</pre></div>
</div>
<p>Si a <a class="reference internal" href="generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler" title="sklearn.preprocessing.MinMaxScaler"><code class="xref py py-class docutils literal notranslate"><span class="pre">MinMaxScaler</span></code></a> se le da un <code class="docutils literal notranslate"><span class="pre">feature_range=(min,</span> <span class="pre">max)</span></code> explícito la fórmula completa es:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">X_std</span> <span class="o">=</span> <span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="n">X</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="o">-</span> <span class="n">X</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>

<span class="n">X_scaled</span> <span class="o">=</span> <span class="n">X_std</span> <span class="o">*</span> <span class="p">(</span><span class="nb">max</span> <span class="o">-</span> <span class="nb">min</span><span class="p">)</span> <span class="o">+</span> <span class="nb">min</span>
</pre></div>
</div>
<p><a class="reference internal" href="generated/sklearn.preprocessing.MaxAbsScaler.html#sklearn.preprocessing.MaxAbsScaler" title="sklearn.preprocessing.MaxAbsScaler"><code class="xref py py-class docutils literal notranslate"><span class="pre">MaxAbsScaler</span></code></a> funciona de una manera muy similar, pero escala de una manera que los datos de entrenamiento se encuentran dentro del rango <code class="docutils literal notranslate"><span class="pre">[-1,</span> <span class="pre">1]</span></code> dividiendo entre el valor máximo más grande en cada característica. Está pensado para datos que ya están centrados en cero o datos dispersos.</p>
<p>Aquí está cómo utilizar los datos de juguete del ejemplo anterior con este escalador:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">X_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span> <span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">],</span>
<span class="gp">... </span>                    <span class="p">[</span> <span class="mf">2.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">],</span>
<span class="gp">... </span>                    <span class="p">[</span> <span class="mf">0.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">]])</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">max_abs_scaler</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">MaxAbsScaler</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_train_maxabs</span> <span class="o">=</span> <span class="n">max_abs_scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_train_maxabs</span>
<span class="go">array([[ 0.5, -1. ,  1. ],</span>
<span class="go">       [ 1. ,  0. ,  0. ],</span>
<span class="go">       [ 0. ,  1. , -0.5]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span> <span class="o">-</span><span class="mf">3.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span>  <span class="mf">4.</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_test_maxabs</span> <span class="o">=</span> <span class="n">max_abs_scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_test_maxabs</span>
<span class="go">array([[-1.5, -1. ,  2. ]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">max_abs_scaler</span><span class="o">.</span><span class="n">scale_</span>
<span class="go">array([2.,  1.,  2.])</span>
</pre></div>
</div>
</section>
<section id="scaling-sparse-data">
<h3><span class="section-number">6.3.1.2. </span>Escalamiento de datos dispersos<a class="headerlink" href="#scaling-sparse-data" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Centrar datos dispersos destruiría la estructura de dispersión en los datos, por lo que rara vez es algo sensato para hacer. Sin embargo, puede tener sentido escalar las entradas dispersas, especialmente si las características están en diferentes escalas.</p>
<p><a class="reference internal" href="generated/sklearn.preprocessing.MaxAbsScaler.html#sklearn.preprocessing.MaxAbsScaler" title="sklearn.preprocessing.MaxAbsScaler"><code class="xref py py-class docutils literal notranslate"><span class="pre">MaxAbsScaler</span></code></a> fue diseñado específicamente para el escalamiento de datos dispersos, y es la forma recomendada de hacerlo. Sin embargo, <a class="reference internal" href="generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler" title="sklearn.preprocessing.StandardScaler"><code class="xref py py-class docutils literal notranslate"><span class="pre">StandardScaler</span></code></a> puede aceptar matrices <code class="docutils literal notranslate"><span class="pre">scipy.sparse</span></code> como entrada, siempre que se pase explícitamente <code class="docutils literal notranslate"><span class="pre">with_mean=False</span></code> al constructor. De lo contrario, se producirá un <code class="docutils literal notranslate"><span class="pre">ValueError</span></code> ya que el centrado silencioso rompería la dispersión y a menudo bloquearía la ejecución al asignar involuntariamente cantidades excesivas de memoria.  <a class="reference internal" href="generated/sklearn.preprocessing.RobustScaler.html#sklearn.preprocessing.RobustScaler" title="sklearn.preprocessing.RobustScaler"><code class="xref py py-class docutils literal notranslate"><span class="pre">RobustScaler</span></code></a> no puede ajustarse a entradas dispersas, pero puede utilizar el método <code class="docutils literal notranslate"><span class="pre">transform</span></code> en entradas dispersas.</p>
<p>Ten en cuenta que los escaladores aceptan tanto el formato de Filas Dispersas Comprimidas (CSR) como el formato de Columnas Dispersas Comprimidas (CSC)  (ver <code class="docutils literal notranslate"><span class="pre">scipy.sparse.csr_matrix</span></code> y <code class="docutils literal notranslate"><span class="pre">scipy.sparse.csc_matrix</span></code>). Cualquier otra entrada dispersa será <strong>convertida a la representación Filas Dispersas Comprimidas</strong>. Para evitar copias de memoria innecesarias, se recomienda elegir la representación CSR o CSC en la parte superior.</p>
<p>Por último, si se espera que los datos centrados sean lo suficientemente pequeños, otra opción es convertir explícitamente la entrada en un arreglo utilizando el método <code class="docutils literal notranslate"><span class="pre">toarray</span></code> de matrices dispersas.</p>
</section>
<section id="scaling-data-with-outliers">
<h3><span class="section-number">6.3.1.3. </span>Escalamiento de datos con valores atípicos<a class="headerlink" href="#scaling-data-with-outliers" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Si tus datos contienen muchos valores atípicos, es probable que el escalamiento utilizando la media y la varianza de los datos no funcione muy bien. En estos casos, puedes utilizar <a class="reference internal" href="generated/sklearn.preprocessing.RobustScaler.html#sklearn.preprocessing.RobustScaler" title="sklearn.preprocessing.RobustScaler"><code class="xref py py-class docutils literal notranslate"><span class="pre">RobustScaler</span></code></a> como reemplazo. Este utiliza estimaciones más robustas para el centrado y el rango de tus datos.</p>
<div class="topic">
<p class="topic-title">Referencias:</p>
<p>Más información sobre la importancia del centrado y escalamiento de los datos está disponible en este FAQ:<a class="reference external" href="http://www.faqs.org/faqs/ai-faq/neural-nets/part2/section-16.html">Should I normalize/standardize/rescale the data?</a></p>
</div>
<div class="topic">
<p class="topic-title">Escalamiento vs Whitening</p>
<p>A veces no es suficiente con centrar y escalar las características de forma independiente, ya que un modelo posterior puede hacer alguna suposición sobre la independencia lineal de las características.</p>
<p>Para solucionar este problema se puede utilizar <a class="reference internal" href="generated/sklearn.decomposition.PCA.html#sklearn.decomposition.PCA" title="sklearn.decomposition.PCA"><code class="xref py py-class docutils literal notranslate"><span class="pre">PCA</span></code></a> con <code class="docutils literal notranslate"><span class="pre">whiten=True</span></code> para eliminar aún más la correlación lineal entre las características.</p>
</div>
</section>
<section id="centering-kernel-matrices">
<span id="kernel-centering"></span><h3><span class="section-number">6.3.1.4. </span>Centrado de matrices del núcleo<a class="headerlink" href="#centering-kernel-matrices" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Si tienes una matriz de núcleo de un núcleo <span class="math notranslate nohighlight">\(K\)</span> que calcula un producto punto en un espacio de características definido por la función <span class="math notranslate nohighlight">\(\phi\)</span>, un <a class="reference internal" href="generated/sklearn.preprocessing.KernelCenterer.html#sklearn.preprocessing.KernelCenterer" title="sklearn.preprocessing.KernelCenterer"><code class="xref py py-class docutils literal notranslate"><span class="pre">KernelCenterer</span></code></a> puede transformar la matriz de núcleo para que contenga productos internos en el espacio de características definido por <span class="math notranslate nohighlight">\(\phi\)</span> seguido de la eliminación de la media en ese espacio.</p>
</section>
</section>
<section id="non-linear-transformation">
<span id="preprocessing-transformer"></span><h2><span class="section-number">6.3.2. </span>Transformación no lineal<a class="headerlink" href="#non-linear-transformation" title="Enlazar permanentemente con este título">¶</a></h2>
<p>Hay dos tipos de transformaciones disponibles: las transformaciones de cuantiles y las transformaciones de potencia. Tanto las transformaciones de cuantiles como las de potencia se basan en transformaciones monótonas de las características y, por tanto, preservan el rango de los valores a lo largo de cada característica.</p>
<p>Las transformaciones de cuantiles ponen todas las características en la misma distribución deseada basándose en la fórmula <span class="math notranslate nohighlight">\(G^{-1}(F(X))\)</span> donde <span class="math notranslate nohighlight">\(F\)</span> es la función de distribución acumulada de la característica y <span class="math notranslate nohighlight">\(G^{-1}\)</span> la <a class="reference external" href="https://en.wikipedia.org/wiki/Quantile_function">función cuantil</a> de la distribución de salida deseada <span class="math notranslate nohighlight">\(G\)</span>. Esta fórmula utiliza los dos siguientes hechos: (i) si <span class="math notranslate nohighlight">\(X\)</span> es una variable aleatoria con una función de distribución acumulada continua <span class="math notranslate nohighlight">\(F\)</span>, entonces <span class="math notranslate nohighlight">\(F(X)\)</span> se distribuye uniformemente en <span class="math notranslate nohighlight">\([0, 1]\)</span>; (ii) si <span class="math notranslate nohighlight">\(U\)</span> es una variable aleatoria con distribución uniforme en <span class="math notranslate nohighlight">\([0, 1]\)</span> entonces <span class="math notranslate nohighlight">\(G^{-1}(U)\)</span> tiene distribución <span class="math notranslate nohighlight">\(G\)</span>. Al realizar una transformación de rango, una transformación de cuantil suaviza las distribuciones inusuales y está menos influenciada por los valores atípicos que los métodos de escalamiento. Sin embargo, distorsiona las correlaciones y distancias dentro y entre características.</p>
<p>Las transformaciones de potencia son una familia de transformaciones paramétricas cuyo objetivo es mapear datos de cualquier distribución a lo más parecido a una Distribución Gaussiana.</p>
<section id="mapping-to-a-uniform-distribution">
<h3><span class="section-number">6.3.2.1. </span>Mapeo a una Distribución Uniforme<a class="headerlink" href="#mapping-to-a-uniform-distribution" title="Enlazar permanentemente con este título">¶</a></h3>
<p><a class="reference internal" href="generated/sklearn.preprocessing.QuantileTransformer.html#sklearn.preprocessing.QuantileTransformer" title="sklearn.preprocessing.QuantileTransformer"><code class="xref py py-class docutils literal notranslate"><span class="pre">QuantileTransformer</span></code></a> proporciona una transformación no paramétrica para mapear los datos a una distribución uniforme con valores entre 0 y 1:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_iris</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_iris</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">quantile_transformer</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">QuantileTransformer</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_train_trans</span> <span class="o">=</span> <span class="n">quantile_transformer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_test_trans</span> <span class="o">=</span> <span class="n">quantile_transformer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">X_train</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">75</span><span class="p">,</span> <span class="mi">100</span><span class="p">])</span> 
<span class="go">array([ 4.3,  5.1,  5.8,  6.5,  7.9])</span>
</pre></div>
</div>
<p>Esta característica corresponde a la longitud del sépalo en cm. Una vez aplicada la transformación de cuantiles, esos hitos se acercan estrechamente a los percentiles definidos anteriormente:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">X_train_trans</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">75</span><span class="p">,</span> <span class="mi">100</span><span class="p">])</span>
<span class="gp">... </span>
<span class="go">array([ 0.00... ,  0.24...,  0.49...,  0.73...,  0.99... ])</span>
</pre></div>
</div>
<p>Esto puede confirmarse en un conjunto de pruebas independientes con observaciones similares:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">X_test</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">75</span><span class="p">,</span> <span class="mi">100</span><span class="p">])</span>
<span class="gp">... </span>
<span class="go">array([ 4.4  ,  5.125,  5.75 ,  6.175,  7.3  ])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">percentile</span><span class="p">(</span><span class="n">X_test_trans</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">75</span><span class="p">,</span> <span class="mi">100</span><span class="p">])</span>
<span class="gp">... </span>
<span class="go">array([ 0.01...,  0.25...,  0.46...,  0.60... ,  0.94...])</span>
</pre></div>
</div>
</section>
<section id="mapping-to-a-gaussian-distribution">
<h3><span class="section-number">6.3.2.2. </span>Mapeo a una Distribución Gaussiana<a class="headerlink" href="#mapping-to-a-gaussian-distribution" title="Enlazar permanentemente con este título">¶</a></h3>
<p>En muchos escenarios de modelado, es deseable la normalidad de las características de un conjunto de datos. Las transformaciones de potencia son una familia de transformaciones paramétricas y monótonas cuyo objetivo es mapear los datos de cualquier distribución a una distribución lo más cercana posible a una distribución Gaussiana con el fin de estabilizar la varianza y minimizar la asimetría.</p>
<p><a class="reference internal" href="generated/sklearn.preprocessing.PowerTransformer.html#sklearn.preprocessing.PowerTransformer" title="sklearn.preprocessing.PowerTransformer"><code class="xref py py-class docutils literal notranslate"><span class="pre">PowerTransformer</span></code></a> actualmente proporciona dos transformaciones de potencia de este tipo, la transformación Yeo-Johnson y la transformación Box-Cox.</p>
<p>La transformación Yeo-Johnson viene dada por:</p>
<div class="math notranslate nohighlight">
\[\begin{split}x_i^{(\lambda)} =
\begin{cases}
 [(x_i + 1)^\lambda - 1] / \lambda &amp; \text{if } \lambda \neq 0, x_i \geq 0, \\[8pt]
\ln{(x_i + 1)} &amp; \text{if } \lambda = 0, x_i \geq 0 \\[8pt]
-[(-x_i + 1)^{2 - \lambda} - 1] / (2 - \lambda) &amp; \text{if } \lambda \neq 2, x_i &lt; 0, \\[8pt]
 - \ln (- x_i + 1) &amp; \text{if } \lambda = 2, x_i &lt; 0
\end{cases}\end{split}\]</div>
<p>mientras que la transformación Box-Cox viene dada por:</p>
<div class="math notranslate nohighlight">
\[\begin{split}x_i^{(\lambda)} =
\begin{cases}
\dfrac{x_i^\lambda - 1}{\lambda} &amp; \text{if } \lambda \neq 0, \\[8pt]
\ln{(x_i)} &amp; \text{if } \lambda = 0,
\end{cases}\end{split}\]</div>
<p>Box-Cox sólo puede aplicarse a datos estrictamente positivos. En ambos métodos, la transformación está parametrizada por <span class="math notranslate nohighlight">\(\lambda\)</span>, que se determina a través de la estimación de máxima verosimilitud. Aquí hay un ejemplo de uso de Box-Cox para mapear muestras extraídas de una distribución lognormal a una distribución normal:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">pt</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">PowerTransformer</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;box-cox&#39;</span><span class="p">,</span> <span class="n">standardize</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_lognormal</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">616</span><span class="p">)</span><span class="o">.</span><span class="n">lognormal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_lognormal</span>
<span class="go">array([[1.28..., 1.18..., 0.84...],</span>
<span class="go">       [0.94..., 1.60..., 0.38...],</span>
<span class="go">       [1.35..., 0.21..., 1.09...]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pt</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_lognormal</span><span class="p">)</span>
<span class="go">array([[ 0.49...,  0.17..., -0.15...],</span>
<span class="go">       [-0.05...,  0.58..., -0.57...],</span>
<span class="go">       [ 0.69..., -0.84...,  0.10...]])</span>
</pre></div>
</div>
<p>Mientras que el ejemplo anterior establece la opción <code class="docutils literal notranslate"><span class="pre">standardize</span></code> en <code class="docutils literal notranslate"><span class="pre">False</span></code>, <a class="reference internal" href="generated/sklearn.preprocessing.PowerTransformer.html#sklearn.preprocessing.PowerTransformer" title="sklearn.preprocessing.PowerTransformer"><code class="xref py py-class docutils literal notranslate"><span class="pre">PowerTransformer</span></code></a> aplicará por defecto una normalización de media cero y varianza unitaria a la salida transformada.</p>
<p>A continuación se muestran ejemplos de Box-Cox y Yeo-Johnson aplicados a varias distribuciones de probabilidad. Ten en cuenta que cuando se aplican a ciertas distribuciones, las transformaciones de potencia consiguen resultados muy parecidos a los Gaussianos, pero con otras, son ineficaces. Esto resalta la importancia de visualizar los datos antes y después de la transformación.</p>
<figure class="align-center">
<a class="reference external image-reference" href="../auto_examples/preprocessing/plot_map_data_to_normal.html"><img alt="../_images/sphx_glr_plot_map_data_to_normal_001.png" src="../_images/sphx_glr_plot_map_data_to_normal_001.png" style="width: 400.0px; height: 800.0px;" /></a>
</figure>
<p>También es posible mapear los datos a una distribución normal usando <a class="reference internal" href="generated/sklearn.preprocessing.QuantileTransformer.html#sklearn.preprocessing.QuantileTransformer" title="sklearn.preprocessing.QuantileTransformer"><code class="xref py py-class docutils literal notranslate"><span class="pre">QuantileTransformer</span></code></a> estableciendo <code class="docutils literal notranslate"><span class="pre">output_distribution='normal'</span></code>. Utilizando el ejemplo anterior con el conjunto de datos iris:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">quantile_transformer</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">QuantileTransformer</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">output_distribution</span><span class="o">=</span><span class="s1">&#39;normal&#39;</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_trans</span> <span class="o">=</span> <span class="n">quantile_transformer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">quantile_transformer</span><span class="o">.</span><span class="n">quantiles_</span>
<span class="go">array([[4.3, 2. , 1. , 0.1],</span>
<span class="go">       [4.4, 2.2, 1.1, 0.1],</span>
<span class="go">       [4.4, 2.2, 1.2, 0.1],</span>
<span class="go">       ...,</span>
<span class="go">       [7.7, 4.1, 6.7, 2.5],</span>
<span class="go">       [7.7, 4.2, 6.7, 2.5],</span>
<span class="go">       [7.9, 4.4, 6.9, 2.5]])</span>
</pre></div>
</div>
<p>Así, la mediana de la entrada se convierte en la media de la salida, centrada en 0. La salida normal es recortada para que el mínimo y el máximo de la entrada — correspondientes a las cantidades 1e-7 y 1 - 1e-7 respectivamente — no se conviertan en infinitos bajo la transformación.</p>
</section>
</section>
<section id="normalization">
<span id="preprocessing-normalization"></span><h2><span class="section-number">6.3.3. </span>Normalización<a class="headerlink" href="#normalization" title="Enlazar permanentemente con este título">¶</a></h2>
<p>La <strong>normalización</strong> es el proceso de <strong>escalamiento de muestras individuales para tener la norma unitaria</strong>. Este proceso puede ser útil si planeas utilizar una forma cuadrática como el producto punto o cualquier otro núcleo para cuantificar la similitud de cualquier par de muestras.</p>
<p>Este supuesto es la base del <a class="reference external" href="https://en.wikipedia.org/wiki/Vector_Space_Model">Modelo de espacio vectorial</a> utilizado a menudo en los contextos de clasificación y agrupamiento de textos.</p>
<p>La función <a class="reference internal" href="generated/sklearn.preprocessing.normalize.html#sklearn.preprocessing.normalize" title="sklearn.preprocessing.normalize"><code class="xref py py-func docutils literal notranslate"><span class="pre">normalize</span></code></a> proporciona una forma rápida y sencilla de realizar esta operación en un único conjunto de datos array-like, ya sea utilizando las normas <code class="docutils literal notranslate"><span class="pre">l1</span></code>, <code class="docutils literal notranslate"><span class="pre">l2</span></code> o <code class="docutils literal notranslate"><span class="pre">max</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">],</span>
<span class="gp">... </span>     <span class="p">[</span> <span class="mf">2.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">],</span>
<span class="gp">... </span>     <span class="p">[</span> <span class="mf">0.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_normalized</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">norm</span><span class="o">=</span><span class="s1">&#39;l2&#39;</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">X_normalized</span>
<span class="go">array([[ 0.40..., -0.40...,  0.81...],</span>
<span class="go">       [ 1.  ...,  0.  ...,  0.  ...],</span>
<span class="go">       [ 0.  ...,  0.70..., -0.70...]])</span>
</pre></div>
</div>
<p>El módulo <code class="docutils literal notranslate"><span class="pre">preprocessing</span></code> proporciona además una clase de utilidad <a class="reference internal" href="generated/sklearn.preprocessing.Normalizer.html#sklearn.preprocessing.Normalizer" title="sklearn.preprocessing.Normalizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Normalizer</span></code></a> que implementa la misma operación utilizando la API <code class="docutils literal notranslate"><span class="pre">Transformer</span></code> (aunque el método <code class="docutils literal notranslate"><span class="pre">fit</span></code> es inútil en este caso: la clase no tiene estado ya que esta operación trata las muestras de forma independiente).</p>
<p>Esta clase es, por tanto, adecuada para su uso en los primeros pasos de un <a class="reference internal" href="generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline" title="sklearn.pipeline.Pipeline"><code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code></a>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">normalizer</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">Normalizer</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>  <span class="c1"># fit does nothing</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">normalizer</span>
<span class="go">Normalizer()</span>
</pre></div>
</div>
<p>La instancia del normalizador puede utilizarse en vectores de muestra como cualquier transformador:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">normalizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="go">array([[ 0.40..., -0.40...,  0.81...],</span>
<span class="go">       [ 1.  ...,  0.  ...,  0.  ...],</span>
<span class="go">       [ 0.  ...,  0.70..., -0.70...]])</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">normalizer</span><span class="o">.</span><span class="n">transform</span><span class="p">([[</span><span class="o">-</span><span class="mf">1.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">]])</span>
<span class="go">array([[-0.70...,  0.70...,  0.  ...]])</span>
</pre></div>
</div>
<p>Nota: La normalización L2 también se conoce como preprocesamiento de signos espaciales.</p>
<div class="topic">
<p class="topic-title">Entrada dispersa</p>
<p><a class="reference internal" href="generated/sklearn.preprocessing.normalize.html#sklearn.preprocessing.normalize" title="sklearn.preprocessing.normalize"><code class="xref py py-func docutils literal notranslate"><span class="pre">normalize</span></code></a> and <a class="reference internal" href="generated/sklearn.preprocessing.Normalizer.html#sklearn.preprocessing.Normalizer" title="sklearn.preprocessing.Normalizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Normalizer</span></code></a> aceptan <strong>tanto array-like densos como matrices dispersas de scipy.sparse como entrada</strong>.</p>
<p>Para la entrada dispersa los datos son <a href="#id1"><span class="problematic" id="id2">**</span></a>convertidos a la representación Filas Dispersas Comprimidas ** (ver scipy.sparse.csr_matrix) antes de ser alimentado a las rutinas eficientes de Cython. Para evitar copias de memoria innecesarias, se recomienda elegir la representación CSR de entrada.</p>
</div>
</section>
<section id="encoding-categorical-features">
<span id="preprocessing-categorical-features"></span><h2><span class="section-number">6.3.4. </span>Codificación de características categóricas<a class="headerlink" href="#encoding-categorical-features" title="Enlazar permanentemente con este título">¶</a></h2>
<p>A menudo las características no se dan como valores continuos sino como categóricos. Por ejemplo, una persona podría tener características <code class="docutils literal notranslate"><span class="pre">[&quot;male&quot;,</span> <span class="pre">&quot;female&quot;]</span></code>,``[«from Europe», «from US», «from Asia»]``, <code class="docutils literal notranslate"><span class="pre">[&quot;uses</span> <span class="pre">Firefox&quot;,</span> <span class="pre">&quot;uses</span> <span class="pre">Chrome&quot;,</span> <span class="pre">&quot;uses</span> <span class="pre">Safari&quot;,</span> <span class="pre">&quot;uses</span> <span class="pre">Internet</span> <span class="pre">Explorer&quot;]</span></code>. Estas características pueden codificarse eficazmente como enteros, por ejemplo <code class="docutils literal notranslate"><span class="pre">[&quot;male&quot;,</span> <span class="pre">&quot;from</span> <span class="pre">US&quot;,</span> <span class="pre">&quot;uses</span> <span class="pre">Internet</span> <span class="pre">Explorer&quot;]</span></code> podría expresarse como <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">1,</span> <span class="pre">3]</span></code> mientras que <code class="docutils literal notranslate"><span class="pre">[&quot;female&quot;,</span> <span class="pre">&quot;from</span> <span class="pre">Asia&quot;,</span> <span class="pre">&quot;uses</span> <span class="pre">Chrome&quot;]</span></code> sería <code class="docutils literal notranslate"><span class="pre">[1,</span> <span class="pre">2,</span> <span class="pre">1]</span></code>.</p>
<p>Para convertir características categóricas en dichos códigos de enteros, podemos utilizar el <a class="reference internal" href="generated/sklearn.preprocessing.OrdinalEncoder.html#sklearn.preprocessing.OrdinalEncoder" title="sklearn.preprocessing.OrdinalEncoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">OrdinalEncoder</span></code></a>. Este estimador transforma cada característica categórica en una nueva característica de enteros (0 a n_categorías - 1):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">enc</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">OrdinalEncoder</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="p">[[</span><span class="s1">&#39;male&#39;</span><span class="p">,</span> <span class="s1">&#39;from US&#39;</span><span class="p">,</span> <span class="s1">&#39;uses Safari&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;female&#39;</span><span class="p">,</span> <span class="s1">&#39;from Europe&#39;</span><span class="p">,</span> <span class="s1">&#39;uses Firefox&#39;</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">enc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="go">OrdinalEncoder()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">enc</span><span class="o">.</span><span class="n">transform</span><span class="p">([[</span><span class="s1">&#39;female&#39;</span><span class="p">,</span> <span class="s1">&#39;from US&#39;</span><span class="p">,</span> <span class="s1">&#39;uses Safari&#39;</span><span class="p">]])</span>
<span class="go">array([[0., 1., 1.]])</span>
</pre></div>
</div>
<p>Sin embargo, esta representación de números enteros no puede utilizarse directamente con todos los estimadores de scikit-learn, ya que éstos esperan una entrada continua, e interpretarían las categorías como si estuvieran ordenadas, lo que a menudo no se desea (es decir, el conjunto de navegadores se ordenó arbitrariamente).</p>
<p>Otra posibilidad para convertir características categóricas en características que puedan ser utilizadas con los estimadores de scikit-learn es utilizar un one-of-K, también conocido como codificación one-hot o dummy. Este tipo de codificación se puede obtener con el <a class="reference internal" href="generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder" title="sklearn.preprocessing.OneHotEncoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">OneHotEncoder</span></code></a>, que transforma cada característica categórica con <code class="docutils literal notranslate"><span class="pre">n_categories</span></code> posibles en <code class="docutils literal notranslate"><span class="pre">n_categories</span></code> con características binarias, una de ellas 1, y todas las demás 0.</p>
<p>Continuando el ejemplo anterior:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">enc</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">OneHotEncoder</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="p">[[</span><span class="s1">&#39;male&#39;</span><span class="p">,</span> <span class="s1">&#39;from US&#39;</span><span class="p">,</span> <span class="s1">&#39;uses Safari&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;female&#39;</span><span class="p">,</span> <span class="s1">&#39;from Europe&#39;</span><span class="p">,</span> <span class="s1">&#39;uses Firefox&#39;</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">enc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="go">OneHotEncoder()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">enc</span><span class="o">.</span><span class="n">transform</span><span class="p">([[</span><span class="s1">&#39;female&#39;</span><span class="p">,</span> <span class="s1">&#39;from US&#39;</span><span class="p">,</span> <span class="s1">&#39;uses Safari&#39;</span><span class="p">],</span>
<span class="gp">... </span>               <span class="p">[</span><span class="s1">&#39;male&#39;</span><span class="p">,</span> <span class="s1">&#39;from Europe&#39;</span><span class="p">,</span> <span class="s1">&#39;uses Safari&#39;</span><span class="p">]])</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
<span class="go">array([[1., 0., 0., 1., 0., 1.],</span>
<span class="go">       [0., 1., 1., 0., 0., 1.]])</span>
</pre></div>
</div>
<p>Por defecto, los valores que puede tomar cada característica se infieren automáticamente del conjunto de datos y se pueden encontrar en el atributo <code class="docutils literal notranslate"><span class="pre">categories_</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">enc</span><span class="o">.</span><span class="n">categories_</span>
<span class="go">[array([&#39;female&#39;, &#39;male&#39;], dtype=object), array([&#39;from Europe&#39;, &#39;from US&#39;], dtype=object), array([&#39;uses Firefox&#39;, &#39;uses Safari&#39;], dtype=object)]</span>
</pre></div>
</div>
<p>Es posible especificar esto explícitamente utilizando el parámetro <a href="#id1"><span class="problematic" id="id2">``</span></a>categories`. En nuestro conjunto de datos hay dos géneros, cuatro continentes posibles y cuatro navegadores web:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">genders</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;female&#39;</span><span class="p">,</span> <span class="s1">&#39;male&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">locations</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;from Africa&#39;</span><span class="p">,</span> <span class="s1">&#39;from Asia&#39;</span><span class="p">,</span> <span class="s1">&#39;from Europe&#39;</span><span class="p">,</span> <span class="s1">&#39;from US&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">browsers</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;uses Chrome&#39;</span><span class="p">,</span> <span class="s1">&#39;uses Firefox&#39;</span><span class="p">,</span> <span class="s1">&#39;uses IE&#39;</span><span class="p">,</span> <span class="s1">&#39;uses Safari&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">enc</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">categories</span><span class="o">=</span><span class="p">[</span><span class="n">genders</span><span class="p">,</span> <span class="n">locations</span><span class="p">,</span> <span class="n">browsers</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># Note that for there are missing categorical values for the 2nd and 3rd</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># feature</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="p">[[</span><span class="s1">&#39;male&#39;</span><span class="p">,</span> <span class="s1">&#39;from US&#39;</span><span class="p">,</span> <span class="s1">&#39;uses Safari&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;female&#39;</span><span class="p">,</span> <span class="s1">&#39;from Europe&#39;</span><span class="p">,</span> <span class="s1">&#39;uses Firefox&#39;</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">enc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="go">OneHotEncoder(categories=[[&#39;female&#39;, &#39;male&#39;],</span>
<span class="go">                          [&#39;from Africa&#39;, &#39;from Asia&#39;, &#39;from Europe&#39;,</span>
<span class="go">                           &#39;from US&#39;],</span>
<span class="go">                          [&#39;uses Chrome&#39;, &#39;uses Firefox&#39;, &#39;uses IE&#39;,</span>
<span class="go">                           &#39;uses Safari&#39;]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">enc</span><span class="o">.</span><span class="n">transform</span><span class="p">([[</span><span class="s1">&#39;female&#39;</span><span class="p">,</span> <span class="s1">&#39;from Asia&#39;</span><span class="p">,</span> <span class="s1">&#39;uses Chrome&#39;</span><span class="p">]])</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
<span class="go">array([[1., 0., 0., 1., 0., 0., 1., 0., 0., 0.]])</span>
</pre></div>
</div>
<p>Si existe la posibilidad de que los datos de entrenamiento puedan tener características categóricas perdidas, a menudo puede ser mejor especificar <code class="docutils literal notranslate"><span class="pre">handle_unknown='ignore'</span></code> en lugar de establecer las <code class="docutils literal notranslate"><span class="pre">categories</span></code> manualmente como arriba. Cuando se especifica <code class="docutils literal notranslate"><span class="pre">handle_unknown='ignore'</span></code> y se encuentran categorías desconocidas durante la transformación, no se producirá ningún error, pero las columnas codificadas en one-hot para esta característica serán todos ceros (<a href="#id1"><span class="problematic" id="id2">``</span></a>handle_unknown=”ignore”` sólo se admite para la codificación one-hot):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">enc</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">handle_unknown</span><span class="o">=</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="p">[[</span><span class="s1">&#39;male&#39;</span><span class="p">,</span> <span class="s1">&#39;from US&#39;</span><span class="p">,</span> <span class="s1">&#39;uses Safari&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;female&#39;</span><span class="p">,</span> <span class="s1">&#39;from Europe&#39;</span><span class="p">,</span> <span class="s1">&#39;uses Firefox&#39;</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">enc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="go">OneHotEncoder(handle_unknown=&#39;ignore&#39;)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">enc</span><span class="o">.</span><span class="n">transform</span><span class="p">([[</span><span class="s1">&#39;female&#39;</span><span class="p">,</span> <span class="s1">&#39;from Asia&#39;</span><span class="p">,</span> <span class="s1">&#39;uses Chrome&#39;</span><span class="p">]])</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
<span class="go">array([[1., 0., 0., 0., 0., 0.]])</span>
</pre></div>
</div>
<p>También es posible codificar cada columna en <code class="docutils literal notranslate"><span class="pre">n_categories</span> <span class="pre">-</span> <span class="pre">1</span></code> columnas en lugar de <code class="docutils literal notranslate"><span class="pre">n_categories</span></code> columnas usando el parámetro <code class="docutils literal notranslate"><span class="pre">drop</span></code>. Este parámetro permite al usuario especificar una categoría para cada característica que se va a descartar. Esto es útil para evitar la colinealidad en la matriz de entrada en algunos clasificadores. Esta funcionalidad es útil, por ejemplo, cuando se utiliza una regresión no regularizada (<a class="reference internal" href="generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression" title="sklearn.linear_model.LinearRegression"><code class="xref py py-class docutils literal notranslate"><span class="pre">LinearRegression</span></code></a>), ya que la colinealidad haría que la matriz de covarianzas no fuera invertible. Cuando este parámetro no None, <code class="docutils literal notranslate"><span class="pre">handle_unknown</span></code> debe establecerse como <code class="docutils literal notranslate"><span class="pre">error</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="p">[[</span><span class="s1">&#39;male&#39;</span><span class="p">,</span> <span class="s1">&#39;from US&#39;</span><span class="p">,</span> <span class="s1">&#39;uses Safari&#39;</span><span class="p">],</span>
<span class="gp">... </span>     <span class="p">[</span><span class="s1">&#39;female&#39;</span><span class="p">,</span> <span class="s1">&#39;from Europe&#39;</span><span class="p">,</span> <span class="s1">&#39;uses Firefox&#39;</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">drop_enc</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="s1">&#39;first&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">drop_enc</span><span class="o">.</span><span class="n">categories_</span>
<span class="go">[array([&#39;female&#39;, &#39;male&#39;], dtype=object), array([&#39;from Europe&#39;, &#39;from US&#39;], dtype=object), array([&#39;uses Firefox&#39;, &#39;uses Safari&#39;], dtype=object)]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">drop_enc</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
<span class="go">array([[1., 1., 1.],</span>
<span class="go">       [0., 0., 0.]])</span>
</pre></div>
</div>
<p>Es posible que quieras eliminar una de las dos columnas sólo para las características con 2 categorías. En este caso, puedes establecer el parámetro <code class="docutils literal notranslate"><span class="pre">drop='if_binary'</span></code>.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="p">[[</span><span class="s1">&#39;male&#39;</span><span class="p">,</span> <span class="s1">&#39;US&#39;</span><span class="p">,</span> <span class="s1">&#39;Safari&#39;</span><span class="p">],</span>
<span class="gp">... </span>     <span class="p">[</span><span class="s1">&#39;female&#39;</span><span class="p">,</span> <span class="s1">&#39;Europe&#39;</span><span class="p">,</span> <span class="s1">&#39;Firefox&#39;</span><span class="p">],</span>
<span class="gp">... </span>     <span class="p">[</span><span class="s1">&#39;female&#39;</span><span class="p">,</span> <span class="s1">&#39;Asia&#39;</span><span class="p">,</span> <span class="s1">&#39;Chrome&#39;</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">drop_enc</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="s1">&#39;if_binary&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">drop_enc</span><span class="o">.</span><span class="n">categories_</span>
<span class="go">[array([&#39;female&#39;, &#39;male&#39;], dtype=object), array([&#39;Asia&#39;, &#39;Europe&#39;, &#39;US&#39;], dtype=object), array([&#39;Chrome&#39;, &#39;Firefox&#39;, &#39;Safari&#39;], dtype=object)]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">drop_enc</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
<span class="go">array([[1., 0., 0., 1., 0., 0., 1.],</span>
<span class="go">       [0., 0., 1., 0., 0., 1., 0.],</span>
<span class="go">       [0., 1., 0., 0., 1., 0., 0.]])</span>
</pre></div>
</div>
<p>En la transformada <code class="docutils literal notranslate"><span class="pre">X</span></code>, la primera columna es la codificación de la característica con las categorías «male»/»female», mientras que las 6 columnas restantes son la codificación de las 2 características con respectivamente 3 categorías cada una.</p>
<p><a class="reference internal" href="generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder" title="sklearn.preprocessing.OneHotEncoder"><code class="xref py py-class docutils literal notranslate"><span class="pre">OneHotEncoder</span></code></a> soporta características categóricas con valores faltantes considerando los valores faltantes como una categoría adicional:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="p">[[</span><span class="s1">&#39;male&#39;</span><span class="p">,</span> <span class="s1">&#39;Safari&#39;</span><span class="p">],</span>
<span class="gp">... </span>     <span class="p">[</span><span class="s1">&#39;female&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
<span class="gp">... </span>     <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="s1">&#39;Firefox&#39;</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">enc</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">handle_unknown</span><span class="o">=</span><span class="s1">&#39;error&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">enc</span><span class="o">.</span><span class="n">categories_</span>
<span class="go">[array([&#39;female&#39;, &#39;male&#39;, nan], dtype=object),</span>
<span class="go"> array([&#39;Firefox&#39;, &#39;Safari&#39;, None], dtype=object)]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">enc</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
<span class="go">array([[0., 1., 0., 0., 1., 0.],</span>
<span class="go">       [1., 0., 0., 0., 0., 1.],</span>
<span class="go">       [0., 0., 1., 1., 0., 0.]])</span>
</pre></div>
</div>
<p>Si una característica contiene tanto <code class="docutils literal notranslate"><span class="pre">np.nan</span></code> como <code class="docutils literal notranslate"><span class="pre">None</span></code> se considerarán categorías separadas:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="p">[[</span><span class="s1">&#39;Safari&#39;</span><span class="p">],</span> <span class="p">[</span><span class="kc">None</span><span class="p">],</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;Firefox&#39;</span><span class="p">]]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">enc</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">handle_unknown</span><span class="o">=</span><span class="s1">&#39;error&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">enc</span><span class="o">.</span><span class="n">categories_</span>
<span class="go">[array([&#39;Firefox&#39;, &#39;Safari&#39;, None, nan], dtype=object)]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">enc</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
<span class="go">array([[0., 1., 0., 0.],</span>
<span class="go">       [0., 0., 1., 0.],</span>
<span class="go">       [0., 0., 0., 1.],</span>
<span class="go">       [1., 0., 0., 0.]])</span>
</pre></div>
</div>
<p>Ver <a class="reference internal" href="feature_extraction.html#dict-feature-extraction"><span class="std std-ref">Cargando características desde diccionarios</span></a> para características categóricas que se representan como un diccionario (dict), no como escalares.</p>
</section>
<section id="discretization">
<span id="preprocessing-discretization"></span><h2><span class="section-number">6.3.5. </span>Discretización<a class="headerlink" href="#discretization" title="Enlazar permanentemente con este título">¶</a></h2>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Discretization_of_continuous_features">Discretización</a> (también conocida como cuantificación o binning) proporciona una forma de dividir características continuas en valores discretos. Ciertos conjuntos de datos con características continuas pueden beneficiarse de la discretización, ya que ésta puede transformar el conjunto de datos de atributos continuos en uno con sólo atributos nominales.</p>
<p>Las características discretizadas codificadas en One-hot pueden hacer que un modelo sea más expresivo, manteniendo al mismo tiempo la capacidad de interpretación. Por ejemplo, el preprocesamiento con un discretizador puede introducir la no linealidad en los modelos lineales.</p>
<section id="k-bins-discretization">
<h3><span class="section-number">6.3.5.1. </span>Discretización K-clases o intervalos de clase<a class="headerlink" href="#k-bins-discretization" title="Enlazar permanentemente con este título">¶</a></h3>
<p><a class="reference internal" href="generated/sklearn.preprocessing.KBinsDiscretizer.html#sklearn.preprocessing.KBinsDiscretizer" title="sklearn.preprocessing.KBinsDiscretizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">KBinsDiscretizer</span></code></a> discretiza las características en <code class="docutils literal notranslate"><span class="pre">k</span></code> intervalos de clases:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span> <span class="o">-</span><span class="mf">3.</span><span class="p">,</span> <span class="mf">5.</span><span class="p">,</span> <span class="mi">15</span> <span class="p">],</span>
<span class="gp">... </span>              <span class="p">[</span>  <span class="mf">0.</span><span class="p">,</span> <span class="mf">6.</span><span class="p">,</span> <span class="mi">14</span> <span class="p">],</span>
<span class="gp">... </span>              <span class="p">[</span>  <span class="mf">6.</span><span class="p">,</span> <span class="mf">3.</span><span class="p">,</span> <span class="mi">11</span> <span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">est</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">KBinsDiscretizer</span><span class="p">(</span><span class="n">n_bins</span><span class="o">=</span><span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">encode</span><span class="o">=</span><span class="s1">&#39;ordinal&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</pre></div>
</div>
<p>Por defecto, la salida está codificada one-hot en una matriz dispersa (Ver <a class="reference internal" href="#preprocessing-categorical-features"><span class="std std-ref">Codificación de características categóricas</span></a>) y esto puede configurarse con el parámetro <code class="docutils literal notranslate"><span class="pre">encode</span></code>. Para cada característica, los límites del intervalo de clase se calculan durante el <code class="docutils literal notranslate"><span class="pre">fit</span></code> y junto con el número de intervalos de clase, definirán los intervalos. Por lo tanto, para el ejemplo actual, estos intervalos se definen como:</p>
<blockquote>
<div><ul class="simple">
<li><p>característica 1: <span class="math notranslate nohighlight">\({[-\infty, -1), [-1, 2), [2, \infty)}\)</span></p></li>
<li><p>característica 2: <span class="math notranslate nohighlight">\({[-\infty, 5), [5, \infty)}\)</span></p></li>
<li><p>característica 3: <span class="math notranslate nohighlight">\({[-\infty, 14), [14, \infty)}\)</span></p></li>
</ul>
</div></blockquote>
<p>Basado en estos intervalos de clase, <code class="docutils literal notranslate"><span class="pre">X</span></code> se transforma de la siguiente manera:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">est</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>                      
<span class="go">array([[ 0., 1., 1.],</span>
<span class="go">       [ 1., 1., 1.],</span>
<span class="go">       [ 2., 0., 0.]])</span>
</pre></div>
</div>
<p>El conjunto de datos resultante contiene atributos ordinales que pueden utilizarse posteriormente en un <a class="reference internal" href="generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline" title="sklearn.pipeline.Pipeline"><code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code></a>.</p>
<p>La discretización es similar a la construcción de histogramas para datos continuos. Sin embargo, los histogramas se centran en el recuento de características que caen en determinados intervalos de clase, mientras que la discretización se centra en asignar valores de características a estos intervalos de clases.</p>
<p><a class="reference internal" href="generated/sklearn.preprocessing.KBinsDiscretizer.html#sklearn.preprocessing.KBinsDiscretizer" title="sklearn.preprocessing.KBinsDiscretizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">KBinsDiscretizer</span></code></a> implementa diferentes estrategias de binning, que se pueden seleccionar con el parámetro <code class="docutils literal notranslate"><span class="pre">strategy</span></code>. La estrategia <a href="#id1"><span class="problematic" id="id2">``</span></a>uniform”” utiliza intervalos de clase de ancho constante. La estrategia “quantile” utiliza los valores cuantiles para tener intervalos de claase igualmente poblados en cada característica. La estrategia «kmeans» define los intervalos basándose en un procedimiento de agrupamiento por k-medias realizado en cada característica de forma independiente.</p>
<p>Ten en cuenta que puedes especificar intervalos de clase personalizados pasando un invocable que defina la estrategia de discretización a <code class="xref py py-class docutils literal notranslate"><span class="pre">FunctionTransformer</span></code>. Por ejemplo, podemos utilizar la función de Pandas <a class="reference external" href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.cut.html#pandas.cut" title="(en pandas versión 1.3.2)"><code class="xref py py-func docutils literal notranslate"><span class="pre">pandas.cut</span></code></a>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bins</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">13</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">labels</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;infant&#39;</span><span class="p">,</span> <span class="s1">&#39;kid&#39;</span><span class="p">,</span> <span class="s1">&#39;teen&#39;</span><span class="p">,</span> <span class="s1">&#39;adult&#39;</span><span class="p">,</span> <span class="s1">&#39;senior citizen&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">transformer</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">FunctionTransformer</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">pd</span><span class="o">.</span><span class="n">cut</span><span class="p">,</span> <span class="n">kw_args</span><span class="o">=</span><span class="p">{</span><span class="s1">&#39;bins&#39;</span><span class="p">:</span> <span class="n">bins</span><span class="p">,</span> <span class="s1">&#39;labels&#39;</span><span class="p">:</span> <span class="n">labels</span><span class="p">,</span> <span class="s1">&#39;retbins&#39;</span><span class="p">:</span> <span class="kc">False</span><span class="p">}</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">15</span><span class="p">,</span> <span class="mi">25</span><span class="p">,</span> <span class="mi">97</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">transformer</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="go">[&#39;infant&#39;, &#39;kid&#39;, &#39;teen&#39;, &#39;adult&#39;, &#39;senior citizen&#39;]</span>
<span class="go">Categories (5, object): [&#39;infant&#39; &lt; &#39;kid&#39; &lt; &#39;teen&#39; &lt; &#39;adult&#39; &lt; &#39;senior citizen&#39;]</span>
</pre></div>
</div>
<div class="topic">
<p class="topic-title">Ejemplos:</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/preprocessing/plot_discretization.html#sphx-glr-auto-examples-preprocessing-plot-discretization-py"><span class="std std-ref">Usar KBinsDiscretizer para discretizar características continuas</span></a></p></li>
<li><p><a class="reference internal" href="../auto_examples/preprocessing/plot_discretization_classification.html#sphx-glr-auto-examples-preprocessing-plot-discretization-classification-py"><span class="std std-ref">Discretización de la característica</span></a></p></li>
<li><p><a class="reference internal" href="../auto_examples/preprocessing/plot_discretization_strategies.html#sphx-glr-auto-examples-preprocessing-plot-discretization-strategies-py"><span class="std std-ref">Demostrar las diferentes estrategias de KBinsDiscretizer</span></a></p></li>
</ul>
</div>
</section>
<section id="feature-binarization">
<span id="preprocessing-binarization"></span><h3><span class="section-number">6.3.5.2. </span>Binarización de característica<a class="headerlink" href="#feature-binarization" title="Enlazar permanentemente con este título">¶</a></h3>
<p>La <strong>binarización de características</strong> es el proceso de <strong>fijar umbrales de las características numéricas para obtener valores booleanos</strong>. Esto puede ser útil para estimadores probabilísticos posteriores que suponen que los datos de entrada se distribuyen según una distribución <a class="reference external" href="https://en.wikipedia.org/wiki/Bernoulli_distribution">Bernoulli</a> multivariante. Por ejemplo, este es el caso de <a class="reference internal" href="generated/sklearn.neural_network.BernoulliRBM.html#sklearn.neural_network.BernoulliRBM" title="sklearn.neural_network.BernoulliRBM"><code class="xref py py-class docutils literal notranslate"><span class="pre">BernoulliRBM</span></code></a>.</p>
<p>También es común entre la comunidad de procesadores de texto utilizar valores binarios de las características (probablemente para simplificar el razonamiento probabilístico) aunque los recuentos normalizados (también conocidos como frecuencias de términos) o las características con valores TF-IDF suelen tener un rendimiento ligeramente superior en la práctica.</p>
<p>En cuanto al <a class="reference internal" href="generated/sklearn.preprocessing.Normalizer.html#sklearn.preprocessing.Normalizer" title="sklearn.preprocessing.Normalizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Normalizer</span></code></a>, la clase de utilidad <a class="reference internal" href="generated/sklearn.preprocessing.Binarizer.html#sklearn.preprocessing.Binarizer" title="sklearn.preprocessing.Binarizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Binarizer</span></code></a> está pensada para ser utilizada en las primeras etapas de <a class="reference internal" href="generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline" title="sklearn.pipeline.Pipeline"><code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code></a>. El método <code class="docutils literal notranslate"><span class="pre">fit</span></code> no hace nada ya que cada muestra es tratada independientemente de las demás:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="p">[[</span> <span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span>  <span class="mf">2.</span><span class="p">],</span>
<span class="gp">... </span>     <span class="p">[</span> <span class="mf">2.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">],</span>
<span class="gp">... </span>     <span class="p">[</span> <span class="mf">0.</span><span class="p">,</span>  <span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">]]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">binarizer</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">Binarizer</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>  <span class="c1"># fit does nothing</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">binarizer</span>
<span class="go">Binarizer()</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">binarizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="go">array([[1., 0., 1.],</span>
<span class="go">       [1., 0., 0.],</span>
<span class="go">       [0., 1., 0.]])</span>
</pre></div>
</div>
<p>Es posible ajustar el umbral del binarizador:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">binarizer</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">Binarizer</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="mf">1.1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">binarizer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="go">array([[0., 0., 1.],</span>
<span class="go">       [1., 0., 0.],</span>
<span class="go">       [0., 0., 0.]])</span>
</pre></div>
</div>
<p>En cuanto a la clase <a class="reference internal" href="generated/sklearn.preprocessing.Normalizer.html#sklearn.preprocessing.Normalizer" title="sklearn.preprocessing.Normalizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Normalizer</span></code></a>, el módulo de preprocesamiento proporciona una función complementaria <a class="reference internal" href="generated/sklearn.preprocessing.binarize.html#sklearn.preprocessing.binarize" title="sklearn.preprocessing.binarize"><code class="xref py py-func docutils literal notranslate"><span class="pre">binarize</span></code></a> para ser utilizada cuando la API del transformador no es necesaria.</p>
<p>Ten en cuenta que el <a class="reference internal" href="generated/sklearn.preprocessing.Binarizer.html#sklearn.preprocessing.Binarizer" title="sklearn.preprocessing.Binarizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Binarizer</span></code></a> es similar al <a class="reference internal" href="generated/sklearn.preprocessing.KBinsDiscretizer.html#sklearn.preprocessing.KBinsDiscretizer" title="sklearn.preprocessing.KBinsDiscretizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">KBinsDiscretizer</span></code></a> cuando <code class="docutils literal notranslate"><span class="pre">k</span> <span class="pre">=</span> <span class="pre">2</span></code>, y cuando el límite del intervalo de clase está en el valor <code class="docutils literal notranslate"><span class="pre">threshold</span></code>.</p>
<div class="topic">
<p class="topic-title">Entrada dispersa</p>
<p><a class="reference internal" href="generated/sklearn.preprocessing.binarize.html#sklearn.preprocessing.binarize" title="sklearn.preprocessing.binarize"><code class="xref py py-func docutils literal notranslate"><span class="pre">binarize</span></code></a> y <a class="reference internal" href="generated/sklearn.preprocessing.Binarizer.html#sklearn.preprocessing.Binarizer" title="sklearn.preprocessing.Binarizer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Binarizer</span></code></a> aceptan <strong>tanto array-like densos como matrices dispersas de scipy.sparse como entrada</strong>.</p>
<p>Para la entrada dispersa los datos son <a href="#id1"><span class="problematic" id="id2">**</span></a>convertidos a la representación Filas Dispersas Comprimidas ** (ver <code class="docutils literal notranslate"><span class="pre">scipy.sparse.csr_matrix</span></code>). Para evitar copias de memoria innecesarias, se recomienda elegir la representación CSR antes.</p>
</div>
</section>
</section>
<section id="imputation-of-missing-values">
<span id="imputation"></span><h2><span class="section-number">6.3.6. </span>Imputación de valores faltantes<a class="headerlink" href="#imputation-of-missing-values" title="Enlazar permanentemente con este título">¶</a></h2>
<p>Las herramientas para la imputación de valores faltantes se discuten en <a class="reference internal" href="impute.html#impute"><span class="std std-ref">Imputación de valores faltantes</span></a>.</p>
</section>
<section id="generating-polynomial-features">
<span id="polynomial-features"></span><h2><span class="section-number">6.3.7. </span>Generación de características polinomiales<a class="headerlink" href="#generating-polynomial-features" title="Enlazar permanentemente con este título">¶</a></h2>
<p>A menudo es útil añadir complejidad al modelo considerando características no lineales de los datos de entrada. Un método simple y común para utilizar son las características polinomiales, que permiten obtener los términos de alto orden e interacción de las características. Se implementa en <code class="xref py py-class docutils literal notranslate"><span class="pre">PolinnomialFeatures</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">PolynomialFeatures</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span>
<span class="go">array([[0, 1],</span>
<span class="go">       [2, 3],</span>
<span class="go">       [4, 5]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">poly</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">poly</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="go">array([[ 1.,  0.,  1.,  0.,  0.,  1.],</span>
<span class="go">       [ 1.,  2.,  3.,  4.,  6.,  9.],</span>
<span class="go">       [ 1.,  4.,  5., 16., 20., 25.]])</span>
</pre></div>
</div>
<p>Las características de X han sido transformadas de <span class="math notranslate nohighlight">\((X_1, X_2)\)</span> a <span class="math notranslate nohighlight">\((1, X_1, X_2, X_1^2, X_1X_2, X_2^2)\)</span>.</p>
<p>En algunos casos, sólo se requieren términos de interacción entre las características, y se pueden conseguir con el ajuste <code class="docutils literal notranslate"><span class="pre">interaction_only=True</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">9</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span>
<span class="go">array([[0, 1, 2],</span>
<span class="go">       [3, 4, 5],</span>
<span class="go">       [6, 7, 8]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">poly</span> <span class="o">=</span> <span class="n">PolynomialFeatures</span><span class="p">(</span><span class="n">degree</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">interaction_only</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">poly</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="go">array([[  1.,   0.,   1.,   2.,   0.,   0.,   2.,   0.],</span>
<span class="go">       [  1.,   3.,   4.,   5.,  12.,  15.,  20.,  60.],</span>
<span class="go">       [  1.,   6.,   7.,   8.,  42.,  48.,  56., 336.]])</span>
</pre></div>
</div>
<p>Las características de X han sido transformadas de <span class="math notranslate nohighlight">\((X_1, X_2, X_3)\)</span> a <span class="math notranslate nohighlight">\((1, X_1, X_2, X_3, X_1X_2, X_1X_3, X_2X_3, X_1X_2X_3)\)</span>.</p>
<p>Ten en cuenta que las características polinómicas se utilizan implícitamente en los <a class="reference external" href="https://en.wikipedia.org/wiki/Kernel_method">métodos del kernel</a> (por ejemplo, <a class="reference internal" href="generated/sklearn.svm.SVC.html#sklearn.svm.SVC" title="sklearn.svm.SVC"><code class="xref py py-class docutils literal notranslate"><span class="pre">SVC</span></code></a>, <a class="reference internal" href="generated/sklearn.decomposition.KernelPCA.html#sklearn.decomposition.KernelPCA" title="sklearn.decomposition.KernelPCA"><code class="xref py py-class docutils literal notranslate"><span class="pre">KernelPCA</span></code></a>) cuando se utilizan polinomios <a class="reference internal" href="svm.html#svm-kernels"><span class="std std-ref">Funciones del núcleo</span></a>.</p>
<p>Ver <a class="reference internal" href="../auto_examples/linear_model/plot_polynomial_interpolation.html#sphx-glr-auto-examples-linear-model-plot-polynomial-interpolation-py"><span class="std std-ref">Interpolación polinómica</span></a> para la Regresión de Cresta usando características polinomiales creadas.</p>
</section>
<section id="custom-transformers">
<span id="function-transformer"></span><h2><span class="section-number">6.3.8. </span>Transformadores personalizados<a class="headerlink" href="#custom-transformers" title="Enlazar permanentemente con este título">¶</a></h2>
<p>A menudo, querrás convertir una función existente de Python en un transformador para ayudar a limpiar o procesar datos. Puedes implementar un transformador desde una función arbitraria con <a class="reference internal" href="generated/sklearn.preprocessing.FunctionTransformer.html#sklearn.preprocessing.FunctionTransformer" title="sklearn.preprocessing.FunctionTransformer"><code class="xref py py-class docutils literal notranslate"><span class="pre">FunctionTransformer</span></code></a>. Por ejemplo, para construir un transformador que aplique una transformación de registro en un pipeline, haz:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">FunctionTransformer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">transformer</span> <span class="o">=</span> <span class="n">FunctionTransformer</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log1p</span><span class="p">,</span> <span class="n">validate</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">transformer</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="go">array([[0.        , 0.69314718],</span>
<span class="go">       [1.09861229, 1.38629436]])</span>
</pre></div>
</div>
<p>Puedes asegurarte de que <code class="docutils literal notranslate"><span class="pre">func</span></code> e <code class="docutils literal notranslate"><span class="pre">inverse_func</span></code> son la inversa de los demás configurando <code class="docutils literal notranslate"><span class="pre">check_inverse=True</span></code> y llamando <code class="docutils literal notranslate"><span class="pre">fit</span></code> antes de <code class="docutils literal notranslate"><span class="pre">transform</span></code>. Por favor, ten en cuenta que se producirá una advertencia y se puede convertir en un error con un <code class="docutils literal notranslate"><span class="pre">filterwarnings</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">warnings</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;error&quot;</span><span class="p">,</span> <span class="n">message</span><span class="o">=</span><span class="s2">&quot;.*check_inverse*.&quot;</span><span class="p">,</span>
<span class="gp">... </span>                        <span class="n">category</span><span class="o">=</span><span class="ne">UserWarning</span><span class="p">,</span> <span class="n">append</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
<p>Para ver un ejemplo de código completo que demuestra el uso de <a class="reference internal" href="generated/sklearn.preprocessing.FunctionTransformer.html#sklearn.preprocessing.FunctionTransformer" title="sklearn.preprocessing.FunctionTransformer"><code class="xref py py-class docutils literal notranslate"><span class="pre">FunctionTransformer</span></code></a> para extraer características de los datos de texto consulta <a class="reference internal" href="../auto_examples/compose/plot_column_transformer.html#sphx-glr-auto-examples-compose-plot-column-transformer-py"><span class="std std-ref">Transformador de columnas con fuentes de datos heterogéneas</span></a></p>
</section>
</section>


      </div>
    <div class="container">
      <footer class="sk-content-footer">
            &copy; 2007 - 2020, scikit-learn developers (BSD License).
          <a href="../_sources/modules/preprocessing.rst.txt" rel="nofollow">Mostrar la fuente de esta página</a>
      </footer>
    </div>
  </div>
</div>
<script src="../_static/js/vendor/bootstrap.min.js"></script>

<script>
    window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
    ga('create', 'UA-22606712-2', 'auto');
    ga('set', 'anonymizeIp', true);
    ga('send', 'pageview');
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>


<script>
$(document).ready(function() {
    /* Add a [>>>] button on the top-right corner of code samples to hide
     * the >>> and ... prompts and the output and thus make the code
     * copyable. */
    var div = $('.highlight-python .highlight,' +
                '.highlight-python3 .highlight,' +
                '.highlight-pycon .highlight,' +
		'.highlight-default .highlight')
    var pre = div.find('pre');

    // get the styles from the current theme
    pre.parent().parent().css('position', 'relative');
    var hide_text = 'Hide prompts and outputs';
    var show_text = 'Show prompts and outputs';

    // create and add the button to all the code blocks that contain >>>
    div.each(function(index) {
        var jthis = $(this);
        if (jthis.find('.gp').length > 0) {
            var button = $('<span class="copybutton">&gt;&gt;&gt;</span>');
            button.attr('title', hide_text);
            button.data('hidden', 'false');
            jthis.prepend(button);
        }
        // tracebacks (.gt) contain bare text elements that need to be
        // wrapped in a span to work with .nextUntil() (see later)
        jthis.find('pre:has(.gt)').contents().filter(function() {
            return ((this.nodeType == 3) && (this.data.trim().length > 0));
        }).wrap('<span>');
    });

    // define the behavior of the button when it's clicked
    $('.copybutton').click(function(e){
        e.preventDefault();
        var button = $(this);
        if (button.data('hidden') === 'false') {
            // hide the code output
            button.parent().find('.go, .gp, .gt').hide();
            button.next('pre').find('.gt').nextUntil('.gp, .go').css('visibility', 'hidden');
            button.css('text-decoration', 'line-through');
            button.attr('title', show_text);
            button.data('hidden', 'true');
        } else {
            // show the code output
            button.parent().find('.go, .gp, .gt').show();
            button.next('pre').find('.gt').nextUntil('.gp, .go').css('visibility', 'visible');
            button.css('text-decoration', 'none');
            button.attr('title', hide_text);
            button.data('hidden', 'false');
        }
    });

	/*** Add permalink buttons next to glossary terms ***/
	$('dl.glossary > dt[id]').append(function() {
		return ('<a class="headerlink" href="#' +
			    this.getAttribute('id') +
			    '" title="Permalink to this term">¶</a>');
	});
  /*** Hide navbar when scrolling down ***/
  // Returns true when headerlink target matches hash in url
  (function() {
    hashTargetOnTop = function() {
        var hash = window.location.hash;
        if ( hash.length < 2 ) { return false; }

        var target = document.getElementById( hash.slice(1) );
        if ( target === null ) { return false; }

        var top = target.getBoundingClientRect().top;
        return (top < 2) && (top > -2);
    };

    // Hide navbar on load if hash target is on top
    var navBar = document.getElementById("navbar");
    var navBarToggler = document.getElementById("sk-navbar-toggler");
    var navBarHeightHidden = "-" + navBar.getBoundingClientRect().height + "px";
    var $window = $(window);

    hideNavBar = function() {
        navBar.style.top = navBarHeightHidden;
    };

    showNavBar = function() {
        navBar.style.top = "0";
    }

    if (hashTargetOnTop()) {
        hideNavBar()
    }

    var prevScrollpos = window.pageYOffset;
    hideOnScroll = function(lastScrollTop) {
        if (($window.width() < 768) && (navBarToggler.getAttribute("aria-expanded") === 'true')) {
            return;
        }
        if (lastScrollTop > 2 && (prevScrollpos <= lastScrollTop) || hashTargetOnTop()){
            hideNavBar()
        } else {
            showNavBar()
        }
        prevScrollpos = lastScrollTop;
    };

    /*** high performance scroll event listener***/
    var raf = window.requestAnimationFrame ||
        window.webkitRequestAnimationFrame ||
        window.mozRequestAnimationFrame ||
        window.msRequestAnimationFrame ||
        window.oRequestAnimationFrame;
    var lastScrollTop = $window.scrollTop();

    if (raf) {
        loop();
    }

    function loop() {
        var scrollTop = $window.scrollTop();
        if (lastScrollTop === scrollTop) {
            raf(loop);
            return;
        } else {
            lastScrollTop = scrollTop;
            hideOnScroll(lastScrollTop);
            raf(loop);
        }
    }
  })();
});

</script>
    
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
    
</body>
</html>