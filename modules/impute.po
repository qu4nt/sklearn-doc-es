# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2007 - 2020, scikit-learn developers (BSD License)
# This file is distributed under the same license as the scikit-learn
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2021.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: scikit-learn 0.24\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-03-31 11:24-0400\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"

#: ../modules/impute.rst:5
msgid "Imputation of missing values"
msgstr ""

#: ../modules/impute.rst:9
msgid ""
"For various reasons, many real world datasets contain missing values, "
"often encoded as blanks, NaNs or other placeholders. Such datasets "
"however are incompatible with scikit-learn estimators which assume that "
"all values in an array are numerical, and that all have and hold meaning."
" A basic strategy to use incomplete datasets is to discard entire rows "
"and/or columns containing missing values. However, this comes at the "
"price of losing data which may be valuable (even though incomplete). A "
"better strategy is to impute the missing values, i.e., to infer them from"
" the known part of the data. See the :ref:`glossary` entry on imputation."
msgstr ""

#: ../modules/impute.rst:21
msgid "Univariate vs. Multivariate Imputation"
msgstr ""

#: ../modules/impute.rst:23
msgid ""
"One type of imputation algorithm is univariate, which imputes values in "
"the i-th feature dimension using only non-missing values in that feature "
"dimension (e.g. :class:`impute.SimpleImputer`). By contrast, multivariate"
" imputation algorithms use the entire set of available feature dimensions"
" to estimate the missing values (e.g. :class:`impute.IterativeImputer`)."
msgstr ""

#: ../modules/impute.rst:33
msgid "Univariate feature imputation"
msgstr ""

#: ../modules/impute.rst:35
msgid ""
"The :class:`SimpleImputer` class provides basic strategies for imputing "
"missing values. Missing values can be imputed with a provided constant "
"value, or using the statistics (mean, median or most frequent) of each "
"column in which the missing values are located. This class also allows "
"for different missing values encodings."
msgstr ""

#: ../modules/impute.rst:41
msgid ""
"The following snippet demonstrates how to replace missing values, encoded"
" as ``np.nan``, using the mean value of the columns (axis 0) that contain"
" the missing values::"
msgstr ""

#: ../modules/impute.rst:56
msgid "The :class:`SimpleImputer` class also supports sparse matrices::"
msgstr ""

#: ../modules/impute.rst:69
msgid ""
"Note that this format is not meant to be used to implicitly store missing"
" values in the matrix because it would densify it at transform time. "
"Missing values encoded by 0 must be used with dense input."
msgstr ""

#: ../modules/impute.rst:73
msgid ""
"The :class:`SimpleImputer` class also supports categorical data "
"represented as string values or pandas categoricals when using the "
"``'most_frequent'`` or ``'constant'`` strategy::"
msgstr ""

#: ../modules/impute.rst:94
msgid "Multivariate feature imputation"
msgstr ""

#: ../modules/impute.rst:96
msgid ""
"A more sophisticated approach is to use the :class:`IterativeImputer` "
"class, which models each feature with missing values as a function of "
"other features, and uses that estimate for imputation. It does so in an "
"iterated round-robin fashion: at each step, a feature column is "
"designated as output ``y`` and the other feature columns are treated as "
"inputs ``X``. A regressor is fit on ``(X, y)`` for known ``y``. Then, the"
" regressor is used to predict the missing values of ``y``.  This is done "
"for each feature in an iterative fashion, and then is repeated for "
"``max_iter`` imputation rounds. The results of the final imputation round"
" are returned."
msgstr ""

#: ../modules/impute.rst:108
msgid ""
"This estimator is still **experimental** for now: default parameters or "
"details of behaviour might change without any deprecation cycle. "
"Resolving the following issues would help stabilize "
":class:`IterativeImputer`: convergence criteria (:issue:`14338`), default"
" estimators (:issue:`13286`), and use of random state (:issue:`15611`). "
"To use it, you need to explicitly import ``enable_iterative_imputer``."
msgstr ""

#: ../modules/impute.rst:130
msgid ""
"Both :class:`SimpleImputer` and :class:`IterativeImputer` can be used in "
"a Pipeline as a way to build a composite estimator that supports "
"imputation. See "
":ref:`sphx_glr_auto_examples_impute_plot_missing_values.py`."
msgstr ""

#: ../modules/impute.rst:135
msgid "Flexibility of IterativeImputer"
msgstr ""

#: ../modules/impute.rst:137
msgid ""
"There are many well-established imputation packages in the R data science"
" ecosystem: Amelia, mi, mice, missForest, etc. missForest is popular, and"
" turns out to be a particular instance of different sequential imputation"
" algorithms that can all be implemented with :class:`IterativeImputer` by"
" passing in different regressors to be used for predicting missing "
"feature values. In the case of missForest, this regressor is a Random "
"Forest. See "
":ref:`sphx_glr_auto_examples_impute_plot_iterative_imputer_variants_comparison.py`."
msgstr ""

#: ../modules/impute.rst:149
msgid "Multiple vs. Single Imputation"
msgstr ""

#: ../modules/impute.rst:151
msgid ""
"In the statistics community, it is common practice to perform multiple "
"imputations, generating, for example, ``m`` separate imputations for a "
"single feature matrix. Each of these ``m`` imputations is then put "
"through the subsequent analysis pipeline (e.g. feature engineering, "
"clustering, regression, classification). The ``m`` final analysis results"
" (e.g. held-out validation errors) allow the data scientist to obtain "
"understanding of how analytic results may differ as a consequence of the "
"inherent uncertainty caused by the missing values. The above practice is "
"called multiple imputation."
msgstr ""

#: ../modules/impute.rst:160
msgid ""
"Our implementation of :class:`IterativeImputer` was inspired by the R "
"MICE package (Multivariate Imputation by Chained Equations) [1]_, but "
"differs from it by returning a single imputation instead of multiple "
"imputations.  However, :class:`IterativeImputer` can also be used for "
"multiple imputations by applying it repeatedly to the same dataset with "
"different random seeds when ``sample_posterior=True``. See [2]_, chapter "
"4 for more discussion on multiple vs. single imputations."
msgstr ""

#: ../modules/impute.rst:168
msgid ""
"It is still an open problem as to how useful single vs. multiple "
"imputation is in the context of prediction and classification when the "
"user is not interested in measuring uncertainty due to missing values."
msgstr ""

#: ../modules/impute.rst:172
msgid ""
"Note that a call to the ``transform`` method of :class:`IterativeImputer`"
" is not allowed to change the number of samples. Therefore multiple "
"imputations cannot be achieved by a single call to ``transform``."
msgstr ""

#: ../modules/impute.rst:177
msgid "References"
msgstr ""

#: ../modules/impute.rst:179
msgid ""
"Stef van Buuren, Karin Groothuis-Oudshoorn (2011). \"mice: Multivariate "
"Imputation by Chained Equations in R\". Journal of Statistical Software "
"45: 1-67."
msgstr ""

#: ../modules/impute.rst:183
msgid ""
"Roderick J A Little and Donald B Rubin (1986). \"Statistical Analysis "
"with Missing Data\". John Wiley & Sons, Inc., New York, NY, USA."
msgstr ""

#: ../modules/impute.rst:189
msgid "Nearest neighbors imputation"
msgstr ""

#: ../modules/impute.rst:191
msgid ""
"The :class:`KNNImputer` class provides imputation for filling in missing "
"values using the k-Nearest Neighbors approach. By default, a euclidean "
"distance metric that supports missing values, "
":func:`~sklearn.metrics.nan_euclidean_distances`, is used to find the "
"nearest neighbors. Each missing feature is imputed using values from "
"``n_neighbors`` nearest neighbors that have a value for the feature. The "
"feature of the neighbors are averaged uniformly or weighted by distance "
"to each neighbor. If a sample has more than one feature missing, then the"
" neighbors for that sample can be different depending on the particular "
"feature being imputed. When the number of available neighbors is less "
"than `n_neighbors` and there are no defined distances to the training "
"set, the training set average for that feature is used during imputation."
" If there is at least one neighbor with a defined distance, the weighted "
"or unweighted average of the remaining neighbors will be used during "
"imputation. If a feature is always missing in training, it is removed "
"during `transform`. For more information on the methodology, see ref. "
"[OL2001]_."
msgstr ""

#: ../modules/impute.rst:207
msgid ""
"The following snippet demonstrates how to replace missing values, encoded"
" as ``np.nan``, using the mean feature value of the two nearest neighbors"
" of samples with missing values::"
msgstr ""

#: ../modules/impute.rst:222
msgid ""
"Olga Troyanskaya, Michael Cantor, Gavin Sherlock, Pat Brown, Trevor "
"Hastie, Robert Tibshirani, David Botstein and Russ B. Altman, Missing "
"value estimation methods for DNA microarrays, BIOINFORMATICS Vol. 17 no. "
"6, 2001 Pages 520-525."
msgstr ""

#: ../modules/impute.rst:230
msgid "Marking imputed values"
msgstr ""

#: ../modules/impute.rst:232
msgid ""
"The :class:`MissingIndicator` transformer is useful to transform a "
"dataset into corresponding binary matrix indicating the presence of "
"missing values in the dataset. This transformation is useful in "
"conjunction with imputation. When using imputation, preserving the "
"information about which values had been missing can be informative. Note "
"that both the :class:`SimpleImputer` and :class:`IterativeImputer` have "
"the boolean parameter ``add_indicator`` (``False`` by default) which when"
" set to ``True`` provides a convenient way of stacking the output of the "
":class:`MissingIndicator` transformer with the output of the imputer."
msgstr ""

#: ../modules/impute.rst:242
msgid ""
"``NaN`` is usually used as the placeholder for missing values. However, "
"it enforces the data type to be float. The parameter ``missing_values`` "
"allows to specify other placeholder such as integer. In the following "
"example, we will use ``-1`` as missing values::"
msgstr ""

#: ../modules/impute.rst:258
msgid ""
"The ``features`` parameter is used to choose the features for which the "
"mask is constructed. By default, it is ``'missing-only'`` which returns "
"the imputer mask of the features containing missing values at ``fit`` "
"time::"
msgstr ""

#: ../modules/impute.rst:265
msgid ""
"The ``features`` parameter can be set to ``'all'`` to return all features"
" whether or not they contain missing values::"
msgstr ""

#: ../modules/impute.rst:277
msgid ""
"When using the :class:`MissingIndicator` in a :class:`Pipeline`, be sure "
"to use the :class:`FeatureUnion` or :class:`ColumnTransformer` to add the"
" indicator features to the regular features. First we obtain the `iris` "
"dataset, and add some missing values to it."
msgstr ""

#: ../modules/impute.rst:293
msgid ""
"Now we create a :class:`FeatureUnion`. All features will be imputed using"
" :class:`SimpleImputer`, in order to enable classifiers to work with this"
" data. Additionally, it adds the indicator variables from "
":class:`MissingIndicator`."
msgstr ""

#: ../modules/impute.rst:307
msgid ""
"Of course, we cannot use the transformer to make any predictions. We "
"should wrap this in a :class:`Pipeline` with a classifier (e.g., a "
":class:`DecisionTreeClassifier`) to be able to make predictions."
msgstr ""

