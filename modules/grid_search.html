

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  
  <title>3.2. Ajustar los hiperparámetros de un estimador &mdash; documentación de scikit-learn - 0.24.1</title>
  
  <link rel="canonical" href="http://scikit-learn.org/stable/modules/grid_search.html" />

  
  <link rel="shortcut icon" href="../_static/favicon.ico"/>
  

  <link rel="stylesheet" href="../_static/css/vendor/bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/gallery.css" type="text/css" />
  <link rel="stylesheet" href="../_static/gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../_static/gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../_static/gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
<script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
<script src="../_static/jquery.js"></script> 
</head>
<body>
<nav id="navbar" class="sk-docs-navbar navbar navbar-expand-md navbar-light bg-light py-0">
  <div class="container-fluid sk-docs-container px-0">
      <a class="navbar-brand py-0" href="../index.html">
        <img
          class="sk-brand-img"
          src="../_static/scikit-learn-logo-small.png"
          alt="logo"/>
      </a>
    <button
      id="sk-navbar-toggler"
      class="navbar-toggler"
      type="button"
      data-toggle="collapse"
      data-target="#navbarSupportedContent"
      aria-controls="navbarSupportedContent"
      aria-expanded="false"
      aria-label="Toggle navigation"
    >
      <span class="navbar-toggler-icon"></span>
    </button>

    <div class="sk-navbar-collapse collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav mr-auto">
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../install.html">Instalación</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../user_guide.html">Manual de Usuario</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="classes.html">API</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../auto_examples/index.html">Ejemplos</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../getting_started.html">¿Cómo empezar?</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../tutorial/index.html">Tutorial</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../whats_new/v0.24.html">Novedades</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../glossary.html">Glosario</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../developers/index.html">Desarrollo</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../faq.html">FAQ</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../support.html">Soporte</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../related_projects.html">Paquetes relacionados</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../roadmap.html">Hoja de ruta</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../about.html">Sobre nosotros</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="https://github.com/scikit-learn/scikit-learn">GitHub</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="https://scikit-learn.org/dev/versions.html">Otras versiones y descargas</a>
        </li>
        <li class="nav-item dropdown nav-more-item-dropdown">
          <a class="sk-nav-link nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Más</a>
          <div class="dropdown-menu" aria-labelledby="navbarDropdown">
              <a class="sk-nav-dropdown-item dropdown-item" href="../getting_started.html">¿Cómo empezar?</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../tutorial/index.html">Tutorial</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../whats_new/v0.24.html">Novedades</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../glossary.html">Glosario</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../developers/index.html">Desarrollo</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../faq.html">FAQ</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../support.html">Soporte</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../related_projects.html">Paquetes relacionados</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../roadmap.html">Hoja de ruta</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../about.html">Sobre nosotros</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="https://github.com/scikit-learn/scikit-learn">GitHub</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="https://scikit-learn.org/dev/versions.html">Otras versiones y descargas</a>
          </div>
        </li>
      </ul>
      <div id="searchbox" role="search">
          <div class="searchformwrapper">
          <form class="search" action="../search.html" method="get">
            <input class="sk-search-text-input" type="text" name="q" aria-labelledby="searchlabel" />
            <input class="sk-search-text-btn" type="submit" value="Ir a" />
          </form>
          </div>
      </div>
    </div>
  </div>
</nav>
<div class="d-flex" id="sk-doc-wrapper">
    <input type="checkbox" name="sk-toggle-checkbox" id="sk-toggle-checkbox">
    <label id="sk-sidemenu-toggle" class="sk-btn-toggle-toc btn sk-btn-primary" for="sk-toggle-checkbox">Alternar menú</label>
    <div id="sk-sidebar-wrapper" class="border-right">
      <div class="sk-sidebar-toc-wrapper">
        <div class="sk-sidebar-toc-logo">
          <a href="../index.html">
            <img
              class="sk-brand-img"
              src="../_static/scikit-learn-logo-small.png"
              alt="logo"/>
          </a>
        </div>
        <div class="btn-group w-100 mb-2" role="group" aria-label="rellinks">
            <a href="cross_validation.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="3.1. Validación cruzada: evaluación del rendimiento del estimador">Prev</a><a href="../model_selection.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="3. Selección y evaluación del modelo">Arriba</a>
            <a href="model_evaluation.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="3.3. Métricas y puntuación: cuantificar la calidad de las predicciones">Sig.</a>
        </div>
        <div class="alert alert-danger p-1 mb-2" role="alert">
          <p class="text-center mb-0">
          <strong>scikit-learn 0.24.1</strong><br/>
          <a href="http://scikit-learn.org/dev/versions.html">Otras versiones</a>
          </p>
        </div>
        <div class="alert alert-warning p-1 mb-2" role="alert">
          <p class="text-center mb-0">
            Por favor <a class="font-weight-bold" href="../about.html#citing-scikit-learn"><string>cítanos</string></a> si usas el software.
          </p>
        </div>
            <div class="sk-sidebar-toc">
              <ul>
<li><a class="reference internal" href="#">3.2. Ajustar los hiperparámetros de un estimador</a><ul>
<li><a class="reference internal" href="#exhaustive-grid-search">3.2.1. Búsqueda exhaustiva en Cuadrícula</a></li>
<li><a class="reference internal" href="#randomized-parameter-optimization">3.2.2. Optimización Aleatoria de Parámetros</a></li>
<li><a class="reference internal" href="#searching-for-optimal-parameters-with-successive-halving">3.2.3. Búsqueda de los parámetros óptimos con la reducción sucesiva a la mitad</a><ul>
<li><a class="reference internal" href="#choosing-min-resources-and-the-number-of-candidates">3.2.3.1. Elegir <code class="docutils literal notranslate"><span class="pre">min_resources</span></code> y el número de candidatos</a></li>
<li><a class="reference internal" href="#amount-of-resource-and-number-of-candidates-at-each-iteration">3.2.3.2. Cantidad de recursos y número de candidatos en cada iteración</a></li>
<li><a class="reference internal" href="#choosing-a-resource">3.2.3.3. Elegir un recurso</a></li>
<li><a class="reference internal" href="#exhausting-the-available-resources">3.2.3.4. Agotar los recursos disponibles</a></li>
<li><a class="reference internal" href="#aggressive-elimination-of-candidates">3.2.3.5. Eliminación agresiva de candidatos</a></li>
<li><a class="reference internal" href="#analysing-results-with-the-cv-results-attribute">3.2.3.6. Analizar resultados con el atributo <code class="docutils literal notranslate"><span class="pre">cv_results_</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#tips-for-parameter-search">3.2.4. Tips para la búsqueda de parámetros</a><ul>
<li><a class="reference internal" href="#specifying-an-objective-metric">3.2.4.1. Especificar una métrica objetiva</a></li>
<li><a class="reference internal" href="#specifying-multiple-metrics-for-evaluation">3.2.4.2. Especificar múltiples métricas para la evaluación</a></li>
<li><a class="reference internal" href="#composite-estimators-and-parameter-spaces">3.2.4.3. Estimadores compuestos y espacios de parámetros</a></li>
<li><a class="reference internal" href="#model-selection-development-and-evaluation">3.2.4.4. Selección de modelos: desarrollo y evaluación</a></li>
<li><a class="reference internal" href="#parallelism">3.2.4.5. Paralelismo</a></li>
<li><a class="reference internal" href="#robustness-to-failure">3.2.4.6. Robustez frente a los fallos</a></li>
</ul>
</li>
<li><a class="reference internal" href="#alternatives-to-brute-force-parameter-search">3.2.5. Alternativas a la búsqueda de parámetros por fuerza bruta</a><ul>
<li><a class="reference internal" href="#model-specific-cross-validation">3.2.5.1. Validación cruzada específica del modelo</a></li>
<li><a class="reference internal" href="#information-criterion">3.2.5.2. Criterio de Información</a></li>
<li><a class="reference internal" href="#out-of-bag-estimates">3.2.5.3. Estimaciones Fuera de la Bolsa (Out of Bag)</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            </div>
      </div>
    </div>
    <div id="sk-page-content-wrapper">
      <div class="sk-page-content container-fluid body px-md-3" role="main">
        
  <section id="tuning-the-hyper-parameters-of-an-estimator">
<span id="grid-search"></span><h1><span class="section-number">3.2. </span>Ajustar los hiperparámetros de un estimador<a class="headerlink" href="#tuning-the-hyper-parameters-of-an-estimator" title="Enlazar permanentemente con este título">¶</a></h1>
<p>Los hiperparámetros son parámetros que no se aprenden directamente dentro de los estimadores. En scikit-learn se pasan como argumentos al constructor de las clases de estimadores. Los ejemplos típicos incluyen <code class="docutils literal notranslate"><span class="pre">C</span></code>, <code class="docutils literal notranslate"><span class="pre">kernel</span></code> y <code class="docutils literal notranslate"><span class="pre">gamma</span></code> para el Clasificador de Vectores de Soporte, <code class="docutils literal notranslate"><span class="pre">alpha</span></code> para Lasso, etc.</p>
<p>Es posible y recomendable buscar en el espacio de hiperparámetros la mejor puntuación de <a class="reference internal" href="cross_validation.html#cross-validation"><span class="std std-ref">validación cruzada</span></a>.</p>
<p>Cualquier parámetro proporcionado al construir un estimador puede ser optimizado de esta manera. Específicamente, para encontrar los nombres y valores actuales de todos los parámetros de un estimador determinado, utiliza:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">estimator</span><span class="o">.</span><span class="n">get_params</span><span class="p">()</span>
</pre></div>
</div>
<p>Una búsqueda consiste en:</p>
<ul class="simple">
<li><p>un estimador (regresor o clasificador como <code class="docutils literal notranslate"><span class="pre">sklearn.svm.SVC()</span></code>);</p></li>
<li><p>un espacio de parámetros;</p></li>
<li><p>un método de búsqueda o muestreo de candidatos;</p></li>
<li><p>un esquema de validación cruzada; y</p></li>
<li><p>una <a class="reference internal" href="#gridsearch-scoring"><span class="std std-ref">función de puntuación</span></a>.</p></li>
</ul>
<p>En scikit-learn se proporcionan dos enfoques genéricos para la búsqueda de parámetros: para valores dados, <a class="reference internal" href="generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV" title="sklearn.model_selection.GridSearchCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">GridSearchCV</span></code></a> considera exhaustivamente todas las combinaciones de parámetros, mientras que <a class="reference internal" href="generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV" title="sklearn.model_selection.RandomizedSearchCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">RandomizedSearchCV</span></code></a> puede muestrear un número determinado de candidatos de un espacio de parámetros con una distribución especificada. Ambas herramientas tienen sus homólogos sucesivos <a class="reference internal" href="generated/sklearn.model_selection.HalvingGridSearchCV.html#sklearn.model_selection.HalvingGridSearchCV" title="sklearn.model_selection.HalvingGridSearchCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">HalvingGridSearchCV</span></code></a> y <a class="reference internal" href="generated/sklearn.model_selection.HalvingRandomSearchCV.html#sklearn.model_selection.HalvingRandomSearchCV" title="sklearn.model_selection.HalvingRandomSearchCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">HalvingRandomSearchCV</span></code></a>, que pueden ser mucho más rápidos a la hora de encontrar una buena combinación de parámetros.</p>
<p>Después de describir estas herramientas, detallamos las <a class="reference internal" href="#grid-search-tips"><span class="std std-ref">mejores prácticas</span></a> aplicables a estos enfoques. Algunos modelos permiten estrategias de búsqueda de parámetros especializadas y eficientes, descritas en <a class="reference internal" href="#alternative-cv"><span class="std std-ref">Alternativas a la búsqueda de parámetros por fuerza bruta</span></a>.</p>
<p>Ten en cuenta que es habitual que un pequeño subconjunto de esos parámetros pueda tener un gran impacto en el rendimiento predictivo o de cálculo del modelo, mientras que otros pueden dejarse con sus valores por defecto. Se recomienda leer la cadena de documentación de la clase del estimador para obtener una comprensión más fina de su comportamiento esperado, posiblemente leyendo la referencia adjunta a la literatura.</p>
<section id="exhaustive-grid-search">
<h2><span class="section-number">3.2.1. </span>Búsqueda exhaustiva en Cuadrícula<a class="headerlink" href="#exhaustive-grid-search" title="Enlazar permanentemente con este título">¶</a></h2>
<p>La búsqueda en cuadrícula proporcionada por <a class="reference internal" href="generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV" title="sklearn.model_selection.GridSearchCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">GridSearchCV</span></code></a> genera exhaustivamente candidatos a partir de una cuadrícula de valores de parámetros especificados con el parámetro <code class="docutils literal notranslate"><span class="pre">param_grid</span></code>. Por ejemplo, la siguiente <code class="docutils literal notranslate"><span class="pre">param_grid</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">param_grid</span> <span class="o">=</span> <span class="p">[</span>
  <span class="p">{</span><span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">1000</span><span class="p">],</span> <span class="s1">&#39;kernel&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;linear&#39;</span><span class="p">]},</span>
  <span class="p">{</span><span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">1000</span><span class="p">],</span> <span class="s1">&#39;gamma&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mf">0.001</span><span class="p">,</span> <span class="mf">0.0001</span><span class="p">],</span> <span class="s1">&#39;kernel&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;rbf&#39;</span><span class="p">]},</span>
 <span class="p">]</span>
</pre></div>
</div>
<p>especifica que se deben explorar dos cuadrículas: una con un kernel lineal y valores de C en [1, 10, 100, 1000], y la segunda con un kernel RBF, y el producto cruzado de valores de C en [1, 10, 100, 1000] y valores de gamma en [0.001, 0.0001].</p>
<p>La instancia <a class="reference internal" href="generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV" title="sklearn.model_selection.GridSearchCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">GridSearchCV</span></code></a> implementa la API de estimadores habitual: al «ajustarla» a un conjunto de datos se evalúan todas las combinaciones posibles de valores de los parámetros y se retiene la mejor combinación.</p>
<div class="topic">
<p class="topic-title">Ejemplos:</p>
<ul class="simple">
<li><p>Consulta <a class="reference internal" href="../auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py"><span class="std std-ref">Estimación de parámetros utilizando la búsqueda en cuadrícula con validación cruzada</span></a> para ver un ejemplo de cálculo de Búsqueda en Cuadrícula en el conjunto de datos de dígitos.</p></li>
<li><p>Consulta <a class="reference internal" href="../auto_examples/model_selection/grid_search_text_feature_extraction.html#sphx-glr-auto-examples-model-selection-grid-search-text-feature-extraction-py"><span class="std std-ref">Ejemplo de pipeline para la extracción y evaluación de características de texto</span></a> para ver un ejemplo de cómo Grid Search (búsqueda en cuadrícula) acopla los parámetros de un extractor de características de documentos de texto (vectorizador de recuento de n-gramas y transformador TF-IDF) con un clasificador (en este caso un SVM lineal entrenado con SGD con red elástica o penalización L2) utilizando una instancia <code class="xref py py-class docutils literal notranslate"><span class="pre">pipeline.Pipeline</span></code>.</p></li>
<li><p>Consulta <a class="reference internal" href="../auto_examples/model_selection/plot_nested_cross_validation_iris.html#sphx-glr-auto-examples-model-selection-plot-nested-cross-validation-iris-py"><span class="std std-ref">Validación cruzada anidada y no anidada</span></a> para ver un ejemplo de Grid Search (búsqueda en cuadrícula) dentro de un bucle de validación cruzada en el conjunto de datos iris. Esta es la mejor práctica para evaluar el rendimiento de un modelo con búsqueda en cuadrícula.</p></li>
<li><p>Consulta <a class="reference internal" href="../auto_examples/model_selection/plot_multi_metric_evaluation.html#sphx-glr-auto-examples-model-selection-plot-multi-metric-evaluation-py"><span class="std std-ref">Demostración de la evaluación multimétrica en cross_val_score y GridSearchCV</span></a> para ver un ejemplo de <a class="reference internal" href="generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV" title="sklearn.model_selection.GridSearchCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">GridSearchCV</span></code></a> utilizado para evaluar múltiples métricas simultáneamente.</p></li>
<li><p>Consulta <a class="reference internal" href="../auto_examples/model_selection/plot_grid_search_refit_callable.html#sphx-glr-auto-examples-model-selection-plot-grid-search-refit-callable-py"><span class="std std-ref">Balancear la complejidad del modelo y la puntuación de validación cruzada</span></a> para ver un ejemplo de uso de la interfaz <code class="docutils literal notranslate"><span class="pre">refit=callable</span></code> en <a class="reference internal" href="generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV" title="sklearn.model_selection.GridSearchCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">GridSearchCV</span></code></a>. El ejemplo muestra cómo esta interfaz añade cierta flexibilidad a la hora de identificar el «mejor» estimador. Esta interfaz también puede utilizarse en la evaluación de múltiples métricas.</p></li>
<li><p>Consulta <a class="reference internal" href="../auto_examples/model_selection/plot_grid_search_stats.html#sphx-glr-auto-examples-model-selection-plot-grid-search-stats-py"><span class="std std-ref">Comparación estadística de modelos utilizando la búsqueda en cuadrícula</span></a> para ver un ejemplo de cómo hacer una comparación estadística de las salidas de <a class="reference internal" href="generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV" title="sklearn.model_selection.GridSearchCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">GridSearchCV</span></code></a>.</p></li>
</ul>
</div>
</section>
<section id="randomized-parameter-optimization">
<span id="randomized-parameter-search"></span><h2><span class="section-number">3.2.2. </span>Optimización Aleatoria de Parámetros<a class="headerlink" href="#randomized-parameter-optimization" title="Enlazar permanentemente con este título">¶</a></h2>
<p>Aunque el uso de una cuadrícula de ajustes de parámetros es el método más utilizado actualmente para la optimización de parámetros, otros métodos de búsqueda tienen propiedades más favorables. <a class="reference internal" href="generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV" title="sklearn.model_selection.RandomizedSearchCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">RandomizedSearchCV</span></code></a> implementa una búsqueda aleatoria sobre los parámetros, donde cada ajuste se muestrea a partir de una distribución sobre los posibles valores de los parámetros. Esto tiene dos ventajas principales sobre una búsqueda exhaustiva:</p>
<ul class="simple">
<li><p>Se puede elegir un presupuesto independientemente del número de parámetros y de los valores posibles.</p></li>
<li><p>Añadir parámetros que no influyen en el rendimiento no disminuye la eficiencia.</p></li>
</ul>
<p>La especificación de cómo se deben muestrear los parámetros se realiza mediante un diccionario, de forma muy similar a la especificación de parámetros para <a class="reference internal" href="generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV" title="sklearn.model_selection.GridSearchCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">GridSearchCV</span></code></a>. Además, se especifica un presupuesto de cálculo, que es el número de candidatos muestreados o iteraciones de muestreo, utilizando el parámetro <code class="docutils literal notranslate"><span class="pre">n_iter</span></code>. Para cada parámetro, se puede especificar una distribución sobre posibles valores o una lista de opciones discretas (que se muestrearán uniformemente):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">expon</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="mi">100</span><span class="p">),</span> <span class="s1">&#39;gamma&#39;</span><span class="p">:</span> <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">expon</span><span class="p">(</span><span class="n">scale</span><span class="o">=</span><span class="mf">.1</span><span class="p">),</span>
  <span class="s1">&#39;kernel&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;rbf&#39;</span><span class="p">],</span> <span class="s1">&#39;class_weight&#39;</span><span class="p">:[</span><span class="s1">&#39;balanced&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">]}</span>
</pre></div>
</div>
<p>Este ejemplo utiliza el módulo <code class="docutils literal notranslate"><span class="pre">scipy.stats</span></code>, que contiene muchas distribuciones útiles para el muestreo de parámetros, como <code class="docutils literal notranslate"><span class="pre">expon</span></code>, <code class="docutils literal notranslate"><span class="pre">gamma</span></code>, <code class="docutils literal notranslate"><span class="pre">uniform</span></code> o <code class="docutils literal notranslate"><span class="pre">randint</span></code>.</p>
<p>En principio, se puede pasar cualquier función que proporcione un método <code class="docutils literal notranslate"><span class="pre">rvs</span></code> (muestra de variante aleatoria) para muestrear un valor. Una llamada a la función <code class="docutils literal notranslate"><span class="pre">rvs</span></code> debe proporcionar muestras aleatorias independientes de los posibles valores de los parámetros en llamadas consecutivas.</p>
<blockquote>
<div><div class="admonition warning">
<p class="admonition-title">Advertencia</p>
<p>Las distribuciones en <code class="docutils literal notranslate"><span class="pre">scipy.stats</span></code> anteriores a la versión scipy 0.16 no permiten especificar un estado aleatorio. En su lugar, utilizan el estado aleatorio global de numpy, que puede ser sembrado a través de <code class="docutils literal notranslate"><span class="pre">np.random.seed</span></code> o establecido utilizando <code class="docutils literal notranslate"><span class="pre">np.random.set_state</span></code>. Sin embargo, a partir de scikit-learn 0.18, el módulo <a class="reference internal" href="classes.html#module-sklearn.model_selection" title="sklearn.model_selection"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.model_selection</span></code></a> establece el estado aleatorio proporcionado por el usuario si scipy &gt;= 0.16 también está disponible.</p>
</div>
</div></blockquote>
<p>Para los parámetros continuos, como <code class="docutils literal notranslate"><span class="pre">C</span></code> arriba, es importante especificar una distribución continua para aprovechar al máximo la aleatorización. De esta manera, el aumento de <code class="docutils literal notranslate"><span class="pre">n_iter</span></code> siempre conducirá a una búsqueda más fina.</p>
<p>Una variable aleatoria continua log-uniforme está disponible a través de <code class="xref py py-class docutils literal notranslate"><span class="pre">loguniform</span></code>. Esta es una versión continua de los parámetros log-espaciados. Por ejemplo, para especificar <code class="docutils literal notranslate"><span class="pre">C</span></code> arriba, se puede usar <code class="docutils literal notranslate"><span class="pre">loguniform(1,</span> <span class="pre">100)</span></code> en lugar de <code class="docutils literal notranslate"><span class="pre">[1,</span> <span class="pre">10,</span> <span class="pre">100]</span></code> o <code class="docutils literal notranslate"><span class="pre">np.logspace(0,</span> <span class="pre">2,</span> <span class="pre">num=1000)</span></code>. Este es un alias de <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.reciprocal.html">stats.reciprocal</a> de SciPy.</p>
<p>Reflejando el ejemplo anterior en la búsqueda en cuadrícula, podemos especificar una variable aleatoria continua que se distribuye log-uniformemente entre <code class="docutils literal notranslate"><span class="pre">1e0</span></code> y <code class="docutils literal notranslate"><span class="pre">1e3</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.utils.fixes</span> <span class="kn">import</span> <span class="n">loguniform</span>
<span class="p">{</span><span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="n">loguniform</span><span class="p">(</span><span class="mf">1e0</span><span class="p">,</span> <span class="mf">1e3</span><span class="p">),</span>
 <span class="s1">&#39;gamma&#39;</span><span class="p">:</span> <span class="n">loguniform</span><span class="p">(</span><span class="mf">1e-4</span><span class="p">,</span> <span class="mf">1e-3</span><span class="p">),</span>
 <span class="s1">&#39;kernel&#39;</span><span class="p">:</span> <span class="p">[</span><span class="s1">&#39;rbf&#39;</span><span class="p">],</span>
 <span class="s1">&#39;class_weight&#39;</span><span class="p">:[</span><span class="s1">&#39;balanced&#39;</span><span class="p">,</span> <span class="kc">None</span><span class="p">]}</span>
</pre></div>
</div>
<div class="topic">
<p class="topic-title">Ejemplos:</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/model_selection/plot_randomized_search.html#sphx-glr-auto-examples-model-selection-plot-randomized-search-py"><span class="std std-ref">Comparando la búsqueda aleatorizada y la búsqueda en cuadrícula para la estimación de hiperparámetros</span></a> compara el uso y la eficiencia de la búsqueda aleatoria y la búsqueda en cuadrícula.</p></li>
</ul>
</div>
<div class="topic">
<p class="topic-title">Referencias:</p>
<ul class="simple">
<li><p>Bergstra, J. y Bengio, Y., Random search for hyper-parameter optimization, The Journal of Machine Learning Research (2012)</p></li>
</ul>
</div>
</section>
<section id="searching-for-optimal-parameters-with-successive-halving">
<span id="successive-halving-user-guide"></span><h2><span class="section-number">3.2.3. </span>Búsqueda de los parámetros óptimos con la reducción sucesiva a la mitad<a class="headerlink" href="#searching-for-optimal-parameters-with-successive-halving" title="Enlazar permanentemente con este título">¶</a></h2>
<p>Scikit-learn también proporciona los estimadores <a class="reference internal" href="generated/sklearn.model_selection.HalvingGridSearchCV.html#sklearn.model_selection.HalvingGridSearchCV" title="sklearn.model_selection.HalvingGridSearchCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">HalvingGridSearchCV</span></code></a> y <a class="reference internal" href="generated/sklearn.model_selection.HalvingRandomSearchCV.html#sklearn.model_selection.HalvingRandomSearchCV" title="sklearn.model_selection.HalvingRandomSearchCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">HalvingRandomSearchCV</span></code></a> que se pueden utilizar para buscar un espacio de parámetros utilizando la reducción sucesiva a la mitad <a class="footnote-reference brackets" href="#id3" id="id1">1</a> <a class="footnote-reference brackets" href="#id4" id="id2">2</a>. La reducción sucesiva a la mitad (successive halving, SH) es como un torneo entre combinaciones de parámetros candidatos. SH es un proceso de selección iterativo en el que todos los candidatos (las combinaciones de parámetros) se evalúan con una pequeña cantidad de recursos en la primera iteración. Sólo algunos de estos candidatos se seleccionan para la siguiente iteración, a la que se asignan más recursos. Para el ajuste de parámetros, el recurso suele ser el número de muestras de entrenamiento, pero también puede ser un parámetro numérico arbitrario como <code class="docutils literal notranslate"><span class="pre">n_estimators</span></code> en un bosque aleatorio.</p>
<p>Como se ilustra en la siguiente figura, sólo un subconjunto de candidatos “sobrevive” hasta la última iteración. Se trata de los candidatos que se han clasificado sistemáticamente entre los candidatos con mayor puntuación en todas las iteraciones. A cada iteración se le asigna una cantidad creciente de recursos por candidato, en este caso el número de muestras.</p>
<figure class="align-center">
<a class="reference external image-reference" href="../auto_examples/model_selection/plot_successive_halving_iterations.html"><img alt="../_images/sphx_glr_plot_successive_halving_iterations_001.png" src="../_images/sphx_glr_plot_successive_halving_iterations_001.png" /></a>
</figure>
<p>Aquí describimos brevemente los parámetros principales, pero cada parámetro y sus interacciones se describen con más detalle en las siguientes secciones. El parámetro <code class="docutils literal notranslate"><span class="pre">factor</span></code> (&gt; 1) controla la tasa de crecimiento de los recursos y la tasa de disminución del número de candidatos. En cada iteración, el número de recursos por candidato se multiplica por <code class="docutils literal notranslate"><span class="pre">factor</span></code> y el número de candidatos se divide por el mismo factor. Junto con <code class="docutils literal notranslate"><span class="pre">resource</span></code> y <code class="docutils literal notranslate"><span class="pre">min_resources</span></code>, <code class="docutils literal notranslate"><span class="pre">factor</span></code> es el parámetro más importante para controlar la búsqueda en nuestra implementación, aunque un valor de 3 suele funcionar bien. <code class="docutils literal notranslate"><span class="pre">factor</span></code> controla efectivamente el número de iteraciones en <a class="reference internal" href="generated/sklearn.model_selection.HalvingGridSearchCV.html#sklearn.model_selection.HalvingGridSearchCV" title="sklearn.model_selection.HalvingGridSearchCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">HalvingGridSearchCV</span></code></a> y el número de candidatos (por defecto) e iteraciones en <a class="reference internal" href="generated/sklearn.model_selection.HalvingRandomSearchCV.html#sklearn.model_selection.HalvingRandomSearchCV" title="sklearn.model_selection.HalvingRandomSearchCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">HalvingRandomSearchCV</span></code></a>. También se puede utilizar <code class="docutils literal notranslate"><span class="pre">aggressive_elimination=True</span></code> si el número de recursos disponibles es pequeño. Hay más control disponible mediante el ajuste del parámetro <code class="docutils literal notranslate"><span class="pre">min_resources</span></code>.</p>
<p>Estos estimadores son todavía <strong>experimentales</strong>: sus predicciones y su API podrían cambiar sin ningún ciclo de obsolescencia. Para utilizarlos, es necesario importar explícitamente <code class="docutils literal notranslate"><span class="pre">enable_halving_search_cv</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="c1"># explicitly require this experimental feature</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.experimental</span> <span class="kn">import</span> <span class="n">enable_halving_search_cv</span>  <span class="c1"># noqa</span>
<span class="gp">&gt;&gt;&gt; </span><span class="c1"># now you can import normally from model_selection</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">HalvingGridSearchCV</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">HalvingRandomSearchCV</span>
</pre></div>
</div>
<div class="topic">
<p class="topic-title">Ejemplos:</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/model_selection/plot_successive_halving_heatmap.html#sphx-glr-auto-examples-model-selection-plot-successive-halving-heatmap-py"><span class="std std-ref">Comparación entre la búsqueda en cuadrícula y la reducción sucesiva a la mitad</span></a></p></li>
<li><p><a class="reference internal" href="../auto_examples/model_selection/plot_successive_halving_iterations.html#sphx-glr-auto-examples-model-selection-plot-successive-halving-iterations-py"><span class="std std-ref">Iteraciones sucesivas a la mitad</span></a></p></li>
</ul>
</div>
<section id="choosing-min-resources-and-the-number-of-candidates">
<h3><span class="section-number">3.2.3.1. </span>Elegir <code class="docutils literal notranslate"><span class="pre">min_resources</span></code> y el número de candidatos<a class="headerlink" href="#choosing-min-resources-and-the-number-of-candidates" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Además de <code class="docutils literal notranslate"><span class="pre">factor</span></code>, los dos parámetros principales que influyen en el comportamiento de una búsqueda sucesiva a la mitad son el parámetro <code class="docutils literal notranslate"><span class="pre">min_resources</span></code> y el número de candidatos (o combinaciones de parámetros) que se evalúan. <code class="docutils literal notranslate"><span class="pre">min_resources</span></code> es la cantidad de recursos asignados en la primera iteración para cada candidato. El número de candidatos se especifica directamente en <a class="reference internal" href="generated/sklearn.model_selection.HalvingRandomSearchCV.html#sklearn.model_selection.HalvingRandomSearchCV" title="sklearn.model_selection.HalvingRandomSearchCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">HalvingRandomSearchCV</span></code></a>, y se determina a partir del parámetro <code class="docutils literal notranslate"><span class="pre">param_grid</span></code> de <a class="reference internal" href="generated/sklearn.model_selection.HalvingGridSearchCV.html#sklearn.model_selection.HalvingGridSearchCV" title="sklearn.model_selection.HalvingGridSearchCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">HalvingGridSearchCV</span></code></a>.</p>
<p>Consideremos un caso en el que el recurso es el número de muestras, y en el que tenemos 1000 muestras. En teoría, con <code class="docutils literal notranslate"><span class="pre">min_resources=10</span></code> y <code class="docutils literal notranslate"><span class="pre">factor=2</span></code>, podemos ejecutar <strong>como máximo</strong> 7 iteraciones con el siguiente número de muestras: <code class="docutils literal notranslate"><span class="pre">[10,</span> <span class="pre">20,</span> <span class="pre">40,</span> <span class="pre">80,</span> <span class="pre">160,</span> <span class="pre">320,</span> <span class="pre">640]</span></code>.</p>
<p>Pero dependiendo del número de candidatos, podríamos realizar menos de 7 iteraciones: si empezamos con un <strong>pequeño</strong> número de candidatos, la última iteración podría utilizar menos de 640 muestras, lo que significa no utilizar todos los recursos disponibles (muestras). Por ejemplo, si empezamos con 5 candidatos, sólo necesitaremos 2 iteraciones: 5 candidatos para la primera iteración, y luego <code class="docutils literal notranslate"><span class="pre">5</span> <span class="pre">//</span> <span class="pre">2</span> <span class="pre">=</span> <span class="pre">2</span></code> candidatos en la segunda iteración, después de la que sabremos cuál es el mejor candidato (por lo que no necesitamos una tercera). Sólo estaríamos utilizando como máximo 20 muestras, lo cual es un desperdicio ya que tenemos 1000 muestras a nuestra disposición. Por otro lado, si empezamos con un <strong>número elevado</strong> de candidatos, podríamos acabar con muchos candidatos en la última iteración, lo que no siempre es ideal: significa que muchos candidatos correrán con todos los recursos, reduciendo básicamente el procedimiento a una búsqueda estándar.</p>
<p>En el caso de <a class="reference internal" href="generated/sklearn.model_selection.HalvingRandomSearchCV.html#sklearn.model_selection.HalvingRandomSearchCV" title="sklearn.model_selection.HalvingRandomSearchCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">HalvingRandomSearchCV</span></code></a>, el número de candidatos se establece por defecto de forma que la última iteración utilice la mayor cantidad posible de recursos disponibles. Para <a class="reference internal" href="generated/sklearn.model_selection.HalvingGridSearchCV.html#sklearn.model_selection.HalvingGridSearchCV" title="sklearn.model_selection.HalvingGridSearchCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">HalvingGridSearchCV</span></code></a>, el número de candidatos viene determinado por el parámetro <code class="docutils literal notranslate"><span class="pre">param_grid</span></code>. Cambiar el valor de <code class="docutils literal notranslate"><span class="pre">min_resources</span></code> afectará al número de iteraciones posibles, y como resultado también tendrá un efecto en el número ideal de candidatos.</p>
<p>Otra consideración a la hora de elegir <code class="docutils literal notranslate"><span class="pre">min_resources</span></code> es si es fácil o no discriminar entre candidatos buenos y malos con una pequeña cantidad de recursos. Por ejemplo, si necesitas muchas muestras para distinguir entre parámetros buenos y malos, se recomienda un <code class="docutils literal notranslate"><span class="pre">min_resources</span></code> alto. Por otro lado, si la distinción es clara incluso con una pequeña cantidad de muestras, entonces puede ser preferible un <code class="docutils literal notranslate"><span class="pre">min_resources</span></code> pequeño, ya que aceleraría el cálculo.</p>
<p>Observa en el ejemplo anterior que la última iteración no utiliza el máximo de recursos disponibles: Hay 1000 muestras disponibles, pero sólo se utilizan 640, como máximo. Por defecto, tanto <a class="reference internal" href="generated/sklearn.model_selection.HalvingRandomSearchCV.html#sklearn.model_selection.HalvingRandomSearchCV" title="sklearn.model_selection.HalvingRandomSearchCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">HalvingRandomSearchCV</span></code></a> como <a class="reference internal" href="generated/sklearn.model_selection.HalvingGridSearchCV.html#sklearn.model_selection.HalvingGridSearchCV" title="sklearn.model_selection.HalvingGridSearchCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">HalvingGridSearchCV</span></code></a> intentan utilizar la mayor cantidad de recursos posible en la última iteración, con la restricción de que esta cantidad de recursos debe ser un múltiplo tanto de <code class="docutils literal notranslate"><span class="pre">min_resources</span></code> como de <code class="docutils literal notranslate"><span class="pre">factor</span></code> (esta restricción quedará clara en la siguiente sección). <a class="reference internal" href="generated/sklearn.model_selection.HalvingRandomSearchCV.html#sklearn.model_selection.HalvingRandomSearchCV" title="sklearn.model_selection.HalvingRandomSearchCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">HalvingRandomSearchCV</span></code></a> logra esto mediante el muestreo de la cantidad correcta de candidatos, mientras que <a class="reference internal" href="generated/sklearn.model_selection.HalvingGridSearchCV.html#sklearn.model_selection.HalvingGridSearchCV" title="sklearn.model_selection.HalvingGridSearchCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">HalvingGridSearchCV</span></code></a> lo logra estableciendo adecuadamente <code class="docutils literal notranslate"><span class="pre">min_resources</span></code>. Por favor, consulta <a class="reference internal" href="#exhausting-the-resources"><span class="std std-ref">Agotar los recursos disponibles</span></a> para más detalles.</p>
</section>
<section id="amount-of-resource-and-number-of-candidates-at-each-iteration">
<span id="amount-of-resource-and-number-of-candidates"></span><h3><span class="section-number">3.2.3.2. </span>Cantidad de recursos y número de candidatos en cada iteración<a class="headerlink" href="#amount-of-resource-and-number-of-candidates-at-each-iteration" title="Enlazar permanentemente con este título">¶</a></h3>
<p>En cualquier iteración <code class="docutils literal notranslate"><span class="pre">i</span></code>, a cada candidato se le asigna una cantidad determinada de recursos que denotamos <code class="docutils literal notranslate"><span class="pre">n_resources_i</span></code>. Esta cantidad está controlada por los parámetros <code class="docutils literal notranslate"><span class="pre">factor</span></code> y <code class="docutils literal notranslate"><span class="pre">min_resources</span></code> como sigue (<code class="docutils literal notranslate"><span class="pre">factor</span></code> es estrictamente mayor que 1):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">n_resources_i</span> <span class="o">=</span> <span class="n">factor</span><span class="o">**</span><span class="n">i</span> <span class="o">*</span> <span class="n">min_resources</span><span class="p">,</span>
</pre></div>
</div>
<p>o, de forma equivalente:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">n_resources_</span><span class="p">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">}</span> <span class="o">=</span> <span class="n">n_resources_i</span> <span class="o">*</span> <span class="n">factor</span>
</pre></div>
</div>
<p>donde <code class="docutils literal notranslate"><span class="pre">min_resources</span> <span class="pre">==</span> <span class="pre">n_resources_0</span></code> es la cantidad de recursos utilizados en la primera iteración. <code class="docutils literal notranslate"><span class="pre">factor</span></code> también define las proporciones de candidatos que se seleccionarán para la siguiente iteración:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">n_candidates_i</span> <span class="o">=</span> <span class="n">n_candidates</span> <span class="o">//</span> <span class="p">(</span><span class="n">factor</span> <span class="o">**</span> <span class="n">i</span><span class="p">)</span>
</pre></div>
</div>
<p>o, de forma equivalente:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">n_candidates_0</span> <span class="o">=</span> <span class="n">n_candidates</span>
<span class="n">n_candidates_</span><span class="p">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">}</span> <span class="o">=</span> <span class="n">n_candidates_i</span> <span class="o">//</span> <span class="n">factor</span>
</pre></div>
</div>
<p>Así que en la primera iteración, utilizamos <code class="docutils literal notranslate"><span class="pre">min_resources</span></code> recursos <code class="docutils literal notranslate"><span class="pre">n_candidates</span></code> veces. En la segunda iteración, utilizamos <code class="docutils literal notranslate"><span class="pre">min_resources</span> <span class="pre">*</span> <span class="pre">factor</span></code> recursos <code class="docutils literal notranslate"><span class="pre">n_candidates</span> <span class="pre">//</span> <span class="pre">factor</span></code> veces. La tercera vuelve a multiplicar los recursos por candidato y divide el número de candidatos. Este proceso se detiene cuando se alcanza la cantidad máxima de recursos por candidato, o cuando hemos identificado al mejor candidato. El mejor candidato se identifica en la iteración que está evaluando <code class="docutils literal notranslate"><span class="pre">factor</span></code> o menos candidatos (ver justo debajo para una explicación).</p>
<p>Aquí hay un ejemplo con <code class="docutils literal notranslate"><span class="pre">min_resources=3</span></code> y <code class="docutils literal notranslate"><span class="pre">factor=2</span></code>, empezando con 70 candidatos:</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 50%" />
<col style="width: 50%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p><code class="docutils literal notranslate"><span class="pre">n_resources_i</span></code></p></th>
<th class="head"><p><code class="docutils literal notranslate"><span class="pre">n_candidates_i</span></code></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>3 (=min_resources)</p></td>
<td><p>70 (=n_candidates)</p></td>
</tr>
<tr class="row-odd"><td><p>3 * 2 = 6</p></td>
<td><p>70 // 2 = 35</p></td>
</tr>
<tr class="row-even"><td><p>6 * 2 = 12</p></td>
<td><p>35 // 2 = 17</p></td>
</tr>
<tr class="row-odd"><td><p>12 * 2 = 24</p></td>
<td><p>17 // 2 = 8</p></td>
</tr>
<tr class="row-even"><td><p>24 * 2 = 48</p></td>
<td><p>8 // 2 = 4</p></td>
</tr>
<tr class="row-odd"><td><p>48 * 2 = 96</p></td>
<td><p>4 // 2 = 2</p></td>
</tr>
</tbody>
</table>
<p>Podemos notar que:</p>
<ul class="simple">
<li><p>el proceso se detiene en la primera iteración que evalúa <code class="docutils literal notranslate"><span class="pre">factor=2</span></code> candidatos: el mejor candidato es el mejor de estos 2 candidatos. No es necesario ejecutar una iteración adicional, ya que sólo evaluaría un candidato (el mejor, que ya hemos identificado). Por esta razón, en general, queremos que la última iteración ejecute como máximo <code class="docutils literal notranslate"><span class="pre">factor</span></code> candidatos. Si la última iteración evalúa más de <code class="docutils literal notranslate"><span class="pre">factor</span></code> candidatos, entonces esta última iteración se reduce a una búsqueda regular (como en <a class="reference internal" href="generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV" title="sklearn.model_selection.RandomizedSearchCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">RandomizedSearchCV</span></code></a> o <a class="reference internal" href="generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV" title="sklearn.model_selection.GridSearchCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">GridSearchCV</span></code></a>).</p></li>
<li><p>cada <code class="docutils literal notranslate"><span class="pre">n_resources_i</span></code> es un múltiplo tanto de <code class="docutils literal notranslate"><span class="pre">factor</span></code> como de <code class="docutils literal notranslate"><span class="pre">min_resources</span></code> (lo cual se confirma por su definición anterior).</p></li>
</ul>
<p>La cantidad de recursos que se utilizan en cada iteración se puede encontrar en el atributo <code class="docutils literal notranslate"><span class="pre">n_resources_</span></code>.</p>
</section>
<section id="choosing-a-resource">
<h3><span class="section-number">3.2.3.3. </span>Elegir un recurso<a class="headerlink" href="#choosing-a-resource" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Por defecto, el recurso se define en términos del número de muestras. Es decir, cada iteración utilizará una cantidad creciente de muestras para entrenar. Sin embargo, puedes especificar manualmente un parámetro para utilizarlo como recurso con el parámetro <code class="docutils literal notranslate"><span class="pre">resource</span></code>. Aquí hay un ejemplo donde el recurso se define en términos del número de estimadores de un bosque aleatorio:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_classification</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.experimental</span> <span class="kn">import</span> <span class="n">enable_halving_search_cv</span>  <span class="c1"># noqa</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">HalvingGridSearchCV</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;max_depth&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span>
<span class="gp">... </span>              <span class="s1">&#39;min_samples_split&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">]}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">base_estimator</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_classification</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sh</span> <span class="o">=</span> <span class="n">HalvingGridSearchCV</span><span class="p">(</span><span class="n">base_estimator</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
<span class="gp">... </span>                         <span class="n">factor</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">resource</span><span class="o">=</span><span class="s1">&#39;n_estimators&#39;</span><span class="p">,</span>
<span class="gp">... </span>                         <span class="n">max_resources</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sh</span><span class="o">.</span><span class="n">best_estimator_</span>
<span class="go">RandomForestClassifier(max_depth=5, n_estimators=24, random_state=0)</span>
</pre></div>
</div>
<p>Ten en cuenta que no es posible presupuestar en un parámetro que es parte de la cuadrícula del parámetro.</p>
</section>
<section id="exhausting-the-available-resources">
<span id="exhausting-the-resources"></span><h3><span class="section-number">3.2.3.4. </span>Agotar los recursos disponibles<a class="headerlink" href="#exhausting-the-available-resources" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Como se ha mencionado anteriormente, el número de recursos que se utiliza en cada iteración depende del parámetro <code class="docutils literal notranslate"><span class="pre">min_resources</span></code>. Si tienes muchos recursos disponibles pero empiezas con un número bajo de recursos, algunos de ellos podrían ser desperdiciados (es decir, no utilizados):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_classification</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.experimental</span> <span class="kn">import</span> <span class="n">enable_halving_search_cv</span>  <span class="c1"># noqa</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">HalvingGridSearchCV</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">param_grid</span><span class="o">=</span> <span class="p">{</span><span class="s1">&#39;kernel&#39;</span><span class="p">:</span> <span class="p">(</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="s1">&#39;rbf&#39;</span><span class="p">),</span>
<span class="gp">... </span>             <span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">]}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">base_estimator</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">gamma</span><span class="o">=</span><span class="s1">&#39;scale&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_classification</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sh</span> <span class="o">=</span> <span class="n">HalvingGridSearchCV</span><span class="p">(</span><span class="n">base_estimator</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
<span class="gp">... </span>                         <span class="n">factor</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">min_resources</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sh</span><span class="o">.</span><span class="n">n_resources_</span>
<span class="go">[20, 40, 80]</span>
</pre></div>
</div>
<p>El proceso de búsqueda sólo utilizará 80 recursos como máximo, mientras que nuestra cantidad máxima de recursos disponibles es <code class="docutils literal notranslate"><span class="pre">n_samples=1000</span></code>. Aquí, tenemos <code class="docutils literal notranslate"><span class="pre">min_resources</span> <span class="pre">=</span> <span class="pre">r_0</span> <span class="pre">=</span> <span class="pre">20</span></code>.</p>
<p>Para <a class="reference internal" href="generated/sklearn.model_selection.HalvingGridSearchCV.html#sklearn.model_selection.HalvingGridSearchCV" title="sklearn.model_selection.HalvingGridSearchCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">HalvingGridSearchCV</span></code></a>, por defecto, el parámetro <code class="docutils literal notranslate"><span class="pre">min_resources</span></code> se establece en “exhaust”. Esto significa que <code class="docutils literal notranslate"><span class="pre">min_resources</span></code> se establece automáticamente de forma que la última iteración pueda utilizar tantos recursos como sea posible, dentro del límite de <code class="docutils literal notranslate"><span class="pre">max_resources</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">sh</span> <span class="o">=</span> <span class="n">HalvingGridSearchCV</span><span class="p">(</span><span class="n">base_estimator</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
<span class="gp">... </span>                         <span class="n">factor</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">min_resources</span><span class="o">=</span><span class="s1">&#39;exhaust&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sh</span><span class="o">.</span><span class="n">n_resources_</span>
<span class="go">[250, 500, 1000]</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">min_resources</span></code> se estableció aquí automáticamente en 250, lo que hace que la última iteración utilice todos los recursos. El valor exacto que se utiliza depende del número de parámetros candidatos, en <code class="docutils literal notranslate"><span class="pre">max_resources</span></code> y en <code class="docutils literal notranslate"><span class="pre">factor</span></code>.</p>
<p>Para <a class="reference internal" href="generated/sklearn.model_selection.HalvingRandomSearchCV.html#sklearn.model_selection.HalvingRandomSearchCV" title="sklearn.model_selection.HalvingRandomSearchCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">HalvingRandomSearchCV</span></code></a>, el agotamiento de los recursos puede hacerse de dos maneras:</p>
<ul class="simple">
<li><p>estableciendo <code class="docutils literal notranslate"><span class="pre">min_resources='exhaust'</span></code>, al igual que para <a class="reference internal" href="generated/sklearn.model_selection.HalvingGridSearchCV.html#sklearn.model_selection.HalvingGridSearchCV" title="sklearn.model_selection.HalvingGridSearchCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">HalvingGridSearchCV</span></code></a>;</p></li>
<li><p>estableciendo <code class="docutils literal notranslate"><span class="pre">n_candidates='exhaust'</span></code>.</p></li>
</ul>
<p>Ambas opciones son mutuamente excluyentes: usar <code class="docutils literal notranslate"><span class="pre">min_resources='exhaust'</span></code> requiere conocer el número de candidatos, y simétricamente <code class="docutils literal notranslate"><span class="pre">n_candidates='exhaust'</span></code> requiere conocer <code class="docutils literal notranslate"><span class="pre">min_resources</span></code>.</p>
<p>En general, agotar el número total de recursos conduce a un mejor parámetro candidato final, y requiere ligeramente más tiempo.</p>
</section>
<section id="aggressive-elimination-of-candidates">
<span id="aggressive-elimination"></span><h3><span class="section-number">3.2.3.5. </span>Eliminación agresiva de candidatos<a class="headerlink" href="#aggressive-elimination-of-candidates" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Idealmente, queremos que la última iteración evalúe <code class="docutils literal notranslate"><span class="pre">factor</span></code> candidatos (ver <a class="reference internal" href="#amount-of-resource-and-number-of-candidates"><span class="std std-ref">Cantidad de recursos y número de candidatos en cada iteración</span></a>). Luego sólo tenemos que elegir el mejor. Cuando el número de recursos disponibles es pequeño respecto al número de candidatos, es posible que la última iteración tenga que evaluar más de <code class="docutils literal notranslate"><span class="pre">factor</span></code> candidatos:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_classification</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.experimental</span> <span class="kn">import</span> <span class="n">enable_halving_search_cv</span>  <span class="c1"># noqa</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">HalvingGridSearchCV</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="go">&gt;&gt;&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;kernel&#39;</span><span class="p">:</span> <span class="p">(</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="s1">&#39;rbf&#39;</span><span class="p">),</span>
<span class="gp">... </span>              <span class="s1">&#39;C&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">]}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">base_estimator</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">gamma</span><span class="o">=</span><span class="s1">&#39;scale&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_classification</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sh</span> <span class="o">=</span> <span class="n">HalvingGridSearchCV</span><span class="p">(</span><span class="n">base_estimator</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
<span class="gp">... </span>                         <span class="n">factor</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">max_resources</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span>
<span class="gp">... </span>                         <span class="n">aggressive_elimination</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sh</span><span class="o">.</span><span class="n">n_resources_</span>
<span class="go">[20, 40]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sh</span><span class="o">.</span><span class="n">n_candidates_</span>
<span class="go">[6, 3]</span>
</pre></div>
</div>
<p>Como no podemos utilizar más de <code class="docutils literal notranslate"><span class="pre">max_resources=40</span></code> recursos, el proceso tiene que detenerse en la segunda iteración que evalúa más de <code class="docutils literal notranslate"><span class="pre">factor=2</span></code> candidatos.</p>
<p>Usando el parámetro <code class="docutils literal notranslate"><span class="pre">aggressive_elimination</span></code>, puedes forzar el proceso de búsqueda para que termine con menos de <code class="docutils literal notranslate"><span class="pre">factor</span></code> candidatos en la última iteración. Para ello, el proceso eliminará tantos candidatos como sea necesario utilizando <code class="docutils literal notranslate"><span class="pre">min_resources</span></code> recursos:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">sh</span> <span class="o">=</span> <span class="n">HalvingGridSearchCV</span><span class="p">(</span><span class="n">base_estimator</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="n">factor</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="n">max_resources</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="n">aggressive_elimination</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="gp">... </span>                           <span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sh</span><span class="o">.</span><span class="n">n_resources_</span>
<span class="go">[20, 20,  40]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">sh</span><span class="o">.</span><span class="n">n_candidates_</span>
<span class="go">[6, 3, 2]</span>
</pre></div>
</div>
<p>Observa que terminamos con 2 candidatos en la última iteración ya que hemos eliminado suficientes candidatos durante las primeras iteraciones, utilizando <code class="docutils literal notranslate"><span class="pre">n_resources</span> <span class="pre">=</span> <span class="pre">min_resources</span> <span class="pre">=</span> <span class="pre">20</span></code>.</p>
</section>
<section id="analysing-results-with-the-cv-results-attribute">
<span id="successive-halving-cv-results"></span><h3><span class="section-number">3.2.3.6. </span>Analizar resultados con el atributo <code class="docutils literal notranslate"><span class="pre">cv_results_</span></code><a class="headerlink" href="#analysing-results-with-the-cv-results-attribute" title="Enlazar permanentemente con este título">¶</a></h3>
<p>El atributo <code class="docutils literal notranslate"><span class="pre">cv_results_</span></code> contiene información útil para analizar los resultados de una búsqueda. Se puede convertir en un dataframe de pandas con <code class="docutils literal notranslate"><span class="pre">df</span> <span class="pre">=</span> <span class="pre">pd.DataFrame(est.cv_results_)</span></code>. El atributo <code class="docutils literal notranslate"><span class="pre">cv_results_</span></code> de <a class="reference internal" href="generated/sklearn.model_selection.HalvingGridSearchCV.html#sklearn.model_selection.HalvingGridSearchCV" title="sklearn.model_selection.HalvingGridSearchCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">HalvingGridSearchCV</span></code></a> y <a class="reference internal" href="generated/sklearn.model_selection.HalvingRandomSearchCV.html#sklearn.model_selection.HalvingRandomSearchCV" title="sklearn.model_selection.HalvingRandomSearchCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">HalvingRandomSearchCV</span></code></a> es similar al de <a class="reference internal" href="generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV" title="sklearn.model_selection.GridSearchCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">GridSearchCV</span></code></a> y <a class="reference internal" href="generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV" title="sklearn.model_selection.RandomizedSearchCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">RandomizedSearchCV</span></code></a>, con información adicional relacionada con el proceso de reducción sucesiva a la mitad.</p>
<p>A continuación se muestra un ejemplo con algunas de las columnas de un dataframe (truncado):</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 3%" />
<col style="width: 5%" />
<col style="width: 12%" />
<col style="width: 13%" />
<col style="width: 67%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"></th>
<th class="head"><p>iter</p></th>
<th class="head"><p>n_resources</p></th>
<th class="head"><p>mean_test_score</p></th>
<th class="head"><p>params</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>0</p></td>
<td><p>0</p></td>
<td><p>125</p></td>
<td><p>0.983667</p></td>
<td><p>{“criterion”: “entropy”, “max_depth”: None, “max_features”: 9, “min_samples_split”: 5}</p></td>
</tr>
<tr class="row-odd"><td><p>1</p></td>
<td><p>0</p></td>
<td><p>125</p></td>
<td><p>0.983667</p></td>
<td><p>{“criterion”: “gini”, “max_depth”: None, “max_features”: 8, “min_samples_split”: 7}</p></td>
</tr>
<tr class="row-even"><td><p>2</p></td>
<td><p>0</p></td>
<td><p>125</p></td>
<td><p>0.983667</p></td>
<td><p>{“criterion”: “gini”, “max_depth”: None, “max_features”: 10, “min_samples_split”: 10}</p></td>
</tr>
<tr class="row-odd"><td><p>3</p></td>
<td><p>0</p></td>
<td><p>125</p></td>
<td><p>0.983667</p></td>
<td><p>{“criterion”: “entropy”, “max_depth”: None, “max_features”: 6, “min_samples_split”: 6}</p></td>
</tr>
<tr class="row-even"><td><p>…</p></td>
<td><p>…</p></td>
<td><p>…</p></td>
<td><p>…</p></td>
<td><p>…</p></td>
</tr>
<tr class="row-odd"><td><p>15</p></td>
<td><p>2</p></td>
<td><p>500</p></td>
<td><p>0.951958</p></td>
<td><p>{“criterion”: “entropy”, “max_depth”: None, “max_features”: 9, “min_samples_split”: 10}</p></td>
</tr>
<tr class="row-even"><td><p>16</p></td>
<td><p>2</p></td>
<td><p>500</p></td>
<td><p>0.947958</p></td>
<td><p>{“criterion”: “gini”, “max_depth”: None, “max_features”: 10, “min_samples_split”: 10}</p></td>
</tr>
<tr class="row-odd"><td><p>17</p></td>
<td><p>2</p></td>
<td><p>500</p></td>
<td><p>0.951958</p></td>
<td><p>{“criterion”: “gini”, “max_depth”: None, “max_features”: 10, “min_samples_split”: 4}</p></td>
</tr>
<tr class="row-even"><td><p>18</p></td>
<td><p>3</p></td>
<td><p>1000</p></td>
<td><p>0.961009</p></td>
<td><p>{“criterion”: “entropy”, “max_depth”: None, “max_features”: 9, “min_samples_split”: 10}</p></td>
</tr>
<tr class="row-odd"><td><p>19</p></td>
<td><p>3</p></td>
<td><p>1000</p></td>
<td><p>0.955989</p></td>
<td><p>{“criterion”: “gini”, “max_depth”: None, “max_features”: 10, “min_samples_split”: 4}</p></td>
</tr>
</tbody>
</table>
<p>Cada fila corresponde a una combinación de parámetros dada (un candidato) y a una iteración determinada. La iteración viene dada por la columna <code class="docutils literal notranslate"><span class="pre">iter</span></code>. La columna <code class="docutils literal notranslate"><span class="pre">n_resources</span></code> indica el número de recursos utilizados.</p>
<p>En el ejemplo anterior, la mejor combinación de parámetros es <code class="docutils literal notranslate"><span class="pre">{'criterion':</span> <span class="pre">'entropy',</span> <span class="pre">'max_depth':</span> <span class="pre">None,</span> <span class="pre">'max_features':</span> <span class="pre">9,</span> <span class="pre">'min_samples_split':</span> <span class="pre">10}</span></code> ya que ha alcanzado la última iteración (3) con la mayor puntuación: 0.96.</p>
<div class="topic">
<p class="topic-title">Referencias:</p>
<dl class="footnote brackets">
<dt class="label" id="id3"><span class="brackets"><a class="fn-backref" href="#id1">1</a></span></dt>
<dd><p>K. Jamieson, A. Talwalkar,
<a class="reference external" href="http://proceedings.mlr.press/v51/jamieson16.html">Non-stochastic Best Arm Identification and Hyperparameter
Optimization</a>, in
proc. of Machine Learning Research, 2016.</p>
</dd>
<dt class="label" id="id4"><span class="brackets"><a class="fn-backref" href="#id2">2</a></span></dt>
<dd><p>L. Li, K. Jamieson, G. DeSalvo, A. Rostamizadeh, A. Talwalkar,
<a class="reference external" href="https://arxiv.org/abs/1603.06560">Hyperband: A Novel Bandit-Based Approach to Hyperparameter Optimization</a>, in Machine Learning Research
18, 2018.</p>
</dd>
</dl>
</div>
</section>
</section>
<section id="tips-for-parameter-search">
<span id="grid-search-tips"></span><h2><span class="section-number">3.2.4. </span>Tips para la búsqueda de parámetros<a class="headerlink" href="#tips-for-parameter-search" title="Enlazar permanentemente con este título">¶</a></h2>
<section id="specifying-an-objective-metric">
<span id="gridsearch-scoring"></span><h3><span class="section-number">3.2.4.1. </span>Especificar una métrica objetiva<a class="headerlink" href="#specifying-an-objective-metric" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Por defecto, la búsqueda de parámetros utiliza la función <code class="docutils literal notranslate"><span class="pre">score</span></code> del estimador para evaluar una configuración de parámetros. Estas son <a class="reference internal" href="generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score" title="sklearn.metrics.accuracy_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.metrics.accuracy_score</span></code></a> para la clasificación y <a class="reference internal" href="generated/sklearn.metrics.r2_score.html#sklearn.metrics.r2_score" title="sklearn.metrics.r2_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.metrics.r2_score</span></code></a> para la regresión. Para algunas aplicaciones, otras funciones de puntuación son más adecuadas (por ejemplo, en la clasificación no balanceada, la puntuación de exactitud es a menudo poco informativa). Se puede especificar una función de puntuación alternativa a través del parámetro <code class="docutils literal notranslate"><span class="pre">scoring</span></code> de la mayoría de las herramientas de búsqueda de parámetros. Ver <a class="reference internal" href="model_evaluation.html#scoring-parameter"><span class="std std-ref">El parámetro scoring: definir las reglas de evaluación del modelo</span></a> para más detalles.</p>
</section>
<section id="specifying-multiple-metrics-for-evaluation">
<span id="multimetric-grid-search"></span><h3><span class="section-number">3.2.4.2. </span>Especificar múltiples métricas para la evaluación<a class="headerlink" href="#specifying-multiple-metrics-for-evaluation" title="Enlazar permanentemente con este título">¶</a></h3>
<p><a class="reference internal" href="generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV" title="sklearn.model_selection.GridSearchCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">GridSearchCV</span></code></a> y <a class="reference internal" href="generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV" title="sklearn.model_selection.RandomizedSearchCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">RandomizedSearchCV</span></code></a> permiten especificar múltiples métricas para el parámetro <code class="docutils literal notranslate"><span class="pre">scoring</span></code>.</p>
<p>La puntuación multimétrica puede especificarse como una lista de cadenas de nombres de puntuaciones predefinidos o como un dict que mapea el nombre del puntuador a la función de puntuación y/o el nombre o los nombres predefinidos del puntuador. Ver <a class="reference internal" href="model_evaluation.html#multimetric-scoring"><span class="std std-ref">Utilizando evaluación métrica múltiple</span></a> para más detalles.</p>
<p>Cuando se especifican múltiples métricas, el parámetro <code class="docutils literal notranslate"><span class="pre">refit</span></code> debe establecerse en la métrica (cadena) para la cual se encontrará <code class="docutils literal notranslate"><span class="pre">best_params_</span></code> y se utilizará para construir el <code class="docutils literal notranslate"><span class="pre">best_estimator_</span></code> en todo el conjunto de datos. Si la búsqueda no debe ser reajustada, establece <code class="docutils literal notranslate"><span class="pre">refit=False</span></code>. Si se deja <code class="docutils literal notranslate"><span class="pre">refit</span></code> con el valor por defecto <code class="docutils literal notranslate"><span class="pre">None</span></code> se producirá un error cuando se utilicen múltiples métricas.</p>
<p>Ver <a class="reference internal" href="../auto_examples/model_selection/plot_multi_metric_evaluation.html#sphx-glr-auto-examples-model-selection-plot-multi-metric-evaluation-py"><span class="std std-ref">Demostración de la evaluación multimétrica en cross_val_score y GridSearchCV</span></a> para un ejemplo de uso.</p>
<p><a class="reference internal" href="generated/sklearn.model_selection.HalvingRandomSearchCV.html#sklearn.model_selection.HalvingRandomSearchCV" title="sklearn.model_selection.HalvingRandomSearchCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">HalvingRandomSearchCV</span></code></a> y <a class="reference internal" href="generated/sklearn.model_selection.HalvingGridSearchCV.html#sklearn.model_selection.HalvingGridSearchCV" title="sklearn.model_selection.HalvingGridSearchCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">HalvingGridSearchCV</span></code></a> no soportan la puntuación multimétrica.</p>
</section>
<section id="composite-estimators-and-parameter-spaces">
<span id="composite-grid-search"></span><h3><span class="section-number">3.2.4.3. </span>Estimadores compuestos y espacios de parámetros<a class="headerlink" href="#composite-estimators-and-parameter-spaces" title="Enlazar permanentemente con este título">¶</a></h3>
<p><a class="reference internal" href="generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV" title="sklearn.model_selection.GridSearchCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">GridSearchCV</span></code></a> y <a class="reference internal" href="generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV" title="sklearn.model_selection.RandomizedSearchCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">RandomizedSearchCV</span></code></a> permiten buscar sobre parámetros de estimadores compuestos o anidados como <a class="reference internal" href="generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline" title="sklearn.pipeline.Pipeline"><code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code></a>, <a class="reference internal" href="generated/sklearn.compose.ColumnTransformer.html#sklearn.compose.ColumnTransformer" title="sklearn.compose.ColumnTransformer"><code class="xref py py-class docutils literal notranslate"><span class="pre">ColumnTransformer</span></code></a>, <a class="reference internal" href="generated/sklearn.ensemble.VotingClassifier.html#sklearn.ensemble.VotingClassifier" title="sklearn.ensemble.VotingClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">VotingClassifier</span></code></a> o <a class="reference internal" href="generated/sklearn.calibration.CalibratedClassifierCV.html#sklearn.calibration.CalibratedClassifierCV" title="sklearn.calibration.CalibratedClassifierCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">CalibratedClassifierCV</span></code></a> utilizando una sintaxis dedicada <code class="docutils literal notranslate"><span class="pre">&lt;estimator&gt;__&lt;parameter&gt;</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.calibration</span> <span class="kn">import</span> <span class="n">CalibratedClassifierCV</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_moons</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_moons</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">calibrated_forest</span> <span class="o">=</span> <span class="n">CalibratedClassifierCV</span><span class="p">(</span>
<span class="gp">... </span>   <span class="n">base_estimator</span><span class="o">=</span><span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">10</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
<span class="gp">... </span>   <span class="s1">&#39;base_estimator__max_depth&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">]}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">calibrated_forest</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">search</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="go">GridSearchCV(cv=5,</span>
<span class="go">             estimator=CalibratedClassifierCV(...),</span>
<span class="go">             param_grid={&#39;base_estimator__max_depth&#39;: [2, 4, 6, 8]})</span>
</pre></div>
</div>
<p>Aquí, <code class="docutils literal notranslate"><span class="pre">&lt;estimator&gt;`</span> <span class="pre">es</span> <span class="pre">el</span> <span class="pre">nombre</span> <span class="pre">del</span> <span class="pre">parámetro</span> <span class="pre">del</span> <span class="pre">estimador</span> <span class="pre">anidado,</span> <span class="pre">en</span> <span class="pre">este</span> <span class="pre">caso</span> <span class="pre">``base_estimator</span></code>. Si el metaestimador se construye como una colección de estimadores como en <code class="docutils literal notranslate"><span class="pre">pipeline.Pipeline</span></code>, entonces <code class="docutils literal notranslate"><span class="pre">&lt;estimator&gt;</span></code> se refiere al nombre del estimador, ver <a class="reference internal" href="compose.html#pipeline-nested-parameters"><span class="std std-ref">Parámetros anidados</span></a>.  En la práctica, puede haber varios niveles de anidación:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">SelectKBest</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">pipe</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([</span>
<span class="gp">... </span>   <span class="p">(</span><span class="s1">&#39;select&#39;</span><span class="p">,</span> <span class="n">SelectKBest</span><span class="p">()),</span>
<span class="gp">... </span>   <span class="p">(</span><span class="s1">&#39;model&#39;</span><span class="p">,</span> <span class="n">calibrated_forest</span><span class="p">)])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span>
<span class="gp">... </span>   <span class="s1">&#39;select__k&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
<span class="gp">... </span>   <span class="s1">&#39;model__base_estimator__max_depth&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">]}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">search</span> <span class="o">=</span> <span class="n">GridSearchCV</span><span class="p">(</span><span class="n">pipe</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p>Consulta <a class="reference internal" href="compose.html#pipeline"><span class="std std-ref">Pipeline: estimadores encadenados</span></a> para realizar búsquedas de parámetros sobre pipelines.</p>
</section>
<section id="model-selection-development-and-evaluation">
<h3><span class="section-number">3.2.4.4. </span>Selección de modelos: desarrollo y evaluación<a class="headerlink" href="#model-selection-development-and-evaluation" title="Enlazar permanentemente con este título">¶</a></h3>
<p>La selección del modelo mediante la evaluación de varios ajustes de los parámetros puede verse como una forma de utilizar los datos etiquetados para «entrenar» los parámetros de la cuadrícula.</p>
<p>A la hora de evaluar el modelo resultante, es importante hacerlo sobre las muestras retenidas que no se han visto durante el proceso de búsqueda en cuadrícula: se recomienda dividir los datos en un <strong>conjunto de desarrollo</strong> (para alimentar la instancia <a class="reference internal" href="generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV" title="sklearn.model_selection.GridSearchCV"><code class="xref py py-class docutils literal notranslate"><span class="pre">GridSearchCV</span></code></a>) y un <strong>conjunto de evaluación</strong> para calcular las métricas de rendimiento.</p>
<p>Esto puede hacerse utilizando la función de utilidad <a class="reference internal" href="generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split" title="sklearn.model_selection.train_test_split"><code class="xref py py-func docutils literal notranslate"><span class="pre">train_test_split</span></code></a>.</p>
</section>
<section id="parallelism">
<h3><span class="section-number">3.2.4.5. </span>Paralelismo<a class="headerlink" href="#parallelism" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Las herramientas de búsqueda de parámetros evalúan cada combinación de parámetros en cada pliegue de datos de forma independiente. Los cálculos pueden ejecutarse en paralelo utilizando la palabra clave <code class="docutils literal notranslate"><span class="pre">n_jobs=-1</span></code>. Consulta la definición de la función para más detalles, y también la entrada del Glosario para <a class="reference internal" href="../glossary.html#term-n_jobs"><span class="xref std std-term">n_jobs</span></a>.</p>
</section>
<section id="robustness-to-failure">
<h3><span class="section-number">3.2.4.6. </span>Robustez frente a los fallos<a class="headerlink" href="#robustness-to-failure" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Algunos ajustes de los parámetros pueden provocar un fallo en <code class="docutils literal notranslate"><span class="pre">fit</span></code> de uno o más pliegues de los datos.  Por defecto, esto hará que toda la búsqueda falle, incluso si algunos ajustes de los parámetros pueden ser evaluados completamente. Si se establece <code class="docutils literal notranslate"><span class="pre">error_score=0</span></code> (o <code class="docutils literal notranslate"><span class="pre">=np.NaN</span></code>), el procedimiento será más robusto ante este tipo de fallos, emitiendo una advertencia y estableciendo la puntuación para ese pliegue en 0 (o <code class="docutils literal notranslate"><span class="pre">NaN</span></code>), pero completando la búsqueda.</p>
</section>
</section>
<section id="alternatives-to-brute-force-parameter-search">
<span id="alternative-cv"></span><h2><span class="section-number">3.2.5. </span>Alternativas a la búsqueda de parámetros por fuerza bruta<a class="headerlink" href="#alternatives-to-brute-force-parameter-search" title="Enlazar permanentemente con este título">¶</a></h2>
<section id="model-specific-cross-validation">
<h3><span class="section-number">3.2.5.1. </span>Validación cruzada específica del modelo<a class="headerlink" href="#model-specific-cross-validation" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Algunos modelos pueden ajustarse a los datos para un rango de valores de algún parámetro casi con la misma eficacia que el ajuste del estimador para un único valor del parámetro. Esta característica puede aprovecharse para realizar una validación cruzada más eficiente utilizada para la selección del modelo de este parámetro.</p>
<p>El parámetro más común que se presta a esta estrategia es el que codifica la fuerza del regularizador. En este caso decimos que calculamos el <strong>camino de regularización</strong> del estimador.</p>
<p>Esta es la lista de estos modelos:</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/sklearn.linear_model.ElasticNetCV.html#sklearn.linear_model.ElasticNetCV" title="sklearn.linear_model.ElasticNetCV"><code class="xref py py-obj docutils literal notranslate"><span class="pre">linear_model.ElasticNetCV</span></code></a></p></td>
<td><p>Modelo de Red Elástica con ajuste iterativo a lo largo de una trayectoria de regularización.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/sklearn.linear_model.LarsCV.html#sklearn.linear_model.LarsCV" title="sklearn.linear_model.LarsCV"><code class="xref py py-obj docutils literal notranslate"><span class="pre">linear_model.LarsCV</span></code></a></p></td>
<td><p>Modelo de Regresión de Ángulo Mínimo con Validación Cruzada.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/sklearn.linear_model.LassoCV.html#sklearn.linear_model.LassoCV" title="sklearn.linear_model.LassoCV"><code class="xref py py-obj docutils literal notranslate"><span class="pre">linear_model.LassoCV</span></code></a></p></td>
<td><p>Modelo lineal Lasso con ajuste iterativo a lo largo del camino de regularización.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/sklearn.linear_model.LassoLarsCV.html#sklearn.linear_model.LassoLarsCV" title="sklearn.linear_model.LassoLarsCV"><code class="xref py py-obj docutils literal notranslate"><span class="pre">linear_model.LassoLarsCV</span></code></a></p></td>
<td><p>Validación cruzada Lasso, utilizando el algoritmo LARS.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/sklearn.linear_model.LogisticRegressionCV.html#sklearn.linear_model.LogisticRegressionCV" title="sklearn.linear_model.LogisticRegressionCV"><code class="xref py py-obj docutils literal notranslate"><span class="pre">linear_model.LogisticRegressionCV</span></code></a></p></td>
<td><p>Clasificador de Regresión Logística CV (también conocido como logit, MaxEnt).</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/sklearn.linear_model.MultiTaskElasticNetCV.html#sklearn.linear_model.MultiTaskElasticNetCV" title="sklearn.linear_model.MultiTaskElasticNetCV"><code class="xref py py-obj docutils literal notranslate"><span class="pre">linear_model.MultiTaskElasticNetCV</span></code></a></p></td>
<td><p>ElasticNet multitarea L1/L2 con validación cruzada incorporada.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/sklearn.linear_model.MultiTaskLassoCV.html#sklearn.linear_model.MultiTaskLassoCV" title="sklearn.linear_model.MultiTaskLassoCV"><code class="xref py py-obj docutils literal notranslate"><span class="pre">linear_model.MultiTaskLassoCV</span></code></a></p></td>
<td><p>Modelo Lasso multitarea entrenado con la norma mixta L1/L2 como regularizador.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/sklearn.linear_model.OrthogonalMatchingPursuitCV.html#sklearn.linear_model.OrthogonalMatchingPursuitCV" title="sklearn.linear_model.OrthogonalMatchingPursuitCV"><code class="xref py py-obj docutils literal notranslate"><span class="pre">linear_model.OrthogonalMatchingPursuitCV</span></code></a></p></td>
<td><p>Modelo de búsqueda de correspondencias ortogonales (Orthogonal Matching Pursuit, OMP) con validación cruzada.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/sklearn.linear_model.RidgeCV.html#sklearn.linear_model.RidgeCV" title="sklearn.linear_model.RidgeCV"><code class="xref py py-obj docutils literal notranslate"><span class="pre">linear_model.RidgeCV</span></code></a></p></td>
<td><p>Regresión de cresta con validación cruzada incorporada.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/sklearn.linear_model.RidgeClassifierCV.html#sklearn.linear_model.RidgeClassifierCV" title="sklearn.linear_model.RidgeClassifierCV"><code class="xref py py-obj docutils literal notranslate"><span class="pre">linear_model.RidgeClassifierCV</span></code></a></p></td>
<td><p>Clasificador de cresta con validación cruzada incorporada.</p></td>
</tr>
</tbody>
</table>
</section>
<section id="information-criterion">
<h3><span class="section-number">3.2.5.2. </span>Criterio de Información<a class="headerlink" href="#information-criterion" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Algunos modelos pueden ofrecer una fórmula de forma cerrada teórica de la información de la estimación óptima del parámetro de regularización mediante el cálculo de un solo camino de regularización (en lugar de varios cuando se utiliza la validación cruzada).</p>
<p>Esta es la lista de modelos que se benefician del Criterio de Información de Akaike (Akaike Information Criterion, AIC) o del Criterio de Información Bayesiano (Criterio de Información Bayesiano, BIC) para la selección automática de modelos:</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/sklearn.linear_model.LassoLarsIC.html#sklearn.linear_model.LassoLarsIC" title="sklearn.linear_model.LassoLarsIC"><code class="xref py py-obj docutils literal notranslate"><span class="pre">linear_model.LassoLarsIC</span></code></a></p></td>
<td><p>Ajuste del modelo Lasso con Lars utilizando BIC o AIC para la selección del modelo</p></td>
</tr>
</tbody>
</table>
</section>
<section id="out-of-bag-estimates">
<span id="out-of-bag"></span><h3><span class="section-number">3.2.5.3. </span>Estimaciones Fuera de la Bolsa (Out of Bag)<a class="headerlink" href="#out-of-bag-estimates" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Cuando se utilizan métodos de ensemble basados en el empaquetado (bagging), es decir, la generación de nuevos conjuntos de entrenamiento mediante muestreo con reemplazo, parte del conjunto de entrenamiento queda sin utilizar.  Para cada clasificador de ensemble, se omite una parte diferente del conjunto de entrenamiento.</p>
<p>Esta porción omitida puede utilizarse para estimar el error de generalización sin tener que depender de un conjunto de validación separado.  Esta estimación es «gratuita», ya que no se necesitan datos adicionales y puede utilizarse para la selección del modelo.</p>
<p>Esto está actualmente implementado en las siguientes clases:</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier" title="sklearn.ensemble.RandomForestClassifier"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ensemble.RandomForestClassifier</span></code></a></p></td>
<td><p>Un clasificador de bosque aleatorio.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor" title="sklearn.ensemble.RandomForestRegressor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ensemble.RandomForestRegressor</span></code></a></p></td>
<td><p>Un regresor de bosque aleatorio.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/sklearn.ensemble.ExtraTreesClassifier.html#sklearn.ensemble.ExtraTreesClassifier" title="sklearn.ensemble.ExtraTreesClassifier"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ensemble.ExtraTreesClassifier</span></code></a></p></td>
<td><p>Un clasificador de árboles extra (extra-trees).</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/sklearn.ensemble.ExtraTreesRegressor.html#sklearn.ensemble.ExtraTreesRegressor" title="sklearn.ensemble.ExtraTreesRegressor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ensemble.ExtraTreesRegressor</span></code></a></p></td>
<td><p>Un regresor de árboles extra (extra-trees).</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/sklearn.ensemble.GradientBoostingClassifier.html#sklearn.ensemble.GradientBoostingClassifier" title="sklearn.ensemble.GradientBoostingClassifier"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ensemble.GradientBoostingClassifier</span></code></a></p></td>
<td><p>Potenciación del gradiente para clasificación.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/sklearn.ensemble.GradientBoostingRegressor.html#sklearn.ensemble.GradientBoostingRegressor" title="sklearn.ensemble.GradientBoostingRegressor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ensemble.GradientBoostingRegressor</span></code></a></p></td>
<td><p>Potenciación del Gradiente para regresión.</p></td>
</tr>
</tbody>
</table>
</section>
</section>
</section>


      </div>
    <div class="container">
      <footer class="sk-content-footer">
            &copy; 2007 - 2020, scikit-learn developers (BSD License).
          <a href="../_sources/modules/grid_search.rst.txt" rel="nofollow">Mostrar la fuente de esta página</a>
      </footer>
    </div>
  </div>
</div>
<script src="../_static/js/vendor/bootstrap.min.js"></script>

<script>
    window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
    ga('create', 'UA-22606712-2', 'auto');
    ga('set', 'anonymizeIp', true);
    ga('send', 'pageview');
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>


<script>
$(document).ready(function() {
    /* Add a [>>>] button on the top-right corner of code samples to hide
     * the >>> and ... prompts and the output and thus make the code
     * copyable. */
    var div = $('.highlight-python .highlight,' +
                '.highlight-python3 .highlight,' +
                '.highlight-pycon .highlight,' +
		'.highlight-default .highlight')
    var pre = div.find('pre');

    // get the styles from the current theme
    pre.parent().parent().css('position', 'relative');
    var hide_text = 'Hide prompts and outputs';
    var show_text = 'Show prompts and outputs';

    // create and add the button to all the code blocks that contain >>>
    div.each(function(index) {
        var jthis = $(this);
        if (jthis.find('.gp').length > 0) {
            var button = $('<span class="copybutton">&gt;&gt;&gt;</span>');
            button.attr('title', hide_text);
            button.data('hidden', 'false');
            jthis.prepend(button);
        }
        // tracebacks (.gt) contain bare text elements that need to be
        // wrapped in a span to work with .nextUntil() (see later)
        jthis.find('pre:has(.gt)').contents().filter(function() {
            return ((this.nodeType == 3) && (this.data.trim().length > 0));
        }).wrap('<span>');
    });

    // define the behavior of the button when it's clicked
    $('.copybutton').click(function(e){
        e.preventDefault();
        var button = $(this);
        if (button.data('hidden') === 'false') {
            // hide the code output
            button.parent().find('.go, .gp, .gt').hide();
            button.next('pre').find('.gt').nextUntil('.gp, .go').css('visibility', 'hidden');
            button.css('text-decoration', 'line-through');
            button.attr('title', show_text);
            button.data('hidden', 'true');
        } else {
            // show the code output
            button.parent().find('.go, .gp, .gt').show();
            button.next('pre').find('.gt').nextUntil('.gp, .go').css('visibility', 'visible');
            button.css('text-decoration', 'none');
            button.attr('title', hide_text);
            button.data('hidden', 'false');
        }
    });

	/*** Add permalink buttons next to glossary terms ***/
	$('dl.glossary > dt[id]').append(function() {
		return ('<a class="headerlink" href="#' +
			    this.getAttribute('id') +
			    '" title="Permalink to this term">¶</a>');
	});
  /*** Hide navbar when scrolling down ***/
  // Returns true when headerlink target matches hash in url
  (function() {
    hashTargetOnTop = function() {
        var hash = window.location.hash;
        if ( hash.length < 2 ) { return false; }

        var target = document.getElementById( hash.slice(1) );
        if ( target === null ) { return false; }

        var top = target.getBoundingClientRect().top;
        return (top < 2) && (top > -2);
    };

    // Hide navbar on load if hash target is on top
    var navBar = document.getElementById("navbar");
    var navBarToggler = document.getElementById("sk-navbar-toggler");
    var navBarHeightHidden = "-" + navBar.getBoundingClientRect().height + "px";
    var $window = $(window);

    hideNavBar = function() {
        navBar.style.top = navBarHeightHidden;
    };

    showNavBar = function() {
        navBar.style.top = "0";
    }

    if (hashTargetOnTop()) {
        hideNavBar()
    }

    var prevScrollpos = window.pageYOffset;
    hideOnScroll = function(lastScrollTop) {
        if (($window.width() < 768) && (navBarToggler.getAttribute("aria-expanded") === 'true')) {
            return;
        }
        if (lastScrollTop > 2 && (prevScrollpos <= lastScrollTop) || hashTargetOnTop()){
            hideNavBar()
        } else {
            showNavBar()
        }
        prevScrollpos = lastScrollTop;
    };

    /*** high performance scroll event listener***/
    var raf = window.requestAnimationFrame ||
        window.webkitRequestAnimationFrame ||
        window.mozRequestAnimationFrame ||
        window.msRequestAnimationFrame ||
        window.oRequestAnimationFrame;
    var lastScrollTop = $window.scrollTop();

    if (raf) {
        loop();
    }

    function loop() {
        var scrollTop = $window.scrollTop();
        if (lastScrollTop === scrollTop) {
            raf(loop);
            return;
        } else {
            lastScrollTop = scrollTop;
            hideOnScroll(lastScrollTop);
            raf(loop);
        }
    }
  })();
});

</script>
    
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
    
</body>
</html>