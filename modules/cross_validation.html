

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  
  <title>3.1. Validación cruzada: evaluación del rendimiento del estimador &mdash; documentación de scikit-learn - 0.24.2</title>
  
  <link rel="canonical" href="http://scikit-learn.org/stable/modules/cross_validation.html" />

  
  <link rel="shortcut icon" href="../_static/favicon.ico"/>
  

  <link rel="stylesheet" href="../_static/css/vendor/bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/gallery.css" type="text/css" />
  <link rel="stylesheet" href="../_static/gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../_static/gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../_static/gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
<script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
<script src="../_static/jquery.js"></script> 
</head>
<body>
<nav id="navbar" class="sk-docs-navbar navbar navbar-expand-md navbar-light bg-light py-0">
  <div class="container-fluid sk-docs-container px-0">
      <a class="navbar-brand py-0" href="../index.html">
        <img
          class="sk-brand-img"
          src="../_static/scikit-learn-logo-small.png"
          alt="logo"/>
      </a>
    <button
      id="sk-navbar-toggler"
      class="navbar-toggler"
      type="button"
      data-toggle="collapse"
      data-target="#navbarSupportedContent"
      aria-controls="navbarSupportedContent"
      aria-expanded="false"
      aria-label="Toggle navigation"
    >
      <span class="navbar-toggler-icon"></span>
    </button>

    <div class="sk-navbar-collapse collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav mr-auto">
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../install.html">Instalación</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../user_guide.html">Manual de Usuario</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="classes.html">API</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../auto_examples/index.html">Ejemplos</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../getting_started.html">¿Cómo empezar?</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../tutorial/index.html">Tutorial</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../whats_new/v0.24.html">Novedades</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../glossary.html">Glosario</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../developers/index.html">Desarrollo</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../faq.html">FAQ</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../support.html">Soporte</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../related_projects.html">Paquetes relacionados</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../roadmap.html">Hoja de ruta</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../about.html">Sobre nosotros</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="https://github.com/scikit-learn/scikit-learn">GitHub</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="https://scikit-learn.org/dev/versions.html">Otras versiones y descargas</a>
        </li>
        <li class="nav-item dropdown nav-more-item-dropdown">
          <a class="sk-nav-link nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Más</a>
          <div class="dropdown-menu" aria-labelledby="navbarDropdown">
              <a class="sk-nav-dropdown-item dropdown-item" href="../getting_started.html">¿Cómo empezar?</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../tutorial/index.html">Tutorial</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../whats_new/v0.24.html">Novedades</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../glossary.html">Glosario</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../developers/index.html">Desarrollo</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../faq.html">FAQ</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../support.html">Soporte</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../related_projects.html">Paquetes relacionados</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../roadmap.html">Hoja de ruta</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../about.html">Sobre nosotros</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="https://github.com/scikit-learn/scikit-learn">GitHub</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="https://scikit-learn.org/dev/versions.html">Otras versiones y descargas</a>
          </div>
        </li>
      </ul>
      <div id="searchbox" role="search">
          <div class="searchformwrapper">
          <form class="search" action="../search.html" method="get">
            <input class="sk-search-text-input" type="text" name="q" aria-labelledby="searchlabel" />
            <input class="sk-search-text-btn" type="submit" value="Ir a" />
          </form>
          </div>
      </div>
    </div>
  </div>
</nav>
<div class="d-flex" id="sk-doc-wrapper">
    <input type="checkbox" name="sk-toggle-checkbox" id="sk-toggle-checkbox">
    <label id="sk-sidemenu-toggle" class="sk-btn-toggle-toc btn sk-btn-primary" for="sk-toggle-checkbox">Alternar menú</label>
    <div id="sk-sidebar-wrapper" class="border-right">
      <div class="sk-sidebar-toc-wrapper">
        <div class="sk-sidebar-toc-logo">
          <a href="../index.html">
            <img
              class="sk-brand-img"
              src="../_static/scikit-learn-logo-small.png"
              alt="logo"/>
          </a>
        </div>
        <div class="btn-group w-100 mb-2" role="group" aria-label="rellinks">
            <a href="../model_selection.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="3. Selección y evaluación del modelo">Prev</a><a href="../model_selection.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="3. Selección y evaluación del modelo">Arriba</a>
            <a href="grid_search.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="3.2. Ajustar los hiperparámetros de un estimador">Sig.</a>
        </div>
        <div class="alert alert-danger p-1 mb-2" role="alert">
          <p class="text-center mb-0">
          <strong>scikit-learn 0.24.2</strong><br/>
          <a href="http://scikit-learn.org/dev/versions.html">Otras versiones</a>
          </p>
        </div>
        <div class="alert alert-warning p-1 mb-2" role="alert">
          <p class="text-center mb-0">
            Por favor <a class="font-weight-bold" href="../about.html#citing-scikit-learn"><string>cítanos</string></a> si usas el software.
          </p>
        </div>
            <div class="sk-sidebar-toc">
              <ul>
<li><a class="reference internal" href="#">3.1. Validación cruzada: evaluación del rendimiento del estimador</a><ul>
<li><a class="reference internal" href="#computing-cross-validated-metrics">3.1.1. Cálculo de métricas de validación cruzada</a><ul>
<li><a class="reference internal" href="#the-cross-validate-function-and-multiple-metric-evaluation">3.1.1.1. La función cross_validate y la evaluación de métricas múltiples</a></li>
<li><a class="reference internal" href="#obtaining-predictions-by-cross-validation">3.1.1.2. Obtención de predicciones por validación cruzada</a></li>
</ul>
</li>
<li><a class="reference internal" href="#cross-validation-iterators">3.1.2. Iteradores de validación cruzada</a><ul>
<li><a class="reference internal" href="#cross-validation-iterators-for-i-i-d-data">3.1.2.1. Iteradores de validación cruzada para datos i.i.d</a><ul>
<li><a class="reference internal" href="#k-fold">3.1.2.1.1. K-fold</a></li>
<li><a class="reference internal" href="#repeated-k-fold">3.1.2.1.2. K-Fold repetido</a></li>
<li><a class="reference internal" href="#leave-one-out-loo">3.1.2.1.3. Leave One Out (LOO)</a></li>
<li><a class="reference internal" href="#leave-p-out-lpo">3.1.2.1.4. Leave P Out (LPO)</a></li>
<li><a class="reference internal" href="#random-permutations-cross-validation-a-k-a-shuffle-split">3.1.2.1.5. Validación cruzada de permutaciones aleatorias, también conocida como Mezcla y División</a></li>
</ul>
</li>
<li><a class="reference internal" href="#cross-validation-iterators-with-stratification-based-on-class-labels">3.1.2.2. Iteradores de validación cruzada con estratificación basada en las etiquetas de clase.</a><ul>
<li><a class="reference internal" href="#stratified-k-fold">3.1.2.2.1. K-fold estratificado</a></li>
<li><a class="reference internal" href="#stratified-shuffle-split">3.1.2.2.2. División aleatoria estratificada</a></li>
</ul>
</li>
<li><a class="reference internal" href="#cross-validation-iterators-for-grouped-data">3.1.2.3. Iteradores de validación cruzada para datos agrupados.</a><ul>
<li><a class="reference internal" href="#group-k-fold">3.1.2.3.1. K-fold de grupos</a></li>
<li><a class="reference internal" href="#leave-one-group-out">3.1.2.3.2. Dejar un grupo afuera (Leave One Group Out)</a></li>
<li><a class="reference internal" href="#leave-p-groups-out">3.1.2.3.3. Dejar fuera los grupos P</a></li>
<li><a class="reference internal" href="#group-shuffle-split">3.1.2.3.4. Dividir grupos de forma aleatoria</a></li>
</ul>
</li>
<li><a class="reference internal" href="#predefined-fold-splits-validation-sets">3.1.2.4. Divisiones predefinidas/ Conjuntos de validación</a></li>
<li><a class="reference internal" href="#using-cross-validation-iterators-to-split-train-and-test">3.1.2.5. Uso de los iteradores de validación cruzada para dividir el entrenamiento y la prueba</a></li>
<li><a class="reference internal" href="#cross-validation-of-time-series-data">3.1.2.6. Validación cruzada de datos de series de tiempo</a><ul>
<li><a class="reference internal" href="#time-series-split">3.1.2.6.1. División de series de tiempo</a></li>
</ul>
</li>
</ul>
</li>
<li><a class="reference internal" href="#a-note-on-shuffling">3.1.3. Nota sobre la mezcla</a></li>
<li><a class="reference internal" href="#cross-validation-and-model-selection">3.1.4. Validación cruzada y selección de modelos</a></li>
<li><a class="reference internal" href="#permutation-test-score">3.1.5. Puntuación de la prueba de permutación</a></li>
</ul>
</li>
</ul>

            </div>
      </div>
    </div>
    <div id="sk-page-content-wrapper">
      <div class="sk-page-content container-fluid body px-md-3" role="main">
        
  <section id="cross-validation-evaluating-estimator-performance">
<span id="cross-validation"></span><h1><span class="section-number">3.1. </span>Validación cruzada: evaluación del rendimiento del estimador<a class="headerlink" href="#cross-validation-evaluating-estimator-performance" title="Enlazar permanentemente con este título">¶</a></h1>
<p>Aprender los parámetros de una función de predicción y probarla sobre los mismos datos es un error metodológico: un modelo que se limitase a repetir las etiquetas de las muestras que acaba de ver tendría una puntuación perfecta, pero no lograría predecir nada útil sobre datos aún no vistos. Esta situación se llama <strong>sobreajuste</strong>. Para evitarla, es práctica común cuando se realiza un experimento de aprendizaje automático (supervisado), el mantener una parte de los datos disponibles como un <strong>conjunto de prueba</strong> <a href="#id1"><span class="problematic" id="id2">``</span></a>X_test, y_test`. Tenga en cuenta que la palabra «experimento» no pretende denotar un uso académico únicamente, ya que incluso en entornos comerciales el aprendizaje automático suele comenzar de forma experimental. Este es un diagrama de flujo del proceso de trabajo típico de validación cruzada en el entrenamiento de modelos. Los mejores parámetros pueden determinarse mediante las técnicas de <a class="reference internal" href="grid_search.html#grid-search"><span class="std std-ref">búsqueda exhaustiva</span></a>.</p>
<a class="reference internal image-reference" href="../_images/grid_search_workflow.png"><img alt="Grid Search Workflow" class="align-center" src="../_images/grid_search_workflow.png" style="width: 400px; height: 240px;" /></a>
<p>En scikit-learn una división aleatoria en conjuntos de entrenamiento y prueba puede ser rápidamente calculada con la función de ayuda <a class="reference internal" href="generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split" title="sklearn.model_selection.train_test_split"><code class="xref py py-func docutils literal notranslate"><span class="pre">train_test_split</span></code></a>. Carguemos el conjunto de datos del iris para ajustar una máquina de vectores de soporte lineal en él:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">datasets</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">svm</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">datasets</span><span class="o">.</span><span class="n">load_iris</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">shape</span>
<span class="go">((150, 4), (150,))</span>
</pre></div>
</div>
<p>Ahora podemos hacer un muestreo rápido de un conjunto de entrenamiento y reservar el 40% de los datos para probar (evaluar) nuestro clasificador:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_train</span><span class="o">.</span><span class="n">shape</span>
<span class="go">((90, 4), (90,))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">y_test</span><span class="o">.</span><span class="n">shape</span>
<span class="go">((60, 4), (60,))</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="go">0.96...</span>
</pre></div>
</div>
<p>Cuando se evalúan diferentes ajustes («hiperparámetros») para los estimadores, como el ajuste <code class="docutils literal notranslate"><span class="pre">C</span></code> que debe establecerse manualmente para una SVM, sigue existiendo el riesgo de sobreajuste <em>en el conjunto de prueba</em> porque los parámetros pueden ajustarse hasta que el estimador tenga un rendimiento óptimo. De este modo, el conocimiento sobre el conjunto de pruebas puede «filtrarse» en el modelo y las métricas de evaluación ya no reportan el rendimiento de la generalización. Para resolver este problema, otra parte del conjunto de datos puede mantenerse como el llamado «conjunto de validación»: el entrenamiento se lleva a cabo en el conjunto de entrenamiento, tras lo cual la evaluación se realiza en el conjunto de validación, y cuando el experimento parece ser exitoso, la evaluación final puede realizarse en el conjunto de prueba.</p>
<p>Sin embargo, al dividir los datos disponibles en tres conjuntos, reducimos drásticamente el número de muestras que pueden utilizarse para el aprendizaje del modelo, y los resultados pueden depender de una determinada elección aleatoria del par de conjuntos (de entrenamiento, de validación).</p>
<p>Una solución a este problema es un procedimiento llamado <a class="reference external" href="https://es.wikipedia.org/wiki/Validaci%C3%B3n_cruzada)">validación cruzada</a> (VC para abreviar). El conjunto de pruebas debe seguir siendo utilizado para la evaluación final, pero el conjunto de validación ya no es necesario cuando se realiza la VC. En el enfoque básico, llamado <em>k</em>-parte VC, el conjunto de entrenamiento se divide en <em>k</em> conjuntos más pequeños (más adelante se describen otros enfoques, pero en general siguen los mismos principios). Se sigue el siguiente procedimiento para cada uno de las <em>k</em> «partes»:</p>
<blockquote>
<div><ul class="simple">
<li><p>Se entrena un modelo utilizando <span class="math notranslate nohighlight">\(k-1\)</span> de las partes como datos de entrenamiento;</p></li>
<li><p>el modelo resultante se valida en la parte restante de los datos (es decir, se utiliza como conjunto de pruebas para calcular una medida de rendimiento como la precisión).</p></li>
</ul>
</div></blockquote>
<p>La medida de rendimiento obtenida mediante la validación cruzada de <em>k</em> partes es entonces la media de los valores calculados en el bucle. Este enfoque puede ser costoso desde el punto de vista computacional, pero no desperdicia demasiados datos (como ocurre cuando se fija un conjunto de validación arbitrario), lo que supone una gran ventaja en problemas como la inferencia inversa, donde el número de muestras es muy pequeño.</p>
<a class="reference internal image-reference" href="../_images/grid_search_cross_validation.png"><img alt="../_images/grid_search_cross_validation.png" class="align-center" src="../_images/grid_search_cross_validation.png" style="width: 500px; height: 300px;" /></a>
<section id="computing-cross-validated-metrics">
<h2><span class="section-number">3.1.1. </span>Cálculo de métricas de validación cruzada<a class="headerlink" href="#computing-cross-validated-metrics" title="Enlazar permanentemente con este título">¶</a></h2>
<p>La forma más sencilla de utilizar la validación cruzada es llamar a la función de ayuda <a class="reference internal" href="generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score" title="sklearn.model_selection.cross_val_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">cross_val_score</span></code></a> sobre el estimador y el conjunto de datos.</p>
<p>El siguiente ejemplo muestra cómo estimar la precisión de una máquina de vectores de soporte de núcleo lineal en el conjunto de datos del iris dividiendo los datos, ajustando un modelo y calculando la puntuación 5 veces consecutivas (con diferentes divisiones cada vez):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scores</span>
<span class="go">array([0.96..., 1. , 0.96..., 0.96..., 1. ])</span>
</pre></div>
</div>
<p>La puntuación media y la desviación estándar vienen dadas por:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%0.2f</span><span class="s2"> accuracy with a standard deviation of </span><span class="si">%0.2f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">scores</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">scores</span><span class="o">.</span><span class="n">std</span><span class="p">()))</span>
<span class="go">0.98 accuracy with a standard deviation of 0.02</span>
</pre></div>
</div>
<p>Por defecto, la puntuación calculada en cada iteración del CV es el método <code class="docutils literal notranslate"><span class="pre">score</span></code> del estimador. Es posible cambiar esto utilizando el parámetro de puntuación:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scores</span> <span class="o">=</span> <span class="n">cross_val_score</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">clf</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;f1_macro&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scores</span>
<span class="go">array([0.96..., 1.  ..., 0.96..., 0.96..., 1.        ])</span>
</pre></div>
</div>
<p>Observa el <a class="reference internal" href="model_evaluation.html#scoring-parameter"><span class="std std-ref">El parámetro scoring: definir las reglas de evaluación del modelo</span></a> para más detalles. En el caso del conjunto de datos Iris, las muestras están equilibradas entre las clases objetivo, por lo que la precisión y la puntuación F1 son casi iguales.</p>
<p>Cuando el argumento <code class="docutils literal notranslate"><span class="pre">cv</span></code> es un entero, <a class="reference internal" href="generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score" title="sklearn.model_selection.cross_val_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">cross_val_score</span></code></a> utiliza por defecto las estrategias <a class="reference internal" href="generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold" title="sklearn.model_selection.KFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">KFold</span></code></a> o <a class="reference internal" href="generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold" title="sklearn.model_selection.StratifiedKFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">StratifiedKFold</span></code></a>, usándose esta última si el estimador deriva de <a class="reference internal" href="generated/sklearn.base.ClassifierMixin.html#sklearn.base.ClassifierMixin" title="sklearn.base.ClassifierMixin"><code class="xref py py-class docutils literal notranslate"><span class="pre">ClassifierMixin</span></code></a>.</p>
<p>También es posible utilizar otras estrategias de validación cruzada pasando un iterador de validación cruzada en su lugar, por ejemplo:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">ShuffleSplit</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">n_samples</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cv</span> <span class="o">=</span> <span class="n">ShuffleSplit</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">)</span>
<span class="go">array([0.977..., 0.977..., 1.  ..., 0.955..., 1.        ])</span>
</pre></div>
</div>
<p>Otra opción es utilizar un iterable que produzca divisiones (entrenamiento, prueba) como matrices de índices, por ejemplo:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">def</span> <span class="nf">custom_cv_2folds</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
<span class="gp">... </span>    <span class="n">n</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="gp">... </span>    <span class="n">i</span> <span class="o">=</span> <span class="mi">1</span>
<span class="gp">... </span>    <span class="k">while</span> <span class="n">i</span> <span class="o">&lt;=</span> <span class="mi">2</span><span class="p">:</span>
<span class="gp">... </span>        <span class="n">idx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n</span> <span class="o">*</span> <span class="p">(</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">n</span> <span class="o">*</span> <span class="n">i</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
<span class="gp">... </span>        <span class="k">yield</span> <span class="n">idx</span><span class="p">,</span> <span class="n">idx</span>
<span class="gp">... </span>        <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
<span class="gp">...</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">custom_cv</span> <span class="o">=</span> <span class="n">custom_cv_2folds</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">custom_cv</span><span class="p">)</span>
<span class="go">array([1.        , 0.973...])</span>
</pre></div>
</div>
<div class="topic">
<p class="topic-title">Transformación de datos con datos retenidos</p>
<p>Al igual que es importante probar un predictor en los datos retenidos del entrenamiento, el preprocesamiento (como la estandarización, la selección de características, etc.) y las transformaciones de datos similares <a class="reference internal" href="../data_transforms.html#data-transforms"><span class="std std-ref">transformaciones de datos</span></a> deberían aprenderse de un conjunto de entrenamiento y aplicarse a los datos retenidos para la predicción:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">preprocessing</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scaler</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">StandardScaler</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_train_transformed</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_transformed</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_test_transformed</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test_transformed</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="go">0.9333...</span>
</pre></div>
</div>
<p>Un <a class="reference internal" href="generated/sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline" title="sklearn.pipeline.Pipeline"><code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code></a> facilita la composición de los estimadores, proporcionando este comportamiento bajo validación cruzada:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">make_pipeline</span><span class="p">(</span><span class="n">preprocessing</span><span class="o">.</span><span class="n">StandardScaler</span><span class="p">(),</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="n">cv</span><span class="p">)</span>
<span class="go">array([0.977..., 0.933..., 0.955..., 0.933..., 0.977...])</span>
</pre></div>
</div>
<p>Véase <a class="reference internal" href="compose.html#combining-estimators"><span class="std std-ref">Pipelines y estimadores compuestos</span></a>.</p>
</div>
<section id="the-cross-validate-function-and-multiple-metric-evaluation">
<span id="multimetric-cross-validation"></span><h3><span class="section-number">3.1.1.1. </span>La función cross_validate y la evaluación de métricas múltiples<a class="headerlink" href="#the-cross-validate-function-and-multiple-metric-evaluation" title="Enlazar permanentemente con este título">¶</a></h3>
<p>La función <a class="reference internal" href="generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate" title="sklearn.model_selection.cross_validate"><code class="xref py py-func docutils literal notranslate"><span class="pre">cross_validate</span></code></a> difiere de <a class="reference internal" href="generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score" title="sklearn.model_selection.cross_val_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">cross_val_score</span></code></a> en dos aspectos:</p>
<ul class="simple">
<li><p>Permite especificar múltiples métricas para su evaluación.</p></li>
<li><p>Devuelve un diccionario que contiene tiempos de ajuste, tiempos de puntuación (y opcionalmente puntuaciones de entrenamiento así como estimadores ajustados) además de la puntuación de la prueba.</p></li>
</ul>
<p>Para la evaluación de una sola métrica, en la que el parámetro de puntuación es una cadena, invocable o None, las claves serán - <code class="docutils literal notranslate"><span class="pre">['test_score',</span> <span class="pre">'fit_time',</span> <span class="pre">'score_time']</span></code></p>
<p>Y para la evaluación de métricas múltiples, el valor de retorno es un diccionario con las siguientes claves - <code class="docutils literal notranslate"><span class="pre">['test_&lt;scorer1_name&gt;',</span> <span class="pre">'test_&lt;scorer2_name&gt;',</span> <span class="pre">'test_&lt;scorer...&gt;',</span> <span class="pre">'fit_time',</span> <span class="pre">'score_time']</span></code></p>
<p><code class="docutils literal notranslate"><span class="pre">retornar_puntuación_de_entrenamiento</span></code> se establece por defecto en <code class="docutils literal notranslate"><span class="pre">False</span></code> para ahorrar tiempo de cálculo. Para evaluar las puntuaciones en el conjunto de entrenamiento también es necesario que se establezca en <code class="docutils literal notranslate"><span class="pre">True</span></code>.</p>
<p>También puede conservar el estimador ajustado en cada conjunto de entrenamiento estableciendo <code class="docutils literal notranslate"><span class="pre">return_estimator=True</span></code>.</p>
<p>Las métricas múltiples se pueden especificar como una lista, tupla o conjunto de nombres de puntuadores predefinidos:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_validate</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">recall_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scoring</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;precision_macro&#39;</span><span class="p">,</span> <span class="s1">&#39;recall_macro&#39;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;linear&#39;</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scores</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">scoring</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">sorted</span><span class="p">(</span><span class="n">scores</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="go">[&#39;fit_time&#39;, &#39;score_time&#39;, &#39;test_precision_macro&#39;, &#39;test_recall_macro&#39;]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scores</span><span class="p">[</span><span class="s1">&#39;test_recall_macro&#39;</span><span class="p">]</span>
<span class="go">array([0.96..., 1.  ..., 0.96..., 0.96..., 1.        ])</span>
</pre></div>
</div>
<p>O como un diccionario que asigna el nombre del calificador a una función de calificación predefinida o personalizada:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">make_scorer</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scoring</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;prec_macro&#39;</span><span class="p">:</span> <span class="s1">&#39;precision_macro&#39;</span><span class="p">,</span>
<span class="gp">... </span>           <span class="s1">&#39;rec_macro&#39;</span><span class="p">:</span> <span class="n">make_scorer</span><span class="p">(</span><span class="n">recall_score</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s1">&#39;macro&#39;</span><span class="p">)}</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scores</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">scoring</span><span class="o">=</span><span class="n">scoring</span><span class="p">,</span>
<span class="gp">... </span>                        <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">return_train_score</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">sorted</span><span class="p">(</span><span class="n">scores</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="go">[&#39;fit_time&#39;, &#39;score_time&#39;, &#39;test_prec_macro&#39;, &#39;test_rec_macro&#39;,</span>
<span class="go"> &#39;train_prec_macro&#39;, &#39;train_rec_macro&#39;]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">scores</span><span class="p">[</span><span class="s1">&#39;train_rec_macro&#39;</span><span class="p">]</span>
<span class="go">array([0.97..., 0.97..., 0.99..., 0.98..., 0.98...])</span>
</pre></div>
</div>
<p>Este es un ejemplo de <code class="docutils literal notranslate"><span class="pre">validación_cruzada</span></code> utilizando una sola métrica:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">scores</span> <span class="o">=</span> <span class="n">cross_validate</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span>
<span class="gp">... </span>                        <span class="n">scoring</span><span class="o">=</span><span class="s1">&#39;precision_macro&#39;</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
<span class="gp">... </span>                        <span class="n">return_estimator</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">sorted</span><span class="p">(</span><span class="n">scores</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
<span class="go">[&#39;estimator&#39;, &#39;fit_time&#39;, &#39;score_time&#39;, &#39;test_score&#39;]</span>
</pre></div>
</div>
</section>
<section id="obtaining-predictions-by-cross-validation">
<h3><span class="section-number">3.1.1.2. </span>Obtención de predicciones por validación cruzada<a class="headerlink" href="#obtaining-predictions-by-cross-validation" title="Enlazar permanentemente con este título">¶</a></h3>
<p>La función <a class="reference internal" href="generated/sklearn.model_selection.cross_val_predict.html#sklearn.model_selection.cross_val_predict" title="sklearn.model_selection.cross_val_predict"><code class="xref py py-func docutils literal notranslate"><span class="pre">cross_val_predict</span></code></a> tiene una interfaz similar a la de <a class="reference internal" href="generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score" title="sklearn.model_selection.cross_val_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">cross_val_score</span></code></a>, pero devuelve, para cada elemento de la entrada, la predicción que se obtuvo para ese elemento cuando estaba en el conjunto de prueba. Sólo pueden utilizarse las estrategias de validación cruzada que asignan todos los elementos a un conjunto de prueba exactamente una vez (en caso contrario, se produce una excepción).</p>
<div class="admonition warning">
<p class="admonition-title">Advertencia</p>
<p>Nota sobre el uso inadecuado de cross_val_predict</p>
<p>El resultado de <a class="reference internal" href="generated/sklearn.model_selection.cross_val_predict.html#sklearn.model_selection.cross_val_predict" title="sklearn.model_selection.cross_val_predict"><code class="xref py py-func docutils literal notranslate"><span class="pre">cross_val_predict</span></code></a> puede ser diferente de los obtenidos usando <a class="reference internal" href="generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score" title="sklearn.model_selection.cross_val_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">cross_val_score</span></code></a> ya que los elementos se agrupan de diferentes maneras. La función <a class="reference internal" href="generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score" title="sklearn.model_selection.cross_val_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">cross_val_score</span></code></a> toma un promedio sobre los pliegues de validación, mientras que <a class="reference internal" href="generated/sklearn.model_selection.cross_val_predict.html#sklearn.model_selection.cross_val_predict" title="sklearn.model_selection.cross_val_predict"><code class="xref py py-func docutils literal notranslate"><span class="pre">cross_val_predict</span></code></a> simplemente devuelve las etiquetas (o probabilidades) de varios modelos distintos no listados. Así, <a class="reference internal" href="generated/sklearn.model_selection.cross_val_predict.html#sklearn.model_selection.cross_val_predict" title="sklearn.model_selection.cross_val_predict"><code class="xref py py-func docutils literal notranslate"><span class="pre">cross_val_predict</span></code></a> no es una medida apropiada de error de generalización.</p>
</div>
<dl class="simple">
<dt>La función <a class="reference internal" href="generated/sklearn.model_selection.cross_val_predict.html#sklearn.model_selection.cross_val_predict" title="sklearn.model_selection.cross_val_predict"><code class="xref py py-func docutils literal notranslate"><span class="pre">cross_val_predict</span></code></a> es apropiada para:</dt><dd><ul class="simple">
<li><p>Visualización de las predicciones obtenidas a partir de diferentes modelos.</p></li>
<li><p>Mezcla de modelos: Cuando las predicciones de un estimador supervisado se utilizan para entrenar a otro estimador en métodos de conjunto.</p></li>
</ul>
</dd>
</dl>
<p>Los iteradores de validación cruzada disponibles se presentan en la siguiente sección.</p>
<div class="topic">
<p class="topic-title">Ejemplos</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/model_selection/plot_roc_crossval.html#sphx-glr-auto-examples-model-selection-plot-roc-crossval-py"><span class="std std-ref">Característica operativa del receptor (Receiver Operating Characteristic, ROC) con validación cruzada</span></a>,</p></li>
<li><p><a class="reference internal" href="../auto_examples/feature_selection/plot_rfe_with_cross_validation.html#sphx-glr-auto-examples-feature-selection-plot-rfe-with-cross-validation-py"><span class="std std-ref">Eliminación recursiva de características con validación cruzada</span></a>,</p></li>
<li><p><a class="reference internal" href="../auto_examples/model_selection/plot_grid_search_digits.html#sphx-glr-auto-examples-model-selection-plot-grid-search-digits-py"><span class="std std-ref">Estimación de parámetros utilizando la búsqueda en cuadrícula con validación cruzada</span></a>,</p></li>
<li><p><a class="reference internal" href="../auto_examples/model_selection/grid_search_text_feature_extraction.html#sphx-glr-auto-examples-model-selection-grid-search-text-feature-extraction-py"><span class="std std-ref">Ejemplo de pipeline para la extracción y evaluación de características de texto</span></a>,</p></li>
<li><p><a class="reference internal" href="../auto_examples/model_selection/plot_cv_predict.html#sphx-glr-auto-examples-model-selection-plot-cv-predict-py"><span class="std std-ref">Graficando predicciones con validación cruzada</span></a>,</p></li>
<li><p><a class="reference internal" href="../auto_examples/model_selection/plot_nested_cross_validation_iris.html#sphx-glr-auto-examples-model-selection-plot-nested-cross-validation-iris-py"><span class="std std-ref">Validación cruzada anidada y no anidada</span></a>.</p></li>
</ul>
</div>
</section>
</section>
<section id="cross-validation-iterators">
<h2><span class="section-number">3.1.2. </span>Iteradores de validación cruzada<a class="headerlink" href="#cross-validation-iterators" title="Enlazar permanentemente con este título">¶</a></h2>
<p>En las siguientes secciones se enumeran las utilidades para generar índices que pueden utilizarse para generar divisiones de conjuntos de datos según diferentes estrategias de validación cruzada.</p>
<section id="cross-validation-iterators-for-i-i-d-data">
<span id="iid-cv"></span><h3><span class="section-number">3.1.2.1. </span>Iteradores de validación cruzada para datos i.i.d<a class="headerlink" href="#cross-validation-iterators-for-i-i-d-data" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Asumir que unos datos son independientes e idénticamente distribuidos (i.i.d.) es hacer la suposición de que todas las muestras provienen del mismo proceso generativo y que se supone que el proceso generativo no tiene memoria de las muestras generadas anteriormente.</p>
<p>En estos casos se pueden utilizar los siguientes validadores cruzados.</p>
<div class="admonition note">
<p class="admonition-title">Nota</p>
<p>Aunque los datos i.i.d. son una suposición común en la teoría del aprendizaje automático, rara vez ésto se cumple en la práctica. Si se sabe que las muestras se han generado utilizando un proceso dependiente del tiempo, es más seguro utilizar un <a class="reference internal" href="#timeseries-cv"><span class="std std-ref">esquema de validación cruzada</span></a> que tenga en cuenta las series temporales. Del mismo modo, si sabemos que el proceso generativo tiene una estructura de grupo (muestras recogidas de diferentes sujetos, experimentos, dispositivos de medición), es más seguro utilizar <a class="reference internal" href="#group-cv"><span class="std std-ref">validación cruzada en función del grupo</span></a>.</p>
</div>
<section id="k-fold">
<span id="id2"></span><h4><span class="section-number">3.1.2.1.1. </span>K-fold<a class="headerlink" href="#k-fold" title="Enlazar permanentemente con este título">¶</a></h4>
<p><a class="reference internal" href="generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold" title="sklearn.model_selection.KFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">KFold</span></code></a> divide todas las muestras en <span class="math notranslate nohighlight">\(k\)</span> grupos de muestras, llamados partes (si <span class="math notranslate nohighlight">\(k = n\)</span>, esto equivale a la estrategia <em>Leave One Out</em>), de igual tamaño (si es posible). La función de predicción se aprende utilizando <span class="math notranslate nohighlight">\(k - 1\)</span> partes, y la parte que se deja fuera se utiliza para la prueba.</p>
<p>Ejemplo de validación cruzada de 2 partes en un conjunto de datos con 4 muestras:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;c&quot;</span><span class="p">,</span> <span class="s2">&quot;d&quot;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">kf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">))</span>
<span class="go">[2 3] [0 1]</span>
<span class="go">[0 1] [2 3]</span>
</pre></div>
</div>
<p>Aquí hay una visualización del comportamiento de la validación cruzada. Ten en cuenta que <a class="reference internal" href="generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold" title="sklearn.model_selection.KFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">KFold</span></code></a> no se ve afectado por las clases o grupos.</p>
<figure class="align-center">
<a class="reference external image-reference" href="../auto_examples/model_selection/plot_cv_indices.html"><img alt="../_images/sphx_glr_plot_cv_indices_004.png" src="../_images/sphx_glr_plot_cv_indices_004.png" style="width: 450.0px; height: 225.0px;" /></a>
</figure>
<p>Cada parte está constituida por dos matrices: la primera está relacionada con el <em>conjunto de entrenamiento</em>, y la segunda con el <em>conjunto de prueba</em>. Así, se pueden crear los conjuntos de entrenamiento/prueba utilizando la indexación de numpy:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span> <span class="p">[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.</span><span class="p">],</span> <span class="p">[</span><span class="mf">2.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">X</span><span class="p">[</span><span class="n">train</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">test</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">train</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">test</span><span class="p">]</span>
</pre></div>
</div>
</section>
<section id="repeated-k-fold">
<span id="id3"></span><h4><span class="section-number">3.1.2.1.2. </span>K-Fold repetido<a class="headerlink" href="#repeated-k-fold" title="Enlazar permanentemente con este título">¶</a></h4>
<p><a class="reference internal" href="generated/sklearn.model_selection.RepeatedKFold.html#sklearn.model_selection.RepeatedKFold" title="sklearn.model_selection.RepeatedKFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">RepeatedKFold</span></code></a> repite K-Fold n veces. Se puede utilizar cuando se requiere ejecutar <a class="reference internal" href="generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold" title="sklearn.model_selection.KFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">KFold</span></code></a> n veces, produciendo diferentes divisiones en cada repetición.</p>
<p>Ejemplo de K-Fold repetido 2 veces:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">RepeatedKFold</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">random_state</span> <span class="o">=</span> <span class="mi">12883823</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">rkf</span> <span class="o">=</span> <span class="n">RepeatedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">n_repeats</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">rkf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">))</span>
<span class="gp">...</span>
<span class="go">[2 3] [0 1]</span>
<span class="go">[0 1] [2 3]</span>
<span class="go">[0 2] [1 3]</span>
<span class="go">[1 3] [0 2]</span>
</pre></div>
</div>
<p>Del mismo modo, <a class="reference internal" href="generated/sklearn.model_selection.RepeatedStratifiedKFold.html#sklearn.model_selection.RepeatedStratifiedKFold" title="sklearn.model_selection.RepeatedStratifiedKFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">RepeatedStratifiedKFold</span></code></a> repite el K-Fold estratificado n veces con una aleatorización diferente en cada repetición.</p>
</section>
<section id="leave-one-out-loo">
<span id="leave-one-out"></span><h4><span class="section-number">3.1.2.1.3. </span>Leave One Out (LOO)<a class="headerlink" href="#leave-one-out-loo" title="Enlazar permanentemente con este título">¶</a></h4>
<p><a class="reference internal" href="generated/sklearn.model_selection.LeaveOneOut.html#sklearn.model_selection.LeaveOneOut" title="sklearn.model_selection.LeaveOneOut"><code class="xref py py-class docutils literal notranslate"><span class="pre">LeaveOneOut</span></code></a> (o LOO) es una simple validación cruzada. Cada conjunto de aprendizaje se crea tomando todas las muestras excepto una, siendo el conjunto de prueba la muestra que se deja fuera. Así, para <span class="math notranslate nohighlight">\(n\)</span> muestras, tenemos <span class="math notranslate nohighlight">\(n\)</span> conjuntos de entrenamiento diferentes y <span class="math notranslate nohighlight">\(n\)</span> conjuntos de prueba diferentes. Este procedimiento de validación cruzada no desperdicia muchos datos, ya que sólo se elimina una muestra del conjunto de entrenamiento:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">LeaveOneOut</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">loo</span> <span class="o">=</span> <span class="n">LeaveOneOut</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">loo</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">))</span>
<span class="go">[1 2 3] [0]</span>
<span class="go">[0 2 3] [1]</span>
<span class="go">[0 1 3] [2]</span>
<span class="go">[0 1 2] [3]</span>
</pre></div>
</div>
<p>Los usuarios potenciales de LOO para la selección de modelos deben sopesar algunas advertencias conocidas. Cuando se compara con la validación cruzada <span class="math notranslate nohighlight">\(k\)</span>, se construyen modelos <span class="math notranslate nohighlight">\(n\)</span> a partir de muestras <span class="math notranslate nohighlight">\(n\)</span> en lugar de modelos <span class="math notranslate nohighlight">\(k\)</span>, donde <span class="math notranslate nohighlight">\(n &gt; k\)</span>. Además, cada uno se entrena con muestras <span class="math notranslate nohighlight">\(n - 1\)</span> en lugar de <span class="math notranslate nohighlight">\((k-1) n / k\)</span>. En ambos casos, asumiendo que <span class="math notranslate nohighlight">\(k\)</span> no es demasiado grande y que <span class="math notranslate nohighlight">\(k &lt; n\)</span>, LOO es más costoso computacionalmente que la validación cruzada de <span class="math notranslate nohighlight">\(k\)</span>.</p>
<p>En términos de precisión, la LOO suele dar lugar a una alta varianza como estimador del error de la prueba. Intuitivamente, dado que <span class="math notranslate nohighlight">\(n - 1\)</span> de las muestras <span class="math notranslate nohighlight">\(n\)</span> se utilizan para construir cada modelo, los modelos construidos a partir de partes son prácticamente idénticos entre sí y al modelo construido a partir del conjunto de entrenamiento completo.</p>
<p>Sin embargo, si la curva de aprendizaje es pronunciada para el volumen de entrenamiento en cuestión, la validación cruzada de 5 o 10 partes puede sobreestimar el error de generalización.</p>
<p>Como regla general, la mayoría de los autores, y la evidencia empírica, sugieren que la validación cruzada de 5 o 10 partes debería preferirse a la LOO.</p>
<div class="topic">
<p class="topic-title">Referencias:</p>
<ul class="simple">
<li><p><a class="reference external" href="http://www.faqs.org/faqs/ai-faq/neural-nets/part3/section-12.html">http://www.faqs.org/faqs/ai-faq/neural-nets/part3/section-12.html</a>;</p></li>
<li><p>T. Hastie, R. Tibshirani, J. Friedman,  <a class="reference external" href="https://web.stanford.edu/~hastie/ElemStatLearn/">The Elements of Statistical Learning</a>, Springer 2009</p></li>
<li><p>L. Breiman, P. Spector <a class="reference external" href="http://digitalassets.lib.berkeley.edu/sdtr/ucb/text/197.pdf">Submodel selection and evaluation in regression: The X-random case</a>, International Statistical Review 1992;</p></li>
<li><p>R. Kohavi, <a class="reference external" href="http://web.cs.iastate.edu/~jtian/cs573/Papers/Kohavi-IJCAI-95.pdf">A Study of Cross-Validation and Bootstrap for Accuracy Estimation and Model Selection</a>, Intl. Jnt. Conf. AI</p></li>
<li><p>R. Bharat Rao, G. Fung, R. Rosales, <a class="reference external" href="https://people.csail.mit.edu/romer/papers/CrossVal_SDM08.pdf">On the Dangers of Cross-Validation. An Experimental Evaluation</a>, SIAM 2008;</p></li>
<li><p>G. James, D. Witten, T. Hastie, R Tibshirani, <a class="reference external" href="https://www-bcf.usc.edu/~gareth/ISL/">An Introduction to
Statistical Learning</a>, Springer 2013.</p></li>
</ul>
</div>
</section>
<section id="leave-p-out-lpo">
<span id="leave-p-out"></span><h4><span class="section-number">3.1.2.1.4. </span>Leave P Out (LPO)<a class="headerlink" href="#leave-p-out-lpo" title="Enlazar permanentemente con este título">¶</a></h4>
<p><a class="reference internal" href="generated/sklearn.model_selection.LeavePOut.html#sklearn.model_selection.LeavePOut" title="sklearn.model_selection.LeavePOut"><code class="xref py py-class docutils literal notranslate"><span class="pre">LeavePOut</span></code></a> es muy similar a <a class="reference internal" href="generated/sklearn.model_selection.LeaveOneOut.html#sklearn.model_selection.LeaveOneOut" title="sklearn.model_selection.LeaveOneOut"><code class="xref py py-class docutils literal notranslate"><span class="pre">LeaveOneOut</span></code></a> ya que crea todos los posibles conjuntos de entrenamiento/prueba eliminando las muestras <span class="math notranslate nohighlight">\(p\)</span> del conjunto completo. Para las muestras de <span class="math notranslate nohighlight">\(n\)</span>, esto produce pares de entrenamiento-prueba de <span class="math notranslate nohighlight">\({n \choose p}\)</span>. A diferencia de <a class="reference internal" href="generated/sklearn.model_selection.LeaveOneOut.html#sklearn.model_selection.LeaveOneOut" title="sklearn.model_selection.LeaveOneOut"><code class="xref py py-class docutils literal notranslate"><span class="pre">LeaveOneOut</span></code></a> y <a class="reference internal" href="generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold" title="sklearn.model_selection.KFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">KFold</span></code></a>, los conjuntos de prueba se superponen para <span class="math notranslate nohighlight">\(p &gt; 1\)</span>.</p>
<p>Ejemplo de Leave-2-Out en un conjunto de datos con 4 muestras:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">LeavePOut</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lpo</span> <span class="o">=</span> <span class="n">LeavePOut</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">lpo</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">))</span>
<span class="go">[2 3] [0 1]</span>
<span class="go">[1 3] [0 2]</span>
<span class="go">[1 2] [0 3]</span>
<span class="go">[0 3] [1 2]</span>
<span class="go">[0 2] [1 3]</span>
<span class="go">[0 1] [2 3]</span>
</pre></div>
</div>
</section>
<section id="random-permutations-cross-validation-a-k-a-shuffle-split">
<span id="shufflesplit"></span><h4><span class="section-number">3.1.2.1.5. </span>Validación cruzada de permutaciones aleatorias, también conocida como Mezcla y División<a class="headerlink" href="#random-permutations-cross-validation-a-k-a-shuffle-split" title="Enlazar permanentemente con este título">¶</a></h4>
<p>El iterador <a class="reference internal" href="generated/sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit" title="sklearn.model_selection.ShuffleSplit"><code class="xref py py-class docutils literal notranslate"><span class="pre">ShuffleSplit</span></code></a> generará un número definido por el usuario de divisiones independientes del conjunto de datos de entrenamiento/prueba. Las muestras se barajan primero y luego se dividen en un par de conjuntos de entrenamiento y prueba.</p>
<p>Es posible controlar la aleatoriedad para la reproducibilidad de los resultados sembrando explícitamente el generador de números pseudoaleatorios <code class="docutils literal notranslate"><span class="pre">random_state</span></code>.</p>
<p>Este es un ejemplo de uso:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">ShuffleSplit</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ss</span> <span class="o">=</span> <span class="n">ShuffleSplit</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span> <span class="ow">in</span> <span class="n">ss</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">train_index</span><span class="p">,</span> <span class="n">test_index</span><span class="p">))</span>
<span class="go">[9 1 6 7 3 0 5] [2 8 4]</span>
<span class="go">[2 9 8 0 6 7 4] [3 5 1]</span>
<span class="go">[4 5 1 0 6 9 7] [2 3 8]</span>
<span class="go">[2 7 5 8 0 3 4] [6 1 9]</span>
<span class="go">[4 1 0 6 8 9 3] [5 2 7]</span>
</pre></div>
</div>
<p>Aquí hay una visualización del comportamiento de la validación cruzada. Tenga en cuenta que <a class="reference internal" href="generated/sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit" title="sklearn.model_selection.ShuffleSplit"><code class="xref py py-class docutils literal notranslate"><span class="pre">ShuffleSplit</span></code></a> no se ve afectado por las clases o grupos.</p>
<figure class="align-center">
<a class="reference external image-reference" href="../auto_examples/model_selection/plot_cv_indices.html"><img alt="../_images/sphx_glr_plot_cv_indices_006.png" src="../_images/sphx_glr_plot_cv_indices_006.png" style="width: 450.0px; height: 225.0px;" /></a>
</figure>
<p>Por tanto, <a class="reference internal" href="generated/sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit" title="sklearn.model_selection.ShuffleSplit"><code class="xref py py-class docutils literal notranslate"><span class="pre">ShuffleSplit</span></code></a> es una buena alternativa a la validación cruzada <a class="reference internal" href="generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold" title="sklearn.model_selection.KFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">KFold</span></code></a> que permite un control más fino del número de iteraciones y de la proporción de muestras en cada lado de la división entrenamiento/prueba.</p>
</section>
</section>
<section id="cross-validation-iterators-with-stratification-based-on-class-labels">
<span id="stratification"></span><h3><span class="section-number">3.1.2.2. </span>Iteradores de validación cruzada con estratificación basada en las etiquetas de clase.<a class="headerlink" href="#cross-validation-iterators-with-stratification-based-on-class-labels" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Algunos problemas de clasificación pueden presentar un gran desequilibrio en la distribución de las clases objetivo: por ejemplo, puede haber varias veces más muestras negativas que positivas. En estos casos se recomienda utilizar el muestreo estratificado como se implementa en <a class="reference internal" href="generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold" title="sklearn.model_selection.StratifiedKFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">StratifiedKFold</span></code></a> y <a class="reference internal" href="generated/sklearn.model_selection.StratifiedShuffleSplit.html#sklearn.model_selection.StratifiedShuffleSplit" title="sklearn.model_selection.StratifiedShuffleSplit"><code class="xref py py-class docutils literal notranslate"><span class="pre">StratifiedShuffleSplit</span></code></a> para asegurar que las frecuencias relativas de las clases se conserven aproximadamente en cada parte de entrenamiento y validación.</p>
<section id="stratified-k-fold">
<span id="id4"></span><h4><span class="section-number">3.1.2.2.1. </span>K-fold estratificado<a class="headerlink" href="#stratified-k-fold" title="Enlazar permanentemente con este título">¶</a></h4>
<p><a class="reference internal" href="generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold" title="sklearn.model_selection.StratifiedKFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">StratifiedKFold</span></code></a> es una variación de <em>k-fold</em> que devuelve partes <em>estratificadas</em>: cada conjunto contiene aproximadamente el mismo porcentaje de muestras de cada clase objetivo que el conjunto completo.</p>
<p>Este es un ejemplo de validación cruzada estratificada de 3 partes en un conjunto de datos con 50 muestras de dos clases no equilibradas.  Se presenta el número de muestras de cada clase y se compara con <a class="reference internal" href="generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold" title="sklearn.model_selection.KFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">KFold</span></code></a>.</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">StratifiedKFold</span><span class="p">,</span> <span class="n">KFold</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">((</span><span class="mi">50</span><span class="p">,</span> <span class="mi">1</span><span class="p">)),</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">(([</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="mi">45</span><span class="p">,</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mi">5</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">skf</span> <span class="o">=</span> <span class="n">StratifiedKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">skf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;train -  </span><span class="si">{}</span><span class="s1">   |   test -  </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
<span class="gp">... </span>        <span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="n">train</span><span class="p">]),</span> <span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="n">test</span><span class="p">])))</span>
<span class="go">train -  [30  3]   |   test -  [15  2]</span>
<span class="go">train -  [30  3]   |   test -  [15  2]</span>
<span class="go">train -  [30  4]   |   test -  [15  1]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">kf</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">kf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;train -  </span><span class="si">{}</span><span class="s1">   |   test -  </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
<span class="gp">... </span>        <span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="n">train</span><span class="p">]),</span> <span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="n">test</span><span class="p">])))</span>
<span class="go">train -  [28  5]   |   test -  [17]</span>
<span class="go">train -  [28  5]   |   test -  [17]</span>
<span class="go">train -  [34]   |   test -  [11  5]</span>
</pre></div>
</div>
<p>Podemos ver que <a class="reference internal" href="generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold" title="sklearn.model_selection.StratifiedKFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">StratifiedKFold</span></code></a> preserva los ratios de clase (aproximadamente 1 / 10) tanto en el conjunto de datos de entrenamiento como en el de prueba.</p>
<p>Aquí hay una visualización del comportamiento de la validación cruzada.</p>
<figure class="align-center">
<a class="reference external image-reference" href="../auto_examples/model_selection/plot_cv_indices.html"><img alt="../_images/sphx_glr_plot_cv_indices_007.png" src="../_images/sphx_glr_plot_cv_indices_007.png" style="width: 450.0px; height: 225.0px;" /></a>
</figure>
<p><a class="reference internal" href="generated/sklearn.model_selection.RepeatedStratifiedKFold.html#sklearn.model_selection.RepeatedStratifiedKFold" title="sklearn.model_selection.RepeatedStratifiedKFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">RepeatedStratifiedKFold</span></code></a> se puede utilizar para repetir el K-Fold Estratificado n veces con diferente aleatorización en cada repetición.</p>
</section>
<section id="stratified-shuffle-split">
<span id="id5"></span><h4><span class="section-number">3.1.2.2.2. </span>División aleatoria estratificada<a class="headerlink" href="#stratified-shuffle-split" title="Enlazar permanentemente con este título">¶</a></h4>
<p><a class="reference internal" href="generated/sklearn.model_selection.StratifiedShuffleSplit.html#sklearn.model_selection.StratifiedShuffleSplit" title="sklearn.model_selection.StratifiedShuffleSplit"><code class="xref py py-class docutils literal notranslate"><span class="pre">StratifiedShuffleSplit</span></code></a> es una variación de <em>Mezcla y División</em>, que devuelve divisiones estratificadas, <em>es decir</em> que crea divisiones conservando el mismo porcentaje para cada clase objetivo que en el conjunto completo.</p>
<p>Aquí hay una visualización del comportamiento de la validación cruzada.</p>
<figure class="align-center">
<a class="reference external image-reference" href="../auto_examples/model_selection/plot_cv_indices.html"><img alt="../_images/sphx_glr_plot_cv_indices_009.png" src="../_images/sphx_glr_plot_cv_indices_009.png" style="width: 450.0px; height: 225.0px;" /></a>
</figure>
</section>
</section>
<section id="cross-validation-iterators-for-grouped-data">
<span id="group-cv"></span><h3><span class="section-number">3.1.2.3. </span>Iteradores de validación cruzada para datos agrupados.<a class="headerlink" href="#cross-validation-iterators-for-grouped-data" title="Enlazar permanentemente con este título">¶</a></h3>
<p>La suposición i.i.d. se rompe si el proceso generativo subyacente produce grupos de muestras dependientes.</p>
<p>Tal agrupación de datos es específica del dominio. Un ejemplo sería cuando hay datos médicos recogidos de múltiples pacientes, con múltiples muestras tomadas de cada paciente. Y es probable que esos datos sean dependientes del grupo individual. En nuestro ejemplo, el identificador del paciente de cada muestra será su identificador de grupo.</p>
<p>En este caso, nos gustaría saber si un modelo entrenado en un determinado conjunto de grupos generaliza bien a los grupos no vistos. Para medirlo, tenemos que asegurarnos de que todas las muestras en esa parte de la validación proceden de grupos que no están representados en absoluto en la parte de entrenamiento emparejado.</p>
<p>Para ello, se pueden utilizar los siguientes divisores de validación cruzada. El identificador de agrupación de las muestras se especifica mediante el parámetro <code class="docutils literal notranslate"><span class="pre">groups</span></code>.</p>
<section id="group-k-fold">
<span id="id6"></span><h4><span class="section-number">3.1.2.3.1. </span>K-fold de grupos<a class="headerlink" href="#group-k-fold" title="Enlazar permanentemente con este título">¶</a></h4>
<p><a class="reference internal" href="generated/sklearn.model_selection.GroupKFold.html#sklearn.model_selection.GroupKFold" title="sklearn.model_selection.GroupKFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">GroupKFold</span></code></a> es una variación de k-fold que garantiza que el mismo grupo no esté representado en los conjuntos de prueba y de entrenamiento. Por ejemplo, si los datos se obtienen de diferentes sujetos con varias muestras por sujeto y si el modelo es lo suficientemente flexible como para aprender de características muy específicas de la persona, podría fallar al generalizar para nuevos sujetos. <a class="reference internal" href="generated/sklearn.model_selection.GroupKFold.html#sklearn.model_selection.GroupKFold" title="sklearn.model_selection.GroupKFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">GroupKFold</span></code></a> permite detectar este tipo de situaciones de sobreajuste.</p>
<p>Imagina que tienes tres sujetos, cada uno con un número asociado del 1 al 3:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GroupKFold</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">2.2</span><span class="p">,</span> <span class="mf">2.4</span><span class="p">,</span> <span class="mf">2.3</span><span class="p">,</span> <span class="mf">4.55</span><span class="p">,</span> <span class="mf">5.8</span><span class="p">,</span> <span class="mf">8.8</span><span class="p">,</span> <span class="mi">9</span><span class="p">,</span> <span class="mi">10</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;c&quot;</span><span class="p">,</span> <span class="s2">&quot;c&quot;</span><span class="p">,</span> <span class="s2">&quot;c&quot;</span><span class="p">,</span> <span class="s2">&quot;d&quot;</span><span class="p">,</span> <span class="s2">&quot;d&quot;</span><span class="p">,</span> <span class="s2">&quot;d&quot;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">groups</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">gkf</span> <span class="o">=</span> <span class="n">GroupKFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">gkf</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="n">groups</span><span class="p">):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">))</span>
<span class="go">[0 1 2 3 4 5] [6 7 8 9]</span>
<span class="go">[0 1 2 6 7 8 9] [3 4 5]</span>
<span class="go">[3 4 5 6 7 8 9] [0 1 2]</span>
</pre></div>
</div>
<p>Cada sujeto está en un pliegue de prueba diferente, y el mismo sujeto nunca está tanto en la prueba como en el entrenamiento. Observa que las partes no tienen exactamente el mismo tamaño debido al desequilibrio de los datos.</p>
<p>Aquí hay una visualización del comportamiento de la validación cruzada.</p>
<figure class="align-center">
<a class="reference external image-reference" href="../auto_examples/model_selection/plot_cv_indices.html"><img alt="../_images/sphx_glr_plot_cv_indices_005.png" src="../_images/sphx_glr_plot_cv_indices_005.png" style="width: 450.0px; height: 225.0px;" /></a>
</figure>
</section>
<section id="leave-one-group-out">
<span id="id7"></span><h4><span class="section-number">3.1.2.3.2. </span>Dejar un grupo afuera (Leave One Group Out)<a class="headerlink" href="#leave-one-group-out" title="Enlazar permanentemente con este título">¶</a></h4>
<p><a class="reference internal" href="generated/sklearn.model_selection.LeaveOneGroupOut.html#sklearn.model_selection.LeaveOneGroupOut" title="sklearn.model_selection.LeaveOneGroupOut"><code class="xref py py-class docutils literal notranslate"><span class="pre">LeaveOneGroupOut</span></code></a> es un esquema de validación cruzada que mantiene las muestras según una matriz de grupos enteros proporcionada por terceros. Esta información de grupo puede utilizarse para codificar partes de validación cruzada predefinidas y específicas del dominio.</p>
<p>De este modo, cada conjunto de entrenamiento está constituido por todas las muestras excepto las relacionadas con un grupo específico.</p>
<p>Por ejemplo, en los casos de experimentos múltiples, se puede utilizar <a class="reference internal" href="generated/sklearn.model_selection.LeaveOneGroupOut.html#sklearn.model_selection.LeaveOneGroupOut" title="sklearn.model_selection.LeaveOneGroupOut"><code class="xref py py-class docutils literal notranslate"><span class="pre">LeaveOneGroupOut</span></code></a> para crear una validación cruzada basada en los diferentes experimentos: creamos un conjunto de entrenamiento utilizando las muestras de todos los experimentos excepto uno:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">LeaveOneGroupOut</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">60</span><span class="p">,</span> <span class="mi">70</span><span class="p">,</span> <span class="mi">80</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">groups</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">logo</span> <span class="o">=</span> <span class="n">LeaveOneGroupOut</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">logo</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="n">groups</span><span class="p">):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">))</span>
<span class="go">[2 3 4 5 6] [0 1]</span>
<span class="go">[0 1 4 5 6] [2 3]</span>
<span class="go">[0 1 2 3] [4 5 6]</span>
</pre></div>
</div>
<p>Otra aplicación común es utilizar información temporal: por ejemplo, los grupos podrían ser el año de recogida de las muestras y así permitir la validación cruzada contra divisiones basadas en el tiempo.</p>
</section>
<section id="leave-p-groups-out">
<span id="id8"></span><h4><span class="section-number">3.1.2.3.3. </span>Dejar fuera los grupos P<a class="headerlink" href="#leave-p-groups-out" title="Enlazar permanentemente con este título">¶</a></h4>
<p><a class="reference internal" href="generated/sklearn.model_selection.LeavePGroupsOut.html#sklearn.model_selection.LeavePGroupsOut" title="sklearn.model_selection.LeavePGroupsOut"><code class="xref py py-class docutils literal notranslate"><span class="pre">LeavePGroupsOut</span></code></a> es similar a <a class="reference internal" href="generated/sklearn.model_selection.LeaveOneGroupOut.html#sklearn.model_selection.LeaveOneGroupOut" title="sklearn.model_selection.LeaveOneGroupOut"><code class="xref py py-class docutils literal notranslate"><span class="pre">LeaveOneGroupOut</span></code></a>, pero elimina las muestras relacionadas con los grupos de <span class="math notranslate nohighlight">\(P\)</span> para cada conjunto de entrenamiento/prueba.</p>
<p>Ejemplo de Dejar-2-Grupos Afuera:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">LeavePGroupsOut</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">groups</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">lpgo</span> <span class="o">=</span> <span class="n">LeavePGroupsOut</span><span class="p">(</span><span class="n">n_groups</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">lpgo</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="n">groups</span><span class="p">):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">))</span>
<span class="go">[4 5] [0 1 2 3]</span>
<span class="go">[2 3] [0 1 4 5]</span>
<span class="go">[0 1] [2 3 4 5]</span>
</pre></div>
</div>
</section>
<section id="group-shuffle-split">
<span id="id9"></span><h4><span class="section-number">3.1.2.3.4. </span>Dividir grupos de forma aleatoria<a class="headerlink" href="#group-shuffle-split" title="Enlazar permanentemente con este título">¶</a></h4>
<p>El iterador <a class="reference internal" href="generated/sklearn.model_selection.GroupShuffleSplit.html#sklearn.model_selection.GroupShuffleSplit" title="sklearn.model_selection.GroupShuffleSplit"><code class="xref py py-class docutils literal notranslate"><span class="pre">GroupShuffleSplit</span></code></a> se comporta como una combinación de <a class="reference internal" href="generated/sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit" title="sklearn.model_selection.ShuffleSplit"><code class="xref py py-class docutils literal notranslate"><span class="pre">ShuffleSplit</span></code></a> y <a class="reference internal" href="generated/sklearn.model_selection.LeavePGroupsOut.html#sklearn.model_selection.LeavePGroupsOut" title="sklearn.model_selection.LeavePGroupsOut"><code class="xref py py-class docutils literal notranslate"><span class="pre">LeavePGroupsOut</span></code></a>, y genera una secuencia de particiones aleatorias en las que se mantiene un subconjunto de grupos para cada partición.</p>
<p>Este es un ejemplo de uso:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GroupShuffleSplit</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">2.2</span><span class="p">,</span> <span class="mf">2.4</span><span class="p">,</span> <span class="mf">2.3</span><span class="p">,</span> <span class="mf">4.55</span><span class="p">,</span> <span class="mf">5.8</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;c&quot;</span><span class="p">,</span> <span class="s2">&quot;c&quot;</span><span class="p">,</span> <span class="s2">&quot;c&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">groups</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">gss</span> <span class="o">=</span> <span class="n">GroupShuffleSplit</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">gss</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="o">=</span><span class="n">groups</span><span class="p">):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">))</span>
<span class="gp">...</span>
<span class="go">[0 1 2 3] [4 5 6 7]</span>
<span class="go">[2 3 6 7] [0 1 4 5]</span>
<span class="go">[2 3 4 5] [0 1 6 7]</span>
<span class="go">[4 5 6 7] [0 1 2 3]</span>
</pre></div>
</div>
<p>Aquí hay una visualización del comportamiento de la validación cruzada.</p>
<figure class="align-center">
<a class="reference external image-reference" href="../auto_examples/model_selection/plot_cv_indices.html"><img alt="../_images/sphx_glr_plot_cv_indices_008.png" src="../_images/sphx_glr_plot_cv_indices_008.png" style="width: 450.0px; height: 225.0px;" /></a>
</figure>
<p>Esta clase es útil cuando se desea el comportamiento de <a class="reference internal" href="generated/sklearn.model_selection.LeavePGroupsOut.html#sklearn.model_selection.LeavePGroupsOut" title="sklearn.model_selection.LeavePGroupsOut"><code class="xref py py-class docutils literal notranslate"><span class="pre">LeavePGroupsOut</span></code></a>, pero el número de grupos es lo suficientemente grande como para que generar todas las posibles particiones con grupos retenidos de <span class="math notranslate nohighlight">\(P\)</span> sea prohibitivamente costoso. En este caso, <a class="reference internal" href="generated/sklearn.model_selection.GroupShuffleSplit.html#sklearn.model_selection.GroupShuffleSplit" title="sklearn.model_selection.GroupShuffleSplit"><code class="xref py py-class docutils literal notranslate"><span class="pre">GroupShuffleSplit</span></code></a> proporciona una muestra aleatoria (con reemplazo) de las particiones de entrenamiento/prueba generadas por <a class="reference internal" href="generated/sklearn.model_selection.LeavePGroupsOut.html#sklearn.model_selection.LeavePGroupsOut" title="sklearn.model_selection.LeavePGroupsOut"><code class="xref py py-class docutils literal notranslate"><span class="pre">LeavePGroupsOut</span></code></a>.</p>
</section>
</section>
<section id="predefined-fold-splits-validation-sets">
<span id="predefined-split"></span><h3><span class="section-number">3.1.2.4. </span>Divisiones predefinidas/ Conjuntos de validación<a class="headerlink" href="#predefined-fold-splits-validation-sets" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Para algunos conjuntos de datos, ya existe una división predefinida de los datos en pliegues (fold) de entrenamiento y validación o en varios pliegues de validación cruzada. Utilizando <a class="reference internal" href="generated/sklearn.model_selection.PredefinedSplit.html#sklearn.model_selection.PredefinedSplit" title="sklearn.model_selection.PredefinedSplit"><code class="xref py py-class docutils literal notranslate"><span class="pre">PredefinedSplit</span></code></a> es posible utilizar estos pliegues, por ejemplo, cuando se buscan hiperparámetros.</p>
<p>Por ejemplo, cuando se utiliza un conjunto de validación, establezca el <code class="docutils literal notranslate"><span class="pre">test_fold</span></code> a 0 para todas las muestras que forman parte del conjunto de validación, y a -1 para todas las demás muestras.</p>
</section>
<section id="using-cross-validation-iterators-to-split-train-and-test">
<h3><span class="section-number">3.1.2.5. </span>Uso de los iteradores de validación cruzada para dividir el entrenamiento y la prueba<a class="headerlink" href="#using-cross-validation-iterators-to-split-train-and-test" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Las anteriores funciones de validación cruzada de grupo también pueden ser útiles para dividir un conjunto de datos en subconjuntos de entrenamiento y prueba. Ten en cuenta que la función <a class="reference internal" href="generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split" title="sklearn.model_selection.train_test_split"><code class="xref py py-func docutils literal notranslate"><span class="pre">train_test_split</span></code></a> es un envoltorio de <a class="reference internal" href="generated/sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit" title="sklearn.model_selection.ShuffleSplit"><code class="xref py py-func docutils literal notranslate"><span class="pre">ShuffleSplit</span></code></a> y, por tanto, sólo permite la división estratificada (utilizando las etiquetas de clase) y no puede tener en cuenta los grupos.</p>
<p>Para realizar la división de entrenamiento y prueba, utiliza los índices de los subconjuntos de entrenamiento y prueba producidos por la salida del generador mediante el método <code class="docutils literal notranslate"><span class="pre">split()</span></code> del divisor de validación cruzada. Por ejemplo:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GroupShuffleSplit</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.1</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">,</span> <span class="mf">2.2</span><span class="p">,</span> <span class="mf">2.4</span><span class="p">,</span> <span class="mf">2.3</span><span class="p">,</span> <span class="mf">4.55</span><span class="p">,</span> <span class="mf">5.8</span><span class="p">,</span> <span class="mf">0.001</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="s2">&quot;a&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;b&quot;</span><span class="p">,</span> <span class="s2">&quot;c&quot;</span><span class="p">,</span> <span class="s2">&quot;c&quot;</span><span class="p">,</span> <span class="s2">&quot;c&quot;</span><span class="p">,</span> <span class="s2">&quot;a&quot;</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">groups</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">train_indx</span><span class="p">,</span> <span class="n">test_indx</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">GroupShuffleSplit</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">groups</span><span class="p">)</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> \
<span class="gp">... </span>    <span class="n">X</span><span class="p">[</span><span class="n">train_indx</span><span class="p">],</span> <span class="n">X</span><span class="p">[</span><span class="n">test_indx</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">train_indx</span><span class="p">],</span> <span class="n">y</span><span class="p">[</span><span class="n">test_indx</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">X_test</span><span class="o">.</span><span class="n">shape</span>
<span class="go">((6,), (2,))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">groups</span><span class="p">[</span><span class="n">train_indx</span><span class="p">]),</span> <span class="n">np</span><span class="o">.</span><span class="n">unique</span><span class="p">(</span><span class="n">groups</span><span class="p">[</span><span class="n">test_indx</span><span class="p">])</span>
<span class="go">(array([1, 2, 4]), array([3]))</span>
</pre></div>
</div>
</section>
<section id="cross-validation-of-time-series-data">
<span id="timeseries-cv"></span><h3><span class="section-number">3.1.2.6. </span>Validación cruzada de datos de series de tiempo<a class="headerlink" href="#cross-validation-of-time-series-data" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Los datos de las series de tiempo se caracterizan por la correlación entre observaciones cercanas en el tiempo (<em>autocorrelación</em>). Sin embargo, las técnicas clásicas de validación cruzada, como <a class="reference internal" href="generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold" title="sklearn.model_selection.KFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">KFold</span></code></a> y <a class="reference internal" href="generated/sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit" title="sklearn.model_selection.ShuffleSplit"><code class="xref py py-class docutils literal notranslate"><span class="pre">ShuffleSplit</span></code></a>, suponen que las muestras son independientes y están idénticamente distribuidas, y darían lugar a una correlación poco razonable entre las instancias de entrenamiento y las de prueba (lo que daría lugar a malas estimaciones del error de generalización) en los datos de series de tiempo. Por lo tanto, es muy importante evaluar nuestro modelo para datos de series de tiempo en las observaciones «futuras» menos parecidas a las que se utilizan para entrenar el modelo. Para conseguirlo, una solución es la que proporciona <a class="reference internal" href="generated/sklearn.model_selection.TimeSeriesSplit.html#sklearn.model_selection.TimeSeriesSplit" title="sklearn.model_selection.TimeSeriesSplit"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeriesSplit</span></code></a>.</p>
<section id="time-series-split">
<span id="id10"></span><h4><span class="section-number">3.1.2.6.1. </span>División de series de tiempo<a class="headerlink" href="#time-series-split" title="Enlazar permanentemente con este título">¶</a></h4>
<p><a class="reference internal" href="generated/sklearn.model_selection.TimeSeriesSplit.html#sklearn.model_selection.TimeSeriesSplit" title="sklearn.model_selection.TimeSeriesSplit"><code class="xref py py-class docutils literal notranslate"><span class="pre">TimeSeriesSplit</span></code></a> es una variación de <em>k-fold</em> que devuelve los primeros pliegues de <span class="math notranslate nohighlight">\(k\)</span> como conjunto de entrenamiento y el <span class="math notranslate nohighlight">\((k+1)\)</span> última parte como conjunto de prueba. Tenga en cuenta que, a diferencia de los métodos estándar de validación cruzada, los conjuntos de entrenamiento sucesivos son superconjuntos de los que vienen antes. Además, añade todos los datos sobrantes a la primera partición de entrenamiento, que siempre se utiliza para entrenar el modelo.</p>
<p>Esta clase puede utilizarse para la validación cruzada de muestras de datos de series de tiempo que se observan en intervalos de tiempo fijos.</p>
<p>Ejemplo de validación cruzada de series de tiempo con 3 divisiones en un conjunto de datos con 6 muestras:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">TimeSeriesSplit</span>

<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">tscv</span> <span class="o">=</span> <span class="n">TimeSeriesSplit</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">tscv</span><span class="p">)</span>
<span class="go">TimeSeriesSplit(gap=0, max_train_size=None, n_splits=3, test_size=None)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">tscv</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">%s</span><span class="s2"> </span><span class="si">%s</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">))</span>
<span class="go">[0 1 2] [3]</span>
<span class="go">[0 1 2 3] [4]</span>
<span class="go">[0 1 2 3 4] [5]</span>
</pre></div>
</div>
<p>Aquí hay una visualización del comportamiento de la validación cruzada.</p>
<figure class="align-center">
<a class="reference external image-reference" href="../auto_examples/model_selection/plot_cv_indices.html"><img alt="../_images/sphx_glr_plot_cv_indices_010.png" src="../_images/sphx_glr_plot_cv_indices_010.png" style="width: 450.0px; height: 225.0px;" /></a>
</figure>
</section>
</section>
</section>
<section id="a-note-on-shuffling">
<h2><span class="section-number">3.1.3. </span>Nota sobre la mezcla<a class="headerlink" href="#a-note-on-shuffling" title="Enlazar permanentemente con este título">¶</a></h2>
<p>Si el orden de los datos no es arbitrario (por ejemplo, las muestras con la misma etiqueta de clase son contiguas), revolverlas primero puede ser esencial para obtener un resultado de validación cruzada significativo. Sin embargo, puede ocurrir lo contrario si las muestras no están distribuidas de forma independiente e idéntica. Por ejemplo, si las muestras corresponden a artículos de noticias, y están ordenadas por su hora de publicación, entonces revolver los datos probablemente conducirá a un modelo sobreajustado y a una puntuación de validación inflada: se probará en muestras que son artificialmente similares (cercanas en el tiempo) a las muestras de entrenamiento.</p>
<p>Algunos iteradores de validación cruzada, como <a class="reference internal" href="generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold" title="sklearn.model_selection.KFold"><code class="xref py py-class docutils literal notranslate"><span class="pre">KFold</span></code></a>, tienen una opción incorporada para revolver los índices de datos antes de dividirlos. Tenga en cuenta que:</p>
<ul class="simple">
<li><p>Esto consume menos memoria que revolver los datos directamente.</p></li>
<li><p>Por defecto no se revuelve, incluso para la validación cruzada (estratificada) de K partes que se realiza especificando <code class="docutils literal notranslate"><span class="pre">cv=algunos_integros</span></code> a <a class="reference internal" href="generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score" title="sklearn.model_selection.cross_val_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">cross_val_score</span></code></a>, búsqueda en cuadrícula, etc. Tenga en cuenta que <a class="reference internal" href="generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split" title="sklearn.model_selection.train_test_split"><code class="xref py py-func docutils literal notranslate"><span class="pre">train_test_split</span></code></a> sigue devolviendo una división aleatoria.</p></li>
<li><p>El parámetro <code class="docutils literal notranslate"><span class="pre">random_state</span></code> es por defecto <code class="docutils literal notranslate"><span class="pre">None</span></code>, lo que significa que la forma de revolver será diferente cada vez que se itere <code class="docutils literal notranslate"><span class="pre">KFold(...,</span> <span class="pre">shuffle=True)</span></code>. Sin embargo, <code class="docutils literal notranslate"><span class="pre">GridSearchCV</span></code> utilizará el mismo proceso de revolver para cada conjunto de parámetros validados por una única llamada a su método <code class="docutils literal notranslate"><span class="pre">fit</span></code>.</p></li>
<li><p>Para obtener resultados idénticos para cada división, establezca <code class="docutils literal notranslate"><span class="pre">random_state</span></code> a un número entero.</p></li>
</ul>
<p>Para más detalles sobre cómo controlar la aleatoriedad de los divisores de cv y evitar errores comunes, véase <a class="reference internal" href="../common_pitfalls.html#randomness"><span class="std std-ref">Control de aleatoriedad</span></a>.</p>
</section>
<section id="cross-validation-and-model-selection">
<h2><span class="section-number">3.1.4. </span>Validación cruzada y selección de modelos<a class="headerlink" href="#cross-validation-and-model-selection" title="Enlazar permanentemente con este título">¶</a></h2>
<p>Los iteradores de validación cruzada también pueden utilizarse para realizar directamente la selección del modelo mediante la búsqueda en cuadrícula de los hiperparámetros óptimos del modelo. Este es el tema de la siguiente sección: <a class="reference internal" href="grid_search.html#grid-search"><span class="std std-ref">Ajustar los hiperparámetros de un estimador</span></a>.</p>
</section>
<section id="permutation-test-score">
<span id="id11"></span><h2><span class="section-number">3.1.5. </span>Puntuación de la prueba de permutación<a class="headerlink" href="#permutation-test-score" title="Enlazar permanentemente con este título">¶</a></h2>
<p><a class="reference internal" href="generated/sklearn.model_selection.permutation_test_score.html#sklearn.model_selection.permutation_test_score" title="sklearn.model_selection.permutation_test_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">permutation_test_score</span></code></a> ofrece otra forma de evaluar el rendimiento de los clasificadores. Proporciona un valor p basado en la permutación, que representa la probabilidad de que un rendimiento observado del clasificador se obtenga por azar. La hipótesis nula en esta prueba es que el clasificador no aprovecha ninguna dependencia estadística entre las características y las etiquetas para hacer predicciones correctas en los datos omitidos. <a class="reference internal" href="generated/sklearn.model_selection.permutation_test_score.html#sklearn.model_selection.permutation_test_score" title="sklearn.model_selection.permutation_test_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">permutation_test_score</span></code></a> genera una distribución nula calculando <code class="docutils literal notranslate"><span class="pre">n_permutaciones</span></code> diferentes de los datos. En cada permutación las etiquetas se revuelven aleatoriamente, eliminando así cualquier dependencia entre las características y las etiquetas. El valor p resultante es la fracción de permutaciones para las que la puntuación media de validación cruzada obtenida por el modelo es mejor que la puntuación de validación cruzada obtenida por el modelo utilizando los datos originales. Para obtener resultados fiables, <code class="docutils literal notranslate"><span class="pre">n_permutaciones</span></code> debe ser normalmente superior a 100 y <code class="docutils literal notranslate"><span class="pre">cv</span></code> entre 3-10 partes.</p>
<p>Un valor p bajo demuestra que el conjunto de datos contiene una dependencia real entre las características y las etiquetas y que el clasificador ha sido capaz de utilizarla para obtener buenos resultados. Un valor p alto podría deberse a la falta de dependencia entre las características y las etiquetas (no hay diferencias en los valores de las características entre las clases) o a que el clasificador no fue capaz de utilizar la dependencia en los datos. En este último caso, el uso de un clasificador más adecuado que sea capaz de utilizar la estructura de los datos daría lugar a un valor p bajo.</p>
<p>La validación cruzada proporciona información sobre el grado de generalización de un clasificador, concretamente el rango de errores esperados del clasificador. Sin embargo, un clasificador entrenado en un conjunto de datos de alta dimensión sin estructura puede tener un rendimiento mejor de lo esperado en la validación cruzada, por pura casualidad. Esto puede ocurrir típicamente con conjuntos de datos pequeños con menos de unos cientos de muestras. <a class="reference internal" href="generated/sklearn.model_selection.permutation_test_score.html#sklearn.model_selection.permutation_test_score" title="sklearn.model_selection.permutation_test_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">permutation_test_score</span></code></a> proporciona información sobre si el clasificador ha encontrado una estructura de clase real y puede ayudar a evaluar el rendimiento del clasificador.</p>
<p>Es importante señalar que se ha demostrado que esta prueba produce valores p bajos incluso si sólo hay una estructura débil en los datos, porque en los conjuntos de datos permutados correspondientes no hay absolutamente ninguna estructura. Por lo tanto, esta prueba sólo es capaz de mostrar cuándo el modelo supera de forma fiable las conjeturas al azar.</p>
<p>Por último, <a class="reference internal" href="generated/sklearn.model_selection.permutation_test_score.html#sklearn.model_selection.permutation_test_score" title="sklearn.model_selection.permutation_test_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">permutation_test_score</span></code></a> se calcula utilizando la fuerza bruta y se ajusta internamente a los modelos <code class="docutils literal notranslate"><span class="pre">(n_permutations</span> <span class="pre">+</span> <span class="pre">1)</span> <span class="pre">*</span> <span class="pre">n_cv</span></code>. Por lo tanto, sólo es viable con conjuntos de datos pequeños para los que el ajuste de un modelo individual es muy rápido.</p>
<div class="topic">
<p class="topic-title">Ejemplos</p>
<ul class="simple">
<li><p><a class="reference internal" href="../auto_examples/feature_selection/plot_permutation_test_for_classification.html#sphx-glr-auto-examples-feature-selection-plot-permutation-test-for-classification-py"><span class="std std-ref">Evalúa con permutaciones la importancia de una puntuación de clasificación</span></a></p></li>
</ul>
</div>
<div class="topic">
<p class="topic-title">Referencias:</p>
<ul class="simple">
<li><p>Ojala and Garriga. <a class="reference external" href="http://www.jmlr.org/papers/volume11/ojala10a/ojala10a.pdf">Permutation Tests for Studying Classifier Performance</a>.
J. Mach. Learn. Res. 2010.</p></li>
</ul>
</div>
</section>
</section>


      </div>
    <div class="container">
      <footer class="sk-content-footer">
            &copy; 2007 - 2020, scikit-learn developers (BSD License).
          <a href="../_sources/modules/cross_validation.rst.txt" rel="nofollow">Mostrar la fuente de esta página</a>
      </footer>
    </div>
  </div>
</div>
<script src="../_static/js/vendor/bootstrap.min.js"></script>

<script>
    window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
    ga('create', 'UA-22606712-2', 'auto');
    ga('set', 'anonymizeIp', true);
    ga('send', 'pageview');
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>


<script>
$(document).ready(function() {
    /* Add a [>>>] button on the top-right corner of code samples to hide
     * the >>> and ... prompts and the output and thus make the code
     * copyable. */
    var div = $('.highlight-python .highlight,' +
                '.highlight-python3 .highlight,' +
                '.highlight-pycon .highlight,' +
		'.highlight-default .highlight')
    var pre = div.find('pre');

    // get the styles from the current theme
    pre.parent().parent().css('position', 'relative');
    var hide_text = 'Hide prompts and outputs';
    var show_text = 'Show prompts and outputs';

    // create and add the button to all the code blocks that contain >>>
    div.each(function(index) {
        var jthis = $(this);
        if (jthis.find('.gp').length > 0) {
            var button = $('<span class="copybutton">&gt;&gt;&gt;</span>');
            button.attr('title', hide_text);
            button.data('hidden', 'false');
            jthis.prepend(button);
        }
        // tracebacks (.gt) contain bare text elements that need to be
        // wrapped in a span to work with .nextUntil() (see later)
        jthis.find('pre:has(.gt)').contents().filter(function() {
            return ((this.nodeType == 3) && (this.data.trim().length > 0));
        }).wrap('<span>');
    });

    // define the behavior of the button when it's clicked
    $('.copybutton').click(function(e){
        e.preventDefault();
        var button = $(this);
        if (button.data('hidden') === 'false') {
            // hide the code output
            button.parent().find('.go, .gp, .gt').hide();
            button.next('pre').find('.gt').nextUntil('.gp, .go').css('visibility', 'hidden');
            button.css('text-decoration', 'line-through');
            button.attr('title', show_text);
            button.data('hidden', 'true');
        } else {
            // show the code output
            button.parent().find('.go, .gp, .gt').show();
            button.next('pre').find('.gt').nextUntil('.gp, .go').css('visibility', 'visible');
            button.css('text-decoration', 'none');
            button.attr('title', hide_text);
            button.data('hidden', 'false');
        }
    });

	/*** Add permalink buttons next to glossary terms ***/
	$('dl.glossary > dt[id]').append(function() {
		return ('<a class="headerlink" href="#' +
			    this.getAttribute('id') +
			    '" title="Permalink to this term">¶</a>');
	});
  /*** Hide navbar when scrolling down ***/
  // Returns true when headerlink target matches hash in url
  (function() {
    hashTargetOnTop = function() {
        var hash = window.location.hash;
        if ( hash.length < 2 ) { return false; }

        var target = document.getElementById( hash.slice(1) );
        if ( target === null ) { return false; }

        var top = target.getBoundingClientRect().top;
        return (top < 2) && (top > -2);
    };

    // Hide navbar on load if hash target is on top
    var navBar = document.getElementById("navbar");
    var navBarToggler = document.getElementById("sk-navbar-toggler");
    var navBarHeightHidden = "-" + navBar.getBoundingClientRect().height + "px";
    var $window = $(window);

    hideNavBar = function() {
        navBar.style.top = navBarHeightHidden;
    };

    showNavBar = function() {
        navBar.style.top = "0";
    }

    if (hashTargetOnTop()) {
        hideNavBar()
    }

    var prevScrollpos = window.pageYOffset;
    hideOnScroll = function(lastScrollTop) {
        if (($window.width() < 768) && (navBarToggler.getAttribute("aria-expanded") === 'true')) {
            return;
        }
        if (lastScrollTop > 2 && (prevScrollpos <= lastScrollTop) || hashTargetOnTop()){
            hideNavBar()
        } else {
            showNavBar()
        }
        prevScrollpos = lastScrollTop;
    };

    /*** high performance scroll event listener***/
    var raf = window.requestAnimationFrame ||
        window.webkitRequestAnimationFrame ||
        window.mozRequestAnimationFrame ||
        window.msRequestAnimationFrame ||
        window.oRequestAnimationFrame;
    var lastScrollTop = $window.scrollTop();

    if (raf) {
        loop();
    }

    function loop() {
        var scrollTop = $window.scrollTop();
        if (lastScrollTop === scrollTop) {
            raf(loop);
            return;
        } else {
            lastScrollTop = scrollTop;
            hideOnScroll(lastScrollTop);
            raf(loop);
        }
    }
  })();
});

</script>
    
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
    
</body>
</html>