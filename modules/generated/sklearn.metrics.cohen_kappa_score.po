# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2007 - 2020, scikit-learn developers (BSD License)
# This file is distributed under the same license as the scikit-learn
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2021.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: scikit-learn 0.24\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-03-31 11:24-0400\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"

#: ../modules/generated/sklearn.metrics.cohen_kappa_score.rst:2
msgid ":mod:`sklearn.metrics`.cohen_kappa_score"
msgstr ""

#: of sklearn.metrics._classification.cohen_kappa_score:2
msgid "Cohen's kappa: a statistic that measures inter-annotator agreement."
msgstr ""

#: of sklearn.metrics._classification.cohen_kappa_score:4
msgid ""
"This function computes Cohen's kappa [R219a3b9132e1-1]_, a score that "
"expresses the level of agreement between two annotators on a "
"classification problem. It is defined as"
msgstr ""

#: of sklearn.metrics._classification.cohen_kappa_score:8
msgid ""
"\\kappa = (p_o - p_e) / (1 - p_e)\n"
"\n"
msgstr ""

#: of sklearn.metrics._classification.cohen_kappa_score:11
msgid ""
"where :math:`p_o` is the empirical probability of agreement on the label "
"assigned to any sample (the observed agreement ratio), and :math:`p_e` is"
" the expected agreement when both annotators assign labels randomly. "
":math:`p_e` is estimated using a per-annotator empirical prior over the "
"class labels [R219a3b9132e1-2]_."
msgstr ""

#: of sklearn.metrics._classification.cohen_kappa_score:17
msgid "Read more in the :ref:`User Guide <cohen_kappa>`."
msgstr ""

#: of sklearn.metrics._classification.cohen_kappa_score
msgid "Parameters"
msgstr ""

#: of sklearn.metrics._classification.cohen_kappa_score:22
msgid "**y1**"
msgstr ""

#: of
msgid "array of shape (n_samples,)"
msgstr ""

#: of sklearn.metrics._classification.cohen_kappa_score:22
msgid "Labels assigned by the first annotator."
msgstr ""

#: of sklearn.metrics._classification.cohen_kappa_score:26
msgid "**y2**"
msgstr ""

#: of sklearn.metrics._classification.cohen_kappa_score:25
msgid ""
"Labels assigned by the second annotator. The kappa statistic is "
"symmetric, so swapping ``y1`` and ``y2`` doesn't change the value."
msgstr ""

#: of sklearn.metrics._classification.cohen_kappa_score:31
msgid "**labels**"
msgstr ""

#: of
msgid "array-like of shape (n_classes,), default=None"
msgstr ""

#: of sklearn.metrics._classification.cohen_kappa_score:29
msgid ""
"List of labels to index the matrix. This may be used to select a subset "
"of labels. If None, all labels that appear at least once in ``y1`` or "
"``y2`` are used."
msgstr ""

#: of sklearn.metrics._classification.cohen_kappa_score:35
msgid "**weights**"
msgstr ""

#: of
msgid "{'linear', 'quadratic'}, default=None"
msgstr ""

#: of sklearn.metrics._classification.cohen_kappa_score:34
msgid ""
"Weighting type to calculate the score. None means no weighted; \"linear\""
" means linear weighted; \"quadratic\" means quadratic weighted."
msgstr ""

#: of sklearn.metrics._classification.cohen_kappa_score:38
msgid "**sample_weight**"
msgstr ""

#: of
msgid "array-like of shape (n_samples,), default=None"
msgstr ""

#: of sklearn.metrics._classification.cohen_kappa_score:38
msgid "Sample weights."
msgstr ""

#: of sklearn.metrics._classification.cohen_kappa_score
msgid "Returns"
msgstr ""

#: of sklearn.metrics._classification.cohen_kappa_score:52
msgid "**kappa**"
msgstr ""

#: of
msgid "float"
msgstr ""

#: of sklearn.metrics._classification.cohen_kappa_score:43
msgid ""
"The kappa statistic, which is a number between -1 and 1. The maximum "
"value means complete agreement; zero or lower means chance agreement."
msgstr ""

#: of sklearn.metrics._classification.cohen_kappa_score:55
msgid "References"
msgstr ""

#: of sklearn.metrics._classification.cohen_kappa_score:56
msgid ""
"J. Cohen (1960). \"A coefficient of agreement for nominal scales\". "
"Educational and Psychological Measurement 20(1):37-46. "
"doi:10.1177/001316446002000104."
msgstr ""

#: of sklearn.metrics._classification.cohen_kappa_score:59
msgid ""
"`R. Artstein and M. Poesio (2008). \"Inter-coder agreement for "
"computational linguistics\". Computational Linguistics 34(4):555-596 "
"<https://www.mitpressjournals.org/doi/pdf/10.1162/coli.07-034-R2>`_."
msgstr ""

#: of sklearn.metrics._classification.cohen_kappa_score:62
#, python-format
msgid ""
"`Wikipedia entry for the Cohen's kappa "
"<https://en.wikipedia.org/wiki/Cohen%27s_kappa>`_."
msgstr ""

#: of sklearn.metrics._classification.cohen_kappa_score:67
msgid "[R219a3b9132e1-1]_, [R219a3b9132e1-2]_, [R219a3b9132e1-3]_"
msgstr ""

