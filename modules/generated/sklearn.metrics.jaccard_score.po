# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2007 - 2020, scikit-learn developers (BSD License)
# This file is distributed under the same license as the scikit-learn
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2021.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: scikit-learn 0.24\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-03-31 11:24-0400\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"

#: ../modules/generated/sklearn.metrics.jaccard_score.rst:2
msgid ":mod:`sklearn.metrics`.jaccard_score"
msgstr ""

#: of sklearn.metrics._classification.jaccard_score:2
msgid "Jaccard similarity coefficient score."
msgstr ""

#: of sklearn.metrics._classification.jaccard_score:4
msgid ""
"The Jaccard index [1], or Jaccard similarity coefficient, defined as the "
"size of the intersection divided by the size of the union of two label "
"sets, is used to compare set of predicted labels for a sample to the "
"corresponding set of labels in ``y_true``."
msgstr ""

#: of sklearn.metrics._classification.jaccard_score:9
msgid "Read more in the :ref:`User Guide <jaccard_similarity_score>`."
msgstr ""

#: of sklearn.metrics._classification.jaccard_score
msgid "Parameters"
msgstr ""

#: of sklearn.metrics._classification.jaccard_score:14
msgid "**y_true**"
msgstr ""

#: of
msgid "1d array-like, or label indicator array / sparse matrix"
msgstr ""

#: of sklearn.metrics._classification.jaccard_score:14
msgid "Ground truth (correct) labels."
msgstr ""

#: of sklearn.metrics._classification.jaccard_score:17
msgid "**y_pred**"
msgstr ""

#: of sklearn.metrics._classification.jaccard_score:17
msgid "Predicted labels, as returned by a classifier."
msgstr ""

#: of sklearn.metrics._classification.jaccard_score:26
msgid "**labels**"
msgstr ""

#: of
msgid "array-like of shape (n_classes,), default=None"
msgstr ""

#: of sklearn.metrics._classification.jaccard_score:20
msgid ""
"The set of labels to include when ``average != 'binary'``, and their "
"order if ``average is None``. Labels present in the data can be excluded,"
" for example to calculate a multiclass average ignoring a majority "
"negative class, while labels not present in the data will result in 0 "
"components in a macro average. For multilabel targets, labels are column "
"indices. By default, all labels in ``y_true`` and ``y_pred`` are used in "
"sorted order."
msgstr ""

#: of sklearn.metrics._classification.jaccard_score:32
msgid "**pos_label**"
msgstr ""

#: of
msgid "str or int, default=1"
msgstr ""

#: of sklearn.metrics._classification.jaccard_score:29
msgid ""
"The class to report if ``average='binary'`` and the data is binary. If "
"the data are multiclass or multilabel, this will be ignored; setting "
"``labels=[pos_label]`` and ``average != 'binary'`` will report scores for"
" that label only."
msgstr ""

#: of sklearn.metrics._classification.jaccard_score:53
msgid "**average**"
msgstr ""

#: of
msgid ""
"{None, 'micro', 'macro', 'samples', 'weighted',             'binary'}, "
"default='binary'"
msgstr ""

#: of sklearn.metrics._classification.jaccard_score:35
msgid ""
"If ``None``, the scores for each class are returned. Otherwise, this "
"determines the type of averaging performed on the data:"
msgstr ""

#: of sklearn.metrics._classification.jaccard_score:39
msgid "``'binary'``:"
msgstr ""

#: of sklearn.metrics._classification.jaccard_score:39
msgid ""
"Only report results for the class specified by ``pos_label``. This is "
"applicable only if targets (``y_{true,pred}``) are binary."
msgstr ""

#: of sklearn.metrics._classification.jaccard_score:42
msgid "``'micro'``:"
msgstr ""

#: of sklearn.metrics._classification.jaccard_score:42
msgid ""
"Calculate metrics globally by counting the total true positives, false "
"negatives and false positives."
msgstr ""

#: of sklearn.metrics._classification.jaccard_score:45
msgid "``'macro'``:"
msgstr ""

#: of sklearn.metrics._classification.jaccard_score:45
msgid ""
"Calculate metrics for each label, and find their unweighted mean.  This "
"does not take label imbalance into account."
msgstr ""

#: of sklearn.metrics._classification.jaccard_score:49
msgid "``'weighted'``:"
msgstr ""

#: of sklearn.metrics._classification.jaccard_score:48
msgid ""
"Calculate metrics for each label, and find their average, weighted by "
"support (the number of true instances for each label). This alters "
"'macro' to account for label imbalance."
msgstr ""

#: of sklearn.metrics._classification.jaccard_score:53
msgid "``'samples'``:"
msgstr ""

#: of sklearn.metrics._classification.jaccard_score:52
msgid ""
"Calculate metrics for each instance, and find their average (only "
"meaningful for multilabel classification)."
msgstr ""

#: of sklearn.metrics._classification.jaccard_score:56
msgid "**sample_weight**"
msgstr ""

#: of
msgid "array-like of shape (n_samples,), default=None"
msgstr ""

#: of sklearn.metrics._classification.jaccard_score:56
msgid "Sample weights."
msgstr ""

#: of sklearn.metrics._classification.jaccard_score:61
msgid "**zero_division**"
msgstr ""

#: of
msgid "\"warn\", {0.0, 1.0}, default=\"warn\""
msgstr ""

#: of sklearn.metrics._classification.jaccard_score:59
msgid ""
"Sets the value to return when there is a zero division, i.e. when there "
"there are no negative values in predictions and labels. If set to "
"\"warn\", this acts like 0, but a warning is also raised."
msgstr ""

#: of sklearn.metrics._classification.jaccard_score
msgid "Returns"
msgstr ""

#: of sklearn.metrics._classification.jaccard_score:72
msgid "**score**"
msgstr ""

#: of
msgid ""
"float (if average is not None) or array of floats, shape =            "
"[n_unique_labels]"
msgstr ""

#: of sklearn.metrics._classification.jaccard_score:77
msgid ":obj:`accuracy_score`, :obj:`f_score`, :obj:`multilabel_confusion_matrix`"
msgstr ""

#: of sklearn.metrics._classification.jaccard_score:81
msgid "Notes"
msgstr ""

#: of sklearn.metrics._classification.jaccard_score:82
msgid ""
":func:`jaccard_score` may be a poor metric if there are no positives for "
"some samples or classes. Jaccard is undefined if there are no true or "
"predicted labels, and our implementation will return a score of 0 with a "
"warning."
msgstr ""

#: of sklearn.metrics._classification.jaccard_score:88
msgid "References"
msgstr ""

#: of sklearn.metrics._classification.jaccard_score:89
msgid ""
"`Wikipedia entry for the Jaccard index "
"<https://en.wikipedia.org/wiki/Jaccard_index>`_."
msgstr ""

#: of sklearn.metrics._classification.jaccard_score:94
msgid "[Red9506405d5f-1]_"
msgstr ""

#: of sklearn.metrics._classification.jaccard_score:97
msgid "Examples"
msgstr ""

#: of sklearn.metrics._classification.jaccard_score:105
msgid "In the binary case:"
msgstr ""

#: of sklearn.metrics._classification.jaccard_score:110
msgid "In the multilabel case:"
msgstr ""

#: of sklearn.metrics._classification.jaccard_score:119
msgid "In the multiclass case:"
msgstr ""

#: ../modules/generated/sklearn.metrics.jaccard_score.examples:4
msgid "Examples using ``sklearn.metrics.jaccard_score``"
msgstr ""

#: ../modules/generated/sklearn.metrics.jaccard_score.examples:15
#: ../modules/generated/sklearn.metrics.jaccard_score.examples:23
msgid ":ref:`sphx_glr_auto_examples_multioutput_plot_classifier_chain_yeast.py`"
msgstr ""

