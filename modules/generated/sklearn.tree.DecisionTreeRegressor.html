

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  
  <title>sklearn.tree.DecisionTreeRegressor &mdash; documentación de scikit-learn - 0.24.1</title>
  
  <link rel="canonical" href="http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html" />

  
  <link rel="shortcut icon" href="../../_static/favicon.ico"/>
  

  <link rel="stylesheet" href="../../_static/css/vendor/bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/gallery.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
<script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
<script src="../../_static/jquery.js"></script> 
</head>
<body>
<nav id="navbar" class="sk-docs-navbar navbar navbar-expand-md navbar-light bg-light py-0">
  <div class="container-fluid sk-docs-container px-0">
      <a class="navbar-brand py-0" href="../../index.html">
        <img
          class="sk-brand-img"
          src="../../_static/scikit-learn-logo-small.png"
          alt="logo"/>
      </a>
    <button
      id="sk-navbar-toggler"
      class="navbar-toggler"
      type="button"
      data-toggle="collapse"
      data-target="#navbarSupportedContent"
      aria-controls="navbarSupportedContent"
      aria-expanded="false"
      aria-label="Toggle navigation"
    >
      <span class="navbar-toggler-icon"></span>
    </button>

    <div class="sk-navbar-collapse collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav mr-auto">
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../install.html">Instalación</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../user_guide.html">Manual de Usuario</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../classes.html">API</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../auto_examples/index.html">Ejemplos</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../getting_started.html">¿Cómo empezar?</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../tutorial/index.html">Tutorial</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../whats_new/v0.24.html">Novedades</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../glossary.html">Glosario</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../developers/index.html">Desarrollo</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../faq.html">FAQ</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../support.html">Soporte</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../related_projects.html">Paquetes relacionados</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../roadmap.html">Hoja de ruta</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../about.html">Sobre nosotros</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="https://github.com/scikit-learn/scikit-learn">GitHub</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="https://scikit-learn.org/dev/versions.html">Otras versiones y descargas</a>
        </li>
        <li class="nav-item dropdown nav-more-item-dropdown">
          <a class="sk-nav-link nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Más</a>
          <div class="dropdown-menu" aria-labelledby="navbarDropdown">
              <a class="sk-nav-dropdown-item dropdown-item" href="../../getting_started.html">¿Cómo empezar?</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../tutorial/index.html">Tutorial</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../whats_new/v0.24.html">Novedades</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../glossary.html">Glosario</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../developers/index.html">Desarrollo</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../faq.html">FAQ</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../support.html">Soporte</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../related_projects.html">Paquetes relacionados</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../roadmap.html">Hoja de ruta</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../about.html">Sobre nosotros</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="https://github.com/scikit-learn/scikit-learn">GitHub</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="https://scikit-learn.org/dev/versions.html">Otras versiones y descargas</a>
          </div>
        </li>
      </ul>
      <div id="searchbox" role="search">
          <div class="searchformwrapper">
          <form class="search" action="../../search.html" method="get">
            <input class="sk-search-text-input" type="text" name="q" aria-labelledby="searchlabel" />
            <input class="sk-search-text-btn" type="submit" value="Ir a" />
          </form>
          </div>
      </div>
    </div>
  </div>
</nav>
<div class="d-flex" id="sk-doc-wrapper">
    <input type="checkbox" name="sk-toggle-checkbox" id="sk-toggle-checkbox">
    <label id="sk-sidemenu-toggle" class="sk-btn-toggle-toc btn sk-btn-primary" for="sk-toggle-checkbox">Alternar menú</label>
    <div id="sk-sidebar-wrapper" class="border-right">
      <div class="sk-sidebar-toc-wrapper">
        <div class="sk-sidebar-toc-logo">
          <a href="../../index.html">
            <img
              class="sk-brand-img"
              src="../../_static/scikit-learn-logo-small.png"
              alt="logo"/>
          </a>
        </div>
        <div class="btn-group w-100 mb-2" role="group" aria-label="rellinks">
            <a href="sklearn.tree.DecisionTreeClassifier.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="sklearn.tree.DecisionTreeClassifier">Prev</a><a href="../classes.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="Referencia de la API">Arriba</a>
            <a href="sklearn.tree.ExtraTreeClassifier.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="sklearn.tree.ExtraTreeClassifier">Sig.</a>
        </div>
        <div class="alert alert-danger p-1 mb-2" role="alert">
          <p class="text-center mb-0">
          <strong>scikit-learn 0.24.1</strong><br/>
          <a href="http://scikit-learn.org/dev/versions.html">Otras versiones</a>
          </p>
        </div>
        <div class="alert alert-warning p-1 mb-2" role="alert">
          <p class="text-center mb-0">
            Por favor <a class="font-weight-bold" href="../../about.html#citing-scikit-learn"><string>cítanos</string></a> si usas el software.
          </p>
        </div>
            <div class="sk-sidebar-toc">
              <ul>
<li><a class="reference internal" href="#"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.tree</span></code>.DecisionTreeRegressor</a><ul>
<li><a class="reference internal" href="#examples-using-sklearn-tree-decisiontreeregressor">Ejemplos con <code class="docutils literal notranslate"><span class="pre">sklearn.tree.DecisionTreeRegressor</span></code></a></li>
</ul>
</li>
</ul>

            </div>
      </div>
    </div>
    <div id="sk-page-content-wrapper">
      <div class="sk-page-content container-fluid body px-md-3" role="main">
        
  <section id="sklearn-tree-decisiontreeregressor">
<h1><a class="reference internal" href="../classes.html#module-sklearn.tree" title="sklearn.tree"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.tree</span></code></a>.DecisionTreeRegressor<a class="headerlink" href="#sklearn-tree-decisiontreeregressor" title="Enlazar permanentemente con este título">¶</a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="sklearn.tree.DecisionTreeRegressor">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">sklearn.tree.</span></span><span class="sig-name descname"><span class="pre">DecisionTreeRegressor</span></span><a class="headerlink" href="#sklearn.tree.DecisionTreeRegressor" title="Enlazar permanentemente con esta definición">¶</a></dt>
<dd><p>Un regresor del árbol de decisión.</p>
<p>Lee más en el <a class="reference internal" href="../tree.html#tree"><span class="std std-ref">Manual de usuario</span></a>.</p>
<dl class="field-list">
<dt class="field-odd">Parámetros</dt>
<dd class="field-odd"><dl>
<dt><strong>criterion</strong><span class="classifier">{«mse», «friedman_mse», «mae», «poisson»}, default=»mse»</span></dt><dd><p>La función para medir la calidad de una separación. Los criterios soportados son «mse» para el error cuadrático medio, que es igual a la reducción de la varianza como criterio de selección de características y minimiza la pérdida L2 utilizando la media de cada nodo terminal, «friedman_mse», que utiliza el error cuadrático medio con la puntuación de mejora de Friedman para las posibles separaciones, «mae» para el error absoluto medio, que minimiza la pérdida L1 utilizando la mediana de cada nodo terminal, y «poisson» que utiliza la reducción de la desviación de Poisson para encontrar separaciones.</p>
<div class="versionadded">
<p><span class="versionmodified added">Nuevo en la versión 0.18: </span>Criterio de error absoluto medio (MAE).</p>
</div>
<div class="versionadded">
<p><span class="versionmodified added">Nuevo en la versión 0.24: </span>Criterio de desviación de Poisson.</p>
</div>
</dd>
<dt><strong>splitter</strong><span class="classifier">{«best», «random»}, default=»best»</span></dt><dd><p>La estrategia utilizada para elegir la separación en cada nodo. Las estrategias soportadas son «best» para elegir la mejor separación y «random» para elegir la mejor separación aleatoria.</p>
</dd>
<dt><strong>max_depth</strong><span class="classifier">int, default=None</span></dt><dd><p>La profundidad máxima del árbol. Si es None, los nodos se expanden hasta que todas las hojas sean puras o hasta que todas las hojas contengan menos muestras que min_samples_split.</p>
</dd>
<dt><strong>min_samples_split</strong><span class="classifier">int o float, default=2</span></dt><dd><p>El número mínimo de muestras necesario para separar un nodo interno:</p>
<ul class="simple">
<li><p>Si es int, entonces considere <code class="docutils literal notranslate"><span class="pre">min_samples_split</span></code> como el número mínimo.</p></li>
<li><p>Si es float, <code class="docutils literal notranslate"><span class="pre">min_samples_split</span></code> es una fracción y <code class="docutils literal notranslate"><span class="pre">ceil(min_samples_split</span> <span class="pre">*</span> <span class="pre">n_samples)</span></code> es el número mínimo de muestras para cada separación.</p></li>
</ul>
<div class="versionchanged">
<p><span class="versionmodified changed">Distinto en la versión 0.18: </span>Se han añadido valores flotantes para las fracciones.</p>
</div>
</dd>
<dt><strong>min_samples_leaf</strong><span class="classifier">int o float, default=1</span></dt><dd><p>El número mínimo de muestras requerido para estar en un nodo hoja. Un punto de separación en cualquier profundidad sólo se considerará si deja al menos <code class="docutils literal notranslate"><span class="pre">min_samples_leaf</span></code> muestras de entrenamiento en cada una de las ramas izquierda y derecha.  Esto puede tener el efecto de suavizar el modelo, especialmente en la regresión.</p>
<ul class="simple">
<li><p>Si es int, entonces considere <code class="docutils literal notranslate"><span class="pre">min_samples_leaf</span></code> como el número mínimo.</p></li>
<li><p>Si es float, entonces <code class="docutils literal notranslate"><span class="pre">min_samples_leaf</span></code> es una fracción y <code class="docutils literal notranslate"><span class="pre">ceil(min_samples_leaf</span> <span class="pre">*</span> <span class="pre">n_samples)</span></code> son el número mínimo de muestras para cada nodo.</p></li>
</ul>
<div class="versionchanged">
<p><span class="versionmodified changed">Distinto en la versión 0.18: </span>Se han añadido valores flotantes para las fracciones.</p>
</div>
</dd>
<dt><strong>min_weight_fraction_leaf</strong><span class="classifier">float, default=0.0</span></dt><dd><p>La fracción ponderada mínima de la suma total de pesos (de todas las muestras de entrada) requerida para estar en un nodo hoja. Las muestras tienen el mismo peso cuando no se proporciona sample_weight.</p>
</dd>
<dt><strong>max_features</strong><span class="classifier">int, float or {«auto», «sqrt», «log2»}, default=None</span></dt><dd><p>El número de características a considerar cuando se busca la mejor separación:</p>
<ul class="simple">
<li><p>Si es int, entonces se consideran las características <code class="docutils literal notranslate"><span class="pre">max_features</span></code> en cada separación.</p></li>
<li><p>Si es float, entonces <code class="docutils literal notranslate"><span class="pre">max_features</span></code> es una fracción y las características <code class="docutils literal notranslate"><span class="pre">int(max_features</span> <span class="pre">*</span> <span class="pre">n_features)</span></code> se consideran en cada separación.</p></li>
<li><p>Si es «auto», entonces <code class="docutils literal notranslate"><span class="pre">max_features=n_features</span></code>.</p></li>
<li><p>Si es «sqrt», entonces <code class="docutils literal notranslate"><span class="pre">max_features=sqrt(n_features)</span></code>.</p></li>
<li><p>Si es «log2», entonces <code class="docutils literal notranslate"><span class="pre">max_features=log2(n_features)</span></code>.</p></li>
<li><p>Si es None, entonces <code class="docutils literal notranslate"><span class="pre">max_features=n_features</span></code>.</p></li>
</ul>
<p>Nota: la búsqueda de una partición no se detiene hasta que se encuentra al menos una partición válida de las muestras del nodo, incluso si requiere inspeccionar efectivamente más características de <code class="docutils literal notranslate"><span class="pre">max_features</span></code>.</p>
</dd>
<dt><strong>random_state</strong><span class="classifier">int, instancia de RandomState o None, default=None</span></dt><dd><p>Controla la aleatoriedad del estimador. Las características siempre se permutan aleatoriamente en cada separación, incluso si <code class="docutils literal notranslate"><span class="pre">splitter</span></code> se establece en <code class="docutils literal notranslate"><span class="pre">&quot;best&quot;</span></code>. Cuando <code class="docutils literal notranslate"><span class="pre">max_features</span> <span class="pre">&lt;</span> <span class="pre">n_features</span></code>, el algoritmo seleccionará <code class="docutils literal notranslate"><span class="pre">max_features</span></code> al azar en cada división antes de encontrar la mejor división entre ellas. Pero la mejor división encontrada puede variar en diferentes ejecuciones, incluso si <code class="docutils literal notranslate"><span class="pre">max_features=n_features</span></code>. Este es el caso, si la mejora del criterio es idéntica para varias separaciones y una de ellas tiene que ser seleccionada al azar. Para obtener un comportamiento determinista durante el ajuste, <code class="docutils literal notranslate"><span class="pre">random_state</span></code> debe fijarse en un número entero. Ver <a class="reference internal" href="../../glossary.html#term-random_state"><span class="xref std std-term">Glosario</span></a> para más detalles.</p>
</dd>
<dt><strong>max_leaf_nodes</strong><span class="classifier">int, default=None</span></dt><dd><p>Crece un árbol con <code class="docutils literal notranslate"><span class="pre">max_leaf_nodes</span></code> en modo best-first. Los mejores nodos se definen como la reducción relativa de la impureza. Si es None, el número de nodos hoja es ilimitado.</p>
</dd>
<dt><strong>min_impurity_decrease</strong><span class="classifier">float, default=0.0</span></dt><dd><p>Un nodo se separará si esta separación induce una disminución de la impureza mayor o igual a este valor.</p>
<p>La ecuación de disminución de impurezas ponderada es la siguiente:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">N_t</span> <span class="o">/</span> <span class="n">N</span> <span class="o">*</span> <span class="p">(</span><span class="n">impurity</span> <span class="o">-</span> <span class="n">N_t_R</span> <span class="o">/</span> <span class="n">N_t</span> <span class="o">*</span> <span class="n">right_impurity</span>
                    <span class="o">-</span> <span class="n">N_t_L</span> <span class="o">/</span> <span class="n">N_t</span> <span class="o">*</span> <span class="n">left_impurity</span><span class="p">)</span>
</pre></div>
</div>
<p>donde <code class="docutils literal notranslate"><span class="pre">N</span></code> es el número total de muestras, <code class="docutils literal notranslate"><span class="pre">N_t</span></code> es el número de muestras en el nodo actual, <code class="docutils literal notranslate"><span class="pre">N_t_L</span></code> es el número de muestras en el hijo izquierdo, y <code class="docutils literal notranslate"><span class="pre">N_t_R</span></code> es el número de muestras en el hijo derecho.</p>
<p><code class="docutils literal notranslate"><span class="pre">N</span></code>, <code class="docutils literal notranslate"><span class="pre">N_t</span></code>, <code class="docutils literal notranslate"><span class="pre">N_t_R</span></code> y <code class="docutils literal notranslate"><span class="pre">N_t_L</span></code> se refieren a la suma ponderada, si se pasa <code class="docutils literal notranslate"><span class="pre">sample_weight</span></code>.</p>
<div class="versionadded">
<p><span class="versionmodified added">Nuevo en la versión 0.19.</span></p>
</div>
</dd>
<dt><strong>min_impurity_split</strong><span class="classifier">float, default=0</span></dt><dd><p>Umbral para la detención temprana en el crecimiento del árbol. Un nodo se separará si su impureza está por encima del umbral, de lo contrario será una hoja.</p>
<div class="deprecated">
<p><span class="versionmodified deprecated">Obsoleto desde la versión 0.19: </span>El valor de <code class="docutils literal notranslate"><span class="pre">min_impurity_split</span></code> ha quedado obsoleto en favor de <code class="docutils literal notranslate"><span class="pre">min_impurity_decrease</span></code> en 0.19. El valor predeterminado de <code class="docutils literal notranslate"><span class="pre">min_impurity_split</span></code> ha cambiado de 1e-7 a 0 en 0.23 y se eliminará en 1.0 (cambio de nombre de 0.25). Utilice <code class="docutils literal notranslate"><span class="pre">min_impurity_decrease</span></code> en su lugar.</p>
</div>
</dd>
<dt><strong>ccp_alpha</strong><span class="classifier">flotante no negativo, default=0.0</span></dt><dd><p>Parámetro de complejidad utilizado para la Poda de Mínima Complejidad de Costes. Se elegirá el subárbol con la mayor complejidad de costes que sea menor que <code class="docutils literal notranslate"><span class="pre">ccp_alpha</span></code>. Por defecto, no se realiza ninguna poda. Ver <a class="reference internal" href="../tree.html#minimal-cost-complexity-pruning"><span class="std std-ref">Poda de Coste-Complejidad Mínima</span></a> para más detalles.</p>
<div class="versionadded">
<p><span class="versionmodified added">Nuevo en la versión 0.22.</span></p>
</div>
</dd>
</dl>
</dd>
<dt class="field-even">Atributos</dt>
<dd class="field-even"><dl class="simple">
<dt><a class="reference internal" href="#sklearn.tree.DecisionTreeRegressor.feature_importances_" title="sklearn.tree.DecisionTreeRegressor.feature_importances_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">feature_importances_</span></code></a><span class="classifier">ndarray de forma (n_features,)</span></dt><dd><p>Devuelve las importancias de las características.</p>
</dd>
<dt><strong>max_features_</strong><span class="classifier">int</span></dt><dd><p>El valor inferido de max_features.</p>
</dd>
<dt><strong>n_features_</strong><span class="classifier">int</span></dt><dd><p>El número de características cuando se realiza <code class="docutils literal notranslate"><span class="pre">fit</span></code>.</p>
</dd>
<dt><strong>n_outputs_</strong><span class="classifier">int</span></dt><dd><p>El número de salidas cuando se realiza <code class="docutils literal notranslate"><span class="pre">fit</span></code>.</p>
</dd>
<dt><strong>tree_</strong><span class="classifier">Instancia del árbol</span></dt><dd><p>El objeto Tree subyacente. Por favor, consulta <code class="docutils literal notranslate"><span class="pre">help(sklearn.tree._tree.Tree)</span></code> para los atributos del objeto Tree y <a class="reference internal" href="../../auto_examples/tree/plot_unveil_tree_structure.html#sphx-glr-auto-examples-tree-plot-unveil-tree-structure-py"><span class="std std-ref">Comprensión de la estructura del árbol de decisiones</span></a> para el uso básico de estos atributos.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">Ver también</p>
<dl class="simple">
<dt><a class="reference internal" href="sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier" title="sklearn.tree.DecisionTreeClassifier"><code class="xref py py-obj docutils literal notranslate"><span class="pre">DecisionTreeClassifier</span></code></a></dt><dd><p>Un clasificador de árbol de decisión.</p>
</dd>
</dl>
</div>
<p class="rubric">Notas</p>
<p>Los valores predeterminados de los parámetros que controlan el tamaño de los árboles (por ejemplo, <code class="docutils literal notranslate"><span class="pre">`max_depth</span></code>, <code class="docutils literal notranslate"><span class="pre">min_samples_leaf</span></code>, etc.) conducen a árboles completamente desarrollados y sin podar que pueden ser potencialmente muy grandes en algunos conjuntos de datos. Para reducir el consumo de memoria, la complejidad y el tamaño de los árboles deben controlarse estableciendo los valores de esos parámetros.</p>
<p class="rubric">Referencias</p>
<dl class="citation">
<dt class="label" id="ra37b7e3adb19-1"><span class="brackets">1</span></dt>
<dd><p><a class="reference external" href="https://en.wikipedia.org/wiki/Decision_tree_learning">https://en.wikipedia.org/wiki/Decision_tree_learning</a></p>
</dd>
<dt class="label" id="ra37b7e3adb19-2"><span class="brackets">2</span></dt>
<dd><p>L. Breiman, J. Friedman, R. Olshen, and C. Stone, «Classification
and Regression Trees», Wadsworth, Belmont, CA, 1984.</p>
</dd>
<dt class="label" id="ra37b7e3adb19-3"><span class="brackets">3</span></dt>
<dd><p>T. Hastie, R. Tibshirani and J. Friedman. «Elements of Statistical
Learning», Springer, 2009.</p>
</dd>
<dt class="label" id="ra37b7e3adb19-4"><span class="brackets">4</span></dt>
<dd><p>L. Breiman, and A. Cutler, «Random Forests»,
<a class="reference external" href="https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm">https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm</a></p>
</dd>
</dl>
<p class="rubric">Ejemplos</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_diabetes</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">cross_val_score</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeRegressor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_diabetes</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">regressor</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">cross_val_score</span><span class="p">(</span><span class="n">regressor</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">cv</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
<span class="gp">... </span>                   
<span class="gp">...</span>
<span class="go">array([-0.39..., -0.46...,  0.02...,  0.06..., -0.50...,</span>
<span class="go">       0.16...,  0.11..., -0.73..., -0.30..., -0.00...])</span>
</pre></div>
</div>
<p class="rubric">Métodos</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#sklearn.tree.DecisionTreeRegressor.apply" title="sklearn.tree.DecisionTreeRegressor.apply"><code class="xref py py-obj docutils literal notranslate"><span class="pre">apply</span></code></a></p></td>
<td><p>Devuelve el índice de la hoja en la que se predice cada muestra.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#sklearn.tree.DecisionTreeRegressor.cost_complexity_pruning_path" title="sklearn.tree.DecisionTreeRegressor.cost_complexity_pruning_path"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cost_complexity_pruning_path</span></code></a></p></td>
<td><p>Calcular la ruta de poda durante la Poda de Mínima Complejidad de costes.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#sklearn.tree.DecisionTreeRegressor.decision_path" title="sklearn.tree.DecisionTreeRegressor.decision_path"><code class="xref py py-obj docutils literal notranslate"><span class="pre">decision_path</span></code></a></p></td>
<td><p>Devuelve la ruta de decisión en el árbol.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#sklearn.tree.DecisionTreeRegressor.fit" title="sklearn.tree.DecisionTreeRegressor.fit"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit</span></code></a></p></td>
<td><p>Construye un regresor de árbol de decisión a partir del conjunto de entrenamiento (X, y).</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#sklearn.tree.DecisionTreeRegressor.get_depth" title="sklearn.tree.DecisionTreeRegressor.get_depth"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_depth</span></code></a></p></td>
<td><p>Devuelve la profundidad del árbol de decisión.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#sklearn.tree.DecisionTreeRegressor.get_n_leaves" title="sklearn.tree.DecisionTreeRegressor.get_n_leaves"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_n_leaves</span></code></a></p></td>
<td><p>Devuelve el número de hojas del árbol de decisión.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#sklearn.tree.DecisionTreeRegressor.get_params" title="sklearn.tree.DecisionTreeRegressor.get_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_params</span></code></a></p></td>
<td><p>Obtiene los parámetros para este estimador.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#sklearn.tree.DecisionTreeRegressor.predict" title="sklearn.tree.DecisionTreeRegressor.predict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">predict</span></code></a></p></td>
<td><p>Predice la clase de regresión para X.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#sklearn.tree.DecisionTreeRegressor.score" title="sklearn.tree.DecisionTreeRegressor.score"><code class="xref py py-obj docutils literal notranslate"><span class="pre">score</span></code></a></p></td>
<td><p>Devuelve el coeficiente de determinación <span class="math notranslate nohighlight">\(R^2\)</span> de la predicción.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#sklearn.tree.DecisionTreeRegressor.set_params" title="sklearn.tree.DecisionTreeRegressor.set_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_params</span></code></a></p></td>
<td><p>Establece los parámetros de este estimador.</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="sklearn.tree.DecisionTreeRegressor.apply">
<span class="sig-name descname"><span class="pre">apply</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.tree.DecisionTreeRegressor.apply" title="Enlazar permanentemente con esta definición">¶</a></dt>
<dd><p>Devuelve el índice de la hoja en la que se predice cada muestra.</p>
<div class="versionadded">
<p><span class="versionmodified added">Nuevo en la versión 0.17.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parámetros</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">{array-like, sparse matrix} de forma (n_samples, n_features)</span></dt><dd><p>Las muestras de entrada. Internamente, se convertirá a <code class="docutils literal notranslate"><span class="pre">dtype=np.float32</span></code> y si se proporciona una matriz dispersa a una <code class="docutils literal notranslate"><span class="pre">csr_matrix</span></code> dispersa.</p>
</dd>
<dt><strong>check_input</strong><span class="classifier">bool, default=True</span></dt><dd><p>Permite eludir varias comprobaciones de entrada. No uses este parámetro a menos que sepas lo que haces.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Devuelve</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>X_leaves</strong><span class="classifier">array-like de forma (n_samples,)</span></dt><dd><p>Para cada punto de datos x en X, devuelve el índice de la hoja en la que termina x. Las hojas se numeran dentro de <code class="docutils literal notranslate"><span class="pre">[0;</span> <span class="pre">self.tree_.node_count)</span></code>, posiblemente con huecos en la numeración.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.tree.DecisionTreeRegressor.cost_complexity_pruning_path">
<span class="sig-name descname"><span class="pre">cost_complexity_pruning_path</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.tree.DecisionTreeRegressor.cost_complexity_pruning_path" title="Enlazar permanentemente con esta definición">¶</a></dt>
<dd><p>Calcular la ruta de poda durante la Poda de Mínima Complejidad de costes.</p>
<p>Ver <a class="reference internal" href="../tree.html#minimal-cost-complexity-pruning"><span class="std std-ref">Poda de Coste-Complejidad Mínima</span></a> para más detalles sobre el proceso de poda.</p>
<dl class="field-list">
<dt class="field-odd">Parámetros</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">{array-like, sparse matrix} de forma (n_samples, n_features)</span></dt><dd><p>Las muestras de entrada de entrenamiento. Internamente, se convertirán a <code class="docutils literal notranslate"><span class="pre">dtype=np.float32</span></code> y si se proporciona una matriz dispersa a una <code class="docutils literal notranslate"><span class="pre">csc_matrix</span></code> dispersa.</p>
</dd>
<dt><strong>y</strong><span class="classifier">array-like de forma (n_samples,) o (n_samples, n_outputs)</span></dt><dd><p>Los valores objetivo (etiquetas de clase) como enteros o cadenas.</p>
</dd>
<dt><strong>sample_weight</strong><span class="classifier">array-like de forma (n_samples,) default=None</span></dt><dd><p>Pesos de las muestras. Si es None, las muestras se ponderan por igual. Las separaciones que crearían nodos hijos con peso neto cero o negativo se ignoran al buscar una separación en cada nodo. Las separaciones también se ignoran si dan lugar a que una sola clase tenga un peso negativo en cualquiera de los nodos hijos.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Devuelve</dt>
<dd class="field-even"><dl>
<dt><strong>ccp_path</strong><span class="classifier"><a class="reference internal" href="sklearn.utils.Bunch.html#sklearn.utils.Bunch" title="sklearn.utils.Bunch"><code class="xref py py-class docutils literal notranslate"><span class="pre">Bunch</span></code></a></span></dt><dd><p>Objeto tipo diccionario, con los siguientes atributos.</p>
<dl class="simple">
<dt>ccp_alphas<span class="classifier">ndarray</span></dt><dd><p>Alfas efectivas del subárbol durante la poda.</p>
</dd>
<dt>impurezas<span class="classifier">ndarray</span></dt><dd><p>Suma de las impurezas de las hojas del subárbol para el valor alfa correspondiente en <code class="docutils literal notranslate"><span class="pre">ccp_alphas</span></code>.</p>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.tree.DecisionTreeRegressor.decision_path">
<span class="sig-name descname"><span class="pre">decision_path</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.tree.DecisionTreeRegressor.decision_path" title="Enlazar permanentemente con esta definición">¶</a></dt>
<dd><p>Devuelve la ruta de decisión en el árbol.</p>
<div class="versionadded">
<p><span class="versionmodified added">Nuevo en la versión 0.18.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parámetros</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">{array-like, sparse matrix} de forma (n_samples, n_features)</span></dt><dd><p>Las muestras de entrada. Internamente, se convertirá a <code class="docutils literal notranslate"><span class="pre">dtype=np.float32</span></code> y si se proporciona una matriz dispersa a una <code class="docutils literal notranslate"><span class="pre">csr_matrix</span></code> dispersa.</p>
</dd>
<dt><strong>check_input</strong><span class="classifier">bool, default=True</span></dt><dd><p>Permite eludir varias comprobaciones de entrada. No uses este parámetro a menos que sepas lo que haces.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Devuelve</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>indicator</strong><span class="classifier">matriz dispersa de forma (n_samples, n_nodes)</span></dt><dd><p>Devuelve una matriz CSR indicadora de nodos donde los elementos no nulos indican que las muestras pasan por los nodos.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="sklearn.tree.DecisionTreeRegressor.feature_importances_">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">feature_importances_</span></span><a class="headerlink" href="#sklearn.tree.DecisionTreeRegressor.feature_importances_" title="Enlazar permanentemente con esta definición">¶</a></dt>
<dd><p>Devuelve las importancias de las características.</p>
<p>La importancia de una característica se calcula como la reducción total (normalizada) del criterio aportado por esa característica. También se conoce como la importancia de Gini.</p>
<p>Advertencia: las importancias de las características basadas en la impureza pueden ser engañosas para características de alta cardinalidad (muchos valores únicos). Ver <a class="reference internal" href="sklearn.inspection.permutation_importance.html#sklearn.inspection.permutation_importance" title="sklearn.inspection.permutation_importance"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.inspection.permutation_importance</span></code></a> como alternativa.</p>
<dl class="field-list simple">
<dt class="field-odd">Devuelve</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>feature_importances_</strong><span class="classifier">ndarray de forma (n_features,)</span></dt><dd><p>Reducción total normalizada de criterios por característica (importancia Gini).</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.tree.DecisionTreeRegressor.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.tree.DecisionTreeRegressor.fit" title="Enlazar permanentemente con esta definición">¶</a></dt>
<dd><p>Construye un regresor de árbol de decisión a partir del conjunto de entrenamiento (X, y).</p>
<dl class="field-list">
<dt class="field-odd">Parámetros</dt>
<dd class="field-odd"><dl>
<dt><strong>X</strong><span class="classifier">{array-like, sparse matrix} de forma (n_samples, n_features)</span></dt><dd><p>Las muestras de entrada de entrenamiento. Internamente, se convertirán a <code class="docutils literal notranslate"><span class="pre">dtype=np.float32</span></code> y si se proporciona una matriz dispersa a una <code class="docutils literal notranslate"><span class="pre">csc_matrix</span></code> dispersa.</p>
</dd>
<dt><strong>y</strong><span class="classifier">array-like de forma (n_samples,) o (n_samples, n_outputs)</span></dt><dd><p>Los valores objetivo (números reales). Utilice <code class="docutils literal notranslate"><span class="pre">dtype=np.float64</span></code> y <code class="docutils literal notranslate"><span class="pre">order='C'</span></code> para obtener la máxima eficiencia.</p>
</dd>
<dt><strong>sample_weight</strong><span class="classifier">array-like de forma (n_samples,) default=None</span></dt><dd><p>Pesos de las muestras. Si es None, las muestras se ponderan por igual. Las separaciones que crearían nodos hijos con peso neto cero o negativo se ignoran al buscar una separación en cada nodo.</p>
</dd>
<dt><strong>check_input</strong><span class="classifier">bool, default=True</span></dt><dd><p>Permite eludir varias comprobaciones de entrada. No uses este parámetro a menos que sepas lo que haces.</p>
</dd>
<dt><strong>X_idx_sorted</strong><span class="classifier">obsoleto, default=»deprecated»</span></dt><dd><p>Este parámetro está obsoleto y no tiene ningún efecto. Se eliminará en la versión 1.1 (cambio de nombre de la versión 0.26).</p>
<div class="deprecated">
<p><span class="versionmodified deprecated">Obsoleto desde la versión 0.24.</span></p>
</div>
</dd>
</dl>
</dd>
<dt class="field-even">Devuelve</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>self</strong><span class="classifier">DecisionTreeRegressor</span></dt><dd><p>Estimador</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.tree.DecisionTreeRegressor.get_depth">
<span class="sig-name descname"><span class="pre">get_depth</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.tree.DecisionTreeRegressor.get_depth" title="Enlazar permanentemente con esta definición">¶</a></dt>
<dd><p>Devuelve la profundidad del árbol de decisión.</p>
<p>La profundidad de un árbol es la distancia máxima entre la raíz y cualquier hoja.</p>
<dl class="field-list simple">
<dt class="field-odd">Devuelve</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>self.tree_.max_depth</strong><span class="classifier">int</span></dt><dd><p>La profundidad máxima del árbol.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.tree.DecisionTreeRegressor.get_n_leaves">
<span class="sig-name descname"><span class="pre">get_n_leaves</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.tree.DecisionTreeRegressor.get_n_leaves" title="Enlazar permanentemente con esta definición">¶</a></dt>
<dd><p>Devuelve el número de hojas del árbol de decisión.</p>
<dl class="field-list simple">
<dt class="field-odd">Devuelve</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>self.tree_.n_leaves</strong><span class="classifier">int</span></dt><dd><p>Número de hojas.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.tree.DecisionTreeRegressor.get_params">
<span class="sig-name descname"><span class="pre">get_params</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.tree.DecisionTreeRegressor.get_params" title="Enlazar permanentemente con esta definición">¶</a></dt>
<dd><p>Obtiene los parámetros para este estimador.</p>
<dl class="field-list simple">
<dt class="field-odd">Parámetros</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>deep</strong><span class="classifier">bool, default=True</span></dt><dd><p>Si es True, devolverá los parámetros para este estimador y los subobjetos contenidos que son estimadores.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Devuelve</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>params</strong><span class="classifier">dict</span></dt><dd><p>Los nombres de los parámetros asignados a sus valores.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.tree.DecisionTreeRegressor.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.tree.DecisionTreeRegressor.predict" title="Enlazar permanentemente con esta definición">¶</a></dt>
<dd><p>Predice la clase de regresión para X.</p>
<p>Para un modelo de clasificación, se devuelve la clase predicha para cada muestra en X. Para un modelo de regresión, se devuelve el valor predicho basado en X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parámetros</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">{array-like, sparse matrix} de forma (n_samples, n_features)</span></dt><dd><p>Las muestras de entrada. Internamente, se convertirá a <code class="docutils literal notranslate"><span class="pre">dtype=np.float32</span></code> y si se proporciona una matriz dispersa a una <code class="docutils literal notranslate"><span class="pre">csr_matrix</span></code> dispersa.</p>
</dd>
<dt><strong>check_input</strong><span class="classifier">bool, default=True</span></dt><dd><p>Permite eludir varias comprobaciones de entrada. No uses este parámetro a menos que sepas lo que haces.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Devuelve</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>y</strong><span class="classifier">array-like de forma (n_samples,) o (n_samples, n_outputs)</span></dt><dd><p>Las clases predichas, o los valores predichos.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.tree.DecisionTreeRegressor.score">
<span class="sig-name descname"><span class="pre">score</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.tree.DecisionTreeRegressor.score" title="Enlazar permanentemente con esta definición">¶</a></dt>
<dd><p>Devuelve el coeficiente de determinación <span class="math notranslate nohighlight">\(R^2\)</span> de la predicción.</p>
<p>El coeficiente <span class="math notranslate nohighlight">\(R^2\)</span> se define como <span class="math notranslate nohighlight">\((1 - \frac{u}{v})\)</span>, donde <span class="math notranslate nohighlight">\(u\)</span> es la suma residual de cuadrados <code class="docutils literal notranslate"><span class="pre">((y_true</span> <span class="pre">-</span> <span class="pre">y_pred)</span> <span class="pre">**</span> <span class="pre">2).sum()</span></code> y <span class="math notranslate nohighlight">\(v\)</span> es la suma total de cuadrados <code class="docutils literal notranslate"><span class="pre">((y_true</span> <span class="pre">-</span> <span class="pre">y_true.mean())</span> <span class="pre">**</span> <span class="pre">2).sum()</span></code>. La mejor puntuación posible es 1,0 y puede ser negativa (porque el modelo puede ser arbitrariamente peor). Un modelo constante que siempre predice el valor esperado de <code class="docutils literal notranslate"><span class="pre">y</span></code>, sin tener en cuenta las características de entrada, obtendría una puntuación <span class="math notranslate nohighlight">\(R^2\)</span> de 0,0.</p>
<dl class="field-list simple">
<dt class="field-odd">Parámetros</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">array-like de forma (n_samples, n_features)</span></dt><dd><p>Muestras de prueba. Para algunos estimadores puede ser una matriz de núcleo precalculada o una lista de objetos genéricos con forma <code class="docutils literal notranslate"><span class="pre">(n_samples,</span> <span class="pre">n_samples_fitted)</span></code>, donde <code class="docutils literal notranslate"><span class="pre">n_samples_fitted</span></code> es el número de muestras utilizadas en el ajuste para el estimador.</p>
</dd>
<dt><strong>y</strong><span class="classifier">array-like de forma (n_samples,) o (n_samples, n_outputs)</span></dt><dd><p>Valores verdaderos para <code class="docutils literal notranslate"><span class="pre">X</span></code>.</p>
</dd>
<dt><strong>sample_weight</strong><span class="classifier">array-like de forma (n_samples,) default=None</span></dt><dd><p>Ponderaciones de la muestra.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Devuelve</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>score</strong><span class="classifier">float</span></dt><dd><p><span class="math notranslate nohighlight">\(R^2\)</span> de <code class="docutils literal notranslate"><span class="pre">self.predict(X)</span></code> con respecto a <code class="docutils literal notranslate"><span class="pre">y</span></code>.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notas</p>
<p>La puntuación <span class="math notranslate nohighlight">\(R^2\)</span> utilizada al llamar a <code class="docutils literal notranslate"><span class="pre">score</span></code> en un regresor utiliza <code class="docutils literal notranslate"><span class="pre">multioutput='uniform_average'</span></code> desde la versión 0.23 para mantener la coherencia con el valor predeterminado de <code class="xref py py-func docutils literal notranslate"><span class="pre">r2_score`</span></code>. Esto influye en el método <code class="docutils literal notranslate"><span class="pre">score</span></code> de todos los regresores de salida múltiple (excepto para <a class="reference internal" href="sklearn.multioutput.MultiOutputRegressor.html#sklearn.multioutput.MultiOutputRegressor" title="sklearn.multioutput.MultiOutputRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultiOutputRegressor</span></code></a>).</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.tree.DecisionTreeRegressor.set_params">
<span class="sig-name descname"><span class="pre">set_params</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.tree.DecisionTreeRegressor.set_params" title="Enlazar permanentemente con esta definición">¶</a></dt>
<dd><p>Establece los parámetros de este estimador.</p>
<p>El método funciona tanto en estimadores simples como en objetos anidados (como <a class="reference internal" href="sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline" title="sklearn.pipeline.Pipeline"><code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code></a>). Estos últimos tienen parámetros de la forma <a href="#id1"><span class="problematic" id="id2">``</span></a>&lt;component&gt;__&lt;parameter&gt;` para que sea posible actualizar cada componente de un objeto anidado.</p>
<dl class="field-list simple">
<dt class="field-odd">Parámetros</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>**params</strong><span class="classifier">dict</span></dt><dd><p>Parámetros del estimador.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Devuelve</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>self</strong><span class="classifier">instancia del estimador</span></dt><dd><p>Instancia del estimador.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<section id="examples-using-sklearn-tree-decisiontreeregressor">
<h2>Ejemplos con <code class="docutils literal notranslate"><span class="pre">sklearn.tree.DecisionTreeRegressor</span></code><a class="headerlink" href="#examples-using-sklearn-tree-decisiontreeregressor" title="Enlazar permanentemente con este título">¶</a></h2>
<div class="sphx-glr-thumbcontainer" tooltip="We are pleased to announce the release of scikit-learn 0.24! Many bug fixes and improvements we..."><figure class="align-default" id="id5">
<img alt="Release Highlights for scikit-learn 0.24" src="../../_images/sphx_glr_plot_release_highlights_0_24_0_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../auto_examples/release_highlights/plot_release_highlights_0_24_0.html#sphx-glr-auto-examples-release-highlights-plot-release-highlights-0-24-0-py"><span class="std std-ref">Aspectos Destacados de scikit-learn 0.24</span></a></span><a class="headerlink" href="#id5" title="Enlace permanente a esta imagen">¶</a></p>
</figcaption>
</figure>
</div><div class="sphx-glr-thumbcontainer" tooltip="We are pleased to announce the release of scikit-learn 0.22, which comes with many bug fixes an..."><figure class="align-default" id="id6">
<img alt="Release Highlights for scikit-learn 0.22" src="../../_images/sphx_glr_plot_release_highlights_0_22_0_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../auto_examples/release_highlights/plot_release_highlights_0_22_0.html#sphx-glr-auto-examples-release-highlights-plot-release-highlights-0-22-0-py"><span class="std std-ref">Aspectos Destacados de scikit-learn 0.22</span></a></span><a class="headerlink" href="#id6" title="Enlace permanente a esta imagen">¶</a></p>
</figcaption>
</figure>
</div><div class="sphx-glr-thumbcontainer" tooltip="    See also sphx_glr_auto_examples_miscellaneous_plot_roc_curve_visualization_api.py"><figure class="align-default" id="id7">
<img alt="Advanced Plotting With Partial Dependence" src="../../_images/sphx_glr_plot_partial_dependence_visualization_api_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../auto_examples/miscellaneous/plot_partial_dependence_visualization_api.html#sphx-glr-auto-examples-miscellaneous-plot-partial-dependence-visualization-api-py"><span class="std std-ref">Graficación Avanzada Con Dependencia Parcial</span></a></span><a class="headerlink" href="#id7" title="Enlace permanente a esta imagen">¶</a></p>
</figcaption>
</figure>
</div><div class="sphx-glr-thumbcontainer" tooltip="The IterativeImputer class is very flexible - it can be used with a variety of estimators to do..."><figure class="align-default" id="id8">
<img alt="Imputing missing values with variants of IterativeImputer" src="../../_images/sphx_glr_plot_iterative_imputer_variants_comparison_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../auto_examples/impute/plot_iterative_imputer_variants_comparison.html#sphx-glr-auto-examples-impute-plot-iterative-imputer-variants-comparison-py"><span class="std std-ref">Imputar valores faltantes con variantes de IterativeImputer</span></a></span><a class="headerlink" href="#id8" title="Enlace permanente a esta imagen">¶</a></p>
</figcaption>
</figure>
</div><div class="clearer"></div></section>
</section>


      </div>
    <div class="container">
      <footer class="sk-content-footer">
            &copy; 2007 - 2020, scikit-learn developers (BSD License).
          <a href="../../_sources/modules/generated/sklearn.tree.DecisionTreeRegressor.rst.txt" rel="nofollow">Mostrar la fuente de esta página</a>
      </footer>
    </div>
  </div>
</div>
<script src="../../_static/js/vendor/bootstrap.min.js"></script>

<script>
    window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
    ga('create', 'UA-22606712-2', 'auto');
    ga('set', 'anonymizeIp', true);
    ga('send', 'pageview');
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>


<script>
$(document).ready(function() {
    /* Add a [>>>] button on the top-right corner of code samples to hide
     * the >>> and ... prompts and the output and thus make the code
     * copyable. */
    var div = $('.highlight-python .highlight,' +
                '.highlight-python3 .highlight,' +
                '.highlight-pycon .highlight,' +
		'.highlight-default .highlight')
    var pre = div.find('pre');

    // get the styles from the current theme
    pre.parent().parent().css('position', 'relative');
    var hide_text = 'Hide prompts and outputs';
    var show_text = 'Show prompts and outputs';

    // create and add the button to all the code blocks that contain >>>
    div.each(function(index) {
        var jthis = $(this);
        if (jthis.find('.gp').length > 0) {
            var button = $('<span class="copybutton">&gt;&gt;&gt;</span>');
            button.attr('title', hide_text);
            button.data('hidden', 'false');
            jthis.prepend(button);
        }
        // tracebacks (.gt) contain bare text elements that need to be
        // wrapped in a span to work with .nextUntil() (see later)
        jthis.find('pre:has(.gt)').contents().filter(function() {
            return ((this.nodeType == 3) && (this.data.trim().length > 0));
        }).wrap('<span>');
    });

    // define the behavior of the button when it's clicked
    $('.copybutton').click(function(e){
        e.preventDefault();
        var button = $(this);
        if (button.data('hidden') === 'false') {
            // hide the code output
            button.parent().find('.go, .gp, .gt').hide();
            button.next('pre').find('.gt').nextUntil('.gp, .go').css('visibility', 'hidden');
            button.css('text-decoration', 'line-through');
            button.attr('title', show_text);
            button.data('hidden', 'true');
        } else {
            // show the code output
            button.parent().find('.go, .gp, .gt').show();
            button.next('pre').find('.gt').nextUntil('.gp, .go').css('visibility', 'visible');
            button.css('text-decoration', 'none');
            button.attr('title', hide_text);
            button.data('hidden', 'false');
        }
    });

	/*** Add permalink buttons next to glossary terms ***/
	$('dl.glossary > dt[id]').append(function() {
		return ('<a class="headerlink" href="#' +
			    this.getAttribute('id') +
			    '" title="Permalink to this term">¶</a>');
	});
  /*** Hide navbar when scrolling down ***/
  // Returns true when headerlink target matches hash in url
  (function() {
    hashTargetOnTop = function() {
        var hash = window.location.hash;
        if ( hash.length < 2 ) { return false; }

        var target = document.getElementById( hash.slice(1) );
        if ( target === null ) { return false; }

        var top = target.getBoundingClientRect().top;
        return (top < 2) && (top > -2);
    };

    // Hide navbar on load if hash target is on top
    var navBar = document.getElementById("navbar");
    var navBarToggler = document.getElementById("sk-navbar-toggler");
    var navBarHeightHidden = "-" + navBar.getBoundingClientRect().height + "px";
    var $window = $(window);

    hideNavBar = function() {
        navBar.style.top = navBarHeightHidden;
    };

    showNavBar = function() {
        navBar.style.top = "0";
    }

    if (hashTargetOnTop()) {
        hideNavBar()
    }

    var prevScrollpos = window.pageYOffset;
    hideOnScroll = function(lastScrollTop) {
        if (($window.width() < 768) && (navBarToggler.getAttribute("aria-expanded") === 'true')) {
            return;
        }
        if (lastScrollTop > 2 && (prevScrollpos <= lastScrollTop) || hashTargetOnTop()){
            hideNavBar()
        } else {
            showNavBar()
        }
        prevScrollpos = lastScrollTop;
    };

    /*** high performance scroll event listener***/
    var raf = window.requestAnimationFrame ||
        window.webkitRequestAnimationFrame ||
        window.mozRequestAnimationFrame ||
        window.msRequestAnimationFrame ||
        window.oRequestAnimationFrame;
    var lastScrollTop = $window.scrollTop();

    if (raf) {
        loop();
    }

    function loop() {
        var scrollTop = $window.scrollTop();
        if (lastScrollTop === scrollTop) {
            raf(loop);
            return;
        } else {
            lastScrollTop = scrollTop;
            hideOnScroll(lastScrollTop);
            raf(loop);
        }
    }
  })();
});

</script>
    
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
    
</body>
</html>