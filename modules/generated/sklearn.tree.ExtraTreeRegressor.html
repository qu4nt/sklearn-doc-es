

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  
  <title>sklearn.tree.ExtraTreeRegressor &mdash; documentación de scikit-learn - 0.24.1</title>
  
  <link rel="canonical" href="http://scikit-learn.org/stable/modules/generated/sklearn.tree.ExtraTreeRegressor.html" />

  
  <link rel="shortcut icon" href="../../_static/favicon.ico"/>
  

  <link rel="stylesheet" href="../../_static/css/vendor/bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/gallery.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
<script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
<script src="../../_static/jquery.js"></script> 
</head>
<body>
<nav id="navbar" class="sk-docs-navbar navbar navbar-expand-md navbar-light bg-light py-0">
  <div class="container-fluid sk-docs-container px-0">
      <a class="navbar-brand py-0" href="../../index.html">
        <img
          class="sk-brand-img"
          src="../../_static/scikit-learn-logo-small.png"
          alt="logo"/>
      </a>
    <button
      id="sk-navbar-toggler"
      class="navbar-toggler"
      type="button"
      data-toggle="collapse"
      data-target="#navbarSupportedContent"
      aria-controls="navbarSupportedContent"
      aria-expanded="false"
      aria-label="Toggle navigation"
    >
      <span class="navbar-toggler-icon"></span>
    </button>

    <div class="sk-navbar-collapse collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav mr-auto">
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../install.html">Instalación</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../user_guide.html">Manual de Usuario</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../classes.html">API</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../auto_examples/index.html">Ejemplos</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../getting_started.html">¿Cómo empezar?</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../tutorial/index.html">Tutorial</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../whats_new/v0.24.html">Novedades</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../glossary.html">Glosario</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../developers/index.html">Desarrollo</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../faq.html">FAQ</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../support.html">Soporte</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../related_projects.html">Paquetes relacionados</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../roadmap.html">Hoja de ruta</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../about.html">Sobre nosotros</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="https://github.com/scikit-learn/scikit-learn">GitHub</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="https://scikit-learn.org/dev/versions.html">Otras versiones y descargas</a>
        </li>
        <li class="nav-item dropdown nav-more-item-dropdown">
          <a class="sk-nav-link nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Más</a>
          <div class="dropdown-menu" aria-labelledby="navbarDropdown">
              <a class="sk-nav-dropdown-item dropdown-item" href="../../getting_started.html">¿Cómo empezar?</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../tutorial/index.html">Tutorial</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../whats_new/v0.24.html">Novedades</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../glossary.html">Glosario</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../developers/index.html">Desarrollo</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../faq.html">FAQ</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../support.html">Soporte</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../related_projects.html">Paquetes relacionados</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../roadmap.html">Hoja de ruta</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../about.html">Sobre nosotros</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="https://github.com/scikit-learn/scikit-learn">GitHub</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="https://scikit-learn.org/dev/versions.html">Otras versiones y descargas</a>
          </div>
        </li>
      </ul>
      <div id="searchbox" role="search">
          <div class="searchformwrapper">
          <form class="search" action="../../search.html" method="get">
            <input class="sk-search-text-input" type="text" name="q" aria-labelledby="searchlabel" />
            <input class="sk-search-text-btn" type="submit" value="Ir a" />
          </form>
          </div>
      </div>
    </div>
  </div>
</nav>
<div class="d-flex" id="sk-doc-wrapper">
    <input type="checkbox" name="sk-toggle-checkbox" id="sk-toggle-checkbox">
    <label id="sk-sidemenu-toggle" class="sk-btn-toggle-toc btn sk-btn-primary" for="sk-toggle-checkbox">Alternar menú</label>
    <div id="sk-sidebar-wrapper" class="border-right">
      <div class="sk-sidebar-toc-wrapper">
        <div class="sk-sidebar-toc-logo">
          <a href="../../index.html">
            <img
              class="sk-brand-img"
              src="../../_static/scikit-learn-logo-small.png"
              alt="logo"/>
          </a>
        </div>
        <div class="btn-group w-100 mb-2" role="group" aria-label="rellinks">
            <a href="sklearn.tree.ExtraTreeClassifier.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="sklearn.tree.ExtraTreeClassifier">Prev</a><a href="../classes.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="Referencia de la API">Arriba</a>
            <a href="sklearn.tree.export_graphviz.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="sklearn.tree.export_graphviz">Sig.</a>
        </div>
        <div class="alert alert-danger p-1 mb-2" role="alert">
          <p class="text-center mb-0">
          <strong>scikit-learn 0.24.1</strong><br/>
          <a href="http://scikit-learn.org/dev/versions.html">Otras versiones</a>
          </p>
        </div>
        <div class="alert alert-warning p-1 mb-2" role="alert">
          <p class="text-center mb-0">
            Por favor <a class="font-weight-bold" href="../../about.html#citing-scikit-learn"><string>cítanos</string></a> si usas el software.
          </p>
        </div>
            <div class="sk-sidebar-toc">
              <ul>
<li><a class="reference internal" href="#"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.tree</span></code>.ExtraTreeRegressor</a></li>
</ul>

            </div>
      </div>
    </div>
    <div id="sk-page-content-wrapper">
      <div class="sk-page-content container-fluid body px-md-3" role="main">
        
  <section id="sklearn-tree-extratreeregressor">
<h1><a class="reference internal" href="../classes.html#module-sklearn.tree" title="sklearn.tree"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.tree</span></code></a>.ExtraTreeRegressor<a class="headerlink" href="#sklearn-tree-extratreeregressor" title="Enlazar permanentemente con este título">¶</a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="sklearn.tree.ExtraTreeRegressor">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">sklearn.tree.</span></span><span class="sig-name descname"><span class="pre">ExtraTreeRegressor</span></span><a class="headerlink" href="#sklearn.tree.ExtraTreeRegressor" title="Enlazar permanentemente con esta definición">¶</a></dt>
<dd><p>Un árbol regresor extremadamente aleatorio.</p>
<p>Los extra-árboles difieren de los árboles de decisión clásicos en la forma en que se construyen. Cuando se busca la mejor división para separar las muestras de un nodo en dos grupos, se dibujan divisiones aleatorias para cada una de las características seleccionadas al azar <code class="docutils literal notranslate"><span class="pre">max_features</span></code> y se elige la mejor división entre ellas. Cuando <code class="docutils literal notranslate"><span class="pre">max_features</span></code> se fija en 1, esto equivale a construir un árbol de decisión totalmente aleatorio.</p>
<p>Advertencia: Los extra-árboles sólo deben utilizarse dentro de los métodos de conjunto.</p>
<p>Lee más en el <a class="reference internal" href="../tree.html#tree"><span class="std std-ref">Manual de usuario</span></a>.</p>
<dl class="field-list">
<dt class="field-odd">Parámetros</dt>
<dd class="field-odd"><dl>
<dt><strong>criterion</strong><span class="classifier">{«mse», «friedman_mse», «mae»}, default=»mse»</span></dt><dd><p>La función para medir la calidad de una separación. Los criterios soportados son «mse» para el error cuadrático medio, que es igual a la reducción de la varianza como criterio de selección de características y «mae» para el error absoluto medio.</p>
<div class="versionadded">
<p><span class="versionmodified added">Nuevo en la versión 0.18: </span>Criterio de Error Absoluto Medio (EAM, MAE en inglés).</p>
</div>
<div class="versionadded">
<p><span class="versionmodified added">Nuevo en la versión 0.24: </span>Criterio de desviación de Poisson.</p>
</div>
</dd>
<dt><strong>splitter</strong><span class="classifier">{«random», «best»}, default=»random»</span></dt><dd><p>La estrategia utilizada para elegir la separación en cada nodo. Las estrategias soportadas son «best» para elegir la mejor separación y «random» para elegir la mejor separación aleatoria.</p>
</dd>
<dt><strong>max_depth</strong><span class="classifier">int, default=None</span></dt><dd><p>La profundidad máxima del árbol. Si es None, los nodos se expanden hasta que todas las hojas sean puras o hasta que todas las hojas contengan menos muestras que min_samples_split.</p>
</dd>
<dt><strong>min_samples_split</strong><span class="classifier">int o float, default=2</span></dt><dd><p>El número mínimo de muestras necesario para separar un nodo interno:</p>
<ul class="simple">
<li><p>Si es int, entonces considere <code class="docutils literal notranslate"><span class="pre">min_samples_split</span></code> como el número mínimo.</p></li>
<li><p>Si es de punto flotante (float), <code class="docutils literal notranslate"><span class="pre">min_samples_split</span></code> es una fracción y <code class="docutils literal notranslate"><span class="pre">ceil(min_samples_split</span> <span class="pre">*</span> <span class="pre">n_samples)</span></code> es el número mínimo de muestras para cada separación.</p></li>
</ul>
<div class="versionchanged">
<p><span class="versionmodified changed">Distinto en la versión 0.18: </span>Se han añadido valores flotantes para las fracciones.</p>
</div>
</dd>
<dt><strong>min_samples_leaf</strong><span class="classifier">int o float, default=1</span></dt><dd><p>El número mínimo de muestras requerido para estar en un nodo hoja. Un punto de separación en cualquier profundidad sólo se considerará si deja al menos <code class="docutils literal notranslate"><span class="pre">min_samples_leaf</span></code> muestras de entrenamiento en cada una de las ramas izquierda y derecha.  Esto puede tener el efecto de suavizar el modelo, especialmente en la regresión.</p>
<ul class="simple">
<li><p>Si es entero, entonces considera <code class="docutils literal notranslate"><span class="pre">min_samples_split</span></code> como el número mínimo.</p></li>
<li><p>Si es de punto flotante (float), entonces <code class="docutils literal notranslate"><span class="pre">min_samples_leaf</span></code> es una fracción y <code class="docutils literal notranslate"><span class="pre">ceil(min_samples_leaf</span> <span class="pre">*</span> <span class="pre">n_samples)</span></code> son el número mínimo de muestras para cada nodo.</p></li>
</ul>
<div class="versionchanged">
<p><span class="versionmodified changed">Distinto en la versión 0.18: </span>Se han añadido valores flotantes para las fracciones.</p>
</div>
</dd>
<dt><strong>min_weight_fraction_leaf</strong><span class="classifier">float, default=0.0</span></dt><dd><p>La fracción ponderada mínima de la suma total de pesos (de todas las muestras de entrada) requerida para estar en un nodo hoja. Las muestras tienen el mismo peso cuando no se proporciona sample_weight.</p>
</dd>
<dt><strong>max_features</strong><span class="classifier">int, float, {«auto», «sqrt», «log2»} o None, default=»auto»</span></dt><dd><p>El número de características a considerar cuando se busca la mejor separación:</p>
<ul class="simple">
<li><p>Si es int, entonces se consideran las características <code class="docutils literal notranslate"><span class="pre">max_features</span></code> en cada separación.</p></li>
<li><p>Si es de punto flotante (float), entonces <code class="docutils literal notranslate"><span class="pre">max_features</span></code> es una fracción y las características <code class="docutils literal notranslate"><span class="pre">int(max_features</span> <span class="pre">*</span> <span class="pre">n_features)</span></code> se consideran en cada separación.</p></li>
<li><p>Si es «auto», entonces <code class="docutils literal notranslate"><span class="pre">max_features=n_features</span></code>.</p></li>
<li><p>Si es «sqrt», entonces <code class="docutils literal notranslate"><span class="pre">max_features=sqrt(n_features)</span></code>.</p></li>
<li><p>Si es «log2», entonces <code class="docutils literal notranslate"><span class="pre">max_features=log2(n_features)</span></code>.</p></li>
<li><p>Si es None, entonces <code class="docutils literal notranslate"><span class="pre">max_features=n_features</span></code>.</p></li>
</ul>
<p>Nota: la búsqueda de una división no se detiene hasta que se encuentra al menos una partición válida de las muestras del nodo, incluso si requiere inspeccionar efectivamente más características que <code class="docutils literal notranslate"><span class="pre">max_features</span></code>.</p>
</dd>
<dt><strong>random_state</strong><span class="classifier">entero, instancia de RandomState o None, default=None</span></dt><dd><p>Se utiliza para elegir aleatoriamente el <code class="docutils literal notranslate"><span class="pre">max_features</span></code> utilizado en cada separación. Ver <a class="reference internal" href="../../glossary.html#term-random_state"><span class="xref std std-term">Glosario</span></a> para más detalles.</p>
</dd>
<dt><strong>min_impurity_decrease</strong><span class="classifier">float, default=0.0</span></dt><dd><p>Un nodo se separará si esta separación induce una disminución de la impureza mayor o igual a este valor.</p>
<p>La ecuación de disminución de impurezas ponderada es la siguiente:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">N_t</span> <span class="o">/</span> <span class="n">N</span> <span class="o">*</span> <span class="p">(</span><span class="n">impurity</span> <span class="o">-</span> <span class="n">N_t_R</span> <span class="o">/</span> <span class="n">N_t</span> <span class="o">*</span> <span class="n">right_impurity</span>
                    <span class="o">-</span> <span class="n">N_t_L</span> <span class="o">/</span> <span class="n">N_t</span> <span class="o">*</span> <span class="n">left_impurity</span><span class="p">)</span>
</pre></div>
</div>
<p>donde <code class="docutils literal notranslate"><span class="pre">N</span></code> es el número total de muestras, <code class="docutils literal notranslate"><span class="pre">N_t</span></code> es el número de muestras en el nodo actual, <code class="docutils literal notranslate"><span class="pre">N_t_L</span></code> es el número de muestras en el hijo izquierdo, y <code class="docutils literal notranslate"><span class="pre">N_t_R</span></code> es el número de muestras en el hijo derecho.</p>
<p><code class="docutils literal notranslate"><span class="pre">N</span></code>, <code class="docutils literal notranslate"><span class="pre">N_t</span></code>, <code class="docutils literal notranslate"><span class="pre">N_t_R</span></code> y <code class="docutils literal notranslate"><span class="pre">N_t_L</span></code> se refieren a la suma ponderada, si se pasa <code class="docutils literal notranslate"><span class="pre">sample_weight</span></code>.</p>
<div class="versionadded">
<p><span class="versionmodified added">Nuevo en la versión 0.19.</span></p>
</div>
</dd>
<dt><strong>min_impurity_split</strong><span class="classifier">float, default=None</span></dt><dd><p>Umbral para la parada anticipada en el crecimiento del árbol. Un nodo se separará si su impureza está por encima del umbral, de lo contrario será una hoja.</p>
<div class="deprecated">
<p><span class="versionmodified deprecated">Obsoleto desde la versión 0.19: </span>El valor de <code class="docutils literal notranslate"><span class="pre">min_impurity_split</span></code> ha quedado obsoleto en favor de <code class="docutils literal notranslate"><span class="pre">min_impurity_decrease</span></code> en 0.19. El valor predeterminado de <code class="docutils literal notranslate"><span class="pre">min_impurity_split</span></code> ha cambiado de 1e-7 a 0 en 0.23 y se eliminará en 1.0 (cambio de nombre de 0.25). Utilice <code class="docutils literal notranslate"><span class="pre">min_impurity_decrease</span></code> en su lugar.</p>
</div>
</dd>
<dt><strong>max_leaf_nodes</strong><span class="classifier">int, default=None</span></dt><dd><p>Crece un árbol con <code class="docutils literal notranslate"><span class="pre">max_leaf_nodes</span></code> en modo best-first. Los mejores nodos se definen como una reducción relativa de la impureza. Si es None, el número de nodos de la hoja es ilimitado.</p>
</dd>
<dt><strong>ccp_alpha</strong><span class="classifier">flotante no negativo, default=0.0</span></dt><dd><p>Parámetro de complejidad utilizado para la poda de complejidad de coste mínimo. Se elegirá el subárbol con la mayor complejidad de costes que sea menor que <code class="docutils literal notranslate"><span class="pre">ccp_alpha</span></code>. Por defecto, no se realiza ninguna poda. Ver <a class="reference internal" href="../tree.html#minimal-cost-complexity-pruning"><span class="std std-ref">Poda de Coste-Complejidad Mínima</span></a> para más detalles.</p>
<div class="versionadded">
<p><span class="versionmodified added">Nuevo en la versión 0.22.</span></p>
</div>
</dd>
</dl>
</dd>
<dt class="field-even">Atributos</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>max_features_</strong><span class="classifier">int</span></dt><dd><p>El valor inferido de max_features.</p>
</dd>
<dt><strong>n_features_</strong><span class="classifier">int</span></dt><dd><p>El número de características cuando <code class="docutils literal notranslate"><span class="pre">fit</span></code> es realizado.</p>
</dd>
<dt><a class="reference internal" href="#sklearn.tree.ExtraTreeRegressor.feature_importances_" title="sklearn.tree.ExtraTreeRegressor.feature_importances_"><code class="xref py py-obj docutils literal notranslate"><span class="pre">feature_importances_</span></code></a><span class="classifier">ndarray de forma (n_features,)</span></dt><dd><p>Devuelve la importancia de las características.</p>
</dd>
<dt><strong>n_outputs_</strong><span class="classifier">int</span></dt><dd><p>El número de salidas cuando se realiza <code class="docutils literal notranslate"><span class="pre">fit</span></code>.</p>
</dd>
<dt><strong>tree_</strong><span class="classifier">Instancia del árbol</span></dt><dd><p>El objeto Tree subyacente. Por favor, consulte <code class="docutils literal notranslate"><span class="pre">help(sklearn.tree._tree.Tree)</span></code> para los atributos del objeto Tree y <a class="reference internal" href="../../auto_examples/tree/plot_unveil_tree_structure.html#sphx-glr-auto-examples-tree-plot-unveil-tree-structure-py"><span class="std std-ref">Comprensión de la estructura del árbol de decisiones</span></a> para el uso básico de estos atributos.</p>
</dd>
</dl>
</dd>
</dl>
<div class="admonition seealso">
<p class="admonition-title">Ver también</p>
<dl class="simple">
<dt><a class="reference internal" href="sklearn.tree.ExtraTreeClassifier.html#sklearn.tree.ExtraTreeClassifier" title="sklearn.tree.ExtraTreeClassifier"><code class="xref py py-obj docutils literal notranslate"><span class="pre">ExtraTreeClassifier</span></code></a></dt><dd><p>Un clasificador de árboles extremadamente aleatorio.</p>
</dd>
<dt><a class="reference internal" href="sklearn.ensemble.ExtraTreesClassifier.html#sklearn.ensemble.ExtraTreesClassifier" title="sklearn.ensemble.ExtraTreesClassifier"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sklearn.ensemble.ExtraTreesClassifier</span></code></a></dt><dd><p>Un clasificador extra-árbol.</p>
</dd>
<dt><a class="reference internal" href="sklearn.ensemble.ExtraTreesRegressor.html#sklearn.ensemble.ExtraTreesRegressor" title="sklearn.ensemble.ExtraTreesRegressor"><code class="xref py py-obj docutils literal notranslate"><span class="pre">sklearn.ensemble.ExtraTreesRegressor</span></code></a></dt><dd><p>Un regresor extra-árbol.</p>
</dd>
</dl>
</div>
<p class="rubric">Notas</p>
<p>Los valores predeterminados de los parámetros que controlan el tamaño de los árboles (por ejemplo, <code class="docutils literal notranslate"><span class="pre">`max_depth</span></code>, <code class="docutils literal notranslate"><span class="pre">min_samples_leaf</span></code>, etc.) conducen a árboles completamente desarrollados y sin podar que pueden ser potencialmente muy grandes en algunos conjuntos de datos. Para reducir el consumo de memoria, la complejidad y el tamaño de los árboles deben controlarse estableciendo los valores de esos parámetros.</p>
<p class="rubric">Referencias</p>
<dl class="citation">
<dt class="label" id="r4939d63d5a49-1"><span class="brackets">1</span></dt>
<dd><p>P. Geurts, D. Ernst., and L. Wehenkel, «Extremely randomized trees»,
Machine Learning, 63(1), 3-42, 2006.</p>
</dd>
</dl>
<p class="rubric">Ejemplos</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_diabetes</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">BaggingRegressor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">ExtraTreeRegressor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">load_diabetes</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">extra_tree</span> <span class="o">=</span> <span class="n">ExtraTreeRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reg</span> <span class="o">=</span> <span class="n">BaggingRegressor</span><span class="p">(</span><span class="n">extra_tree</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">reg</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="go">0.33...</span>
</pre></div>
</div>
<p class="rubric">Métodos</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#sklearn.tree.ExtraTreeRegressor.apply" title="sklearn.tree.ExtraTreeRegressor.apply"><code class="xref py py-obj docutils literal notranslate"><span class="pre">apply</span></code></a></p></td>
<td><p>Devuelve el índice de la hoja como la que se predice cada muestra.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#sklearn.tree.ExtraTreeRegressor.cost_complexity_pruning_path" title="sklearn.tree.ExtraTreeRegressor.cost_complexity_pruning_path"><code class="xref py py-obj docutils literal notranslate"><span class="pre">cost_complexity_pruning_path</span></code></a></p></td>
<td><p>Calcule la ruta de poda durante la poda de coste-complejidad mínima.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#sklearn.tree.ExtraTreeRegressor.decision_path" title="sklearn.tree.ExtraTreeRegressor.decision_path"><code class="xref py py-obj docutils literal notranslate"><span class="pre">decision_path</span></code></a></p></td>
<td><p>Devuelve la ruta de decisión en el árbol.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#sklearn.tree.ExtraTreeRegressor.fit" title="sklearn.tree.ExtraTreeRegressor.fit"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit</span></code></a></p></td>
<td><p>Construir un árbol de decisión regresor a partir del conjunto de entrenamiento (X, y).</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#sklearn.tree.ExtraTreeRegressor.get_depth" title="sklearn.tree.ExtraTreeRegressor.get_depth"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_depth</span></code></a></p></td>
<td><p>Devuelve la profundidad del árbol de decisión.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#sklearn.tree.ExtraTreeRegressor.get_n_leaves" title="sklearn.tree.ExtraTreeRegressor.get_n_leaves"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_n_leaves</span></code></a></p></td>
<td><p>Devuelve el número de hojas del árbol de decisión.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#sklearn.tree.ExtraTreeRegressor.get_params" title="sklearn.tree.ExtraTreeRegressor.get_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_params</span></code></a></p></td>
<td><p>Obtiene los parámetros para este estimador.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#sklearn.tree.ExtraTreeRegressor.predict" title="sklearn.tree.ExtraTreeRegressor.predict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">predict</span></code></a></p></td>
<td><p>Predice la clase o regresión para X.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#sklearn.tree.ExtraTreeRegressor.score" title="sklearn.tree.ExtraTreeRegressor.score"><code class="xref py py-obj docutils literal notranslate"><span class="pre">score</span></code></a></p></td>
<td><p>Devuelve el coeficiente de determinación <span class="math notranslate nohighlight">\(R^2\)</span> de la predicción.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#sklearn.tree.ExtraTreeRegressor.set_params" title="sklearn.tree.ExtraTreeRegressor.set_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_params</span></code></a></p></td>
<td><p>Establece los parámetros de este estimador.</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="sklearn.tree.ExtraTreeRegressor.apply">
<span class="sig-name descname"><span class="pre">apply</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.tree.ExtraTreeRegressor.apply" title="Enlazar permanentemente con esta definición">¶</a></dt>
<dd><p>Devuelve el índice de la hoja como la que se predice cada muestra.</p>
<div class="versionadded">
<p><span class="versionmodified added">Nuevo en la versión 0.17.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parámetros</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">{array-like, sparse matrix} de forma (n_samples, n_features)</span></dt><dd><p>Las muestras de entrada. Internamente, se convertirá a <code class="docutils literal notranslate"><span class="pre">dtype=np.float32</span></code> y si se proporciona una matriz dispersa a una <code class="docutils literal notranslate"><span class="pre">csr_matrix</span></code> dispersa.</p>
</dd>
<dt><strong>check_input</strong><span class="classifier">bool, default=True</span></dt><dd><p>Permite eludir varias comprobaciones de entrada. No uses este parámetro a menos que sepas lo que haces.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Devuelve</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>X_leaves</strong><span class="classifier">array-like de forma (n_samples,)</span></dt><dd><p>Para cada punto de datos x en X, devuelve el índice de la hoja en la que termina x. Las hojas se numeran dentro de <code class="docutils literal notranslate"><span class="pre">[0;</span> <span class="pre">self.tree_.node_count)</span></code>, posiblemente con huecos en la numeración.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.tree.ExtraTreeRegressor.cost_complexity_pruning_path">
<span class="sig-name descname"><span class="pre">cost_complexity_pruning_path</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.tree.ExtraTreeRegressor.cost_complexity_pruning_path" title="Enlazar permanentemente con esta definición">¶</a></dt>
<dd><p>Calcule la ruta de poda durante la poda de coste-complejidad mínima.</p>
<p>Ver <a class="reference internal" href="../tree.html#minimal-cost-complexity-pruning"><span class="std std-ref">Poda de Coste-Complejidad Mínima</span></a> for details on the pruning process.</p>
<dl class="field-list">
<dt class="field-odd">Parámetros</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">{array-like, sparse matrix} de forma (n_samples, n_features)</span></dt><dd><p>Las muestras de entrada de entrenamiento. Internamente, se convertirá a <code class="docutils literal notranslate"><span class="pre">dtype=np.float32</span></code> y si se proporciona una matriz dispersa a una <code class="docutils literal notranslate"><span class="pre">csc_matrix</span></code> dispersa.</p>
</dd>
<dt><strong>y</strong><span class="classifier">array-like de forma (n_samples,) o (n_samples, n_outputs)</span></dt><dd><p>Los valores objetivo (etiquetas de clase) como enteros o cadenas.</p>
</dd>
<dt><strong>sample_weight</strong><span class="classifier">array-like de forma (n_samples,) default=None</span></dt><dd><p>Pesos de las muestras. Si es None, las muestras se ponderan por igual. Las separaciones que crearían nodos hijos con peso neto cero o negativo se ignoran al buscar una separación en cada nodo. Las separaciones también se ignoran si dan lugar a que una sola clase tenga un peso negativo en cualquiera de los nodos hijos.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Devuelve</dt>
<dd class="field-even"><dl>
<dt><strong>ccp_path</strong><span class="classifier"><a class="reference internal" href="sklearn.utils.Bunch.html#sklearn.utils.Bunch" title="sklearn.utils.Bunch"><code class="xref py py-class docutils literal notranslate"><span class="pre">Bunch</span></code></a></span></dt><dd><p>Objeto tipo diccionario, con los siguientes atributos.</p>
<dl class="simple">
<dt>ccp_alphas<span class="classifier">ndarray</span></dt><dd><p>Alfas efectivas del subárbol durante la poda.</p>
</dd>
<dt>impurezas<span class="classifier">ndarray</span></dt><dd><p>Suma de las impurezas de las hojas del subárbol para el valor alfa correspondiente en <code class="docutils literal notranslate"><span class="pre">ccp_alphas</span></code>.</p>
</dd>
</dl>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.tree.ExtraTreeRegressor.decision_path">
<span class="sig-name descname"><span class="pre">decision_path</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.tree.ExtraTreeRegressor.decision_path" title="Enlazar permanentemente con esta definición">¶</a></dt>
<dd><p>Devuelve la ruta de decisión en el árbol.</p>
<div class="versionadded">
<p><span class="versionmodified added">Nuevo en la versión 0.18.</span></p>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parámetros</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">{array-like, sparse matrix} de forma (n_samples, n_features)</span></dt><dd><p>Las muestras de entrada. Internamente, se convertirá a <code class="docutils literal notranslate"><span class="pre">dtype=np.float32</span></code> y si se proporciona una matriz dispersa a una <code class="docutils literal notranslate"><span class="pre">csr_matrix</span></code> dispersa.</p>
</dd>
<dt><strong>check_input</strong><span class="classifier">bool, default=True</span></dt><dd><p>Permite eludir varias comprobaciones de entrada. No uses este parámetro a menos que sepas lo que haces.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Devuelve</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>indicator</strong><span class="classifier">matriz dispersa de forma (n_samples, n_nodes)</span></dt><dd><p>Devuelve una matriz CSR indicadora de nodos donde los elementos no nulos indican que las muestras pasan por los nodos.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="sklearn.tree.ExtraTreeRegressor.feature_importances_">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">feature_importances_</span></span><a class="headerlink" href="#sklearn.tree.ExtraTreeRegressor.feature_importances_" title="Enlazar permanentemente con esta definición">¶</a></dt>
<dd><p>Devuelve la importancia de las características.</p>
<p>La importancia de una característica se calcula como la reducción total (normalizada) del criterio aportado por esa característica. También se conoce como la importancia de Gini.</p>
<p>Advertencia: las importancias de las características basadas en la impureza pueden ser no representativas para las características de alta cardinalidad (muchos valores únicos). Ver <a class="reference internal" href="sklearn.inspection.permutation_importance.html#sklearn.inspection.permutation_importance" title="sklearn.inspection.permutation_importance"><code class="xref py py-func docutils literal notranslate"><span class="pre">sklearn.inspection.permutation_importance</span></code></a> como alternativa.</p>
<dl class="field-list simple">
<dt class="field-odd">Devuelve</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>feature_importances_</strong><span class="classifier">ndarray de forma (n_features,)</span></dt><dd><p>Reducción total normalizada de los criterios por característica (importancia de Gini).</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.tree.ExtraTreeRegressor.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.tree.ExtraTreeRegressor.fit" title="Enlazar permanentemente con esta definición">¶</a></dt>
<dd><p>Construir un árbol de decisión regresor a partir del conjunto de entrenamiento (X, y).</p>
<dl class="field-list">
<dt class="field-odd">Parámetros</dt>
<dd class="field-odd"><dl>
<dt><strong>X</strong><span class="classifier">{array-like, sparse matrix} de forma (n_samples, n_features)</span></dt><dd><p>Las muestras de entrada de entrenamiento. Internamente, se convertirá a <code class="docutils literal notranslate"><span class="pre">dtype=np.float32</span></code> y si se proporciona una matriz dispersa a una <code class="docutils literal notranslate"><span class="pre">csc_matrix</span></code> dispersa.</p>
</dd>
<dt><strong>y</strong><span class="classifier">array-like de forma (n_samples,) o (n_samples, n_outputs)</span></dt><dd><p>Los valores objetivo (números reales). Utilice <code class="docutils literal notranslate"><span class="pre">dtype=np.float64</span></code> y <code class="docutils literal notranslate"><span class="pre">order='C'</span></code> para obtener la máxima eficiencia.</p>
</dd>
<dt><strong>sample_weight</strong><span class="classifier">array-like de forma (n_samples,) default=None</span></dt><dd><p>Pesos de las muestras. Si es None, las muestras se ponderan por igual. Las separaciones que crearían nodos hijos con peso neto cero o negativo se ignoran al buscar una separación en cada nodo.</p>
</dd>
<dt><strong>check_input</strong><span class="classifier">bool, default=True</span></dt><dd><p>Permite eludir varias comprobaciones de entrada. No uses este parámetro a menos que sepas lo que haces.</p>
</dd>
<dt><strong>X_idx_sorted</strong><span class="classifier">obsoleto, default=»deprecated»</span></dt><dd><p>Este parámetro está obsoleto y no tiene ningún efecto. Se eliminará en la versión 1.1 (cambio de nombre de la versión 0.26).</p>
<div class="deprecated">
<p><span class="versionmodified deprecated">Obsoleto desde la versión 0.24.</span></p>
</div>
</dd>
</dl>
</dd>
<dt class="field-even">Devuelve</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>self</strong><span class="classifier">DecisionTreeRegressor</span></dt><dd><p>Estimador ajustado.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.tree.ExtraTreeRegressor.get_depth">
<span class="sig-name descname"><span class="pre">get_depth</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.tree.ExtraTreeRegressor.get_depth" title="Enlazar permanentemente con esta definición">¶</a></dt>
<dd><p>Devuelve la profundidad del árbol de decisión.</p>
<p>La profundidad de un árbol es la distancia máxima entre la raíz y cualquier hoja.</p>
<dl class="field-list simple">
<dt class="field-odd">Devuelve</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>self.tree_.max_depth</strong><span class="classifier">int</span></dt><dd><p>La profundidad máxima del árbol.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.tree.ExtraTreeRegressor.get_n_leaves">
<span class="sig-name descname"><span class="pre">get_n_leaves</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.tree.ExtraTreeRegressor.get_n_leaves" title="Enlazar permanentemente con esta definición">¶</a></dt>
<dd><p>Devuelve el número de hojas del árbol de decisión.</p>
<dl class="field-list simple">
<dt class="field-odd">Devuelve</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>self.tree_.n_leaves</strong><span class="classifier">int</span></dt><dd><p>Número de hojas.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.tree.ExtraTreeRegressor.get_params">
<span class="sig-name descname"><span class="pre">get_params</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.tree.ExtraTreeRegressor.get_params" title="Enlazar permanentemente con esta definición">¶</a></dt>
<dd><p>Obtiene los parámetros para este estimador.</p>
<dl class="field-list simple">
<dt class="field-odd">Parámetros</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>deep</strong><span class="classifier">bool, default=True</span></dt><dd><p>Si es True, devolverá los parámetros para este estimador y los subobjetos contenidos que son estimadores.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Devuelve</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>params</strong><span class="classifier">dict</span></dt><dd><p>Nombres de parámetros mapeados a sus valores.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.tree.ExtraTreeRegressor.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.tree.ExtraTreeRegressor.predict" title="Enlazar permanentemente con esta definición">¶</a></dt>
<dd><p>Predice la clase o regresión para X.</p>
<p>Para un modelo de clasificación, se devuelve la clase predicha para cada muestra en X. Para un modelo de regresión, se devuelve el valor predicho basado en X.</p>
<dl class="field-list simple">
<dt class="field-odd">Parámetros</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">{array-like, sparse matrix} de forma (n_samples, n_features)</span></dt><dd><p>Las muestras de entrada. Internamente, se convertirá a <code class="docutils literal notranslate"><span class="pre">dtype=np.float32</span></code> y si se proporciona una matriz dispersa a una <code class="docutils literal notranslate"><span class="pre">csr_matrix</span></code> dispersa.</p>
</dd>
<dt><strong>check_input</strong><span class="classifier">bool, default=True</span></dt><dd><p>Permite eludir varias comprobaciones de entrada. No uses este parámetro a menos que sepas lo que haces.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Devuelve</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>y</strong><span class="classifier">array-like de forma (n_samples,) o (n_samples, n_outputs)</span></dt><dd><p>Las clases predichas, o los valores predichos.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.tree.ExtraTreeRegressor.score">
<span class="sig-name descname"><span class="pre">score</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.tree.ExtraTreeRegressor.score" title="Enlazar permanentemente con esta definición">¶</a></dt>
<dd><p>Devuelve el coeficiente de determinación <span class="math notranslate nohighlight">\(R^2\)</span> de la predicción.</p>
<p>El coeficiente <span class="math notranslate nohighlight">\(R^2\)</span> se define como <span class="math notranslate nohighlight">\((1 - \frac{u}{v})\)</span>, donde <span class="math notranslate nohighlight">\(u\)</span> es la suma residual de cuadrados <code class="docutils literal notranslate"><span class="pre">((y_true</span> <span class="pre">-</span> <span class="pre">y_pred)</span> <span class="pre">**</span> <span class="pre">2).sum()</span></code> y <span class="math notranslate nohighlight">\(v\)</span> es la suma total de cuadrados <code class="docutils literal notranslate"><span class="pre">((y_true</span> <span class="pre">-</span> <span class="pre">y_true.mean())</span> <span class="pre">**</span> <span class="pre">2).sum()</span></code>. La mejor puntuación posible es 1,0 y puede ser negativa (porque el modelo puede ser arbitrariamente peor). Un modelo constante que siempre predice el valor esperado de <code class="docutils literal notranslate"><span class="pre">y</span></code>, sin tener en cuenta las características de entrada, obtendría una puntuación <span class="math notranslate nohighlight">\(R^2\)</span> de 0,0.</p>
<dl class="field-list simple">
<dt class="field-odd">Parámetros</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">array-like de forma (n_samples, n_features)</span></dt><dd><p>Muestras de prueba. Para algunos estimadores esto puede ser una matriz de núcleo precalculada o una lista de objetos genéricos con forma <code class="docutils literal notranslate"><span class="pre">(n_samples,</span> <span class="pre">n_samples_fitted)</span></code>, donde <code class="docutils literal notranslate"><span class="pre">n_samples_fitted</span></code> es el número de muestras utilizadas en el ajuste para el estimador.</p>
</dd>
<dt><strong>y</strong><span class="classifier">array-like de forma (n_samples,) o (n_samples, n_outputs)</span></dt><dd><p>Valores verdaderos para <code class="docutils literal notranslate"><span class="pre">X</span></code>.</p>
</dd>
<dt><strong>sample_weight</strong><span class="classifier">array-like de forma (n_samples,) default=None</span></dt><dd><p>Ponderaciones de muestras.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Devuelve</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>score</strong><span class="classifier">float</span></dt><dd><p><span class="math notranslate nohighlight">\(R^2\)</span> de <code class="docutils literal notranslate"><span class="pre">self.predict(X)</span></code> con respecto a <code class="docutils literal notranslate"><span class="pre">y</span></code>.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notas</p>
<p>La puntuación <span class="math notranslate nohighlight">\(R^2\)</span> utilizada al llamar a <code class="docutils literal notranslate"><span class="pre">score</span></code> en un regresor utiliza <code class="docutils literal notranslate"><span class="pre">multioutput='uniform_average'</span></code> desde la versión 0.23 para mantener la coherencia con el valor predeterminado de <code class="xref py py-func docutils literal notranslate"><span class="pre">r2_score`</span></code>. Esto influye en el método <code class="docutils literal notranslate"><span class="pre">score</span></code> de todos los regresores de salida múltiple (excepto para <a class="reference internal" href="sklearn.multioutput.MultiOutputRegressor.html#sklearn.multioutput.MultiOutputRegressor" title="sklearn.multioutput.MultiOutputRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultiOutputRegressor</span></code></a>).</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.tree.ExtraTreeRegressor.set_params">
<span class="sig-name descname"><span class="pre">set_params</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.tree.ExtraTreeRegressor.set_params" title="Enlazar permanentemente con esta definición">¶</a></dt>
<dd><p>Establece los parámetros de este estimador.</p>
<p>El método funciona tanto con estimadores simples como con objetos anidados (como <a class="reference internal" href="sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline" title="sklearn.pipeline.Pipeline"><code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code></a>). Estos últimos tienen parámetros de la forma <a href="#id1"><span class="problematic" id="id2">``</span></a>&lt;component&gt;__&lt;parameter&gt;` para que sea posible actualizar cada componente de un objeto anidado.</p>
<dl class="field-list simple">
<dt class="field-odd">Parámetros</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>**params</strong><span class="classifier">dict</span></dt><dd><p>Parámetros del estimador.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Devuelve</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>self</strong><span class="classifier">instancia del estimador</span></dt><dd><p>Instancia del estimador.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<div class="clearer"></div></section>


      </div>
    <div class="container">
      <footer class="sk-content-footer">
            &copy; 2007 - 2020, scikit-learn developers (BSD License).
          <a href="../../_sources/modules/generated/sklearn.tree.ExtraTreeRegressor.rst.txt" rel="nofollow">Mostrar la fuente de esta página</a>
      </footer>
    </div>
  </div>
</div>
<script src="../../_static/js/vendor/bootstrap.min.js"></script>

<script>
    window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
    ga('create', 'UA-22606712-2', 'auto');
    ga('set', 'anonymizeIp', true);
    ga('send', 'pageview');
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>


<script>
$(document).ready(function() {
    /* Add a [>>>] button on the top-right corner of code samples to hide
     * the >>> and ... prompts and the output and thus make the code
     * copyable. */
    var div = $('.highlight-python .highlight,' +
                '.highlight-python3 .highlight,' +
                '.highlight-pycon .highlight,' +
		'.highlight-default .highlight')
    var pre = div.find('pre');

    // get the styles from the current theme
    pre.parent().parent().css('position', 'relative');
    var hide_text = 'Hide prompts and outputs';
    var show_text = 'Show prompts and outputs';

    // create and add the button to all the code blocks that contain >>>
    div.each(function(index) {
        var jthis = $(this);
        if (jthis.find('.gp').length > 0) {
            var button = $('<span class="copybutton">&gt;&gt;&gt;</span>');
            button.attr('title', hide_text);
            button.data('hidden', 'false');
            jthis.prepend(button);
        }
        // tracebacks (.gt) contain bare text elements that need to be
        // wrapped in a span to work with .nextUntil() (see later)
        jthis.find('pre:has(.gt)').contents().filter(function() {
            return ((this.nodeType == 3) && (this.data.trim().length > 0));
        }).wrap('<span>');
    });

    // define the behavior of the button when it's clicked
    $('.copybutton').click(function(e){
        e.preventDefault();
        var button = $(this);
        if (button.data('hidden') === 'false') {
            // hide the code output
            button.parent().find('.go, .gp, .gt').hide();
            button.next('pre').find('.gt').nextUntil('.gp, .go').css('visibility', 'hidden');
            button.css('text-decoration', 'line-through');
            button.attr('title', show_text);
            button.data('hidden', 'true');
        } else {
            // show the code output
            button.parent().find('.go, .gp, .gt').show();
            button.next('pre').find('.gt').nextUntil('.gp, .go').css('visibility', 'visible');
            button.css('text-decoration', 'none');
            button.attr('title', hide_text);
            button.data('hidden', 'false');
        }
    });

	/*** Add permalink buttons next to glossary terms ***/
	$('dl.glossary > dt[id]').append(function() {
		return ('<a class="headerlink" href="#' +
			    this.getAttribute('id') +
			    '" title="Permalink to this term">¶</a>');
	});
  /*** Hide navbar when scrolling down ***/
  // Returns true when headerlink target matches hash in url
  (function() {
    hashTargetOnTop = function() {
        var hash = window.location.hash;
        if ( hash.length < 2 ) { return false; }

        var target = document.getElementById( hash.slice(1) );
        if ( target === null ) { return false; }

        var top = target.getBoundingClientRect().top;
        return (top < 2) && (top > -2);
    };

    // Hide navbar on load if hash target is on top
    var navBar = document.getElementById("navbar");
    var navBarToggler = document.getElementById("sk-navbar-toggler");
    var navBarHeightHidden = "-" + navBar.getBoundingClientRect().height + "px";
    var $window = $(window);

    hideNavBar = function() {
        navBar.style.top = navBarHeightHidden;
    };

    showNavBar = function() {
        navBar.style.top = "0";
    }

    if (hashTargetOnTop()) {
        hideNavBar()
    }

    var prevScrollpos = window.pageYOffset;
    hideOnScroll = function(lastScrollTop) {
        if (($window.width() < 768) && (navBarToggler.getAttribute("aria-expanded") === 'true')) {
            return;
        }
        if (lastScrollTop > 2 && (prevScrollpos <= lastScrollTop) || hashTargetOnTop()){
            hideNavBar()
        } else {
            showNavBar()
        }
        prevScrollpos = lastScrollTop;
    };

    /*** high performance scroll event listener***/
    var raf = window.requestAnimationFrame ||
        window.webkitRequestAnimationFrame ||
        window.mozRequestAnimationFrame ||
        window.msRequestAnimationFrame ||
        window.oRequestAnimationFrame;
    var lastScrollTop = $window.scrollTop();

    if (raf) {
        loop();
    }

    function loop() {
        var scrollTop = $window.scrollTop();
        if (lastScrollTop === scrollTop) {
            raf(loop);
            return;
        } else {
            lastScrollTop = scrollTop;
            hideOnScroll(lastScrollTop);
            raf(loop);
        }
    }
  })();
});

</script>
    
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
    
</body>
</html>