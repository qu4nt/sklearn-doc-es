# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2007 - 2020, scikit-learn developers (BSD License)
# This file is distributed under the same license as the scikit-learn
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2021.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: scikit-learn 0.24\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-03-31 11:24-0400\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"

#: ../modules/generated/sklearn.feature_selection.mutual_info_classif.rst:2
msgid ":mod:`sklearn.feature_selection`.mutual_info_classif"
msgstr ""

#: of sklearn.feature_selection._mutual_info.mutual_info_classif:2
msgid "Estimate mutual information for a discrete target variable."
msgstr ""

#: of sklearn.feature_selection._mutual_info.mutual_info_classif:4
msgid ""
"Mutual information (MI) [R50b872b699c4-1]_ between two random variables "
"is a non-negative value, which measures the dependency between the "
"variables. It is equal to zero if and only if two random variables are "
"independent, and higher values mean higher dependency."
msgstr ""

#: of sklearn.feature_selection._mutual_info.mutual_info_classif:9
msgid ""
"The function relies on nonparametric methods based on entropy estimation "
"from k-nearest neighbors distances as described in [R50b872b699c4-2]_ and"
" [R50b872b699c4-3]_. Both methods are based on the idea originally "
"proposed in [R50b872b699c4-4]_."
msgstr ""

#: of sklearn.feature_selection._mutual_info.mutual_info_classif:13
msgid ""
"It can be used for univariate features selection, read more in the "
":ref:`User Guide <univariate_feature_selection>`."
msgstr ""

#: of sklearn.feature_selection._mutual_info.mutual_info_classif
msgid "Parameters"
msgstr ""

#: of sklearn.feature_selection._mutual_info.mutual_info_classif:19
msgid "**X**"
msgstr ""

#: of
msgid "array-like or sparse matrix, shape (n_samples, n_features)"
msgstr ""

#: of sklearn.feature_selection._mutual_info.mutual_info_classif:19
msgid "Feature matrix."
msgstr ""

#: of sklearn.feature_selection._mutual_info.mutual_info_classif:22
msgid "**y**"
msgstr ""

#: of
msgid "array-like of shape (n_samples,)"
msgstr ""

#: of sklearn.feature_selection._mutual_info.mutual_info_classif:22
msgid "Target vector."
msgstr ""

#: of sklearn.feature_selection._mutual_info.mutual_info_classif:29
msgid "**discrete_features**"
msgstr ""

#: of
msgid "{'auto', bool, array-like}, default='auto'"
msgstr ""

#: of sklearn.feature_selection._mutual_info.mutual_info_classif:25
msgid ""
"If bool, then determines whether to consider all features discrete or "
"continuous. If array, then it should be either a boolean mask with shape "
"(n_features,) or array with indices of discrete features. If 'auto', it "
"is assigned to False for dense `X` and to True for sparse `X`."
msgstr ""

#: of sklearn.feature_selection._mutual_info.mutual_info_classif:34
msgid "**n_neighbors**"
msgstr ""

#: of
msgid "int, default=3"
msgstr ""

#: of sklearn.feature_selection._mutual_info.mutual_info_classif:32
msgid ""
"Number of neighbors to use for MI estimation for continuous variables, "
"see [R50b872b699c4-2]_ and [R50b872b699c4-3]_. Higher values reduce "
"variance of the estimation, but could introduce a bias."
msgstr ""

#: of sklearn.feature_selection._mutual_info.mutual_info_classif:38
msgid "**copy**"
msgstr ""

#: of
msgid "bool, default=True"
msgstr ""

#: of sklearn.feature_selection._mutual_info.mutual_info_classif:37
msgid ""
"Whether to make a copy of the given data. If set to False, the initial "
"data will be overwritten."
msgstr ""

#: of sklearn.feature_selection._mutual_info.mutual_info_classif:44
msgid "**random_state**"
msgstr ""

#: of
msgid "int, RandomState instance or None, default=None"
msgstr ""

#: of sklearn.feature_selection._mutual_info.mutual_info_classif:41
msgid ""
"Determines random number generation for adding small noise to continuous "
"variables in order to remove repeated values. Pass an int for "
"reproducible results across multiple function calls. See :term:`Glossary "
"<random_state>`."
msgstr ""

#: of sklearn.feature_selection._mutual_info.mutual_info_classif
msgid "Returns"
msgstr ""

#: of sklearn.feature_selection._mutual_info.mutual_info_classif:56
msgid "**mi**"
msgstr ""

#: of
msgid "ndarray, shape (n_features,)"
msgstr ""

#: of sklearn.feature_selection._mutual_info.mutual_info_classif:49
msgid "Estimated mutual information between each feature and the target."
msgstr ""

#: of sklearn.feature_selection._mutual_info.mutual_info_classif:59
msgid "Notes"
msgstr ""

#: of sklearn.feature_selection._mutual_info.mutual_info_classif:60
msgid ""
"The term \"discrete features\" is used instead of naming them "
"\"categorical\", because it describes the essence more accurately. For "
"example, pixel intensities of an image are discrete features (but hardly "
"categorical) and you will get better results if mark them as such. Also "
"note, that treating a continuous variable as discrete and vice versa will"
" usually give incorrect results, so be attentive about that."
msgstr ""

#: of sklearn.feature_selection._mutual_info.mutual_info_classif:67
msgid ""
"True mutual information can't be negative. If its estimate turns out to "
"be negative, it is replaced by zero."
msgstr ""

#: of sklearn.feature_selection._mutual_info.mutual_info_classif:71
msgid "References"
msgstr ""

#: of sklearn.feature_selection._mutual_info.mutual_info_classif:72
msgid ""
"`Mutual Information <https://en.wikipedia.org/wiki/Mutual_information>`_ "
"on Wikipedia."
msgstr ""

#: of sklearn.feature_selection._mutual_info.mutual_info_classif:75
msgid ""
"A. Kraskov, H. Stogbauer and P. Grassberger, \"Estimating mutual "
"information\". Phys. Rev. E 69, 2004."
msgstr ""

#: of sklearn.feature_selection._mutual_info.mutual_info_classif:77
msgid ""
"B. C. Ross \"Mutual Information between Discrete and Continuous Data "
"Sets\". PLoS ONE 9(2), 2014."
msgstr ""

#: of sklearn.feature_selection._mutual_info.mutual_info_classif:79
msgid ""
"L. F. Kozachenko, N. N. Leonenko, \"Sample Estimate of the Entropy of a "
"Random Vector:, Probl. Peredachi Inf., 23:2 (1987), 9-16"
msgstr ""

#: of sklearn.feature_selection._mutual_info.mutual_info_classif:84
msgid ""
"[R50b872b699c4-1]_, [R50b872b699c4-2]_, [R50b872b699c4-3]_, "
"[R50b872b699c4-4]_"
msgstr ""

