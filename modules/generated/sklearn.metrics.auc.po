# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2007 - 2020, scikit-learn developers (BSD License)
# This file is distributed under the same license as the scikit-learn
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2021.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: scikit-learn 0.24\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-03-31 12:43-0400\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"

#: ../modules/generated/sklearn.metrics.auc.rst:2
msgid ":mod:`sklearn.metrics`.auc"
msgstr ""

#: of sklearn.metrics._ranking.auc:2
msgid "Compute Area Under the Curve (AUC) using the trapezoidal rule."
msgstr ""

#: of sklearn.metrics._ranking.auc:4
msgid ""
"This is a general function, given points on a curve.  For computing the "
"area under the ROC-curve, see :func:`roc_auc_score`.  For an alternative "
"way to summarize a precision-recall curve, see "
":func:`average_precision_score`."
msgstr ""

#: of sklearn.metrics._ranking.auc
msgid "Parameters"
msgstr ""

#: of sklearn.metrics._ranking.auc:13
msgid "**x**"
msgstr ""

#: of
msgid "ndarray of shape (n,)"
msgstr ""

#: of sklearn.metrics._ranking.auc:12
msgid ""
"x coordinates. These must be either monotonic increasing or monotonic "
"decreasing."
msgstr ""

#: of sklearn.metrics._ranking.auc:16
msgid "**y**"
msgstr ""

#: of
msgid "ndarray of shape, (n,)"
msgstr ""

#: of sklearn.metrics._ranking.auc:16
msgid "y coordinates."
msgstr ""

#: of sklearn.metrics._ranking.auc
msgid "Returns"
msgstr ""

#: of sklearn.metrics._ranking.auc:27
msgid "**auc**"
msgstr ""

#: of
msgid "float"
msgstr ""

#: of sklearn.metrics._ranking.auc:32
msgid ":obj:`roc_auc_score`"
msgstr ""

#: of sklearn.metrics._ranking.auc:33
msgid "Compute the area under the ROC curve."
msgstr ""

#: of sklearn.metrics._ranking.auc:34
msgid ":obj:`average_precision_score`"
msgstr ""

#: of sklearn.metrics._ranking.auc:35
msgid "Compute average precision from prediction scores."
msgstr ""

#: of sklearn.metrics._ranking.auc:36
msgid ":obj:`precision_recall_curve`"
msgstr ""

#: of sklearn.metrics._ranking.auc:37
msgid "Compute precision-recall pairs for different probability thresholds."
msgstr ""

#: of sklearn.metrics._ranking.auc:43
msgid "Examples"
msgstr ""

#: ../modules/generated/sklearn.metrics.auc.examples:4
msgid "Examples using ``sklearn.metrics.auc``"
msgstr ""

#: ../modules/generated/sklearn.metrics.auc.examples:15
#: ../modules/generated/sklearn.metrics.auc.examples:23
msgid ":ref:`sphx_glr_auto_examples_linear_model_plot_poisson_regression_non_normal_loss.py`"
msgstr ""

#: ../modules/generated/sklearn.metrics.auc.examples:34
#: ../modules/generated/sklearn.metrics.auc.examples:42
msgid ":ref:`sphx_glr_auto_examples_linear_model_plot_tweedie_regression_insurance_claims.py`"
msgstr ""

#~ msgid ":ref:`sphx_glr_auto_examples_model_selection_plot_roc_crossval.py`"
#~ msgstr ""

#~ msgid ":ref:`sphx_glr_auto_examples_model_selection_plot_roc.py`"
#~ msgstr ""

#~ msgid ":ref:`sphx_glr_auto_examples_model_selection_plot_precision_recall.py`"
#~ msgstr ""

