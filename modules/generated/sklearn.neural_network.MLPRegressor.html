

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  
  <title>sklearn.neural_network.MLPRegressor &mdash; documentación de scikit-learn - 0.24.2</title>
  
  <link rel="canonical" href="http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html" />

  
  <link rel="shortcut icon" href="../../_static/favicon.ico"/>
  

  <link rel="stylesheet" href="../../_static/css/vendor/bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/gallery.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
<script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
<script src="../../_static/jquery.js"></script> 
</head>
<body>
<nav id="navbar" class="sk-docs-navbar navbar navbar-expand-md navbar-light bg-light py-0">
  <div class="container-fluid sk-docs-container px-0">
      <a class="navbar-brand py-0" href="../../index.html">
        <img
          class="sk-brand-img"
          src="../../_static/scikit-learn-logo-small.png"
          alt="logo"/>
      </a>
    <button
      id="sk-navbar-toggler"
      class="navbar-toggler"
      type="button"
      data-toggle="collapse"
      data-target="#navbarSupportedContent"
      aria-controls="navbarSupportedContent"
      aria-expanded="false"
      aria-label="Toggle navigation"
    >
      <span class="navbar-toggler-icon"></span>
    </button>

    <div class="sk-navbar-collapse collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav mr-auto">
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../install.html">Instalación</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../user_guide.html">Manual de Usuario</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../classes.html">API</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../auto_examples/index.html">Ejemplos</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../getting_started.html">¿Cómo empezar?</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../tutorial/index.html">Tutorial</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../whats_new/v0.24.html">Novedades</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../glossary.html">Glosario</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../developers/index.html">Desarrollo</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../faq.html">FAQ</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../support.html">Soporte</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../related_projects.html">Paquetes relacionados</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../roadmap.html">Hoja de ruta</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../about.html">Sobre nosotros</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="https://github.com/scikit-learn/scikit-learn">GitHub</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="https://scikit-learn.org/dev/versions.html">Otras versiones y descargas</a>
        </li>
        <li class="nav-item dropdown nav-more-item-dropdown">
          <a class="sk-nav-link nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Más</a>
          <div class="dropdown-menu" aria-labelledby="navbarDropdown">
              <a class="sk-nav-dropdown-item dropdown-item" href="../../getting_started.html">¿Cómo empezar?</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../tutorial/index.html">Tutorial</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../whats_new/v0.24.html">Novedades</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../glossary.html">Glosario</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../developers/index.html">Desarrollo</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../faq.html">FAQ</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../support.html">Soporte</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../related_projects.html">Paquetes relacionados</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../roadmap.html">Hoja de ruta</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../about.html">Sobre nosotros</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="https://github.com/scikit-learn/scikit-learn">GitHub</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="https://scikit-learn.org/dev/versions.html">Otras versiones y descargas</a>
          </div>
        </li>
      </ul>
      <div id="searchbox" role="search">
          <div class="searchformwrapper">
          <form class="search" action="../../search.html" method="get">
            <input class="sk-search-text-input" type="text" name="q" aria-labelledby="searchlabel" />
            <input class="sk-search-text-btn" type="submit" value="Ir a" />
          </form>
          </div>
      </div>
    </div>
  </div>
</nav>
<div class="d-flex" id="sk-doc-wrapper">
    <input type="checkbox" name="sk-toggle-checkbox" id="sk-toggle-checkbox">
    <label id="sk-sidemenu-toggle" class="sk-btn-toggle-toc btn sk-btn-primary" for="sk-toggle-checkbox">Alternar menú</label>
    <div id="sk-sidebar-wrapper" class="border-right">
      <div class="sk-sidebar-toc-wrapper">
        <div class="sk-sidebar-toc-logo">
          <a href="../../index.html">
            <img
              class="sk-brand-img"
              src="../../_static/scikit-learn-logo-small.png"
              alt="logo"/>
          </a>
        </div>
        <div class="btn-group w-100 mb-2" role="group" aria-label="rellinks">
            <a href="sklearn.neural_network.MLPClassifier.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="sklearn.neural_network.MLPClassifier">Prev</a><a href="../classes.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="Referencia de la API">Arriba</a>
            <a href="sklearn.pipeline.FeatureUnion.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="sklearn.pipeline.FeatureUnion">Sig.</a>
        </div>
        <div class="alert alert-danger p-1 mb-2" role="alert">
          <p class="text-center mb-0">
          <strong>scikit-learn 0.24.2</strong><br/>
          <a href="http://scikit-learn.org/dev/versions.html">Otras versiones</a>
          </p>
        </div>
        <div class="alert alert-warning p-1 mb-2" role="alert">
          <p class="text-center mb-0">
            Por favor <a class="font-weight-bold" href="../../about.html#citing-scikit-learn"><string>cítanos</string></a> si usas el software.
          </p>
        </div>
            <div class="sk-sidebar-toc">
              <ul>
<li><a class="reference internal" href="#"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.neural_network</span></code>.MLPRegressor</a><ul>
<li><a class="reference internal" href="#examples-using-sklearn-neural-network-mlpregressor">Ejemplos utilizando <code class="docutils literal notranslate"><span class="pre">sklearn.neural_network.MLPRegressor</span></code></a></li>
</ul>
</li>
</ul>

            </div>
      </div>
    </div>
    <div id="sk-page-content-wrapper">
      <div class="sk-page-content container-fluid body px-md-3" role="main">
        
  <section id="sklearn-neural-network-mlpregressor">
<h1><a class="reference internal" href="../classes.html#module-sklearn.neural_network" title="sklearn.neural_network"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.neural_network</span></code></a>.MLPRegressor<a class="headerlink" href="#sklearn-neural-network-mlpregressor" title="Enlazar permanentemente con este título">¶</a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="sklearn.neural_network.MLPRegressor">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">sklearn.neural_network.</span></span><span class="sig-name descname"><span class="pre">MLPRegressor</span></span><a class="headerlink" href="#sklearn.neural_network.MLPRegressor" title="Enlazar permanentemente con esta definición">¶</a></dt>
<dd><p>Regresor Perceptrón multicapa.</p>
<p>Este modelo optimiza la pérdida cuadrada utilizando LBFGS o el descenso de gradiente estocástico.</p>
<div class="versionadded">
<p><span class="versionmodified added">Nuevo en la versión 0.18.</span></p>
</div>
<dl class="field-list">
<dt class="field-odd">Parámetros</dt>
<dd class="field-odd"><dl>
<dt><strong>hidden_layer_sizes</strong><span class="classifier">tupla, length = n_layers - 2, default=(100,)</span></dt><dd><p>El elemento i-ésimo representa el número de neuronas en la i-ésima capa oculta.</p>
</dd>
<dt><strong>activation</strong><span class="classifier">{“identity”, “logistic”, “tanh”, “relu”}, default=”relu”</span></dt><dd><p>Función de activación para la capa oculta.</p>
<ul class="simple">
<li><p>“identity”, activación no-op, útil para implementar el cuello de botella lineal, devuelve f(x) = x</p></li>
<li><p>“logistic”, la función sigmoide logística, devuelve f(x) = 1 / (1 + exp(-x)).</p></li>
<li><p>“tanh”, la función tangente hiperbólica, devuelve f(x) = tanh(x).</p></li>
<li><p>“relu”, la función de unidad lineal rectificada, devuelve f(x) = max(0, x)</p></li>
</ul>
</dd>
<dt><strong>solver</strong><span class="classifier">{“lbfgs”, “sgd”, “adam”}, default=”adam”</span></dt><dd><p>El solucionador para la optimización de la ponderación.</p>
<ul class="simple">
<li><p>“lbfgs” es un optimizador en la familia de los métodos cuasi-Newton.</p></li>
<li><p>“sgd” se refiere al descenso de gradiente estocástico.</p></li>
<li><p>“adam” se refiere a un optimizador basado en el gradiente estocástico propuesto por Kingma, Diederik y Jimmy Ba</p></li>
</ul>
<p>Nota: El solucionador por defecto “adam” funciona bastante bien en conjuntos de datos relativamente grandes (con miles de muestras de entrenamiento o más) en términos de tiempo de entrenamiento y puntuación de validación. Sin embargo, para conjuntos de datos pequeños, “lbfgs” puede converger más rápido y funcionar mejor.</p>
</dd>
<dt><strong>alpha</strong><span class="classifier">float, default=0.0001</span></dt><dd><p>Parámetro de penalización L2 (término de regularización).</p>
</dd>
<dt><strong>batch_size</strong><span class="classifier">int, default=”auto”</span></dt><dd><p>Tamaño de los minilotes para los optimizadores estocásticos. Si el solucionador es “lbfgs”, el clasificador no utilizará minilotes. Cuando se establece en «auto», <code class="docutils literal notranslate"><span class="pre">batch_size=min(200,</span> <span class="pre">n_samples)</span></code></p>
</dd>
<dt><strong>learning_rate</strong><span class="classifier">{“constant”, “invscaling”, “adaptive”}, default=”constant”</span></dt><dd><p>Programación de la tasa de aprendizaje para las actualizaciones de ponderación.</p>
<ul class="simple">
<li><p>“constant” es una tasa de aprendizaje constante dada por “learning_rate_init”.</p></li>
<li><p>“invscaling” disminuye gradualmente la tasa de aprendizaje <code class="docutils literal notranslate"><span class="pre">learning_rate_</span></code> en cada paso de tiempo “t” utilizando un exponente de escala inversa de “power_t”. effective_learning_rate = learning_rate_init / pow(t, power_t)</p></li>
<li><p>“adaptive” mantiene la tasa de aprendizaje constante a “learning_rate_init” mientras la pérdida asociada al entrenamiento siga disminuyendo. Cada vez que dos épocas consecutivas no consiguen disminuir la pérdida asociada al entrenamiento en al menos tol, o no consiguen aumentar la puntuación de validación en al menos tol si “early_stopping” está activado, la tasa de aprendizaje actual se divide por 5.</p></li>
</ul>
<p>Sólo se utiliza cuando solver=”sgd”.</p>
</dd>
<dt><strong>learning_rate_init</strong><span class="classifier">double, default=0.001</span></dt><dd><p>La tasa de aprendizaje inicial utilizada. Controla el tamaño del paso en la actualización de las ponderaciones. Sólo se utiliza cuando solver=”sgd” o “adam”.</p>
</dd>
<dt><strong>power_t</strong><span class="classifier">double, default=0.5</span></dt><dd><p>El exponente de la tasa de aprendizaje de escala inversa. Se utiliza en la actualización de la tasa de aprendizaje efectiva cuando learning_rate se establece en “invscaling”. Sólo se utiliza cuando solver=”sgd”.</p>
</dd>
<dt><strong>max_iter</strong><span class="classifier">int, default=200</span></dt><dd><p>Número máximo de iteraciones. El solucionador itera hasta la convergencia (determinada por “tol”) o este número de iteraciones. Para los solucionadores estocásticos (“sgd”, “adam”), ten en cuenta que esto determina el número de épocas (cuántas veces se utilizará cada punto de datos), no el número de pasos del gradiente.</p>
</dd>
<dt><strong>shuffle</strong><span class="classifier">bool, default=True</span></dt><dd><p>Si se revuelven las muestras en cada iteración. Sólo se utiliza cuando solver=”sgd” o “adam”.</p>
</dd>
<dt><strong>random_state</strong><span class="classifier">entero, instancia de RandomState, default=None</span></dt><dd><p>Determina la generación de números aleatorios para la inicialización de las ponderaciones y el sesgo, la división de entrenamiento-prueba si se utiliza la parada anticipada, y el muestreo por lotes cuando solver=”sgd” o “adam”. Pasa un int para obtener resultados reproducibles a través de múltiples llamadas a la función. Ver <a class="reference internal" href="../../glossary.html#term-random_state"><span class="xref std std-term">Glosario</span></a>.</p>
</dd>
<dt><strong>tol</strong><span class="classifier">float, default=1e-4</span></dt><dd><p>Tolerancia para la optimización. Cuando la pérdida o la puntuación no mejora en al menos <code class="docutils literal notranslate"><span class="pre">tol</span></code> durante <code class="docutils literal notranslate"><span class="pre">n_iter_no_change</span></code> iteraciones consecutivas, a menos que <code class="docutils literal notranslate"><span class="pre">learning_rate</span></code> esté establecido en “adaptive”, se considera que se ha alcanzado la convergencia y se detiene el entrenamiento.</p>
</dd>
<dt><strong>verbose</strong><span class="classifier">bool, default=False</span></dt><dd><p>Si se imprimen mensajes de progreso en stdout.</p>
</dd>
<dt><strong>warm_start</strong><span class="classifier">bool, default=False</span></dt><dd><p>Cuando se establece en True, reutiliza la solución de la llamada previa a fit como inicialización, de lo contrario, sólo borra la solución previa. Ver <a class="reference internal" href="../../glossary.html#term-warm_start"><span class="xref std std-term">el Glosario</span></a>.</p>
</dd>
<dt><strong>momentum</strong><span class="classifier">float, default=0.9</span></dt><dd><p>Momentum para la actualización del descenso de gradiente. Debe estar entre 0 y 1. Sólo se utiliza cuando solver=”sgd”.</p>
</dd>
<dt><strong>nesterovs_momentum</strong><span class="classifier">bool, default=True</span></dt><dd><p>Si se utiliza el momentum de Nesterov. Sólo se utiliza cuando solver=”sgd” y momentum &gt; 0.</p>
</dd>
<dt><strong>early_stopping</strong><span class="classifier">bool, default=False</span></dt><dd><p>Si se utiliza la parada anticipada para terminar el entrenamiento cuando la puntuación de validación no está mejorando. Si se establece como verdadero, se apartará automáticamente el 10% de los datos de entrenamiento como validación y terminará el entrenamiento cuando la puntuación de validación no mejore al menos en <code class="docutils literal notranslate"><span class="pre">tol</span></code> durante <code class="docutils literal notranslate"><span class="pre">n_iter_no_change</span></code> épocas consecutivas. Sólo es efectivo cuando solver=”sgd” o “adam”</p>
</dd>
<dt><strong>validation_fraction</strong><span class="classifier">float, default=0.1</span></dt><dd><p>La proporción de los datos de entrenamiento que se reservan como conjunto de validación para la parada anticipada. Debe estar entre 0 y 1. Sólo se utiliza si early_stopping es True</p>
</dd>
<dt><strong>beta_1</strong><span class="classifier">float, default=0.9</span></dt><dd><p>Tasa de decaimiento exponencial para las estimaciones del vector del primer momento en adam, debe estar en [0, 1). Sólo se utiliza cuando solver=”adam”</p>
</dd>
<dt><strong>beta_2</strong><span class="classifier">float, default=0.999</span></dt><dd><p>Tasa de decaimiento exponencial para las estimaciones del vector del segundo momento en adam, debe estar en [0, 1). Sólo se utiliza cuando solver=”adam”</p>
</dd>
<dt><strong>epsilon</strong><span class="classifier">float, default=1e-8</span></dt><dd><p>Valor para la estabilidad numérica en adam. Sólo se utiliza cuando solver=”adam”</p>
</dd>
<dt><strong>n_iter_no_change</strong><span class="classifier">int, default=10</span></dt><dd><p>Número máximo de épocas para no cumplir con la mejora de <code class="docutils literal notranslate"><span class="pre">tol</span></code>. Sólo efectivo cuando solver=”sgd” o “adam”</p>
<div class="versionadded">
<p><span class="versionmodified added">Nuevo en la versión 0.20.</span></p>
</div>
</dd>
<dt><strong>max_fun</strong><span class="classifier">int, default=15000</span></dt><dd><p>Sólo se utiliza cuando solver=”lbfgs”. Número máximo de llamadas a la función. El solucionador itera hasta la convergencia (determinada por “tol”), hasta que el número de iteraciones alcanza max_iter, o hasta este número de llamadas a la función. Ten en cuenta que el número de llamadas a la función será mayor o igual que el número de iteraciones para el MLPRegressor.</p>
<div class="versionadded">
<p><span class="versionmodified added">Nuevo en la versión 0.22.</span></p>
</div>
</dd>
</dl>
</dd>
<dt class="field-even">Atributos</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>loss_</strong><span class="classifier">float</span></dt><dd><p>La pérdida actual calculada con la función de pérdida.</p>
</dd>
<dt><strong>best_loss_</strong><span class="classifier">float</span></dt><dd><p>La pérdida mínima alcanzada por el solucionador a lo largo del ajuste.</p>
</dd>
<dt><strong>loss_curve_</strong> : list de forma (<code class="docutils literal notranslate"><span class="pre">n_iter_</span></code>,)<span class="classifier">list de forma (</span></dt><dd><p>Loss value evaluated at the end of each training step.
The ith element in the list represents the loss at the ith iteration.</p>
</dd>
<dt><strong>t_</strong><span class="classifier">int</span></dt><dd><p>The number of training samples seen by the solver during fitting.
Mathematically equals <code class="docutils literal notranslate"><span class="pre">n_iters</span> <span class="pre">*</span> <span class="pre">X.shape[0]</span></code>, it means
<code class="docutils literal notranslate"><span class="pre">time_step</span></code> and it is used by optimizer’s learning rate scheduler.</p>
</dd>
<dt><strong>coefs_</strong><span class="classifier">list de forma (n_layers - 1,)</span></dt><dd><p>El elemento i-ésimo en la lista representa la matriz de ponderación correspondiente a la capa i.</p>
</dd>
<dt><strong>intercepts_</strong><span class="classifier">list de forma (n_layers - 1,)</span></dt><dd><p>El i-ésimo elemento en la lista representa el vector de sesgo correspondiente a la capa i + 1.</p>
</dd>
<dt><strong>n_iter_</strong><span class="classifier">int</span></dt><dd><p>The number of iterations the solver has run.</p>
</dd>
<dt><strong>n_layers_</strong><span class="classifier">int</span></dt><dd><p>Número de capas.</p>
</dd>
<dt><strong>n_outputs_</strong><span class="classifier">int</span></dt><dd><p>Número de salidas.</p>
</dd>
<dt><strong>out_activation_</strong><span class="classifier">str</span></dt><dd><p>Nombre de la función de activación de salida.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notas</p>
<p>El MLPRegressor entrena de forma iterativa ya que en cada paso de tiempo se calculan las derivadas parciales de la función de pérdida con respecto a los parámetros del modelo para actualizar los parámetros.</p>
<p>También puede tener un término de regularización añadido a la función de pérdida que reduce los parámetros del modelo para evitar el sobreajuste.</p>
<p>Esta implementación funciona con datos representados como arreglos numpy densos y dispersos de valores de punto flotante.</p>
<p class="rubric">Referencias</p>
<dl class="simple">
<dt>Hinton, Geoffrey E.</dt><dd><p>«Connectionist learning procedures.» Artificial intelligence 40.1
(1989): 185-234.</p>
</dd>
<dt>Glorot, Xavier, y Yoshua Bengio. «Understanding the difficulty of</dt><dd><p>training deep feedforward neural networks.» International Conference
on Artificial Intelligence and Statistics. 2010.</p>
</dd>
<dt>He, Kaiming, et al. «Delving deep into rectifiers: Surpassing human-level</dt><dd><p>performance on imagenet classification.» arXiv preprint
arXiv:1502.01852 (2015).</p>
</dd>
<dt>Kingma, Diederik, y Jimmy Ba. «Adam: A method for stochastic</dt><dd><p>optimization.» arXiv preprint arXiv:1412.6980 (2014).</p>
</dd>
</dl>
<p class="rubric">Ejemplos</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.neural_network</span> <span class="kn">import</span> <span class="n">MLPRegressor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_regression</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_regression</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">200</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span>
<span class="gp">... </span>                                                    <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">regr</span> <span class="o">=</span> <span class="n">MLPRegressor</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">500</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">regr</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">[:</span><span class="mi">2</span><span class="p">])</span>
<span class="go">array([-0.9..., -7.1...])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">regr</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="go">0.4...</span>
</pre></div>
</div>
<p class="rubric">Métodos</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#sklearn.neural_network.MLPRegressor.fit" title="sklearn.neural_network.MLPRegressor.fit"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit</span></code></a></p></td>
<td><p>Ajusta el modelo a la matriz de datos X y objetivo(s) y.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#sklearn.neural_network.MLPRegressor.get_params" title="sklearn.neural_network.MLPRegressor.get_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_params</span></code></a></p></td>
<td><p>Obtiene los parámetros para este estimador.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#sklearn.neural_network.MLPRegressor.predict" title="sklearn.neural_network.MLPRegressor.predict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">predict</span></code></a></p></td>
<td><p>Predice utilizando el modelo de perceptrón multicapa.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#sklearn.neural_network.MLPRegressor.score" title="sklearn.neural_network.MLPRegressor.score"><code class="xref py py-obj docutils literal notranslate"><span class="pre">score</span></code></a></p></td>
<td><p>Devuelve el coeficiente de determinación <span class="math notranslate nohighlight">\(R^2\)</span> de la predicción.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#sklearn.neural_network.MLPRegressor.set_params" title="sklearn.neural_network.MLPRegressor.set_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_params</span></code></a></p></td>
<td><p>Establece los parámetros de este estimador.</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="sklearn.neural_network.MLPRegressor.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.neural_network.MLPRegressor.fit" title="Enlazar permanentemente con esta definición">¶</a></dt>
<dd><p>Ajusta el modelo a la matriz de datos X y objetivo(s) y.</p>
<dl class="field-list simple">
<dt class="field-odd">Parámetros</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">ndarray o matriz dispersa de forma (n_samples, n_features)</span></dt><dd><p>Los datos de entrada.</p>
</dd>
<dt><strong>y</strong><span class="classifier">ndarray de forma (n_samples,) o (n_samples, n_outputs)</span></dt><dd><p>Los valores objetivo (etiquetas de clase en clasificación, números reales en regresión).</p>
</dd>
</dl>
</dd>
<dt class="field-even">Devuelve</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>self</strong><span class="classifier">devuelve un modelo MLP entrenado.</span></dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.neural_network.MLPRegressor.get_params">
<span class="sig-name descname"><span class="pre">get_params</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.neural_network.MLPRegressor.get_params" title="Enlazar permanentemente con esta definición">¶</a></dt>
<dd><p>Obtiene los parámetros para este estimador.</p>
<dl class="field-list simple">
<dt class="field-odd">Parámetros</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>deep</strong><span class="classifier">bool, default=True</span></dt><dd><p>Si es True, devolverá los parámetros para este estimador y los subobjetos contenidos que son estimadores.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Devuelve</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>params</strong><span class="classifier">dict</span></dt><dd><p>Nombres de parámetros mapeados a sus valores.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="sklearn.neural_network.MLPRegressor.partial_fit">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">partial_fit</span></span><a class="headerlink" href="#sklearn.neural_network.MLPRegressor.partial_fit" title="Enlazar permanentemente con esta definición">¶</a></dt>
<dd><p>Actualiza el modelo con una sola iteración sobre los datos dados.</p>
<dl class="field-list simple">
<dt class="field-odd">Parámetros</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">{array-like, sparse matrix} de forma (n_samples, n_features)</span></dt><dd><p>Los datos de entrada.</p>
</dd>
<dt><strong>y</strong><span class="classifier">ndarray de forma (n_samples,)</span></dt><dd><p>Los valores objetivo.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Devuelve</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>self</strong><span class="classifier">devuelve un modelo MLP entrenado.</span></dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.neural_network.MLPRegressor.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.neural_network.MLPRegressor.predict" title="Enlazar permanentemente con esta definición">¶</a></dt>
<dd><p>Predice utilizando el modelo de perceptrón multicapa.</p>
<dl class="field-list simple">
<dt class="field-odd">Parámetros</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">{array-like, sparse matrix} de forma (n_samples, n_features)</span></dt><dd><p>Los datos de entrada.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Devuelve</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>y</strong><span class="classifier">ndarray de forma (n_samples, n_outputs)</span></dt><dd><p>Los valores predichos.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.neural_network.MLPRegressor.score">
<span class="sig-name descname"><span class="pre">score</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.neural_network.MLPRegressor.score" title="Enlazar permanentemente con esta definición">¶</a></dt>
<dd><p>Devuelve el coeficiente de determinación <span class="math notranslate nohighlight">\(R^2\)</span> de la predicción.</p>
<p>El coeficiente <span class="math notranslate nohighlight">\(R^2\)</span> se define como <span class="math notranslate nohighlight">\((1 - \frac{u}{v})\)</span>, donde <span class="math notranslate nohighlight">\(u\)</span> es la suma de cuadrados de los residuos <code class="docutils literal notranslate"><span class="pre">((y_true</span> <span class="pre">-</span> <span class="pre">y_pred)</span> <span class="pre">**</span> <span class="pre">2).sum()</span></code> y <span class="math notranslate nohighlight">\(v\)</span> es la suma total de cuadrados <code class="docutils literal notranslate"><span class="pre">((y_true</span> <span class="pre">-</span> <span class="pre">y_true.mean())</span> <span class="pre">**</span> <span class="pre">2).sum()</span></code>. La mejor puntuación posible es 1.0 y puede ser negativa (porque el modelo puede ser arbitrariamente peor). Un modelo constante que siempre predice el valor esperado de <code class="docutils literal notranslate"><span class="pre">y</span></code>, sin tener en cuenta las características de entrada, obtendría una puntuación <span class="math notranslate nohighlight">\(R^2\)</span> de 0.0.</p>
<dl class="field-list simple">
<dt class="field-odd">Parámetros</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">array-like de forma (n_samples, n_features)</span></dt><dd><p>Muestras de prueba. Para algunos estimadores puede ser una matriz de núcleo precalculada o una lista de objetos genéricos con forma <code class="docutils literal notranslate"><span class="pre">(n_samples,</span> <span class="pre">n_samples_fitted)</span></code>, donde <code class="docutils literal notranslate"><span class="pre">n_samples_fitted</span></code> es el número de muestras utilizadas en el ajuste para el estimador.</p>
</dd>
<dt><strong>y</strong><span class="classifier">array-like de forma (n_samples,) o (n_samples, n_outputs)</span></dt><dd><p>Valores verdaderos para <code class="docutils literal notranslate"><span class="pre">X</span></code>.</p>
</dd>
<dt><strong>sample_weight</strong><span class="classifier">array-like de forma (n_samples,), default=None</span></dt><dd><p>Ponderaciones de muestras.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Devuelve</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>score</strong><span class="classifier">float</span></dt><dd><p><span class="math notranslate nohighlight">\(R^2\)</span> de <code class="docutils literal notranslate"><span class="pre">self.predict(X)</span></code> con respecto a <code class="docutils literal notranslate"><span class="pre">y</span></code>.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notas</p>
<p>La puntuación <span class="math notranslate nohighlight">\(R^2\)</span> utilizada al llamar a <code class="docutils literal notranslate"><span class="pre">score</span></code> en un regresor utiliza <code class="docutils literal notranslate"><span class="pre">multioutput='uniform_average'</span></code> desde la versión 0.23 para mantener la consistencia con el valor predeterminado de <a class="reference internal" href="sklearn.metrics.r2_score.html#sklearn.metrics.r2_score" title="sklearn.metrics.r2_score"><code class="xref py py-func docutils literal notranslate"><span class="pre">r2_score</span></code></a>. Esto influye en el método <code class="docutils literal notranslate"><span class="pre">score</span></code> de todos los regresores de salida múltiple (excepto para <a class="reference internal" href="sklearn.multioutput.MultiOutputRegressor.html#sklearn.multioutput.MultiOutputRegressor" title="sklearn.multioutput.MultiOutputRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">MultiOutputRegressor</span></code></a>).</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.neural_network.MLPRegressor.set_params">
<span class="sig-name descname"><span class="pre">set_params</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.neural_network.MLPRegressor.set_params" title="Enlazar permanentemente con esta definición">¶</a></dt>
<dd><p>Establece los parámetros de este estimador.</p>
<p>El método funciona tanto en estimadores simples como en objetos anidados (como <a class="reference internal" href="sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline" title="sklearn.pipeline.Pipeline"><code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code></a>). Estos últimos tienen parámetros de la forma <code class="docutils literal notranslate"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> para que sea posible actualizar cada componente de un objeto anidado.</p>
<dl class="field-list simple">
<dt class="field-odd">Parámetros</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>**params</strong><span class="classifier">dict</span></dt><dd><p>Parámetros del estimador.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Devuelve</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>self</strong><span class="classifier">instancia del estimador</span></dt><dd><p>Instancia del estimador.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<section id="examples-using-sklearn-neural-network-mlpregressor">
<h2>Ejemplos utilizando <code class="docutils literal notranslate"><span class="pre">sklearn.neural_network.MLPRegressor</span></code><a class="headerlink" href="#examples-using-sklearn-neural-network-mlpregressor" title="Enlazar permanentemente con este título">¶</a></h2>
<div class="sphx-glr-thumbcontainer" tooltip="Partial dependence plots show the dependence between the target function [2]_ and a set of feat..."><figure class="align-default" id="id1">
<img alt="Partial Dependence and Individual Conditional Expectation Plots" src="../../_images/sphx_glr_plot_partial_dependence_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../auto_examples/inspection/plot_partial_dependence.html#sphx-glr-auto-examples-inspection-plot-partial-dependence-py"><span class="std std-ref">Gráficos de Dependencia Parcial y de Expectativa Condicional Individual</span></a></span><a class="headerlink" href="#id1" title="Enlace permanente a esta imagen">¶</a></p>
</figcaption>
</figure>
</div><div class="sphx-glr-thumbcontainer" tooltip="    See also sphx_glr_auto_examples_miscellaneous_plot_roc_curve_visualization_api.py"><figure class="align-default" id="id2">
<img alt="Advanced Plotting With Partial Dependence" src="../../_images/sphx_glr_plot_partial_dependence_visualization_api_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../auto_examples/miscellaneous/plot_partial_dependence_visualization_api.html#sphx-glr-auto-examples-miscellaneous-plot-partial-dependence-visualization-api-py"><span class="std std-ref">Graficación Avanzada Con Dependencia Parcial</span></a></span><a class="headerlink" href="#id2" title="Enlace permanente a esta imagen">¶</a></p>
</figcaption>
</figure>
</div><div class="clearer"></div></section>
</section>


      </div>
    <div class="container">
      <footer class="sk-content-footer">
            &copy; 2007 - 2020, scikit-learn developers (BSD License).
          <a href="../../_sources/modules/generated/sklearn.neural_network.MLPRegressor.rst.txt" rel="nofollow">Mostrar la fuente de esta página</a>
      </footer>
    </div>
  </div>
</div>
<script src="../../_static/js/vendor/bootstrap.min.js"></script>

<script>
    window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
    ga('create', 'UA-22606712-2', 'auto');
    ga('set', 'anonymizeIp', true);
    ga('send', 'pageview');
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>


<script>
$(document).ready(function() {
    /* Add a [>>>] button on the top-right corner of code samples to hide
     * the >>> and ... prompts and the output and thus make the code
     * copyable. */
    var div = $('.highlight-python .highlight,' +
                '.highlight-python3 .highlight,' +
                '.highlight-pycon .highlight,' +
		'.highlight-default .highlight')
    var pre = div.find('pre');

    // get the styles from the current theme
    pre.parent().parent().css('position', 'relative');
    var hide_text = 'Hide prompts and outputs';
    var show_text = 'Show prompts and outputs';

    // create and add the button to all the code blocks that contain >>>
    div.each(function(index) {
        var jthis = $(this);
        if (jthis.find('.gp').length > 0) {
            var button = $('<span class="copybutton">&gt;&gt;&gt;</span>');
            button.attr('title', hide_text);
            button.data('hidden', 'false');
            jthis.prepend(button);
        }
        // tracebacks (.gt) contain bare text elements that need to be
        // wrapped in a span to work with .nextUntil() (see later)
        jthis.find('pre:has(.gt)').contents().filter(function() {
            return ((this.nodeType == 3) && (this.data.trim().length > 0));
        }).wrap('<span>');
    });

    // define the behavior of the button when it's clicked
    $('.copybutton').click(function(e){
        e.preventDefault();
        var button = $(this);
        if (button.data('hidden') === 'false') {
            // hide the code output
            button.parent().find('.go, .gp, .gt').hide();
            button.next('pre').find('.gt').nextUntil('.gp, .go').css('visibility', 'hidden');
            button.css('text-decoration', 'line-through');
            button.attr('title', show_text);
            button.data('hidden', 'true');
        } else {
            // show the code output
            button.parent().find('.go, .gp, .gt').show();
            button.next('pre').find('.gt').nextUntil('.gp, .go').css('visibility', 'visible');
            button.css('text-decoration', 'none');
            button.attr('title', hide_text);
            button.data('hidden', 'false');
        }
    });

	/*** Add permalink buttons next to glossary terms ***/
	$('dl.glossary > dt[id]').append(function() {
		return ('<a class="headerlink" href="#' +
			    this.getAttribute('id') +
			    '" title="Permalink to this term">¶</a>');
	});
  /*** Hide navbar when scrolling down ***/
  // Returns true when headerlink target matches hash in url
  (function() {
    hashTargetOnTop = function() {
        var hash = window.location.hash;
        if ( hash.length < 2 ) { return false; }

        var target = document.getElementById( hash.slice(1) );
        if ( target === null ) { return false; }

        var top = target.getBoundingClientRect().top;
        return (top < 2) && (top > -2);
    };

    // Hide navbar on load if hash target is on top
    var navBar = document.getElementById("navbar");
    var navBarToggler = document.getElementById("sk-navbar-toggler");
    var navBarHeightHidden = "-" + navBar.getBoundingClientRect().height + "px";
    var $window = $(window);

    hideNavBar = function() {
        navBar.style.top = navBarHeightHidden;
    };

    showNavBar = function() {
        navBar.style.top = "0";
    }

    if (hashTargetOnTop()) {
        hideNavBar()
    }

    var prevScrollpos = window.pageYOffset;
    hideOnScroll = function(lastScrollTop) {
        if (($window.width() < 768) && (navBarToggler.getAttribute("aria-expanded") === 'true')) {
            return;
        }
        if (lastScrollTop > 2 && (prevScrollpos <= lastScrollTop) || hashTargetOnTop()){
            hideNavBar()
        } else {
            showNavBar()
        }
        prevScrollpos = lastScrollTop;
    };

    /*** high performance scroll event listener***/
    var raf = window.requestAnimationFrame ||
        window.webkitRequestAnimationFrame ||
        window.mozRequestAnimationFrame ||
        window.msRequestAnimationFrame ||
        window.oRequestAnimationFrame;
    var lastScrollTop = $window.scrollTop();

    if (raf) {
        loop();
    }

    function loop() {
        var scrollTop = $window.scrollTop();
        if (lastScrollTop === scrollTop) {
            raf(loop);
            return;
        } else {
            lastScrollTop = scrollTop;
            hideOnScroll(lastScrollTop);
            raf(loop);
        }
    }
  })();
});

</script>
    
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
    
</body>
</html>