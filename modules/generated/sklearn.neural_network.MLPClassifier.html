

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  
  <title>sklearn.neural_network.MLPClassifier &mdash; documentación de scikit-learn - 0.24.2</title>
  
  <link rel="canonical" href="http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html" />

  
  <link rel="shortcut icon" href="../../_static/favicon.ico"/>
  

  <link rel="stylesheet" href="../../_static/css/vendor/bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/gallery.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
<script id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
<script src="../../_static/jquery.js"></script> 
</head>
<body>
<nav id="navbar" class="sk-docs-navbar navbar navbar-expand-md navbar-light bg-light py-0">
  <div class="container-fluid sk-docs-container px-0">
      <a class="navbar-brand py-0" href="../../index.html">
        <img
          class="sk-brand-img"
          src="../../_static/scikit-learn-logo-small.png"
          alt="logo"/>
      </a>
    <button
      id="sk-navbar-toggler"
      class="navbar-toggler"
      type="button"
      data-toggle="collapse"
      data-target="#navbarSupportedContent"
      aria-controls="navbarSupportedContent"
      aria-expanded="false"
      aria-label="Toggle navigation"
    >
      <span class="navbar-toggler-icon"></span>
    </button>

    <div class="sk-navbar-collapse collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav mr-auto">
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../install.html">Instalación</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../user_guide.html">Manual de Usuario</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../classes.html">API</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../../auto_examples/index.html">Ejemplos</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../getting_started.html">¿Cómo empezar?</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../tutorial/index.html">Tutorial</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../whats_new/v0.24.html">Novedades</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../glossary.html">Glosario</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../developers/index.html">Desarrollo</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../faq.html">FAQ</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../support.html">Soporte</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../related_projects.html">Paquetes relacionados</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../roadmap.html">Hoja de ruta</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../../about.html">Sobre nosotros</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="https://github.com/scikit-learn/scikit-learn">GitHub</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="https://scikit-learn.org/dev/versions.html">Otras versiones y descargas</a>
        </li>
        <li class="nav-item dropdown nav-more-item-dropdown">
          <a class="sk-nav-link nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Más</a>
          <div class="dropdown-menu" aria-labelledby="navbarDropdown">
              <a class="sk-nav-dropdown-item dropdown-item" href="../../getting_started.html">¿Cómo empezar?</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../tutorial/index.html">Tutorial</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../whats_new/v0.24.html">Novedades</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../glossary.html">Glosario</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../developers/index.html">Desarrollo</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../faq.html">FAQ</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../support.html">Soporte</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../related_projects.html">Paquetes relacionados</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../roadmap.html">Hoja de ruta</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../../about.html">Sobre nosotros</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="https://github.com/scikit-learn/scikit-learn">GitHub</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="https://scikit-learn.org/dev/versions.html">Otras versiones y descargas</a>
          </div>
        </li>
      </ul>
      <div id="searchbox" role="search">
          <div class="searchformwrapper">
          <form class="search" action="../../search.html" method="get">
            <input class="sk-search-text-input" type="text" name="q" aria-labelledby="searchlabel" />
            <input class="sk-search-text-btn" type="submit" value="Ir a" />
          </form>
          </div>
      </div>
    </div>
  </div>
</nav>
<div class="d-flex" id="sk-doc-wrapper">
    <input type="checkbox" name="sk-toggle-checkbox" id="sk-toggle-checkbox">
    <label id="sk-sidemenu-toggle" class="sk-btn-toggle-toc btn sk-btn-primary" for="sk-toggle-checkbox">Alternar menú</label>
    <div id="sk-sidebar-wrapper" class="border-right">
      <div class="sk-sidebar-toc-wrapper">
        <div class="sk-sidebar-toc-logo">
          <a href="../../index.html">
            <img
              class="sk-brand-img"
              src="../../_static/scikit-learn-logo-small.png"
              alt="logo"/>
          </a>
        </div>
        <div class="btn-group w-100 mb-2" role="group" aria-label="rellinks">
            <a href="sklearn.neural_network.BernoulliRBM.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="sklearn.neural_network.BernoulliRBM">Prev</a><a href="../classes.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="Referencia de la API">Arriba</a>
            <a href="sklearn.neural_network.MLPRegressor.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="sklearn.neural_network.MLPRegressor">Sig.</a>
        </div>
        <div class="alert alert-danger p-1 mb-2" role="alert">
          <p class="text-center mb-0">
          <strong>scikit-learn 0.24.2</strong><br/>
          <a href="http://scikit-learn.org/dev/versions.html">Otras versiones</a>
          </p>
        </div>
        <div class="alert alert-warning p-1 mb-2" role="alert">
          <p class="text-center mb-0">
            Por favor <a class="font-weight-bold" href="../../about.html#citing-scikit-learn"><string>cítanos</string></a> si usas el software.
          </p>
        </div>
            <div class="sk-sidebar-toc">
              <ul>
<li><a class="reference internal" href="#"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.neural_network</span></code>.MLPClassifier</a><ul>
<li><a class="reference internal" href="#examples-using-sklearn-neural-network-mlpclassifier">Ejemplos utilizando <code class="docutils literal notranslate"><span class="pre">sklearn.neural_network.MLPClassifier</span></code></a></li>
</ul>
</li>
</ul>

            </div>
      </div>
    </div>
    <div id="sk-page-content-wrapper">
      <div class="sk-page-content container-fluid body px-md-3" role="main">
        
  <section id="sklearn-neural-network-mlpclassifier">
<h1><a class="reference internal" href="../classes.html#module-sklearn.neural_network" title="sklearn.neural_network"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.neural_network</span></code></a>.MLPClassifier<a class="headerlink" href="#sklearn-neural-network-mlpclassifier" title="Enlazar permanentemente con este título">¶</a></h1>
<dl class="py class">
<dt class="sig sig-object py" id="sklearn.neural_network.MLPClassifier">
<em class="property"><span class="pre">class</span> </em><span class="sig-prename descclassname"><span class="pre">sklearn.neural_network.</span></span><span class="sig-name descname"><span class="pre">MLPClassifier</span></span><a class="headerlink" href="#sklearn.neural_network.MLPClassifier" title="Enlazar permanentemente con esta definición">¶</a></dt>
<dd><p>Clasificador Perceptrón multicapa.</p>
<p>Este modelo optimiza la función de pérdida logarítmica utilizando LBFGS o el descenso de gradiente estocástico.</p>
<div class="versionadded">
<p><span class="versionmodified added">Nuevo en la versión 0.18.</span></p>
</div>
<dl class="field-list">
<dt class="field-odd">Parámetros</dt>
<dd class="field-odd"><dl>
<dt><strong>hidden_layer_sizes</strong><span class="classifier">tupla, length = n_layers - 2, default=(100,)</span></dt><dd><p>El elemento i-ésimo representa el número de neuronas en la i-ésima capa oculta.</p>
</dd>
<dt><strong>activation</strong><span class="classifier">{“identity”, “logistic”, “tanh”, “relu”}, default=”relu”</span></dt><dd><p>Función de activación para la capa oculta.</p>
<ul class="simple">
<li><p>“identity”, activación no-op, útil para implementar el cuello de botella lineal, devuelve f(x) = x</p></li>
<li><p>“logistic”, la función sigmoide logística, devuelve f(x) = 1 / (1 + exp(-x)).</p></li>
<li><p>“tanh”, la función tangente hiperbólica, devuelve f(x) = tanh(x).</p></li>
<li><p>“relu”, la función de unidad lineal rectificada, devuelve f(x) = max(0, x)</p></li>
</ul>
</dd>
<dt><strong>solver</strong><span class="classifier">{“lbfgs”, “sgd”, “adam”}, default=”adam”</span></dt><dd><p>El solucionador para la optimización de la ponderación.</p>
<ul class="simple">
<li><p>“lbfgs” es un optimizador en la familia de los métodos cuasi-Newton.</p></li>
<li><p>“sgd” se refiere al descenso de gradiente estocástico.</p></li>
<li><p>“adam” se refiere a un optimizador basado en el gradiente estocástico propuesto por Kingma, Diederik y Jimmy Ba</p></li>
</ul>
<p>Nota: El solucionador por defecto “adam” funciona bastante bien en conjuntos de datos relativamente grandes (con miles de muestras de entrenamiento o más) en términos de tiempo de entrenamiento y puntuación de validación. Sin embargo, para conjuntos de datos pequeños, “lbfgs” puede converger más rápido y funcionar mejor.</p>
</dd>
<dt><strong>alpha</strong><span class="classifier">float, default=0.0001</span></dt><dd><p>Parámetro de penalización L2 (término de regularización).</p>
</dd>
<dt><strong>batch_size</strong><span class="classifier">int, default=”auto”</span></dt><dd><p>Tamaño de los minilotes para los optimizadores estocásticos. Si el solucionador es “lbfgs”, el clasificador no utilizará minilotes. Cuando se establece en «auto», <code class="docutils literal notranslate"><span class="pre">batch_size=min(200,</span> <span class="pre">n_samples)</span></code></p>
</dd>
<dt><strong>learning_rate</strong><span class="classifier">{“constant”, “invscaling”, “adaptive”}, default=”constant”</span></dt><dd><p>Programación de la tasa de aprendizaje para las actualizaciones de ponderación.</p>
<ul class="simple">
<li><p>“constant” es una tasa de aprendizaje constante dada por “learning_rate_init”.</p></li>
<li><p>“invscaling” disminuye gradualmente la tasa de aprendizaje <code class="docutils literal notranslate"><span class="pre">learning_rate_</span></code> en cada paso de tiempo “t” utilizando un exponente de escala inversa de “power_t”. effective_learning_rate = learning_rate_init / pow(t, power_t)</p></li>
<li><p>“adaptive” mantiene la tasa de aprendizaje constante a “learning_rate_init” mientras la pérdida asociada al entrenamiento siga disminuyendo. Cada vez que dos épocas consecutivas no consiguen disminuir la pérdida asociada al entrenamiento en al menos tol, o no consiguen aumentar la puntuación de validación en al menos tol si “early_stopping” está activado, la tasa de aprendizaje actual se divide por 5.</p></li>
</ul>
<p>Sólo se utiliza cuando <code class="docutils literal notranslate"><span class="pre">solver='sgd'</span></code>.</p>
</dd>
<dt><strong>learning_rate_init</strong><span class="classifier">double, default=0.001</span></dt><dd><p>La tasa de aprendizaje inicial utilizada. Controla el tamaño del paso en la actualización de las ponderaciones. Sólo se utiliza cuando solver=”sgd” o “adam”.</p>
</dd>
<dt><strong>power_t</strong><span class="classifier">double, default=0.5</span></dt><dd><p>El exponente de la tasa de aprendizaje de escala inversa. Se utiliza en la actualización de la tasa de aprendizaje efectiva cuando learning_rate se establece en “invscaling”. Sólo se utiliza cuando solver=”sgd”.</p>
</dd>
<dt><strong>max_iter</strong><span class="classifier">int, default=200</span></dt><dd><p>Número máximo de iteraciones. El solucionador itera hasta la convergencia (determinada por “tol”) o este número de iteraciones. Para los solucionadores estocásticos (“sgd”, “adam”), ten en cuenta que esto determina el número de épocas (cuántas veces se utilizará cada punto de datos), no el número de pasos del gradiente.</p>
</dd>
<dt><strong>shuffle</strong><span class="classifier">bool, default=True</span></dt><dd><p>Si se revuelven las muestras en cada iteración. Sólo se utiliza cuando solver=”sgd” o “adam”.</p>
</dd>
<dt><strong>random_state</strong><span class="classifier">entero, instancia de RandomState, default=None</span></dt><dd><p>Determina la generación de números aleatorios para la inicialización de las ponderaciones y el sesgo, la división de entrenamiento-prueba si se utiliza la parada anticipada, y el muestreo por lotes cuando solver=”sgd” o “adam”. Pasa un int para obtener resultados reproducibles a través de múltiples llamadas a la función. Ver <a class="reference internal" href="../../glossary.html#term-random_state"><span class="xref std std-term">Glosario</span></a>.</p>
</dd>
<dt><strong>tol</strong><span class="classifier">float, default=1e-4</span></dt><dd><p>Tolerancia para la optimización. Cuando la pérdida o la puntuación no mejora en al menos <code class="docutils literal notranslate"><span class="pre">tol</span></code> durante <code class="docutils literal notranslate"><span class="pre">n_iter_no_change</span></code> iteraciones consecutivas, a menos que <code class="docutils literal notranslate"><span class="pre">learning_rate</span></code> esté establecido en “adaptive”, se considera que se ha alcanzado la convergencia y se detiene el entrenamiento.</p>
</dd>
<dt><strong>verbose</strong><span class="classifier">bool, default=False</span></dt><dd><p>Si se imprimen mensajes de progreso en stdout.</p>
</dd>
<dt><strong>warm_start</strong><span class="classifier">bool, default=False</span></dt><dd><p>Cuando se establece en True, reutiliza la solución de la llamada previa a fit como inicialización, de lo contrario, sólo borra la solución previa. Ver <a class="reference internal" href="../../glossary.html#term-warm_start"><span class="xref std std-term">Glosario</span></a>.</p>
</dd>
<dt><strong>momentum</strong><span class="classifier">float, default=0.9</span></dt><dd><p>Momentum para la actualización del descenso de gradiente. Debe estar entre 0 y 1. Sólo se utiliza cuando solver=”sgd”.</p>
</dd>
<dt><strong>nesterovs_momentum</strong><span class="classifier">bool, default=True</span></dt><dd><p>Si se utiliza el momentum de Nesterov. Sólo se utiliza cuando solver=”sgd” y momentum &gt; 0.</p>
</dd>
<dt><strong>early_stopping</strong><span class="classifier">bool, default=False</span></dt><dd><p>Whether to use early stopping to terminate training when validation
score is not improving. If set to true, it will automatically set
aside 10% of training data as validation and terminate training when
validation score is not improving by at least tol for
<code class="docutils literal notranslate"><span class="pre">n_iter_no_change</span></code> consecutive epochs. The split is stratified,
except in a multilabel setting.
If early stopping is False, then the training stops when the training
loss does not improve by more than tol for n_iter_no_change consecutive
passes over the training set.
Only effective when solver=”sgd” or “adam”</p>
</dd>
<dt><strong>validation_fraction</strong><span class="classifier">float, default=0.1</span></dt><dd><p>La proporción de los datos de entrenamiento que se reservan como conjunto de validación para la parada anticipada. Debe estar entre 0 y 1. Sólo se utiliza si early_stopping es True</p>
</dd>
<dt><strong>beta_1</strong><span class="classifier">float, default=0.9</span></dt><dd><p>Tasa de decaimiento exponencial para las estimaciones del vector del primer momento en adam, debe estar en [0, 1). Sólo se utiliza cuando solver=”adam”</p>
</dd>
<dt><strong>beta_2</strong><span class="classifier">float, default=0.999</span></dt><dd><p>Tasa de decaimiento exponencial para las estimaciones del vector del segundo momento en adam, debe estar en [0, 1). Sólo se utiliza cuando solver=”adam”</p>
</dd>
<dt><strong>epsilon</strong><span class="classifier">float, default=1e-8</span></dt><dd><p>Valor para la estabilidad numérica en adam. Sólo se utiliza cuando solver=”adam”</p>
</dd>
<dt><strong>n_iter_no_change</strong><span class="classifier">int, default=10</span></dt><dd><p>Número máximo de épocas para no cumplir con la mejora de <code class="docutils literal notranslate"><span class="pre">tol</span></code>. Sólo efectivo cuando solver=”sgd” o “adam”</p>
<div class="versionadded">
<p><span class="versionmodified added">Nuevo en la versión 0.20.</span></p>
</div>
</dd>
<dt><strong>max_fun</strong><span class="classifier">int, default=15000</span></dt><dd><p>Sólo se utiliza cuando solver=”lbfgs”. Número máximo de llamadas a la función. El solucionador itera hasta la convergencia (determinada por “tol”), hasta que el número de iteraciones alcanza max_iter, o hasta este número de llamadas a la función. Ten en cuenta que el número de llamadas a la función será mayor o igual que el número de iteraciones para el <code class="docutils literal notranslate"><span class="pre">MLPClassifier</span></code>.</p>
<div class="versionadded">
<p><span class="versionmodified added">Nuevo en la versión 0.22.</span></p>
</div>
</dd>
</dl>
</dd>
<dt class="field-even">Atributos</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>classes_</strong><span class="classifier">ndarray o list de ndarray de forma (n_classes,)</span></dt><dd><p>Etiquetas de clase para cada salida.</p>
</dd>
<dt><strong>loss_</strong><span class="classifier">float</span></dt><dd><p>La pérdida actual calculada con la función de pérdida.</p>
</dd>
<dt><strong>best_loss_</strong><span class="classifier">float</span></dt><dd><p>La pérdida mínima alcanzada por el solucionador a lo largo del ajuste.</p>
</dd>
<dt><strong>loss_curve_</strong> : list de forma (<code class="docutils literal notranslate"><span class="pre">n_iter_</span></code>,)<span class="classifier">list de forma (</span></dt><dd><p>El i-ésimo elemento en la lista representa la pérdida en la i-ésima iteración.</p>
</dd>
<dt><strong>t_</strong><span class="classifier">int</span></dt><dd><p>El número de muestras de entrenamiento consideradas por el solucionador durante el ajuste.</p>
</dd>
<dt><strong>coefs_</strong><span class="classifier">list de forma (n_layers - 1,)</span></dt><dd><p>El elemento i-ésimo en la lista representa la matriz de ponderación correspondiente a la capa i.</p>
</dd>
<dt><strong>intercepts_</strong><span class="classifier">list de forma (n_layers - 1,)</span></dt><dd><p>El i-ésimo elemento en la lista representa el vector de sesgo correspondiente a la capa i + 1.</p>
</dd>
<dt><strong>n_iter_</strong><span class="classifier">int</span></dt><dd><p>The number of iterations the solver has run.</p>
</dd>
<dt><strong>n_layers_</strong><span class="classifier">int</span></dt><dd><p>Número de capas.</p>
</dd>
<dt><strong>n_outputs_</strong><span class="classifier">int</span></dt><dd><p>Número de salidas.</p>
</dd>
<dt><strong>out_activation_</strong><span class="classifier">str</span></dt><dd><p>Nombre de la función de activación de salida.</p>
</dd>
</dl>
</dd>
</dl>
<p class="rubric">Notas</p>
<p>MLPClassifier entrena de forma iterativa ya que en cada paso de tiempo se calculan las derivadas parciales de la función de pérdida con respecto a los parámetros del modelo para actualizar los parámetros.</p>
<p>También puede tener un término de regularización añadido a la función de pérdida que reduce los parámetros del modelo para evitar el sobreajuste.</p>
<p>Esta implementación funciona con datos representados como arreglos numpy densos o arreglos scipy dispersos de valores de punto flotante.</p>
<p class="rubric">Referencias</p>
<dl class="simple">
<dt>Hinton, Geoffrey E.</dt><dd><p>«Connectionist learning procedures.» Artificial intelligence 40.1
(1989): 185-234.</p>
</dd>
<dt>Glorot, Xavier y Yoshua Bengio. «Understanding the difficulty of</dt><dd><p>training deep feedforward neural networks.» International Conference
on Artificial Intelligence and Statistics. 2010.</p>
</dd>
<dt>He, Kaiming, et al. «Delving deep into rectifiers: Surpassing human-level</dt><dd><p>performance on imagenet classification.» arXiv preprint
arXiv:1502.01852 (2015).</p>
</dd>
<dt>Kingma, Diederik y Jimmy Ba. «Adam: A method for stochastic</dt><dd><p>optimization.» arXiv preprint arXiv:1412.6980 (2014).</p>
</dd>
</dl>
<p class="rubric">Ejemplos</p>
<div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.neural_network</span> <span class="kn">import</span> <span class="n">MLPClassifier</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_classification</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_classification</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">,</span>
<span class="gp">... </span>                                                    <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span> <span class="o">=</span> <span class="n">MLPClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">300</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">X_test</span><span class="p">[:</span><span class="mi">1</span><span class="p">])</span>
<span class="go">array([[0.038..., 0.961...]])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">[:</span><span class="mi">5</span><span class="p">,</span> <span class="p">:])</span>
<span class="go">array([1, 0, 1, 0, 1])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="go">0.8...</span>
</pre></div>
</div>
<p class="rubric">Métodos</p>
<table class="longtable docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="#sklearn.neural_network.MLPClassifier.fit" title="sklearn.neural_network.MLPClassifier.fit"><code class="xref py py-obj docutils literal notranslate"><span class="pre">fit</span></code></a></p></td>
<td><p>Ajusta el modelo a la matriz de datos X y objetivo(s) y.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#sklearn.neural_network.MLPClassifier.get_params" title="sklearn.neural_network.MLPClassifier.get_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">get_params</span></code></a></p></td>
<td><p>Obtiene los parámetros para este estimador.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#sklearn.neural_network.MLPClassifier.predict" title="sklearn.neural_network.MLPClassifier.predict"><code class="xref py py-obj docutils literal notranslate"><span class="pre">predict</span></code></a></p></td>
<td><p>Predice utilizando el clasificador perceptrón multicapa</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#sklearn.neural_network.MLPClassifier.predict_log_proba" title="sklearn.neural_network.MLPClassifier.predict_log_proba"><code class="xref py py-obj docutils literal notranslate"><span class="pre">predict_log_proba</span></code></a></p></td>
<td><p>Devuelve el logaritmo de las estimaciones de probabilidad.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#sklearn.neural_network.MLPClassifier.predict_proba" title="sklearn.neural_network.MLPClassifier.predict_proba"><code class="xref py py-obj docutils literal notranslate"><span class="pre">predict_proba</span></code></a></p></td>
<td><p>Estimaciones de probabilidad.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="#sklearn.neural_network.MLPClassifier.score" title="sklearn.neural_network.MLPClassifier.score"><code class="xref py py-obj docutils literal notranslate"><span class="pre">score</span></code></a></p></td>
<td><p>Devuelve la exactitud media en los datos de prueba y las etiquetas dadas.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="#sklearn.neural_network.MLPClassifier.set_params" title="sklearn.neural_network.MLPClassifier.set_params"><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_params</span></code></a></p></td>
<td><p>Establece los parámetros de este estimador.</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="sklearn.neural_network.MLPClassifier.fit">
<span class="sig-name descname"><span class="pre">fit</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.neural_network.MLPClassifier.fit" title="Enlazar permanentemente con esta definición">¶</a></dt>
<dd><p>Ajusta el modelo a la matriz de datos X y objetivo(s) y.</p>
<dl class="field-list simple">
<dt class="field-odd">Parámetros</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">ndarray o matriz dispersa de forma (n_samples, n_features)</span></dt><dd><p>Los datos de entrada.</p>
</dd>
<dt><strong>y</strong><span class="classifier">ndarray de forma (n_samples,) o (n_samples, n_outputs)</span></dt><dd><p>Los valores objetivo (etiquetas de clase en clasificación, números reales en regresión).</p>
</dd>
</dl>
</dd>
<dt class="field-even">Devuelve</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>self</strong><span class="classifier">devuelve un modelo MLP entrenado.</span></dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.neural_network.MLPClassifier.get_params">
<span class="sig-name descname"><span class="pre">get_params</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.neural_network.MLPClassifier.get_params" title="Enlazar permanentemente con esta definición">¶</a></dt>
<dd><p>Obtiene los parámetros para este estimador.</p>
<dl class="field-list simple">
<dt class="field-odd">Parámetros</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>deep</strong><span class="classifier">bool, default=True</span></dt><dd><p>Si es True, devolverá los parámetros para este estimador y los subobjetos contenidos que son estimadores.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Devuelve</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>params</strong><span class="classifier">dict</span></dt><dd><p>Nombres de parámetros mapeados a sus valores.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py property">
<dt class="sig sig-object py" id="sklearn.neural_network.MLPClassifier.partial_fit">
<em class="property"><span class="pre">property</span> </em><span class="sig-name descname"><span class="pre">partial_fit</span></span><a class="headerlink" href="#sklearn.neural_network.MLPClassifier.partial_fit" title="Enlazar permanentemente con esta definición">¶</a></dt>
<dd><p>Actualiza el modelo con una sola iteración sobre los datos dados.</p>
<dl class="field-list simple">
<dt class="field-odd">Parámetros</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">{array-like, sparse matrix} de forma (n_samples, n_features)</span></dt><dd><p>Los datos de entrada.</p>
</dd>
<dt><strong>y</strong><span class="classifier">array-like de forma (n_samples,)</span></dt><dd><p>Los valores objetivo.</p>
</dd>
<dt><strong>classes</strong><span class="classifier">arreglo de forma (n_classes,), default=None</span></dt><dd><p>Clases a través de todas las llamadas a partial_fit. Puede obtenerse mediante <code class="docutils literal notranslate"><span class="pre">np.unique(y_all)</span></code>, donde y_all es el vector objetivo del conjunto de datos completo. Este argumento es necesario para la primera llamada a partial_fit y puede omitirse en las llamadas posteriores. Ten en cuenta que no es necesario que y contenga todas las etiquetas en <code class="docutils literal notranslate"><span class="pre">classes</span></code>.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Devuelve</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>self</strong><span class="classifier">devuelve un modelo MLP entrenado.</span></dt><dd></dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.neural_network.MLPClassifier.predict">
<span class="sig-name descname"><span class="pre">predict</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.neural_network.MLPClassifier.predict" title="Enlazar permanentemente con esta definición">¶</a></dt>
<dd><p>Predice utilizando el clasificador perceptrón multicapa</p>
<dl class="field-list simple">
<dt class="field-odd">Parámetros</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">{array-like, sparse matrix} de forma (n_samples, n_features)</span></dt><dd><p>Los datos de entrada.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Devuelve</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>y</strong><span class="classifier">ndarray, forma (n_samples,) o (n_samples, n_classes)</span></dt><dd><p>Las clases predichas.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.neural_network.MLPClassifier.predict_log_proba">
<span class="sig-name descname"><span class="pre">predict_log_proba</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.neural_network.MLPClassifier.predict_log_proba" title="Enlazar permanentemente con esta definición">¶</a></dt>
<dd><p>Devuelve el logaritmo de las estimaciones de probabilidad.</p>
<dl class="field-list simple">
<dt class="field-odd">Parámetros</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">ndarray de forma (n_samples, n_features)</span></dt><dd><p>Los datos de entrada.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Devuelve</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>log_y_prob</strong><span class="classifier">ndarray de forma (n_samples, n_classes)</span></dt><dd><p>La probabilidad logarítmica predicha de la muestra para cada clase en el modelo, donde las clases se ordenan como están en <code class="docutils literal notranslate"><span class="pre">self.classes_</span></code>. Equivalente a log(predict_proba(X))</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.neural_network.MLPClassifier.predict_proba">
<span class="sig-name descname"><span class="pre">predict_proba</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.neural_network.MLPClassifier.predict_proba" title="Enlazar permanentemente con esta definición">¶</a></dt>
<dd><p>Estimaciones de probabilidad.</p>
<dl class="field-list simple">
<dt class="field-odd">Parámetros</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">{array-like, sparse matrix} de forma (n_samples, n_features)</span></dt><dd><p>Los datos de entrada.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Devuelve</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>y_prob</strong><span class="classifier">ndarray de forma (n_samples, n_classes)</span></dt><dd><p>La probabilidad predicha de la muestra para cada clase en el modelo, donde las clases se ordenan como están en <code class="docutils literal notranslate"><span class="pre">self.classes_</span></code>.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.neural_network.MLPClassifier.score">
<span class="sig-name descname"><span class="pre">score</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.neural_network.MLPClassifier.score" title="Enlazar permanentemente con esta definición">¶</a></dt>
<dd><p>Devuelve la exactitud media en los datos de prueba y las etiquetas dadas.</p>
<p>En la clasificación multietiqueta, se trata de la exactitud del subconjunto, que es una métrica rigurosa, ya que se requiere para cada muestra que cada conjunto de etiquetas sea predicho correctamente.</p>
<dl class="field-list simple">
<dt class="field-odd">Parámetros</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>X</strong><span class="classifier">array-like de forma (n_samples, n_features)</span></dt><dd><p>Muestras de prueba.</p>
</dd>
<dt><strong>y</strong><span class="classifier">array-like de forma (n_samples,) o (n_samples, n_outputs)</span></dt><dd><p>Etiquetas verdaderas para <code class="docutils literal notranslate"><span class="pre">X</span></code>.</p>
</dd>
<dt><strong>sample_weight</strong><span class="classifier">array-like de forma (n_samples,), default=None</span></dt><dd><p>Ponderaciones de muestras.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Devuelve</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>score</strong><span class="classifier">float</span></dt><dd><p>Precisión media de <code class="docutils literal notranslate"><span class="pre">self.predict(X)</span></code> con respecto a <code class="docutils literal notranslate"><span class="pre">y</span></code>.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="sklearn.neural_network.MLPClassifier.set_params">
<span class="sig-name descname"><span class="pre">set_params</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#sklearn.neural_network.MLPClassifier.set_params" title="Enlazar permanentemente con esta definición">¶</a></dt>
<dd><p>Establece los parámetros de este estimador.</p>
<p>El método funciona tanto en estimadores simples como en objetos anidados (como <a class="reference internal" href="sklearn.pipeline.Pipeline.html#sklearn.pipeline.Pipeline" title="sklearn.pipeline.Pipeline"><code class="xref py py-class docutils literal notranslate"><span class="pre">Pipeline</span></code></a>). Estos últimos tienen parámetros de la forma <code class="docutils literal notranslate"><span class="pre">&lt;component&gt;__&lt;parameter&gt;</span></code> para que sea posible actualizar cada componente de un objeto anidado.</p>
<dl class="field-list simple">
<dt class="field-odd">Parámetros</dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>**params</strong><span class="classifier">dict</span></dt><dd><p>Parámetros del estimador.</p>
</dd>
</dl>
</dd>
<dt class="field-even">Devuelve</dt>
<dd class="field-even"><dl class="simple">
<dt><strong>self</strong><span class="classifier">instancia del estimador</span></dt><dd><p>Instancia del estimador.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

</dd></dl>

<section id="examples-using-sklearn-neural-network-mlpclassifier">
<h2>Ejemplos utilizando <code class="docutils literal notranslate"><span class="pre">sklearn.neural_network.MLPClassifier</span></code><a class="headerlink" href="#examples-using-sklearn-neural-network-mlpclassifier" title="Enlazar permanentemente con este título">¶</a></h2>
<div class="sphx-glr-thumbcontainer" tooltip="Sometimes looking at the learned coefficients of a neural network can provide insight into the ..."><figure class="align-default" id="id1">
<img alt="Visualization of MLP weights on MNIST" src="../../_images/sphx_glr_plot_mnist_filters_thumb.png" />
<figcaption>
<p><span class="caption-text"><a class="reference internal" href="../../auto_examples/neural_networks/plot_mnist_filters.html#sphx-glr-auto-examples-neural-networks-plot-mnist-filters-py"><span class="std std-ref">Visualización de las ponderaciones del MLP en MNIST</span></a></span><a class="headerlink" href="#id1" title="Enlace permanente a esta imagen">¶</a></p>
</figcaption>
</figure>
</div><div class="clearer"></div></section>
</section>


      </div>
    <div class="container">
      <footer class="sk-content-footer">
            &copy; 2007 - 2020, scikit-learn developers (BSD License).
          <a href="../../_sources/modules/generated/sklearn.neural_network.MLPClassifier.rst.txt" rel="nofollow">Mostrar la fuente de esta página</a>
      </footer>
    </div>
  </div>
</div>
<script src="../../_static/js/vendor/bootstrap.min.js"></script>

<script>
    window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
    ga('create', 'UA-22606712-2', 'auto');
    ga('set', 'anonymizeIp', true);
    ga('send', 'pageview');
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>


<script>
$(document).ready(function() {
    /* Add a [>>>] button on the top-right corner of code samples to hide
     * the >>> and ... prompts and the output and thus make the code
     * copyable. */
    var div = $('.highlight-python .highlight,' +
                '.highlight-python3 .highlight,' +
                '.highlight-pycon .highlight,' +
		'.highlight-default .highlight')
    var pre = div.find('pre');

    // get the styles from the current theme
    pre.parent().parent().css('position', 'relative');
    var hide_text = 'Hide prompts and outputs';
    var show_text = 'Show prompts and outputs';

    // create and add the button to all the code blocks that contain >>>
    div.each(function(index) {
        var jthis = $(this);
        if (jthis.find('.gp').length > 0) {
            var button = $('<span class="copybutton">&gt;&gt;&gt;</span>');
            button.attr('title', hide_text);
            button.data('hidden', 'false');
            jthis.prepend(button);
        }
        // tracebacks (.gt) contain bare text elements that need to be
        // wrapped in a span to work with .nextUntil() (see later)
        jthis.find('pre:has(.gt)').contents().filter(function() {
            return ((this.nodeType == 3) && (this.data.trim().length > 0));
        }).wrap('<span>');
    });

    // define the behavior of the button when it's clicked
    $('.copybutton').click(function(e){
        e.preventDefault();
        var button = $(this);
        if (button.data('hidden') === 'false') {
            // hide the code output
            button.parent().find('.go, .gp, .gt').hide();
            button.next('pre').find('.gt').nextUntil('.gp, .go').css('visibility', 'hidden');
            button.css('text-decoration', 'line-through');
            button.attr('title', show_text);
            button.data('hidden', 'true');
        } else {
            // show the code output
            button.parent().find('.go, .gp, .gt').show();
            button.next('pre').find('.gt').nextUntil('.gp, .go').css('visibility', 'visible');
            button.css('text-decoration', 'none');
            button.attr('title', hide_text);
            button.data('hidden', 'false');
        }
    });

	/*** Add permalink buttons next to glossary terms ***/
	$('dl.glossary > dt[id]').append(function() {
		return ('<a class="headerlink" href="#' +
			    this.getAttribute('id') +
			    '" title="Permalink to this term">¶</a>');
	});
  /*** Hide navbar when scrolling down ***/
  // Returns true when headerlink target matches hash in url
  (function() {
    hashTargetOnTop = function() {
        var hash = window.location.hash;
        if ( hash.length < 2 ) { return false; }

        var target = document.getElementById( hash.slice(1) );
        if ( target === null ) { return false; }

        var top = target.getBoundingClientRect().top;
        return (top < 2) && (top > -2);
    };

    // Hide navbar on load if hash target is on top
    var navBar = document.getElementById("navbar");
    var navBarToggler = document.getElementById("sk-navbar-toggler");
    var navBarHeightHidden = "-" + navBar.getBoundingClientRect().height + "px";
    var $window = $(window);

    hideNavBar = function() {
        navBar.style.top = navBarHeightHidden;
    };

    showNavBar = function() {
        navBar.style.top = "0";
    }

    if (hashTargetOnTop()) {
        hideNavBar()
    }

    var prevScrollpos = window.pageYOffset;
    hideOnScroll = function(lastScrollTop) {
        if (($window.width() < 768) && (navBarToggler.getAttribute("aria-expanded") === 'true')) {
            return;
        }
        if (lastScrollTop > 2 && (prevScrollpos <= lastScrollTop) || hashTargetOnTop()){
            hideNavBar()
        } else {
            showNavBar()
        }
        prevScrollpos = lastScrollTop;
    };

    /*** high performance scroll event listener***/
    var raf = window.requestAnimationFrame ||
        window.webkitRequestAnimationFrame ||
        window.mozRequestAnimationFrame ||
        window.msRequestAnimationFrame ||
        window.oRequestAnimationFrame;
    var lastScrollTop = $window.scrollTop();

    if (raf) {
        loop();
    }

    function loop() {
        var scrollTop = $window.scrollTop();
        if (lastScrollTop === scrollTop) {
            raf(loop);
            return;
        } else {
            lastScrollTop = scrollTop;
            hideOnScroll(lastScrollTop);
            raf(loop);
        }
    }
  })();
});

</script>
    
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
    
</body>
</html>