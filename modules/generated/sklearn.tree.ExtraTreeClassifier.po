# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2007 - 2020, scikit-learn developers (BSD License)
# This file is distributed under the same license as the scikit-learn
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2021.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: scikit-learn 0.24\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-03-31 11:24-0400\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"

#: ../modules/generated/sklearn.tree.ExtraTreeClassifier.rst:2
msgid ":mod:`sklearn.tree`.ExtraTreeClassifier"
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:2
msgid "An extremely randomized tree classifier."
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:4
msgid ""
"Extra-trees differ from classic decision trees in the way they are built."
" When looking for the best split to separate the samples of a node into "
"two groups, random splits are drawn for each of the `max_features` "
"randomly selected features and the best split among those is chosen. When"
" `max_features` is set 1, this amounts to building a totally random "
"decision tree."
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:11
msgid "Warning: Extra-trees should only be used within ensemble methods."
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:13
msgid "Read more in the :ref:`User Guide <tree>`."
msgstr ""

#: of sklearn.base.BaseEstimator.get_params
#: sklearn.base.BaseEstimator.set_params sklearn.base.ClassifierMixin.score
#: sklearn.tree._classes.BaseDecisionTree.apply
#: sklearn.tree._classes.BaseDecisionTree.cost_complexity_pruning_path
#: sklearn.tree._classes.BaseDecisionTree.decision_path
#: sklearn.tree._classes.BaseDecisionTree.predict
#: sklearn.tree._classes.DecisionTreeClassifier.fit
#: sklearn.tree._classes.DecisionTreeClassifier.predict_log_proba
#: sklearn.tree._classes.DecisionTreeClassifier.predict_proba
#: sklearn.tree._classes.ExtraTreeClassifier
msgid "Parameters"
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:19
msgid "**criterion**"
msgstr ""

#: of
msgid "{\"gini\", \"entropy\"}, default=\"gini\""
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:18
msgid ""
"The function to measure the quality of a split. Supported criteria are "
"\"gini\" for the Gini impurity and \"entropy\" for the information gain."
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:24
msgid "**splitter**"
msgstr ""

#: of
msgid "{\"random\", \"best\"}, default=\"random\""
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:22
msgid ""
"The strategy used to choose the split at each node. Supported strategies "
"are \"best\" to choose the best split and \"random\" to choose the best "
"random split."
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:29
msgid "**max_depth**"
msgstr ""

#: of
msgid "int, default=None"
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:27
msgid ""
"The maximum depth of the tree. If None, then nodes are expanded until all"
" leaves are pure or until all leaves contain less than min_samples_split "
"samples."
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:40
msgid "**min_samples_split**"
msgstr ""

#: of
msgid "int or float, default=2"
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:32
msgid "The minimum number of samples required to split an internal node:"
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:34
msgid "If int, then consider `min_samples_split` as the minimum number."
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:35
msgid ""
"If float, then `min_samples_split` is a fraction and "
"`ceil(min_samples_split * n_samples)` are the minimum number of samples "
"for each split."
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:39
#: sklearn.tree._classes.ExtraTreeClassifier:54
msgid "Added float values for fractions."
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:55
msgid "**min_samples_leaf**"
msgstr ""

#: of
msgid "int or float, default=1"
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:43
msgid ""
"The minimum number of samples required to be at a leaf node. A split "
"point at any depth will only be considered if it leaves at least "
"``min_samples_leaf`` training samples in each of the left and right "
"branches.  This may have the effect of smoothing the model, especially in"
" regression."
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:49
msgid "If int, then consider `min_samples_leaf` as the minimum number."
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:50
msgid ""
"If float, then `min_samples_leaf` is a fraction and "
"`ceil(min_samples_leaf * n_samples)` are the minimum number of samples "
"for each node."
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:60
msgid "**min_weight_fraction_leaf**"
msgstr ""

#: of
msgid "float, default=0.0"
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:58
msgid ""
"The minimum weighted fraction of the sum total of weights (of all the "
"input samples) required to be at a leaf node. Samples have equal weight "
"when sample_weight is not provided."
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:76
msgid "**max_features**"
msgstr ""

#: of
msgid "int, float, {\"auto\", \"sqrt\", \"log2\"} or None, default=\"auto\""
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:63
msgid "The number of features to consider when looking for the best split:"
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:65
msgid "If int, then consider `max_features` features at each split."
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:66
msgid ""
"If float, then `max_features` is a fraction and `int(max_features * "
"n_features)` features are considered at each split."
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:69
msgid "If \"auto\", then `max_features=sqrt(n_features)`."
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:70
msgid "If \"sqrt\", then `max_features=sqrt(n_features)`."
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:71
msgid "If \"log2\", then `max_features=log2(n_features)`."
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:72
msgid "If None, then `max_features=n_features`."
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:74
msgid ""
"Note: the search for a split does not stop until at least one valid "
"partition of the node samples is found, even if it requires to "
"effectively inspect more than ``max_features`` features."
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:80
msgid "**random_state**"
msgstr ""

#: of
msgid "int, RandomState instance or None, default=None"
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:79
msgid ""
"Used to pick randomly the `max_features` used at each split. See "
":term:`Glossary <random_state>` for details."
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:85
msgid "**max_leaf_nodes**"
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:83
msgid ""
"Grow a tree with ``max_leaf_nodes`` in best-first fashion. Best nodes are"
" defined as relative reduction in impurity. If None then unlimited number"
" of leaf nodes."
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:103
msgid "**min_impurity_decrease**"
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:88
msgid ""
"A node will be split if this split induces a decrease of the impurity "
"greater than or equal to this value."
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:91
msgid "The weighted impurity decrease equation is the following::"
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:96
msgid ""
"where ``N`` is the total number of samples, ``N_t`` is the number of "
"samples at the current node, ``N_t_L`` is the number of samples in the "
"left child, and ``N_t_R`` is the number of samples in the right child."
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:100
msgid ""
"``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum, if"
" ``sample_weight`` is passed."
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:114
msgid "**min_impurity_split**"
msgstr ""

#: of
msgid "float, default=None"
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:106
msgid ""
"Threshold for early stopping in tree growth. A node will split if its "
"impurity is above the threshold, otherwise it is a leaf."
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:109
msgid ""
"``min_impurity_split`` has been deprecated in favor of "
"``min_impurity_decrease`` in 0.19. The default value of "
"``min_impurity_split`` has changed from 1e-7 to 0 in 0.23 and it will be "
"removed in 1.0 (renaming of 0.25). Use ``min_impurity_decrease`` instead."
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:135
msgid "**class_weight**"
msgstr ""

#: of
msgid "dict, list of dict or \"balanced\", default=None"
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:117
msgid ""
"Weights associated with classes in the form ``{class_label: weight}``. If"
" None, all classes are supposed to have weight one. For multi-output "
"problems, a list of dicts can be provided in the same order as the "
"columns of y."
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:122
msgid ""
"Note that for multioutput (including multilabel) weights should be "
"defined for each class of every column in its own dict. For example, for "
"four-class multilabel classification weights should be [{0: 1, 1: 1}, {0:"
" 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of [{1:1}, {2:5}, {3:1}, "
"{4:1}]."
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:128
msgid ""
"The \"balanced\" mode uses the values of y to automatically adjust "
"weights inversely proportional to class frequencies in the input data as "
"``n_samples / (n_classes * np.bincount(y))``"
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:132
msgid "For multi-output, the weights of each column of y will be multiplied."
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:134
msgid ""
"Note that these weights will be multiplied with sample_weight (passed "
"through the fit method) if sample_weight is specified."
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:146
msgid "**ccp_alpha**"
msgstr ""

#: of
msgid "non-negative float, default=0.0"
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:138
msgid ""
"Complexity parameter used for Minimal Cost-Complexity Pruning. The "
"subtree with the largest cost complexity that is smaller than "
"``ccp_alpha`` will be chosen. By default, no pruning is performed. See "
":ref:`minimal_cost_complexity_pruning` for details."
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier
msgid "Attributes"
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:152
msgid "**classes_**"
msgstr ""

#: of
msgid "ndarray of shape (n_classes,) or list of ndarray"
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:151
msgid ""
"The classes labels (single output problem), or a list of arrays of class "
"labels (multi-output problem)."
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:155
msgid "**max_features_**"
msgstr ""

#: of
msgid "int"
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:155
msgid "The inferred value of max_features."
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:160
msgid "**n_classes_**"
msgstr ""

#: of
msgid "int or list of int"
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:158
msgid ""
"The number of classes (for single output problems), or a list containing "
"the number of classes for each output (for multi-output problems)."
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:163
msgid ":obj:`feature_importances_ <feature_importances_>`"
msgstr ""

#: of
msgid "ndarray of shape (n_features,)"
msgstr ""

#: of sklearn.tree.ExtraTreeClassifier.feature_importances_:2
#: sklearn.tree._classes.ExtraTreeClassifier:163
msgid "Return the feature importances."
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:166
msgid "**n_features_**"
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:166
msgid "The number of features when ``fit`` is performed."
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:169
msgid "**n_outputs_**"
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:169
msgid "The number of outputs when ``fit`` is performed."
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:178
msgid "**tree_**"
msgstr ""

#: of
msgid "Tree instance"
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:172
msgid ""
"The underlying Tree object. Please refer to "
"``help(sklearn.tree._tree.Tree)`` for attributes of Tree object and "
":ref:`sphx_glr_auto_examples_tree_plot_unveil_tree_structure.py` for "
"basic usage of these attributes."
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:183
msgid ":obj:`ExtraTreeRegressor`"
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:184
msgid "An extremely randomized tree regressor."
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:185
msgid ":obj:`sklearn.ensemble.ExtraTreesClassifier`"
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:186
msgid "An extra-trees classifier."
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:187
msgid ":obj:`sklearn.ensemble.ExtraTreesRegressor`"
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:188
msgid "An extra-trees regressor."
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:192
msgid "Notes"
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:193
msgid ""
"The default values for the parameters controlling the size of the trees "
"(e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and "
"unpruned trees which can potentially be very large on some data sets. To "
"reduce memory consumption, the complexity and size of the trees should be"
" controlled by setting those parameter values."
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:200
msgid "References"
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:201
msgid ""
"P. Geurts, D. Ernst., and L. Wehenkel, \"Extremely randomized trees\", "
"Machine Learning, 63(1), 3-42, 2006."
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:206
msgid "[Rdd99a0224c6e-1]_"
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:209
msgid "Examples"
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:224
msgid "Methods"
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:239:<autosummary>:1
msgid ":obj:`apply <sklearn.tree.ExtraTreeClassifier.apply>`\\"
msgstr ""

#: of sklearn.tree._classes.BaseDecisionTree.apply:2
#: sklearn.tree._classes.ExtraTreeClassifier:239:<autosummary>:1
msgid "Return the index of the leaf that each sample is predicted as."
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:239:<autosummary>:1
msgid ""
":obj:`cost_complexity_pruning_path "
"<sklearn.tree.ExtraTreeClassifier.cost_complexity_pruning_path>`\\"
msgstr ""

#: of sklearn.tree._classes.BaseDecisionTree.cost_complexity_pruning_path:2
#: sklearn.tree._classes.ExtraTreeClassifier:239:<autosummary>:1
msgid "Compute the pruning path during Minimal Cost-Complexity Pruning."
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:239:<autosummary>:1
msgid ":obj:`decision_path <sklearn.tree.ExtraTreeClassifier.decision_path>`\\"
msgstr ""

#: of sklearn.tree._classes.BaseDecisionTree.decision_path:2
#: sklearn.tree._classes.ExtraTreeClassifier:239:<autosummary>:1
msgid "Return the decision path in the tree."
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:239:<autosummary>:1
msgid ":obj:`fit <sklearn.tree.ExtraTreeClassifier.fit>`\\"
msgstr ""

#: of sklearn.tree._classes.DecisionTreeClassifier.fit:2
#: sklearn.tree._classes.ExtraTreeClassifier:239:<autosummary>:1
msgid "Build a decision tree classifier from the training set (X, y)."
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:239:<autosummary>:1
msgid ":obj:`get_depth <sklearn.tree.ExtraTreeClassifier.get_depth>`\\"
msgstr ""

#: of sklearn.tree._classes.BaseDecisionTree.get_depth:2
#: sklearn.tree._classes.ExtraTreeClassifier:239:<autosummary>:1
msgid "Return the depth of the decision tree."
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:239:<autosummary>:1
msgid ":obj:`get_n_leaves <sklearn.tree.ExtraTreeClassifier.get_n_leaves>`\\"
msgstr ""

#: of sklearn.tree._classes.BaseDecisionTree.get_n_leaves:2
#: sklearn.tree._classes.ExtraTreeClassifier:239:<autosummary>:1
msgid "Return the number of leaves of the decision tree."
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:239:<autosummary>:1
msgid ":obj:`get_params <sklearn.tree.ExtraTreeClassifier.get_params>`\\"
msgstr ""

#: of sklearn.base.BaseEstimator.get_params:2
#: sklearn.tree._classes.ExtraTreeClassifier:239:<autosummary>:1
msgid "Get parameters for this estimator."
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:239:<autosummary>:1
msgid ":obj:`predict <sklearn.tree.ExtraTreeClassifier.predict>`\\"
msgstr ""

#: of sklearn.tree._classes.BaseDecisionTree.predict:2
#: sklearn.tree._classes.ExtraTreeClassifier:239:<autosummary>:1
msgid "Predict class or regression value for X."
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:239:<autosummary>:1
msgid ""
":obj:`predict_log_proba "
"<sklearn.tree.ExtraTreeClassifier.predict_log_proba>`\\"
msgstr ""

#: of sklearn.tree._classes.DecisionTreeClassifier.predict_log_proba:2
#: sklearn.tree._classes.ExtraTreeClassifier:239:<autosummary>:1
msgid "Predict class log-probabilities of the input samples X."
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:239:<autosummary>:1
msgid ":obj:`predict_proba <sklearn.tree.ExtraTreeClassifier.predict_proba>`\\"
msgstr ""

#: of sklearn.tree._classes.DecisionTreeClassifier.predict_proba:2
#: sklearn.tree._classes.ExtraTreeClassifier:239:<autosummary>:1
msgid "Predict class probabilities of the input samples X."
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:239:<autosummary>:1
msgid ":obj:`score <sklearn.tree.ExtraTreeClassifier.score>`\\"
msgstr ""

#: of sklearn.base.ClassifierMixin.score:2
#: sklearn.tree._classes.ExtraTreeClassifier:239:<autosummary>:1
msgid "Return the mean accuracy on the given test data and labels."
msgstr ""

#: of sklearn.tree._classes.ExtraTreeClassifier:239:<autosummary>:1
msgid ":obj:`set_params <sklearn.tree.ExtraTreeClassifier.set_params>`\\"
msgstr ""

#: of sklearn.base.BaseEstimator.set_params:2
#: sklearn.tree._classes.ExtraTreeClassifier:239:<autosummary>:1
msgid "Set the parameters of this estimator."
msgstr ""

#: of sklearn.base.ClassifierMixin.score:11
#: sklearn.tree._classes.BaseDecisionTree.apply:11
#: sklearn.tree._classes.BaseDecisionTree.cost_complexity_pruning_path:12
#: sklearn.tree._classes.BaseDecisionTree.decision_path:11
#: sklearn.tree._classes.BaseDecisionTree.predict:13
#: sklearn.tree._classes.DecisionTreeClassifier.fit:10
#: sklearn.tree._classes.DecisionTreeClassifier.predict_log_proba:10
#: sklearn.tree._classes.DecisionTreeClassifier.predict_proba:12
msgid "**X**"
msgstr ""

#: of
msgid "{array-like, sparse matrix} of shape (n_samples, n_features)"
msgstr ""

#: of sklearn.tree._classes.BaseDecisionTree.apply:9
#: sklearn.tree._classes.BaseDecisionTree.decision_path:9
#: sklearn.tree._classes.BaseDecisionTree.predict:11
#: sklearn.tree._classes.DecisionTreeClassifier.predict_log_proba:8
#: sklearn.tree._classes.DecisionTreeClassifier.predict_proba:10
msgid ""
"The input samples. Internally, it will be converted to "
"``dtype=np.float32`` and if a sparse matrix is provided to a sparse "
"``csr_matrix``."
msgstr ""

#: of sklearn.tree._classes.BaseDecisionTree.apply:15
#: sklearn.tree._classes.BaseDecisionTree.decision_path:15
#: sklearn.tree._classes.BaseDecisionTree.predict:17
#: sklearn.tree._classes.DecisionTreeClassifier.fit:24
#: sklearn.tree._classes.DecisionTreeClassifier.predict_proba:16
msgid "**check_input**"
msgstr ""

#: of
msgid "bool, default=True"
msgstr ""

#: of sklearn.tree._classes.BaseDecisionTree.apply:14
#: sklearn.tree._classes.BaseDecisionTree.decision_path:14
#: sklearn.tree._classes.BaseDecisionTree.predict:16
#: sklearn.tree._classes.DecisionTreeClassifier.fit:23
#: sklearn.tree._classes.DecisionTreeClassifier.predict_proba:15
msgid ""
"Allow to bypass several input checking. Don't use this parameter unless "
"you know what you do."
msgstr ""

#: of sklearn.base.BaseEstimator.get_params
#: sklearn.base.BaseEstimator.set_params sklearn.base.ClassifierMixin.score
#: sklearn.tree.ExtraTreeClassifier.feature_importances_
#: sklearn.tree._classes.BaseDecisionTree.apply
#: sklearn.tree._classes.BaseDecisionTree.cost_complexity_pruning_path
#: sklearn.tree._classes.BaseDecisionTree.decision_path
#: sklearn.tree._classes.BaseDecisionTree.get_depth
#: sklearn.tree._classes.BaseDecisionTree.get_n_leaves
#: sklearn.tree._classes.BaseDecisionTree.predict
#: sklearn.tree._classes.DecisionTreeClassifier.fit
#: sklearn.tree._classes.DecisionTreeClassifier.predict_log_proba
#: sklearn.tree._classes.DecisionTreeClassifier.predict_proba
msgid "Returns"
msgstr ""

#: of sklearn.tree._classes.BaseDecisionTree.apply:34
msgid "**X_leaves**"
msgstr ""

#: of
msgid "array-like of shape (n_samples,)"
msgstr ""

#: of sklearn.tree._classes.BaseDecisionTree.apply:20
msgid ""
"For each datapoint x in X, return the index of the leaf x ends up in. "
"Leaves are numbered within ``[0; self.tree_.node_count)``, possibly with "
"gaps in the numbering."
msgstr ""

#: of sklearn.tree._classes.BaseDecisionTree.cost_complexity_pruning_path:4
msgid ""
"See :ref:`minimal_cost_complexity_pruning` for details on the pruning "
"process."
msgstr ""

#: of sklearn.tree._classes.BaseDecisionTree.cost_complexity_pruning_path:10
#: sklearn.tree._classes.DecisionTreeClassifier.fit:8
msgid ""
"The training input samples. Internally, it will be converted to "
"``dtype=np.float32`` and if a sparse matrix is provided to a sparse "
"``csc_matrix``."
msgstr ""

#: of sklearn.base.ClassifierMixin.score:14
#: sklearn.tree._classes.BaseDecisionTree.cost_complexity_pruning_path:15
#: sklearn.tree._classes.BaseDecisionTree.predict:33
#: sklearn.tree._classes.DecisionTreeClassifier.fit:13
msgid "**y**"
msgstr ""

#: of
msgid "array-like of shape (n_samples,) or (n_samples, n_outputs)"
msgstr ""

#: of sklearn.tree._classes.BaseDecisionTree.cost_complexity_pruning_path:15
#: sklearn.tree._classes.DecisionTreeClassifier.fit:13
msgid "The target values (class labels) as integers or strings."
msgstr ""

#: of sklearn.base.ClassifierMixin.score:17
#: sklearn.tree._classes.BaseDecisionTree.cost_complexity_pruning_path:22
#: sklearn.tree._classes.DecisionTreeClassifier.fit:20
msgid "**sample_weight**"
msgstr ""

#: of
msgid "array-like of shape (n_samples,), default=None"
msgstr ""

#: of sklearn.tree._classes.BaseDecisionTree.cost_complexity_pruning_path:18
#: sklearn.tree._classes.DecisionTreeClassifier.fit:16
msgid ""
"Sample weights. If None, then samples are equally weighted. Splits that "
"would create child nodes with net zero or negative weight are ignored "
"while searching for a split in each node. Splits are also ignored if they"
" would result in any single class carrying a negative weight in either "
"child node."
msgstr ""

#: of sklearn.tree._classes.BaseDecisionTree.cost_complexity_pruning_path:45
msgid "**ccp_path** : :class:`~sklearn.utils.Bunch`"
msgstr ""

#: of sklearn.tree._classes.BaseDecisionTree.cost_complexity_pruning_path:44
msgid "Bunch"
msgstr ""

#: of sklearn.tree._classes.BaseDecisionTree.cost_complexity_pruning_path:27
msgid "Dictionary-like object, with the following attributes."
msgstr ""

#: of sklearn.tree._classes.BaseDecisionTree.cost_complexity_pruning_path:30
msgid "ccp_alphas"
msgstr ""

#: of
msgid "ndarray"
msgstr ""

#: of sklearn.tree._classes.BaseDecisionTree.cost_complexity_pruning_path:30
msgid "Effective alphas of subtree during pruning."
msgstr ""

#: of sklearn.tree._classes.BaseDecisionTree.cost_complexity_pruning_path:45
msgid "impurities"
msgstr ""

#: of sklearn.tree._classes.BaseDecisionTree.cost_complexity_pruning_path:33
msgid ""
"Sum of the impurities of the subtree leaves for the corresponding alpha "
"value in ``ccp_alphas``."
msgstr ""

#: of sklearn.tree._classes.BaseDecisionTree.decision_path:32
msgid "**indicator**"
msgstr ""

#: of
msgid "sparse matrix of shape (n_samples, n_nodes)"
msgstr ""

#: of sklearn.tree._classes.BaseDecisionTree.decision_path:20
msgid ""
"Return a node indicator CSR matrix where non zero elements indicates that"
" the samples goes through the nodes."
msgstr ""

#: of sklearn.tree.ExtraTreeClassifier.feature_importances_:4
msgid ""
"The importance of a feature is computed as the (normalized) total "
"reduction of the criterion brought by that feature. It is also known as "
"the Gini importance."
msgstr ""

#: of sklearn.tree.ExtraTreeClassifier.feature_importances_:8
msgid ""
"Warning: impurity-based feature importances can be misleading for high "
"cardinality features (many unique values). See "
":func:`sklearn.inspection.permutation_importance` as an alternative."
msgstr ""

#: of sklearn.tree.ExtraTreeClassifier.feature_importances_:28
msgid "**feature_importances_**"
msgstr ""

#: of sklearn.tree.ExtraTreeClassifier.feature_importances_:16
msgid "Normalized total reduction of criteria by feature (Gini importance)."
msgstr ""

#: of sklearn.tree._classes.DecisionTreeClassifier.fit:30
msgid "**X_idx_sorted**"
msgstr ""

#: of
msgid "deprecated, default=\"deprecated\""
msgstr ""

#: of sklearn.tree._classes.DecisionTreeClassifier.fit:27
msgid ""
"This parameter is deprecated and has no effect. It will be removed in 1.1"
" (renaming of 0.26)."
msgstr ""

#: of sklearn.base.BaseEstimator.set_params:28
#: sklearn.tree._classes.DecisionTreeClassifier.fit:46
msgid "**self**"
msgstr ""

#: of
msgid "DecisionTreeClassifier"
msgstr ""

#: of sklearn.tree._classes.DecisionTreeClassifier.fit:35
msgid "Fitted estimator."
msgstr ""

#: of sklearn.tree._classes.BaseDecisionTree.get_depth:4
msgid "The depth of a tree is the maximum distance between the root and any leaf."
msgstr ""

#: of sklearn.tree._classes.BaseDecisionTree.get_depth:22
msgid "**self.tree_.max_depth**"
msgstr ""

#: of sklearn.tree._classes.BaseDecisionTree.get_depth:11
msgid "The maximum depth of the tree."
msgstr ""

#: of sklearn.tree._classes.BaseDecisionTree.get_n_leaves:20
msgid "**self.tree_.n_leaves**"
msgstr ""

#: of sklearn.tree._classes.BaseDecisionTree.get_n_leaves:9
msgid "Number of leaves."
msgstr ""

#: of sklearn.base.BaseEstimator.get_params:9
msgid "**deep**"
msgstr ""

#: of sklearn.base.BaseEstimator.get_params:8
msgid ""
"If True, will return the parameters for this estimator and contained "
"subobjects that are estimators."
msgstr ""

#: of sklearn.base.BaseEstimator.get_params:25
msgid "**params**"
msgstr ""

#: of
msgid "dict"
msgstr ""

#: of sklearn.base.BaseEstimator.get_params:14
msgid "Parameter names mapped to their values."
msgstr ""

#: of sklearn.tree._classes.BaseDecisionTree.predict:4
msgid ""
"For a classification model, the predicted class for each sample in X is "
"returned. For a regression model, the predicted value based on X is "
"returned."
msgstr ""

#: of sklearn.tree._classes.BaseDecisionTree.predict:22
msgid "The predicted classes, or the predict values."
msgstr ""

#: of sklearn.tree._classes.DecisionTreeClassifier.predict_log_proba:27
#: sklearn.tree._classes.DecisionTreeClassifier.predict_proba:33
msgid "**proba**"
msgstr ""

#: of
msgid ""
"ndarray of shape (n_samples, n_classes) or list of n_outputs             "
"such arrays if n_outputs > 1"
msgstr ""

#: of sklearn.tree._classes.DecisionTreeClassifier.predict_log_proba:15
msgid ""
"The class log-probabilities of the input samples. The order of the "
"classes corresponds to that in the attribute :term:`classes_`."
msgstr ""

#: of sklearn.tree._classes.DecisionTreeClassifier.predict_proba:4
msgid ""
"The predicted class probability is the fraction of samples of the same "
"class in a leaf."
msgstr ""

#: of sklearn.tree._classes.DecisionTreeClassifier.predict_proba:21
msgid ""
"The class probabilities of the input samples. The order of the classes "
"corresponds to that in the attribute :term:`classes_`."
msgstr ""

#: of sklearn.base.ClassifierMixin.score:4
msgid ""
"In multi-label classification, this is the subset accuracy which is a "
"harsh metric since you require for each sample that each label set be "
"correctly predicted."
msgstr ""

#: of
msgid "array-like of shape (n_samples, n_features)"
msgstr ""

#: of sklearn.base.ClassifierMixin.score:11
msgid "Test samples."
msgstr ""

#: of sklearn.base.ClassifierMixin.score:14
msgid "True labels for `X`."
msgstr ""

#: of sklearn.base.ClassifierMixin.score:17
msgid "Sample weights."
msgstr ""

#: of sklearn.base.ClassifierMixin.score:33
msgid "**score**"
msgstr ""

#: of
msgid "float"
msgstr ""

#: of sklearn.base.ClassifierMixin.score:22
msgid "Mean accuracy of ``self.predict(X)`` wrt. `y`."
msgstr ""

#: of sklearn.base.BaseEstimator.set_params:4
msgid ""
"The method works on simple estimators as well as on nested objects (such "
"as :class:`~sklearn.pipeline.Pipeline`). The latter have parameters of "
"the form ``<component>__<parameter>`` so that it's possible to update "
"each component of a nested object."
msgstr ""

#: of sklearn.base.BaseEstimator.set_params:12
msgid "**\\*\\*params**"
msgstr ""

#: of sklearn.base.BaseEstimator.set_params:12
msgid "Estimator parameters."
msgstr ""

#: of
msgid "estimator instance"
msgstr ""

#: of sklearn.base.BaseEstimator.set_params:17
msgid "Estimator instance."
msgstr ""

