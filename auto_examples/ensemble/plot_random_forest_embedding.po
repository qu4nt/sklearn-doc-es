# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2007 - 2020, scikit-learn developers (BSD License)
# This file is distributed under the same license as the scikit-learn
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2021.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: scikit-learn 0.24\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-03-31 11:24-0400\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"

#: ../auto_examples/ensemble/plot_random_forest_embedding.rst:13
msgid ""
"Click :ref:`here "
"<sphx_glr_download_auto_examples_ensemble_plot_random_forest_embedding.py>`"
" to download the full example code or to run this example in your browser"
" via Binder"
msgstr ""

#: ../auto_examples/ensemble/plot_random_forest_embedding.rst:23
msgid "Hashing feature transformation using Totally Random Trees"
msgstr ""

#: ../auto_examples/ensemble/plot_random_forest_embedding.rst:25
msgid ""
"RandomTreesEmbedding provides a way to map data to a very high-"
"dimensional, sparse representation, which might be beneficial for "
"classification. The mapping is completely unsupervised and very "
"efficient."
msgstr ""

#: ../auto_examples/ensemble/plot_random_forest_embedding.rst:30
msgid ""
"This example visualizes the partitions given by several trees and shows "
"how the transformation can also be used for non-linear dimensionality "
"reduction or non-linear classification."
msgstr ""

#: ../auto_examples/ensemble/plot_random_forest_embedding.rst:34
msgid ""
"Points that are neighboring often share the same leaf of a tree and "
"therefore share large parts of their hashed representation. This allows "
"to separate two concentric circles simply based on the principal "
"components of the transformed data with truncated SVD."
msgstr ""

#: ../auto_examples/ensemble/plot_random_forest_embedding.rst:39
msgid ""
"In high-dimensional spaces, linear classifiers often achieve excellent "
"accuracy. For sparse binary data, BernoulliNB is particularly well-"
"suited. The bottom row compares the decision boundary obtained by "
"BernoulliNB in the transformed space with an ExtraTreesClassifier forests"
" learned on the original data."
msgstr ""

#: ../auto_examples/ensemble/plot_random_forest_embedding.rst:57
msgid "Out:"
msgstr ""

#: ../auto_examples/ensemble/plot_random_forest_embedding.rst:158
msgid "**Total running time of the script:** ( 0 minutes  0.794 seconds)"
msgstr ""

#: ../auto_examples/ensemble/plot_random_forest_embedding.rst:180
msgid ""
":download:`Download Python source code: plot_random_forest_embedding.py "
"<plot_random_forest_embedding.py>`"
msgstr ""

#: ../auto_examples/ensemble/plot_random_forest_embedding.rst:186
msgid ""
":download:`Download Jupyter notebook: plot_random_forest_embedding.ipynb "
"<plot_random_forest_embedding.ipynb>`"
msgstr ""

#: ../auto_examples/ensemble/plot_random_forest_embedding.rst:193
msgid "`Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_"
msgstr ""

