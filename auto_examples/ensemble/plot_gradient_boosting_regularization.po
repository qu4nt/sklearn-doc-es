# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2007 - 2020, scikit-learn developers (BSD License)
# This file is distributed under the same license as the scikit-learn
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2021.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: scikit-learn 0.24\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-03-31 11:24-0400\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"

#: ../auto_examples/ensemble/plot_gradient_boosting_regularization.rst:13
msgid ""
"Click :ref:`here "
"<sphx_glr_download_auto_examples_ensemble_plot_gradient_boosting_regularization.py>`"
" to download the full example code or to run this example in your browser"
" via Binder"
msgstr ""

#: ../auto_examples/ensemble/plot_gradient_boosting_regularization.rst:23
msgid "Gradient Boosting regularization"
msgstr ""

#: ../auto_examples/ensemble/plot_gradient_boosting_regularization.rst:25
msgid ""
"Illustration of the effect of different regularization strategies for "
"Gradient Boosting. The example is taken from Hastie et al 2009 [1]_."
msgstr ""

#: ../auto_examples/ensemble/plot_gradient_boosting_regularization.rst:28
msgid ""
"The loss function used is binomial deviance. Regularization via shrinkage"
" (``learning_rate < 1.0``) improves performance considerably. In "
"combination with shrinkage, stochastic gradient boosting (``subsample < "
"1.0``) can produce more accurate models by reducing the variance via "
"bagging. Subsampling without shrinkage usually does poorly. Another "
"strategy to reduce the variance is by subsampling the features analogous "
"to the random splits in Random Forests (via the ``max_features`` "
"parameter)."
msgstr ""

#: ../auto_examples/ensemble/plot_gradient_boosting_regularization.rst:38
msgid ""
"T. Hastie, R. Tibshirani and J. Friedman, \"Elements of Statistical "
"Learning Ed. 2\", Springer, 2009."
msgstr ""

#: ../auto_examples/ensemble/plot_gradient_boosting_regularization.rst:117
msgid "**Total running time of the script:** ( 0 minutes  26.648 seconds)"
msgstr ""

#: ../auto_examples/ensemble/plot_gradient_boosting_regularization.rst:139
msgid ""
":download:`Download Python source code: "
"plot_gradient_boosting_regularization.py "
"<plot_gradient_boosting_regularization.py>`"
msgstr ""

#: ../auto_examples/ensemble/plot_gradient_boosting_regularization.rst:145
msgid ""
":download:`Download Jupyter notebook: "
"plot_gradient_boosting_regularization.ipynb "
"<plot_gradient_boosting_regularization.ipynb>`"
msgstr ""

#: ../auto_examples/ensemble/plot_gradient_boosting_regularization.rst:152
msgid "`Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_"
msgstr ""

