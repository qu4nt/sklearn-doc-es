# SOME DESCRIPTIVE TITLE.
# Copyright (C) 2007 - 2020, scikit-learn developers (BSD License)
# This file is distributed under the same license as the scikit-learn
# package.
# FIRST AUTHOR <EMAIL@ADDRESS>, 2021.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: scikit-learn 0.24\n"
"Report-Msgid-Bugs-To: \n"
"POT-Creation-Date: 2021-03-31 11:24-0400\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Generated-By: Babel 2.9.0\n"

#: ../auto_examples/ensemble/plot_gradient_boosting_early_stopping.rst:13
msgid ""
"Click :ref:`here "
"<sphx_glr_download_auto_examples_ensemble_plot_gradient_boosting_early_stopping.py>`"
" to download the full example code or to run this example in your browser"
" via Binder"
msgstr ""

#: ../auto_examples/ensemble/plot_gradient_boosting_early_stopping.rst:23
msgid "Early stopping of Gradient Boosting"
msgstr ""

#: ../auto_examples/ensemble/plot_gradient_boosting_early_stopping.rst:25
msgid ""
"Gradient boosting is an ensembling technique where several weak learners "
"(regression trees) are combined to yield a powerful single model, in an "
"iterative fashion."
msgstr ""

#: ../auto_examples/ensemble/plot_gradient_boosting_early_stopping.rst:29
msgid ""
"Early stopping support in Gradient Boosting enables us to find the least "
"number of iterations which is sufficient to build a model that "
"generalizes well to unseen data."
msgstr ""

#: ../auto_examples/ensemble/plot_gradient_boosting_early_stopping.rst:33
msgid ""
"The concept of early stopping is simple. We specify a "
"``validation_fraction`` which denotes the fraction of the whole dataset "
"that will be kept aside from training to assess the validation loss of "
"the model. The gradient boosting model is trained using the training set "
"and evaluated using the validation set. When each additional stage of "
"regression tree is added, the validation set is used to score the model."
"  This is continued until the scores of the model in the last "
"``n_iter_no_change`` stages do not improve by atleast `tol`. After that "
"the model is considered to have converged and further addition of stages "
"is \"stopped early\"."
msgstr ""

#: ../auto_examples/ensemble/plot_gradient_boosting_early_stopping.rst:43
msgid ""
"The number of stages of the final model is available at the attribute "
"``n_estimators_``."
msgstr ""

#: ../auto_examples/ensemble/plot_gradient_boosting_early_stopping.rst:46
msgid ""
"This example illustrates how the early stopping can used in the "
":class:`~sklearn.ensemble.GradientBoostingClassifier` model to achieve "
"almost the same accuracy as compared to a model built without early "
"stopping using many fewer estimators. This can significantly reduce "
"training time, memory usage and prediction latency."
msgstr ""

#: ../auto_examples/ensemble/plot_gradient_boosting_early_stopping.rst:127
msgid "Compare scores with and without early stopping"
msgstr ""

#: ../auto_examples/ensemble/plot_gradient_boosting_early_stopping.rst:182
msgid "Compare fit times with and without early stopping"
msgstr ""

#: ../auto_examples/ensemble/plot_gradient_boosting_early_stopping.rst:226
msgid "**Total running time of the script:** ( 1 minutes  2.903 seconds)"
msgstr ""

#: ../auto_examples/ensemble/plot_gradient_boosting_early_stopping.rst:248
msgid ""
":download:`Download Python source code: "
"plot_gradient_boosting_early_stopping.py "
"<plot_gradient_boosting_early_stopping.py>`"
msgstr ""

#: ../auto_examples/ensemble/plot_gradient_boosting_early_stopping.rst:254
msgid ""
":download:`Download Jupyter notebook: "
"plot_gradient_boosting_early_stopping.ipynb "
"<plot_gradient_boosting_early_stopping.ipynb>`"
msgstr ""

#: ../auto_examples/ensemble/plot_gradient_boosting_early_stopping.rst:261
msgid "`Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_"
msgstr ""

