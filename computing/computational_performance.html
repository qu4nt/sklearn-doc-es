

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  
  <title>8.2. Rendimiento computacional &mdash; documentación de scikit-learn - 0.24.2</title>
  
  <link rel="canonical" href="http://scikit-learn.org/stable/computing/computational_performance.html" />

  
  <link rel="shortcut icon" href="../_static/favicon.ico"/>
  

  <link rel="stylesheet" href="../_static/css/vendor/bootstrap.min.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/gallery.css" type="text/css" />
  <link rel="stylesheet" href="../_static/gallery-binder.css" type="text/css" />
  <link rel="stylesheet" href="../_static/gallery-dataframe.css" type="text/css" />
  <link rel="stylesheet" href="../_static/gallery-rendered-html.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
<script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
<script src="../_static/jquery.js"></script> 
</head>
<body>
<nav id="navbar" class="sk-docs-navbar navbar navbar-expand-md navbar-light bg-light py-0">
  <div class="container-fluid sk-docs-container px-0">
      <a class="navbar-brand py-0" href="../index.html">
        <img
          class="sk-brand-img"
          src="../_static/scikit-learn-logo-small.png"
          alt="logo"/>
      </a>
    <button
      id="sk-navbar-toggler"
      class="navbar-toggler"
      type="button"
      data-toggle="collapse"
      data-target="#navbarSupportedContent"
      aria-controls="navbarSupportedContent"
      aria-expanded="false"
      aria-label="Toggle navigation"
    >
      <span class="navbar-toggler-icon"></span>
    </button>

    <div class="sk-navbar-collapse collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav mr-auto">
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../install.html">Instalación</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../user_guide.html">Manual de Usuario</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../modules/classes.html">API</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link" href="../auto_examples/index.html">Ejemplos</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../getting_started.html">¿Cómo empezar?</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../tutorial/index.html">Tutorial</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../whats_new/v0.24.html">Novedades</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../glossary.html">Glosario</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../developers/index.html">Desarrollo</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../faq.html">FAQ</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../support.html">Soporte</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../related_projects.html">Paquetes relacionados</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../roadmap.html">Hoja de ruta</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="../about.html">Sobre nosotros</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="https://github.com/scikit-learn/scikit-learn">GitHub</a>
        </li>
        <li class="nav-item">
          <a class="sk-nav-link nav-link nav-more-item-mobile-items" href="https://scikit-learn.org/dev/versions.html">Otras versiones y descargas</a>
        </li>
        <li class="nav-item dropdown nav-more-item-dropdown">
          <a class="sk-nav-link nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Más</a>
          <div class="dropdown-menu" aria-labelledby="navbarDropdown">
              <a class="sk-nav-dropdown-item dropdown-item" href="../getting_started.html">¿Cómo empezar?</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../tutorial/index.html">Tutorial</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../whats_new/v0.24.html">Novedades</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../glossary.html">Glosario</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../developers/index.html">Desarrollo</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../faq.html">FAQ</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../support.html">Soporte</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../related_projects.html">Paquetes relacionados</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../roadmap.html">Hoja de ruta</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="../about.html">Sobre nosotros</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="https://github.com/scikit-learn/scikit-learn">GitHub</a>
              <a class="sk-nav-dropdown-item dropdown-item" href="https://scikit-learn.org/dev/versions.html">Otras versiones y descargas</a>
          </div>
        </li>
      </ul>
      <div id="searchbox" role="search">
          <div class="searchformwrapper">
          <form class="search" action="../search.html" method="get">
            <input class="sk-search-text-input" type="text" name="q" aria-labelledby="searchlabel" />
            <input class="sk-search-text-btn" type="submit" value="Ir a" />
          </form>
          </div>
      </div>
    </div>
  </div>
</nav>
<div class="d-flex" id="sk-doc-wrapper">
    <input type="checkbox" name="sk-toggle-checkbox" id="sk-toggle-checkbox">
    <label id="sk-sidemenu-toggle" class="sk-btn-toggle-toc btn sk-btn-primary" for="sk-toggle-checkbox">Alternar menú</label>
    <div id="sk-sidebar-wrapper" class="border-right">
      <div class="sk-sidebar-toc-wrapper">
        <div class="sk-sidebar-toc-logo">
          <a href="../index.html">
            <img
              class="sk-brand-img"
              src="../_static/scikit-learn-logo-small.png"
              alt="logo"/>
          </a>
        </div>
        <div class="btn-group w-100 mb-2" role="group" aria-label="rellinks">
            <a href="scaling_strategies.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="8.1. Estrategias para escalar computacionalmente: datos más grandes">Prev</a><a href="../computing.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="8. Calculando con scikit-learn">Arriba</a>
            <a href="parallelism.html" role="button" class="btn sk-btn-rellink py-1" sk-rellink-tooltip="8.3. Paralelismo, gestión de recursos y configuración">Sig.</a>
        </div>
        <div class="alert alert-danger p-1 mb-2" role="alert">
          <p class="text-center mb-0">
          <strong>scikit-learn 0.24.2</strong><br/>
          <a href="http://scikit-learn.org/dev/versions.html">Otras versiones</a>
          </p>
        </div>
        <div class="alert alert-warning p-1 mb-2" role="alert">
          <p class="text-center mb-0">
            Por favor <a class="font-weight-bold" href="../about.html#citing-scikit-learn"><string>cítanos</string></a> si usas el software.
          </p>
        </div>
            <div class="sk-sidebar-toc">
            
              <ul>
              
              
              
              
              
              
              
              
              <li>
                <a href="../user_guide.html" class="sk-toc-active">Manual de Usuario</a>
              </li>
              <ul>
              
                <li>
                  <a href="../supervised_learning.html" class="">1. Aprendizaje supervisado</a>
                  
                </li>
              
                <li>
                  <a href="../unsupervised_learning.html" class="">2. Aprendizaje no supervisado</a>
                  
                </li>
              
                <li>
                  <a href="../model_selection.html" class="">3. Selección y evaluación del modelo</a>
                  
                </li>
              
                <li>
                  <a href="../inspection.html" class="">4. Inspección</a>
                  
                </li>
              
                <li>
                  <a href="../visualizations.html" class="">5. Visualizaciones</a>
                  
                </li>
              
                <li>
                  <a href="../data_transforms.html" class="">6. Transformaciones de conjuntos de datos</a>
                  
                </li>
              
                <li>
                  <a href="../datasets.html" class="">7. Herramientas de carga de conjuntos de datos</a>
                  
                </li>
              
                <li>
                  <a href="../computing.html" class="sk-toc-active">8. Calculando con scikit-learn</a>
                  
                  <ul>
                    
                      <li class="sk-toctree-l3">
                        <a href="scaling_strategies.html">8.1. Estrategias para escalar computacionalmente: datos más grandes</a>
                      </li>
                    
                      <li class="sk-toctree-l3">
                        <a href="">8.2. Rendimiento computacional</a>
                      </li>
                    
                      <li class="sk-toctree-l3">
                        <a href="parallelism.html">8.3. Paralelismo, gestión de recursos y configuración</a>
                      </li>
                    
                  </ul>
                  
                </li>
              
                <li>
                  <a href="../modules/model_persistence.html" class="">9. Persistencia del modelo</a>
                  
                </li>
              
                <li>
                  <a href="../common_pitfalls.html" class="">10. Fallas comunes y prácticas recomendadas</a>
                  
                </li>
              
              </ul>
              
              
              
              
              
              
              
              
              
              
              </ul>
            </div>
      </div>
    </div>
    <div id="sk-page-content-wrapper">
      <div class="sk-page-content container-fluid body px-md-3" role="main">
        
  <section id="computational-performance">
<span id="id1"></span><h1><span class="section-number">8.2. </span>Rendimiento computacional<a class="headerlink" href="#computational-performance" title="Enlazar permanentemente con este título">¶</a></h1>
<p>Para algunas aplicaciones, el rendimiento (principalmente la latencia y el rendimiento en el momento de la predicción) de los estimadores es crucial. También puede ser interesante tener en cuenta el rendimiento del entrenamiento, pero esto suele ser menos importante en una configuración de producción (donde a menudo tiene lugar fuera de línea).</p>
<p>Revisaremos aquí los órdenes de magnitud que se pueden esperar de una serie de estimadores de scikit-learn en diferentes contextos y proporcionaremos algunos consejos y trucos para superar los cuellos de botella de rendimiento.</p>
<p>La latencia de predicción se mide como el tiempo necesario para realizar una predicción (por ejemplo, en microsegundos). La latencia suele verse como una distribución y los ingenieros de operaciones suelen centrarse en la latencia en un percentil determinado de esta distribución (por ejemplo, el percentil 90).</p>
<p>El rendimiento de las predicciones se define como el número de predicciones que el software puede realizar en un tiempo determinado (por ejemplo, en predicciones por segundo).</p>
<p>Un aspecto importante de la optimización del rendimiento es también que puede perjudicar la precisión de las predicciones. En efecto, los modelos más sencillos (por ejemplo, lineales en lugar de no lineales, o con menos parámetros) suelen funcionar más rápido, pero no siempre son capaces de tener en cuenta las mismas propiedades exactas de los datos que los más complejos.</p>
<section id="prediction-latency">
<h2><span class="section-number">8.2.1. </span>Latencia de predicción<a class="headerlink" href="#prediction-latency" title="Enlazar permanentemente con este título">¶</a></h2>
<p>Una de las preocupaciones más directas que uno puede tener al utilizar/elegir un conjunto de herramientas de aprendizaje automático es la latencia con la que se pueden hacer predicciones en un entorno de producción.</p>
<dl class="simple">
<dt>Los principales factores que influyen en la latencia de la predicción son</dt><dd><ol class="arabic simple">
<li><p>Número de características</p></li>
<li><p>Representación de los datos de entrada y dispersión</p></li>
<li><p>Complejidad del modelo</p></li>
<li><p>Extracción de características</p></li>
</ol>
</dd>
</dl>
<p>Un último parámetro importante es también la posibilidad de hacer predicciones en modo masivo o uno a uno.</p>
<section id="bulk-versus-atomic-mode">
<h3><span class="section-number">8.2.1.1. </span>Modo Bulk versus Atómico<a class="headerlink" href="#bulk-versus-atomic-mode" title="Enlazar permanentemente con este título">¶</a></h3>
<p>En general, hacer predicciones a granel (muchas instancias al mismo tiempo) es más eficiente por una serie de razones (previsibilidad de bifurcación, caché de la CPU, optimizaciones de las bibliotecas de álgebra lineal, etc.). Aquí vemos, en un entorno con pocas características, que, independientemente de la elección del estimador, el modo masivo es siempre más rápido, y para algunos de ellos en 1 o 2 órdenes de magnitud:</p>
<p class="centered">
<strong><a class="reference external" href="../auto_examples/applications/plot_prediction_latency.html"><img alt="atomic_prediction_latency" src="../_images/sphx_glr_plot_prediction_latency_001.png" style="width: 800.0px; height: 480.0px;" /></a></strong></p><p class="centered">
<strong><a class="reference external" href="../auto_examples/applications/plot_prediction_latency.html"><img alt="bulk_prediction_latency" src="../_images/sphx_glr_plot_prediction_latency_002.png" style="width: 800.0px; height: 480.0px;" /></a></strong></p><p>Para comparar diferentes estimadores en su caso, sólo tiene que cambiar el parámetro <code class="docutils literal notranslate"><span class="pre">n_features</span></code> en este ejemplo: <a class="reference internal" href="../auto_examples/applications/plot_prediction_latency.html#sphx-glr-auto-examples-applications-plot-prediction-latency-py"><span class="std std-ref">Latencia de predicción</span></a>. Esto debería darle una estimación del orden de magnitud de la latencia de predicción.</p>
</section>
<section id="configuring-scikit-learn-for-reduced-validation-overhead">
<h3><span class="section-number">8.2.1.2. </span>Configuración de Scikit-learn para reducir la carga de validación<a class="headerlink" href="#configuring-scikit-learn-for-reduced-validation-overhead" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Scikit-learn realiza algunas validaciones sobre los datos que aumentan la sobrecarga por llamada a <code class="docutils literal notranslate"><span class="pre">predict</span></code> y funciones similares. En particular, la comprobación de que las características son finitas (no NaN o infinitas) implica una pasada completa por los datos. Si se asegura de que sus datos son aceptables, puede suprimir la comprobación de finitud estableciendo la variable de entorno <code class="docutils literal notranslate"><span class="pre">SKLEARN_ASSUME_FINITE</span></code> a una cadena no vacía antes de importar scikit-learn, o configurarlo en Python con <a class="reference internal" href="../modules/generated/sklearn.set_config.html#sklearn.set_config" title="sklearn.set_config"><code class="xref py py-func docutils literal notranslate"><span class="pre">set_config</span></code></a>. Para un mayor control que estas configuraciones globales, un <a class="reference internal" href="../modules/generated/sklearn.config_context.html#sklearn.config_context" title="sklearn.config_context"><code class="xref py py-func docutils literal notranslate"><span class="pre">config_context</span></code></a> te permite establecer esta configuración dentro de un contexto especificado:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">sklearn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">config_context</span><span class="p">(</span><span class="n">assume_finite</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">pass</span>  <span class="c1"># do learning/prediction here with reduced validation</span>
</pre></div>
</div>
<p>Nota que esto afectará a todos los usos de <a class="reference internal" href="../modules/generated/sklearn.utils.assert_all_finite.html#sklearn.utils.assert_all_finite" title="sklearn.utils.assert_all_finite"><code class="xref py py-func docutils literal notranslate"><span class="pre">assert_all_finite</span></code></a> dentro del contexto.</p>
</section>
<section id="influence-of-the-number-of-features">
<h3><span class="section-number">8.2.1.3. </span>Influencia del número de características<a class="headerlink" href="#influence-of-the-number-of-features" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Obviamente, cuando el número de características aumenta, también lo hace el consumo de memoria de cada ejemplo. De hecho, para una matriz de <span class="math notranslate nohighlight">\(M\)</span> instancias con <span class="math notranslate nohighlight">\(N\)</span> características, la complejidad espacial está en <span class="math notranslate nohighlight">\(O(NM)\)</span>. Desde el punto de vista informático, esto significa también que el número de operaciones básicas (por ejemplo, las multiplicaciones para los productos vector-matriz en los modelos lineales) también aumenta. He aquí un gráfico de la evolución de la latencia de la predicción con el número de características:</p>
<p class="centered">
<strong><a class="reference external" href="../auto_examples/applications/plot_prediction_latency.html"><img alt="influence_of_n_features_on_latency" src="../_images/sphx_glr_plot_prediction_latency_003.png" style="width: 800.0px; height: 480.0px;" /></a></strong></p><p>En general, se puede esperar que el tiempo de predicción aumente al menos linealmente con el número de características (pueden darse casos no lineales dependiendo de la huella de memoria global y del estimador).</p>
</section>
<section id="influence-of-the-input-data-representation">
<h3><span class="section-number">8.2.1.4. </span>Influencia de la representación de los datos de entrada<a class="headerlink" href="#influence-of-the-input-data-representation" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Scipy proporciona estructuras de datos de matrices dispersas que están optimizadas para almacenar datos dispersos. La principal característica de los formatos dispersos es que no se almacenan ceros, por lo que si los datos son dispersos, se utiliza mucha menos memoria. Un valor distinto de cero en una representación dispersa (<a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/sparse.html">CSR o CSC</a>) sólo ocupará, por término medio, una posición entera de 32 bits + el valor de 64 bits en coma flotante + otros 32 bits por fila o columna de la matriz. El uso de una entrada dispersa en un modelo lineal denso (o disperso) puede acelerar la predicción en gran medida, ya que sólo las características de valor no nulo afectan al producto de puntos y, por tanto, a las predicciones del modelo. Por lo tanto, si tiene 100 valores no nulos en un espacio de 1e6 dimensiones, sólo necesitará 100 operaciones de multiplicación y suma en lugar de 1e6.</p>
<p>El cálculo sobre una representación densa, sin embargo, puede aprovechar las operaciones vectoriales altamente optimizadas y el multithreading en BLAS, y tiende a dar lugar a menos pérdidas de caché de la CPU. Por lo tanto, la dispersión debería ser bastante alta (10% de no ceros como máximo, a comprobar dependiendo del hardware) para que la representación de entrada dispersa sea más rápida que la representación de entrada densa en una máquina con muchas CPUs y una implementación de BLAS optimizada.</p>
<p>Aquí hay un código de ejemplo para probar la escasez de su entrada:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">sparsity_ratio</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
    <span class="k">return</span> <span class="mf">1.0</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">count_nonzero</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;input sparsity ratio:&quot;</span><span class="p">,</span> <span class="n">sparsity_ratio</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
</pre></div>
</div>
<p>Como regla general, puedes considerar que si la tasa de dispersión es superior al 90%, probablemente puedas beneficiarte de los formatos dispersos. Consulta la <a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/sparse.html">documentación sobre formatos de matrices dispersas de Scipy</a> para obtener más información sobre cómo construir (o convertir tus datos a) formatos de matrices dispersas. La mayoría de las veces los formatos <code class="docutils literal notranslate"><span class="pre">CSR</span></code> y <code class="docutils literal notranslate"><span class="pre">CSC</span></code> funcionan mejor.</p>
</section>
<section id="influence-of-the-model-complexity">
<h3><span class="section-number">8.2.1.5. </span>Influencia de la complejidad del modelo<a class="headerlink" href="#influence-of-the-model-complexity" title="Enlazar permanentemente con este título">¶</a></h3>
<p>En general, cuando la complejidad del modelo aumenta, se supone que la potencia de predicción y la latencia aumentan. Aumentar la capacidad de predicción suele ser interesante, pero para muchas aplicaciones es mejor no aumentar demasiado la latencia de la predicción. A continuación revisaremos esta idea para diferentes familias de modelos supervisados.</p>
<p>Para <a class="reference internal" href="../modules/classes.html#module-sklearn.linear_model" title="sklearn.linear_model"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.linear_model</span></code></a> (por ejemplo, Lasso, ElasticNet, SGDClassifier/Regressor, Ridge &amp; RidgeClassifier, PassiveAggressiveClassifier/Regressor, LinearSVC, LogisticRegression…) la función de decisión que se aplica en el momento de la predicción es la misma (un producto punto) , por lo que la latencia debería ser equivalente.</p>
<p>Aquí hay un ejemplo usando <a class="reference internal" href="../modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier" title="sklearn.linear_model.SGDClassifier"><code class="xref py py-class docutils literal notranslate"><span class="pre">SGDClassifier</span></code></a> con la penalización <code class="docutils literal notranslate"><span class="pre">elasticnet</span></code>. La fuerza de la regularización es controlada globalmente por el parámetro <code class="docutils literal notranslate"><span class="pre">alpha</span></code>. Con un parámetro «alfa» suficientemente alto, se puede aumentar el parámetro «l1_ratio» de «elasticnet» para imponer varios niveles de dispersión en los coeficientes del modelo. Una mayor dispersión se interpreta como una menor complejidad del modelo, ya que necesitamos menos coeficientes para describirlo completamente. Por supuesto, la dispersión influye a su vez en el tiempo de predicción, ya que el producto-punto disperso requiere un tiempo aproximadamente proporcional al número de coeficientes distintos de cero.</p>
<p class="centered">
<strong><a class="reference external" href="../auto_examples/applications/plot_model_complexity_influence.html"><img alt="en_model_complexity" src="../_images/sphx_glr_plot_model_complexity_influence_001.png" style="width: 512.0px; height: 384.0px;" /></a></strong></p><p>Para la familia de algoritmos <a class="reference internal" href="../modules/classes.html#module-sklearn.svm" title="sklearn.svm"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.svm</span></code></a> con un núcleo no lineal, la latencia está ligada al número de vectores de soporte (cuanto menos, más rápido). La latencia y el rendimiento deberían crecer (asintóticamente) de forma lineal con el número de vectores de soporte en un modelo SVC o SVR. El núcleo también influye en la latencia, ya que se utiliza para calcular la proyección del vector de entrada una vez por vector de soporte. En el siguiente gráfico se utilizó el parámetro <code class="docutils literal notranslate"><span class="pre">nu</span></code> de <a class="reference internal" href="../modules/generated/sklearn.svm.NuSVR.html#sklearn.svm.NuSVR" title="sklearn.svm.NuSVR"><code class="xref py py-class docutils literal notranslate"><span class="pre">NuSVR</span></code></a> para influir en el número de vectores de soporte.</p>
<p class="centered">
<strong><a class="reference external" href="../auto_examples/applications/plot_model_complexity_influence.html"><img alt="nusvr_model_complexity" src="../_images/sphx_glr_plot_model_complexity_influence_002.png" style="width: 512.0px; height: 384.0px;" /></a></strong></p><p>En el caso de <a class="reference internal" href="../modules/classes.html#module-sklearn.ensemble" title="sklearn.ensemble"><code class="xref py py-mod docutils literal notranslate"><span class="pre">sklearn.ensemble</span></code></a> de árboles (por ejemplo, RandomForest, GBT, ExtraTrees, etc.), el número de árboles y su profundidad desempeñan el papel más importante. La latencia y el rendimiento deberían escalar linealmente con el número de árboles. En este caso utilizamos directamente el parámetro <code class="docutils literal notranslate"><span class="pre">n_estimators</span></code> de <a class="reference internal" href="../modules/generated/sklearn.ensemble.GradientBoostingRegressor.html#sklearn.ensemble.GradientBoostingRegressor" title="sklearn.ensemble.GradientBoostingRegressor"><code class="xref py py-class docutils literal notranslate"><span class="pre">GradientBoostingRegressor</span></code></a>.</p>
<p class="centered">
<strong><a class="reference external" href="../auto_examples/applications/plot_model_complexity_influence.html"><img alt="gbt_model_complexity" src="../_images/sphx_glr_plot_model_complexity_influence_003.png" style="width: 512.0px; height: 384.0px;" /></a></strong></p><p>En cualquier caso, hay que tener en cuenta que la disminución de la complejidad del modelo puede perjudicar la precisión, como se ha mencionado anteriormente. Por ejemplo, un problema separable de forma no lineal puede tratarse con un modelo lineal rápido, pero es muy probable que la capacidad de predicción se vea afectada en el proceso.</p>
</section>
<section id="feature-extraction-latency">
<h3><span class="section-number">8.2.1.6. </span>Latencia de la extracción de características<a class="headerlink" href="#feature-extraction-latency" title="Enlazar permanentemente con este título">¶</a></h3>
<p>La mayoría de los modelos de scikit-learn suelen ser bastante rápidos, ya que se implementan con extensiones compiladas de Cython o bibliotecas de computación optimizadas. Por otro lado, en muchas aplicaciones del mundo real, el proceso de extracción de características (es decir, la conversión de los datos en bruto, como las filas de la base de datos o los paquetes de red, en arreglos de numpy) rige el tiempo de predicción general. Por ejemplo, en la tarea de clasificación de textos de Reuters, toda la preparación (lectura y análisis sintáctico de los archivos SGML, tokenización del texto y hash en un espacio vectorial común) lleva de 100 a 500 veces más tiempo que el código de predicción real, dependiendo del modelo elegido.</p>
<blockquote>
<div></div></blockquote>
<p class="centered">
<strong><a class="reference external" href="../auto_examples/applications/plot_out_of_core_classification.html"><img alt="prediction_time" src="../_images/sphx_glr_plot_out_of_core_classification_004.png" style="width: 512.0px; height: 384.0px;" /></a></strong></p><p>Por lo tanto, en muchos casos se recomienda cronometrar y perfilar cuidadosamente su código de extracción de características, ya que puede ser un buen lugar para comenzar a optimizar cuando su latencia general es demasiado lenta para su aplicación.</p>
</section>
</section>
<section id="prediction-throughput">
<h2><span class="section-number">8.2.2. </span>Rendimiento de predicción<a class="headerlink" href="#prediction-throughput" title="Enlazar permanentemente con este título">¶</a></h2>
<p>Otra métrica importante que hay que tener en cuenta a la hora de dimensionar los sistemas de producción es el rendimiento, es decir, el número de predicciones que se pueden hacer en un tiempo determinado. A continuación se muestra una referencia del ejemplo <a class="reference internal" href="../auto_examples/applications/plot_prediction_latency.html#sphx-glr-auto-examples-applications-plot-prediction-latency-py"><span class="std std-ref">Latencia de predicción</span></a> que mide esta cantidad para una serie de estimadores sobre datos sintéticos:</p>
<p class="centered">
<strong><a class="reference external" href="../auto_examples/applications/plot_prediction_latency.html"><img alt="throughput_benchmark" src="../_images/sphx_glr_plot_prediction_latency_004.png" style="width: 800.0px; height: 480.0px;" /></a></strong></p><p>Estos rendimientos se consiguen en un solo proceso. Una forma obvia de aumentar el rendimiento de tu aplicación es generar instancias adicionales (normalmente procesos en Python debido al <a class="reference external" href="https://wiki.python.org/moin/GlobalInterpreterLock">GIL</a>) que compartan el mismo modelo. También se pueden añadir máquinas para repartir la carga. Sin embargo, una explicación detallada sobre cómo lograr esto está más allá del alcance de esta documentación.</p>
</section>
<section id="tips-and-tricks">
<h2><span class="section-number">8.2.3. </span>Consejos y trucos<a class="headerlink" href="#tips-and-tricks" title="Enlazar permanentemente con este título">¶</a></h2>
<section id="linear-algebra-libraries">
<h3><span class="section-number">8.2.3.1. </span>Bibliotecas de álgebra lineal<a class="headerlink" href="#linear-algebra-libraries" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Como scikit-learn depende en gran medida de Numpy/Scipy y del álgebra lineal en general, tiene sentido cuidar explícitamente las versiones de estas bibliotecas. Básicamente, debe asegurarse de que Numpy se construye utilizando una biblioteca optimizada <a class="reference external" href="https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms">BLAS</a> / <a class="reference external" href="https://en.wikipedia.org/wiki/LAPACK">LAPACK</a>.</p>
<p>No todos los modelos se benefician de las implementaciones optimizadas de BLAS y Lapack. Por ejemplo, los modelos basados en árboles de decisión (aleatorios) no suelen depender de las llamadas a BLAS en sus bucles internos, ni tampoco los SVM de núcleo (<code class="docutils literal notranslate"><span class="pre">SVC</span></code>, <code class="docutils literal notranslate"><span class="pre">SVR</span></code>, <code class="docutils literal notranslate"><span class="pre">NuSVC</span></code>, <code class="docutils literal notranslate"><span class="pre">NuSVR</span></code>).  Por otro lado, un modelo lineal implementado con una llamada BLAS DGEMM (a través de <code class="docutils literal notranslate"><span class="pre">numpy.dot</span></code>) se beneficiará enormemente de una implementación BLAS ajustada y conducirá a órdenes de magnitud de velocidad sobre un BLAS no optimizado.</p>
<p>Puede mostrar la implementación de BLAS / LAPACK utilizada por su instalación de NumPy / SciPy / scikit-learn con los siguientes comandos:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">numpy.distutils.system_info</span> <span class="kn">import</span> <span class="n">get_info</span>
<span class="nb">print</span><span class="p">(</span><span class="n">get_info</span><span class="p">(</span><span class="s1">&#39;blas_opt&#39;</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">get_info</span><span class="p">(</span><span class="s1">&#39;lapack_opt&#39;</span><span class="p">))</span>
</pre></div>
</div>
<dl class="simple">
<dt>Las implementaciones optimizadas de BLAS / LAPACK incluyen:</dt><dd><ul class="simple">
<li><p>Atlas (necesita un ajuste específico del hardware mediante la reconstrucción en la máquina de destino)</p></li>
<li><p>OpenBLAS</p></li>
<li><p>MKL</p></li>
<li><p>Marcos Apple Accelerate y vecLib (sólo para OSX)</p></li>
</ul>
</dd>
</dl>
<p>Se puede encontrar más información en la página de instalación de <a class="reference external" href="https://docs.scipy.org/doc/numpy/user/install.html">Scipy</a> y en este <a class="reference external" href="http://danielnouri.org/notes/2012/12/19/libblas-and-liblapack-issues-and-speed,-with-scipy-and-ubuntu/">blog post</a> de Daniel Nouri que tiene algunas buenas instrucciones de instalación paso a paso para Debian / Ubuntu.</p>
</section>
<section id="limiting-working-memory">
<span id="working-memory"></span><h3><span class="section-number">8.2.3.2. </span>Limitación de la memoria de trabajo<a class="headerlink" href="#limiting-working-memory" title="Enlazar permanentemente con este título">¶</a></h3>
<p>Algunos cálculos cuando se implementan utilizando operaciones vectoriales estándar de numpy implican el uso de una gran cantidad de memoria temporal.  Esto puede potencialmente agotar la memoria del sistema.  Cuando los cálculos pueden realizarse en trozos de memoria fija, intentamos hacerlo, y permitimos al usuario indicar el tamaño máximo de esta memoria de trabajo (por defecto 1GB) usando <a class="reference internal" href="../modules/generated/sklearn.set_config.html#sklearn.set_config" title="sklearn.set_config"><code class="xref py py-func docutils literal notranslate"><span class="pre">set_config</span></code></a> o <a class="reference internal" href="../modules/generated/sklearn.config_context.html#sklearn.config_context" title="sklearn.config_context"><code class="xref py py-func docutils literal notranslate"><span class="pre">config_context</span></code></a>.  Lo siguiente sugiere limitar la memoria de trabajo temporal a 128 MiB:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">sklearn</span>
<span class="gp">&gt;&gt;&gt; </span><span class="k">with</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">config_context</span><span class="p">(</span><span class="n">working_memory</span><span class="o">=</span><span class="mi">128</span><span class="p">):</span>
<span class="gp">... </span>    <span class="k">pass</span>  <span class="c1"># do chunked work here</span>
</pre></div>
</div>
<p>Un ejemplo de operación fragmentada que se adhiere a esta configuración es <a class="reference internal" href="../modules/generated/sklearn.metrics.pairwise_distances_chunked.html#sklearn.metrics.pairwise_distances_chunked" title="sklearn.metrics.pairwise_distances_chunked"><code class="xref py py-func docutils literal notranslate"><span class="pre">pairwise_distances_chunked</span></code></a>, que facilita el cálculo de las reducciones por filas de una matriz de distancia por pares.</p>
</section>
<section id="model-compression">
<h3><span class="section-number">8.2.3.3. </span>Modelo de compresión<a class="headerlink" href="#model-compression" title="Enlazar permanentemente con este título">¶</a></h3>
<p>La compresión de modelos en scikit-learn sólo se refiere a los modelos lineales por el momento. En este contexto, significa que queremos controlar la dispersión del modelo (es decir, el número de coordenadas no nulas en los vectores del modelo). Por lo general, es una buena idea combinar la dispersión del modelo con la representación de datos de entrada dispersos.</p>
<p>Este es un ejemplo de código que ilustra el uso del método <code class="docutils literal notranslate"><span class="pre">sparsify()</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">clf</span> <span class="o">=</span> <span class="n">SGDRegressor</span><span class="p">(</span><span class="n">penalty</span><span class="o">=</span><span class="s1">&#39;elasticnet&#39;</span><span class="p">,</span> <span class="n">l1_ratio</span><span class="o">=</span><span class="mf">0.25</span><span class="p">)</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">sparsify</span><span class="p">()</span>
<span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>
</div>
<p>En este ejemplo preferimos la penalización <code class="docutils literal notranslate"><span class="pre">elasticnet</span></code> ya que suele ser un buen compromiso entre la compacidad del modelo y la potencia de predicción. También se puede ajustar el parámetro <code class="docutils literal notranslate"><span class="pre">l1_ratio</span></code> (en combinación con la fuerza de regularización <code class="docutils literal notranslate"><span class="pre">alpha</span></code>) para controlar este compromiso.</p>
<p>Un típico <a class="reference external" href="https://github.com/scikit-learn/scikit-learn/blob/main/benchmarks/bench_sparsify.py">benchmark</a> sobre datos sintéticos arroja una disminución de la latencia superior al 30% cuando tanto el modelo como la entrada son dispersos (con una proporción de coeficientes no nulos de 0.000024 y 0.027400 respectivamente). El kilometraje puede variar en función de la dispersión y el tamaño de los datos y el modelo. Además, la sparsificación puede ser muy útil para reducir el uso de memoria de los modelos predictivos desplegados en los servidores de producción.</p>
</section>
<section id="model-reshaping">
<h3><span class="section-number">8.2.3.4. </span>Reestructuración de modelos<a class="headerlink" href="#model-reshaping" title="Enlazar permanentemente con este título">¶</a></h3>
<p>La reestructuración del modelo consiste en seleccionar sólo una parte de las características disponibles para ajustarse a un modelo. En otras palabras, si un modelo descarta características durante la fase de aprendizaje, podemos eliminarlas de la entrada. Esto tiene varias ventajas. En primer lugar, reduce la sobrecarga de memoria (y, por tanto, de tiempo) del propio modelo. También permite descartar componentes de selección de características explícitas en una cadena de producción una vez que sabemos qué características conservar de una ejecución anterior. Por último, puede ayudar a reducir el tiempo de procesamiento y el uso de E/S en las capas de acceso a los datos y de extracción de características al no recoger y construir características que son descartadas por el modelo. Por ejemplo, si los datos brutos proceden de una base de datos, puede permitir escribir consultas más sencillas y rápidas o reducir el uso de E/S haciendo que las consultas devuelvan registros más ligeros. Por el momento, la remodelación debe realizarse manualmente en scikit-learn. En el caso de entradas dispersas (particularmente en formato <code class="docutils literal notranslate"><span class="pre">CSR</span></code>), generalmente es suficiente con no generar las características relevantes, dejando sus columnas vacías.</p>
</section>
<section id="links">
<h3><span class="section-number">8.2.3.5. </span>Enlaces<a class="headerlink" href="#links" title="Enlazar permanentemente con este título">¶</a></h3>
<blockquote>
<div><ul class="simple">
<li><p><a class="reference internal" href="../developers/performance.html#performance-howto"><span class="std std-ref">documentación sobre el rendimiento de los desarrolladores de scikit-learn</span></a></p></li>
<li><p><a class="reference external" href="https://docs.scipy.org/doc/scipy/reference/sparse.html">Scipy sparse matrix formats documentation</a></p></li>
</ul>
</div></blockquote>
</section>
</section>
</section>


      </div>
    <div class="container">
      <footer class="sk-content-footer">
            &copy; 2007 - 2020, scikit-learn developers (BSD License).
          <a href="../_sources/computing/computational_performance.rst.txt" rel="nofollow">Mostrar la fuente de esta página</a>
      </footer>
    </div>
  </div>
</div>
<script src="../_static/js/vendor/bootstrap.min.js"></script>

<script>
    window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
    ga('create', 'UA-22606712-2', 'auto');
    ga('set', 'anonymizeIp', true);
    ga('send', 'pageview');
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>


<script>
$(document).ready(function() {
    /* Add a [>>>] button on the top-right corner of code samples to hide
     * the >>> and ... prompts and the output and thus make the code
     * copyable. */
    var div = $('.highlight-python .highlight,' +
                '.highlight-python3 .highlight,' +
                '.highlight-pycon .highlight,' +
		'.highlight-default .highlight')
    var pre = div.find('pre');

    // get the styles from the current theme
    pre.parent().parent().css('position', 'relative');
    var hide_text = 'Hide prompts and outputs';
    var show_text = 'Show prompts and outputs';

    // create and add the button to all the code blocks that contain >>>
    div.each(function(index) {
        var jthis = $(this);
        if (jthis.find('.gp').length > 0) {
            var button = $('<span class="copybutton">&gt;&gt;&gt;</span>');
            button.attr('title', hide_text);
            button.data('hidden', 'false');
            jthis.prepend(button);
        }
        // tracebacks (.gt) contain bare text elements that need to be
        // wrapped in a span to work with .nextUntil() (see later)
        jthis.find('pre:has(.gt)').contents().filter(function() {
            return ((this.nodeType == 3) && (this.data.trim().length > 0));
        }).wrap('<span>');
    });

    // define the behavior of the button when it's clicked
    $('.copybutton').click(function(e){
        e.preventDefault();
        var button = $(this);
        if (button.data('hidden') === 'false') {
            // hide the code output
            button.parent().find('.go, .gp, .gt').hide();
            button.next('pre').find('.gt').nextUntil('.gp, .go').css('visibility', 'hidden');
            button.css('text-decoration', 'line-through');
            button.attr('title', show_text);
            button.data('hidden', 'true');
        } else {
            // show the code output
            button.parent().find('.go, .gp, .gt').show();
            button.next('pre').find('.gt').nextUntil('.gp, .go').css('visibility', 'visible');
            button.css('text-decoration', 'none');
            button.attr('title', hide_text);
            button.data('hidden', 'false');
        }
    });

	/*** Add permalink buttons next to glossary terms ***/
	$('dl.glossary > dt[id]').append(function() {
		return ('<a class="headerlink" href="#' +
			    this.getAttribute('id') +
			    '" title="Permalink to this term">¶</a>');
	});
  /*** Hide navbar when scrolling down ***/
  // Returns true when headerlink target matches hash in url
  (function() {
    hashTargetOnTop = function() {
        var hash = window.location.hash;
        if ( hash.length < 2 ) { return false; }

        var target = document.getElementById( hash.slice(1) );
        if ( target === null ) { return false; }

        var top = target.getBoundingClientRect().top;
        return (top < 2) && (top > -2);
    };

    // Hide navbar on load if hash target is on top
    var navBar = document.getElementById("navbar");
    var navBarToggler = document.getElementById("sk-navbar-toggler");
    var navBarHeightHidden = "-" + navBar.getBoundingClientRect().height + "px";
    var $window = $(window);

    hideNavBar = function() {
        navBar.style.top = navBarHeightHidden;
    };

    showNavBar = function() {
        navBar.style.top = "0";
    }

    if (hashTargetOnTop()) {
        hideNavBar()
    }

    var prevScrollpos = window.pageYOffset;
    hideOnScroll = function(lastScrollTop) {
        if (($window.width() < 768) && (navBarToggler.getAttribute("aria-expanded") === 'true')) {
            return;
        }
        if (lastScrollTop > 2 && (prevScrollpos <= lastScrollTop) || hashTargetOnTop()){
            hideNavBar()
        } else {
            showNavBar()
        }
        prevScrollpos = lastScrollTop;
    };

    /*** high performance scroll event listener***/
    var raf = window.requestAnimationFrame ||
        window.webkitRequestAnimationFrame ||
        window.mozRequestAnimationFrame ||
        window.msRequestAnimationFrame ||
        window.oRequestAnimationFrame;
    var lastScrollTop = $window.scrollTop();

    if (raf) {
        loop();
    }

    function loop() {
        var scrollTop = $window.scrollTop();
        if (lastScrollTop === scrollTop) {
            raf(loop);
            return;
        } else {
            lastScrollTop = scrollTop;
            hideOnScroll(lastScrollTop);
            raf(loop);
        }
    }
  })();
});

</script>
    
<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script>
    
</body>
</html>